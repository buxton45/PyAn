{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./check_DOVS_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import adjustText\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "from Utilities_df import DFConstructType\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65d6fd",
   "metadata": {},
   "source": [
    "# Analyze collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074daca",
   "metadata": {},
   "source": [
    "## AMI NonVee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_0 = '2023-09-24'\n",
    "date_1 = '2023-09-30'\n",
    "#-------------------------\n",
    "save_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check'\n",
    "save_subdir = f\"{date_0.replace('-','')}_{date_1.replace('-','')}\"\n",
    "#-----\n",
    "base_dir     = os.path.join(save_dir_base, save_subdir)\n",
    "base_dir_ami = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\AMINonVee')\n",
    "base_dir_ede = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\EndEvents')\n",
    "save_dir     = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\Results')\n",
    "#-----\n",
    "assert(os.path.exists(base_dir_ami))\n",
    "assert(os.path.exists(base_dir_ede))\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl')):\n",
    "    with open(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl'), 'rb') as handle:\n",
    "        outg_rec_nb_to_files_dict = pickle.load(handle)\n",
    "else:\n",
    "    #-------------------------\n",
    "    paths = Utilities.find_all_paths(\n",
    "        base_dir=base_dir_ami, \n",
    "        glob_pattern=r'ami_nonvee_[0-9]*.csv', \n",
    "        regex_pattern=None\n",
    "    )\n",
    "    paths=natsorted(paths)\n",
    "    #-------------------------\n",
    "    outg_rec_nbs_in_files = dict()\n",
    "    for path in paths:\n",
    "        assert(path not in outg_rec_nbs_in_files.keys())\n",
    "        df = GenAn.read_df_from_csv(path)\n",
    "        outg_rec_nbs_in_files[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "    outg_rec_nb_to_files_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(outg_rec_nb_to_files_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#-------------------------\n",
    "all_outg_rec_nbs = list(outg_rec_nb_to_files_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57008118",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl')):\n",
    "    with open(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl'), 'rb') as handle:\n",
    "        outg_rec_nb_to_files_ede_dict = pickle.load(handle)\n",
    "else:\n",
    "    #-------------------------\n",
    "    paths_ede = Utilities.find_all_paths(\n",
    "        base_dir=base_dir_ede, \n",
    "        glob_pattern=r'end_events_[0-9]*.csv', \n",
    "        regex_pattern=None\n",
    "    )\n",
    "    paths_ede=natsorted(paths_ede)\n",
    "    #-------------------------\n",
    "    outg_rec_nbs_in_files_ede = dict()\n",
    "    for path in paths_ede:\n",
    "        assert(path not in outg_rec_nbs_in_files_ede.keys())\n",
    "        df = GenAn.read_df_from_csv(path)\n",
    "        outg_rec_nbs_in_files_ede[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "    outg_rec_nb_to_files_ede_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files_ede)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(outg_rec_nb_to_files_ede_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#-------------------------\n",
    "all_outg_rec_nbs_ede = list(outg_rec_nb_to_files_ede_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb08355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "instvabc_slcr = DFSlicer(\n",
    "    single_slicers = [\n",
    "        dict(\n",
    "            column='aep_derived_uom', \n",
    "            value='VOLT', \n",
    "            comparison_operator='=='\n",
    "        ), \n",
    "        dict(\n",
    "            column='aep_srvc_qlty_idntfr', \n",
    "            value=['INSTVA1', 'INSTVB1', 'INSTVC1'], \n",
    "            comparison_operator='isin'\n",
    "        )\n",
    "    ], \n",
    "    name='VOLT, INSTV(ABC)1', \n",
    "    join_single_slicers='and'\n",
    ")\n",
    "#-------------------------\n",
    "volt_avg_slcr = DFSlicer(\n",
    "    single_slicers = [\n",
    "        dict(\n",
    "            column='aep_derived_uom', \n",
    "            value='VOLT', \n",
    "            comparison_operator='=='\n",
    "        ), \n",
    "        dict(\n",
    "            column='aep_srvc_qlty_idntfr', \n",
    "            value='AVG', \n",
    "            comparison_operator='=='\n",
    "        )\n",
    "    ], \n",
    "    name='VOLT, AVG', \n",
    "    join_single_slicers='and'\n",
    ")\n",
    "#-------------------------\n",
    "slicers=[instvabc_slcr, volt_avg_slcr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_suboutg_endpt_plots=True\n",
    "\n",
    "calculate_by_PN = True\n",
    "# combine_by_PN_likeness_thresh = pd.Timedelta('1 minutes')\n",
    "combine_by_PN_likeness_thresh = pd.Timedelta('15 minutes')\n",
    "\n",
    "expand_outg_search_time_tight = pd.Timedelta('1 hours')\n",
    "expand_outg_search_time_loose = pd.Timedelta('12 hours')\n",
    "use_est_outg_times=False\n",
    "# use_est_outg_times=True\n",
    "use_full_ede_outgs=False\n",
    "run_outg_inclusion_assessment=True\n",
    "max_pct_PNs_missing_allowed=0\n",
    "# max_pct_PNs_missing_allowed=20\n",
    "#-----\n",
    "expand_outg_est_search_time = expand_outg_search_time_loose\n",
    "if use_est_outg_times:\n",
    "    expand_outg_search_time = expand_outg_search_time_tight\n",
    "else:\n",
    "    expand_outg_search_time = expand_outg_search_time_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(save_dir, r'Results.pdf')\n",
    "pdf = PdfPages(pdf_path)\n",
    "#-------------------------\n",
    "pdf_path_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_dovs_beg = PdfPages(pdf_path_dovs_beg)\n",
    "#-------------------------\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_path_2 = Utilities.append_to_path(\n",
    "        pdf_path, \n",
    "        '_w_suboutg_endpt_plots', \n",
    "        ext_to_find='.pdf', \n",
    "        append_to_end_if_ext_no_found=False\n",
    "    )\n",
    "    pdf_2 = PdfPages(pdf_path_2)\n",
    "#-------------------------\n",
    "pdf_path_n_w_power = os.path.join(save_dir, r'n_w_power_v_time.pdf')\n",
    "pdf_n_w_power = PdfPages(pdf_path_n_w_power)\n",
    "#-----\n",
    "pdf_path_n_w_power_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path_n_w_power, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_n_w_power_dovs_beg = PdfPages(pdf_path_n_w_power_dovs_beg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_PNs_w_power_threshold = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d73bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "all_detailed_summary_dfs=[]\n",
    "all_detailed_summary_dfs_dovs_beg=[]\n",
    "ci_cmi_summary_df = pd.DataFrame(columns=[\n",
    "    'outg_rec_nb', \n",
    "    'ci_dovs',  'ci_ami', 'ci_ami_dovs_beg', \n",
    "    'cmi_dovs', 'cmi_ami', 'cmi_ami_dovs_beg'\n",
    "])\n",
    "\n",
    "#-------------------------\n",
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=all_outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "\n",
    "#-------------------------\n",
    "# Now, iterate through all outages\n",
    "for i_outg, outg_rec_nb in enumerate(all_outg_rec_nbs):\n",
    "    print(f'\\n\\ti_outg: {i_outg+1}/{len(all_outg_rec_nbs)}')\n",
    "    print(f'\\toutg_rec_nb = {outg_rec_nb}')\n",
    "    #-----\n",
    "    ami_df = GenAn.read_df_from_csv_batch(outg_rec_nb_to_files_dict[outg_rec_nb])\n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = ami_df[ami_df['OUTG_REC_NB_GPD_FOR_SQL']==outg_rec_nb].copy()\n",
    "    \n",
    "    # Although I cannot yet call choose_best_slicer_and_perform_slicing and reduce_INSTV_ABC_1_vals_in_df, \n",
    "    #   as the standard cleaning and conversions must be done first, I am able to cut down the size of\n",
    "    #   ami_df_i by joining the slicers with 'or' statements.\n",
    "    # Thus, ami_df_i will be reduced to only the subset of data which will be considered in \n",
    "    #   choose_best_slicer_and_perform_slicing\n",
    "    # As mentioned, this will cut down the size of ami_df_i and will also save time and resources by not having\n",
    "    #   to run entire DF through cleaning and conversions procedures.\n",
    "    ami_df_i = DFSlicer.combine_slicers_and_perform_slicing(\n",
    "        df=ami_df_i, \n",
    "        slicers=slicers, \n",
    "        join_slicers='or'\n",
    "    )\n",
    "    if ami_df_i.shape[0]==0:\n",
    "        continue\n",
    "        \n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = AMINonVee.perform_std_initiation_and_cleaning(ami_df_i)\n",
    "    #-----\n",
    "    # Should the following be added to AMINonVee.perform_std_initiation_and_cleaning?\n",
    "    ami_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df_i, \n",
    "        time_col='starttimeperiod', \n",
    "        placement_col='starttimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    ami_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df_i, \n",
    "        time_col='endtimeperiod', \n",
    "        placement_col='endtimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = choose_best_slicer_and_perform_slicing(\n",
    "        df=ami_df_i, \n",
    "        slicers=slicers, \n",
    "        groupby_SN=True, \n",
    "        t_search_min_max=None, \n",
    "        time_col='starttimeperiod_local', \n",
    "        value_col=None, \n",
    "        SN_col='serialnumber', \n",
    "        return_sorted=True\n",
    "    )\n",
    "\n",
    "    ami_df_i = reduce_INSTV_ABC_1_vals_in_df(\n",
    "        df=ami_df_i, \n",
    "        value_col='value', \n",
    "        aep_derived_uom_col='aep_derived_uom', \n",
    "        aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "        output_aep_srvc_qlty_idntfr = 'INSTV(ABC)1'\n",
    "    )\n",
    "\n",
    "    if ami_df_i.shape[0]==0:\n",
    "        continue\n",
    "        \n",
    "    #-------------------------\n",
    "    # Each serial number should have a single value per time stamp\n",
    "    assert(ami_df_i.groupby(['serialnumber', 'starttimeperiod_local']).ngroups == ami_df_i.shape[0])\n",
    "\n",
    "    #-------------------------\n",
    "    if run_outg_inclusion_assessment:\n",
    "        to_include_i = assess_outage_inclusion_requirements(\n",
    "            ami_df_i=ami_df_i, \n",
    "            outg_rec_nb=outg_rec_nb, \n",
    "            dovs_df=dovs_df, \n",
    "            max_pct_PNs_missing_allowed=max_pct_PNs_missing_allowed\n",
    "\n",
    "        )\n",
    "        if not to_include_i:\n",
    "            print(f'outg_rec_nb={outg_rec_nb} did not pass inclusion requirements, skipping!!!!!')\n",
    "            continue\n",
    "    #-------------------------    \n",
    "    n_SNs  = ami_df_i['serialnumber'].nunique()\n",
    "    n_PNs  = ami_df_i['aep_premise_nb'].nunique()\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NOTE: Can save time by grabbing ede_df_i then performing tz conversion and adding DOVS\n",
    "    if outg_rec_nb not in outg_rec_nb_to_files_ede_dict.keys():\n",
    "        ede_df_i=None\n",
    "    else:\n",
    "        ede_df = GenAn.read_df_from_csv_batch(outg_rec_nb_to_files_ede_dict[outg_rec_nb])\n",
    "        ede_df_i = ede_df[ede_df['OUTG_REC_NB_GPD_FOR_SQL']==outg_rec_nb].copy()\n",
    "\n",
    "        #-----\n",
    "        ede_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "            df=ede_df_i, \n",
    "            time_col='valuesinterval', \n",
    "            placement_col='valuesinterval_local', \n",
    "            run_quick=True, \n",
    "            n_strip=6, \n",
    "            inplace=False\n",
    "        )\n",
    "        ede_df_i = AMIEndEvents.reduce_end_event_reasons_in_df(df=ede_df_i)\n",
    "        #-----\n",
    "        ede_cols_to_keep = [\n",
    "            'valuesinterval_local', \n",
    "            'reason', \n",
    "            'serialnumber', \n",
    "            'aep_premise_nb', \n",
    "            'enddeviceeventtypeid', \n",
    "            'event_type', \n",
    "            'OUTG_REC_NB_GPD_FOR_SQL', \n",
    "            'trsf_pole_nb_GPD_FOR_SQL',\n",
    "        ]\n",
    "        ede_df_i = ede_df_i[ede_cols_to_keep]\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    dovs_df_i = DOVSOutages.retrieve_outage_from_dovs_df(\n",
    "        dovs_df=dovs_df, \n",
    "        outg_rec_nb=outg_rec_nb, \n",
    "        outg_rec_nb_idfr='index', \n",
    "        assert_outg_rec_nb_found=True\n",
    "    )\n",
    "    assert(dovs_df_i.shape[0]==1)\n",
    "    # Get the outage time from DOVS\n",
    "    dovs_outg_t_beg_end = dovs_df_i.iloc[0][['DT_OFF_TS_FULL', 'DT_ON_TS']].tolist()\n",
    "    assert(len(dovs_outg_t_beg_end)==2)\n",
    "    dovs_outg_t_beg, dovs_outg_t_end = dovs_outg_t_beg_end\n",
    "    #-------------------------\n",
    "    # Get the CI and CMI from DOVS\n",
    "    ci_cmi_dovs = dovs_df_i.iloc[0][['CI_NB', 'CMI_NB']].tolist()\n",
    "    assert(len(ci_cmi_dovs)==2)\n",
    "    ci_dovs, cmi_dovs = ci_cmi_dovs\n",
    "    #-------------------------\n",
    "    # Get the number of premises from DOVS\n",
    "    n_PNs_dovs = len(set(dovs_df_i.iloc[0]['premise_nbs']))\n",
    "    #-------------------------\n",
    "    # Get the outage number from DOVS\n",
    "    outage_nb = dovs_df_i.iloc[0]['OUTAGE_NB']\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    res_dict = calculate_ci_cmi_w_ami_w_ede_help(\n",
    "        df=ami_df_i, \n",
    "        ede_df=ede_df_i, \n",
    "        dovs_outg_t_beg_end=dovs_outg_t_beg_end, \n",
    "        expand_outg_search_time=expand_outg_search_time, \n",
    "        conservative_estimate=True, \n",
    "        est_ede_kwargs=dict(use_full_ede_outgs=use_full_ede_outgs), \n",
    "        audit_selection_method='ede only', \n",
    "        return_CI_SNs=False, \n",
    "        use_est_outg_times=use_est_outg_times, \n",
    "        pct_SNs_required_for_outage_est=0, \n",
    "        expand_outg_est_search_time=expand_outg_est_search_time, \n",
    "        use_only_overall_endpoints_of_est_outg_times=False, \n",
    "        t_int_beg_col='starttimeperiod_local', \n",
    "        t_int_end_col='endtimeperiod_local', \n",
    "        value_col='value', \n",
    "        SN_col='serialnumber', \n",
    "        return_all_best_ests=True, \n",
    "        return_all_best_ests_type='pd.DataFrame'\n",
    "    )\n",
    "    #-----\n",
    "    ci_ami       = res_dict['CI']\n",
    "    cmi_ami      = res_dict['CMI']\n",
    "    best_ests_df = res_dict['all_best_ests']\n",
    "    #--------------------------------------------------\n",
    "    if calculate_by_PN and best_ests_df.shape[0]>0:\n",
    "        try:\n",
    "            best_ests_df = combine_PNs_in_best_ests_df(\n",
    "                best_ests_df, \n",
    "                likeness_thresh = combine_by_PN_likeness_thresh, \n",
    "                SN_col = 'SN', \n",
    "                PN_col = 'PN', \n",
    "                i_outg_col = 'i_outg'     \n",
    "            )\n",
    "            ci_ami  = best_ests_df['PN'].nunique()\n",
    "            cmi_ami = (best_ests_df['winner_max']-best_ests_df['winner_min']).sum().total_seconds()/60\n",
    "        except:\n",
    "            print(f'outg_rec_nb={outg_rec_nb} failed combine_PNs_in_best_ests_df, so skipping')\n",
    "            continue\n",
    "    #--------------------------------------------------\n",
    "    # cnsrvtv_out_t_beg/_end are used for placing bounds on the plots generated\n",
    "    # If best_ests_df has non-zero size (meaning the algorithm found outages), use to set plotting time.\n",
    "    # Otherwise, use dovs_outg_t_beg/_end\n",
    "    # NOTE: If one did not want to show any data which was thrown out due to overlapping, one would want to\n",
    "    #         update cnsrvtv_out_t_beg/_end after the identify_dovs_overlaps_from_best_ests procedure below \n",
    "    #         (and subsequent trimming of best_ests_df)\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        cnsrvtv_out_t_beg = np.min([best_ests_df['conservative_min'].min(), dovs_outg_t_beg])\n",
    "        cnsrvtv_out_t_end = np.max([best_ests_df['conservative_max'].max(), dovs_outg_t_end])\n",
    "    else:\n",
    "        cnsrvtv_out_t_beg = dovs_outg_t_beg\n",
    "        cnsrvtv_out_t_end = dovs_outg_t_end\n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        # Identify and handle any overlaps with other DOVS events\n",
    "        #-------------------------\n",
    "        # dovs_sql_fcn=DOVSOutages_SQL.build_sql_std_outage\n",
    "        dovs_sql_fcn=DOVSOutages_SQL.build_sql_outage        \n",
    "        #-------------------------\n",
    "        # I'll need potential overlapping DOVS df using (dovs_outg_t_beg, dovs_outg_t_end) and also\n",
    "        #   using (best_ests_df[t_min_col].min(), best_ests_df[t_max_col].max())\n",
    "        # Since these typically have significant overlap, grab potential overlapping DOVS events for \n",
    "        #   all, and then subset as needed\n",
    "        ptntl_ovrlp_dovs_df = get_potential_overlapping_dovs(\n",
    "            PNs=ami_df_i['aep_premise_nb'].unique().tolist(), \n",
    "            outg_t_beg=np.min([dovs_outg_t_beg, best_ests_df['winner_min'].min()]), \n",
    "            outg_t_end=np.max([dovs_outg_t_end, best_ests_df['winner_max'].max()]), \n",
    "            dovs_sql_fcn=dovs_sql_fcn, \n",
    "        )\n",
    "        #-----\n",
    "        ptntl_ovrlp_dovs_df_out_times = ptntl_ovrlp_dovs_df[\n",
    "            (ptntl_ovrlp_dovs_df['DT_OFF_TS_FULL'] <= dovs_outg_t_end) & \n",
    "            (ptntl_ovrlp_dovs_df['DT_ON_TS']       >= dovs_outg_t_beg)\n",
    "        ]\n",
    "        ptntl_ovrlp_dovs_df_est_times = ptntl_ovrlp_dovs_df[\n",
    "            (ptntl_ovrlp_dovs_df['DT_OFF_TS_FULL'] <= best_ests_df['winner_max'].max()) & \n",
    "            (ptntl_ovrlp_dovs_df['DT_ON_TS']       >= best_ests_df['winner_min'].min())\n",
    "        ]        \n",
    "        #-------------------------\n",
    "        # First, find if any other DOVS outages overlap with the current one\n",
    "        #-----\n",
    "        # NOTE: Supply best_ests_df to get_outgs_in_dovs_df_overlapping_outg_rec_nb_i_by_PN below so 'lost_power'\n",
    "        #       column is output\n",
    "        overlap_outgs_for_PNs_df = get_outgs_in_dovs_df_overlapping_outg_rec_nb_i_by_PN(\n",
    "            outg_rec_nb_i=outg_rec_nb, \n",
    "            dovs_df=ptntl_ovrlp_dovs_df_out_times, \n",
    "            best_ests_df=best_ests_df, \n",
    "            outg_rec_nb_col='OUTG_REC_NB', \n",
    "            PN_col='PREMISE_NB', \n",
    "            t_min_col='DT_OFF_TS_FULL', \n",
    "            t_max_col='DT_ON_TS', \n",
    "            PN_col_best_ests='PN'\n",
    "        )\n",
    "        #-------------------------\n",
    "        # If any PN has one or more overlapping DOVS events, output info to file\n",
    "        n_PNs_w_overlap = (overlap_outgs_for_PNs_df['n_overlap']>0).sum()\n",
    "        if n_PNs_w_overlap>0:\n",
    "            print(f'Need to output to new file\\n\\tn_PNs_w_overlap={n_PNs_w_overlap}')\n",
    "        #-------------------------\n",
    "        # If any PN which lost power has one or more overlapping DOVS events, stop analysis\n",
    "        n_out_PNs_w_overlap = overlap_outgs_for_PNs_df[overlap_outgs_for_PNs_df['lost_power']==True]['overlap_outg_rec_nbs'].apply(lambda x: len(x)>0).sum()\n",
    "        if n_out_PNs_w_overlap>0:\n",
    "            print('STOP analysis')\n",
    "            continue\n",
    "        #-------------------------\n",
    "        # Procedure above ensure that the current outage, as defined by DOVS, does not overlap with any other DOVS outages.\n",
    "        # Now, we are safe to check whether any of our estimates for the current outage overlap with any other DOVS outages!\n",
    "        # ==> Should be safe to set assert_no_overlaps=True in identify_dovs_overlaps_from_best_ests or \n",
    "        #       remove_any_dovs_overlaps_from_best_ests below\n",
    "        best_ests_df_w_keep_info = identify_dovs_overlaps_from_best_ests(\n",
    "            best_ests_df                = best_ests_df, \n",
    "            outg_rec_nb                 = outg_rec_nb, \n",
    "            dovs_df                     = ptntl_ovrlp_dovs_df_est_times, \n",
    "            get_ptntl_ovrlp_dovs_kwargs = None, \n",
    "            assert_no_overlaps          = True, \n",
    "            PN_col                      = 'PN', \n",
    "            t_min_col                   = 'winner_min', \n",
    "            t_max_col                   = 'winner_max', \n",
    "            PN_col_dovs                 = 'PREMISE_NB', \n",
    "            t_min_col_dovs              = 'DT_OFF_TS_FULL', \n",
    "            t_max_col_dovs              = 'DT_ON_TS', \n",
    "            outg_rec_nb_col_dovs        = 'OUTG_REC_NB', \n",
    "            overlap_outg_col            = 'overlap_DOVS', \n",
    "            overlap_times_col           = 'overlap_times', \n",
    "            keep_col                    = 'keep'\n",
    "        )\n",
    "        best_ests_df = best_ests_df_w_keep_info[best_ests_df_w_keep_info['keep']==True].drop(\n",
    "            columns=['overlap_DOVS', 'overlap_times', 'keep']\n",
    "        )\n",
    "        #-----\n",
    "        ci_ami  = best_ests_df['PN'].nunique()\n",
    "        cmi_ami = (best_ests_df['winner_max']-best_ests_df['winner_min']).sum().total_seconds()/60\n",
    "        #-------------------------\n",
    "        # In ami_df_i, mark any entries which were essentially removed via the identify_dovs_overlaps_from_best_ests\n",
    "        #   and removal procedure above\n",
    "        ami_df_i = set_removed_due_to_overlap_in_ami_df_i(\n",
    "            ami_df_i=ami_df_i, \n",
    "            best_ests_df=best_ests_df_w_keep_info, \n",
    "            PN_col='aep_premise_nb', \n",
    "            time_idfr='starttimeperiod_local', \n",
    "            PN_col_be='PN', \n",
    "            keep_col_be='keep', \n",
    "            overlap_times_col_be='overlap_times', \n",
    "            removed_due_to_overlap_col='removed_due_to_overlap'\n",
    "        )\n",
    "            \n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        best_ests_df_dovs_beg = alter_best_ests_df_using_dovs_outg_t_beg(\n",
    "            best_ests_df=best_ests_df,\n",
    "            dovs_df=dovs_df_i, \n",
    "            outg_rec_nb=outg_rec_nb\n",
    "        )\n",
    "        if calculate_by_PN:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['PN'].nunique()\n",
    "        else:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['SN'].nunique()\n",
    "        cmi_ami_dovs_beg = (best_ests_df_dovs_beg['winner_max']-best_ests_df_dovs_beg['winner_min']).sum().total_seconds()/60\n",
    "    else:\n",
    "        best_ests_df_dovs_beg = best_ests_df.copy()\n",
    "        ci_ami_dovs_beg = ci_ami\n",
    "        cmi_ami_dovs_beg = cmi_ami        \n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        means_df, best_ests_df_w_db_lbl = get_mean_times_w_dbscan(\n",
    "            best_ests_df, \n",
    "            eps_min=5, \n",
    "            min_samples=2, \n",
    "            ests_to_include_in_clustering=['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output=[\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df=True\n",
    "        )\n",
    "        #-------------------------\n",
    "        n_PNs_w_power_srs = build_n_PNs_w_power_srs(\n",
    "            best_ests_df=best_ests_df, \n",
    "            ami_df_i=ami_df_i, \n",
    "            return_pct=True, \n",
    "            PN_col='PN', \n",
    "            t_min_col='winner_min', \n",
    "            t_max_col='winner_max', \n",
    "            i_outg_col='i_outg', \n",
    "            PN_col_ami_df='aep_premise_nb'\n",
    "        )        \n",
    "        #-------------------------\n",
    "        detailed_summary_df_i = build_detailed_summary_df(\n",
    "            means_df=means_df, \n",
    "            best_ests_df_w_db_lbl=best_ests_df_w_db_lbl,\n",
    "            CI_tot=ci_ami, \n",
    "            CMI_tot=cmi_ami, \n",
    "            n_PNs_ami=n_PNs,\n",
    "            outg_rec_nb=outg_rec_nb, \n",
    "            dovs_df_i=dovs_df_i, \n",
    "            db_label_col='db_label', \n",
    "            winner_min_col='winner_min', \n",
    "            winner_max_col='winner_max', \n",
    "            PN_col='PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col='i_outg'\n",
    "        )\n",
    "        #----------\n",
    "        detailed_summary_df_i[f'first_above_thresh ({n_PNs_w_power_threshold})'] = None\n",
    "        detailed_summary_df_i[f'last_above_thresh ({n_PNs_w_power_threshold})']  = None\n",
    "        frst_abv, last_abv = get_first_last_above_threshold(\n",
    "            n_PNs_w_power_srs=n_PNs_w_power_srs, \n",
    "            threshold=n_PNs_w_power_threshold\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'first_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = frst_abv\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'last_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = last_abv        \n",
    "        #-------------------------\n",
    "        all_detailed_summary_dfs.append(detailed_summary_df_i)\n",
    "    else:\n",
    "        means_df, best_ests_df_w_db_lbl = None, None\n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = get_mean_times_w_dbscan(\n",
    "            best_ests_df_dovs_beg, \n",
    "            eps_min=5, \n",
    "            min_samples=2, \n",
    "            ests_to_include_in_clustering=['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output=[\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df=True\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_dovs_beg_i = build_detailed_summary_df(\n",
    "            means_df=means_df_dovs_beg, \n",
    "            best_ests_df_w_db_lbl=best_ests_df_dovs_beg_w_db_lbl,\n",
    "            CI_tot=ci_ami_dovs_beg, \n",
    "            CMI_tot=cmi_ami_dovs_beg, \n",
    "            n_PNs_ami=n_PNs,\n",
    "            outg_rec_nb=outg_rec_nb, \n",
    "            dovs_df_i=dovs_df_i, \n",
    "            db_label_col='db_label', \n",
    "            winner_min_col='winner_min', \n",
    "            winner_max_col='winner_max', \n",
    "            PN_col='PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col='i_outg'\n",
    "        )\n",
    "        all_detailed_summary_dfs_dovs_beg.append(detailed_summary_df_dovs_beg_i)\n",
    "    else:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = None, None\n",
    "    #-------------------------\n",
    "    ci_cmi_summary_df = pd.concat([\n",
    "        ci_cmi_summary_df, \n",
    "        pd.DataFrame(\n",
    "            dict(\n",
    "                outg_rec_nb=outg_rec_nb, \n",
    "                ci_dovs=ci_dovs,   ci_ami=ci_ami, ci_ami_dovs_beg=ci_ami_dovs_beg, \n",
    "                cmi_dovs=cmi_dovs, cmi_ami=cmi_ami, cmi_ami_dovs_beg=cmi_ami_dovs_beg\n",
    "            ), \n",
    "            index=[ci_cmi_summary_df.shape[0]]\n",
    "        )\n",
    "    ])\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # ######################### PLOTTING #########################\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    # Instead of using get_full_part_not_outage_subset_dfs, simply grab the PNs which suffered\n",
    "    #   outages from best_ests_df\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        outg_SNs = best_ests_df['PN'].unique().tolist()\n",
    "    else:\n",
    "        outg_SNs = []\n",
    "    #-----\n",
    "    ami_df_i_out      = ami_df_i[ami_df_i['aep_premise_nb'].isin(outg_SNs)]\n",
    "    ami_df_i_not_out  = ami_df_i[~ami_df_i['aep_premise_nb'].isin(outg_SNs)]  \n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    fig, axs = plot_all_out_not_NEW(\n",
    "        fig_num              = fig_num, \n",
    "        ami_df_i             = ami_df_i, \n",
    "        ami_df_i_out         = ami_df_i_out, \n",
    "        ami_df_i_not_out     = ami_df_i_not_out, \n",
    "        dovs_outg_t_beg      = dovs_outg_t_beg, \n",
    "        dovs_outg_t_end      = dovs_outg_t_end, \n",
    "        cnsrvtv_out_t_beg    = cnsrvtv_out_t_beg, \n",
    "        cnsrvtv_out_t_end    = cnsrvtv_out_t_end, \n",
    "        means_df             = means_df, \n",
    "        outg_rec_nb          = outg_rec_nb, \n",
    "        outage_nb            = outage_nb, \n",
    "        n_PNs_dovs           = n_PNs_dovs, \n",
    "        ci_dovs              = ci_dovs, \n",
    "        cmi_dovs             = cmi_dovs, \n",
    "        ci_ami               = ci_ami, \n",
    "        cmi_ami              = cmi_ami, \n",
    "        name                 = 'AMI', \n",
    "        results_2_dict       = dict(\n",
    "            ci_ami   = ci_ami_dovs_beg, \n",
    "            cmi_ami  = cmi_ami_dovs_beg, \n",
    "            means_df = means_df_dovs_beg, \n",
    "            name = 'AMI w/ DOVS t_beg'\n",
    "        ), \n",
    "        expand_time          = pd.Timedelta('1 hour'), \n",
    "        removed_due_to_overlap_col='removed_due_to_overlap', \n",
    "        mean_keys_to_include = ['winner', 'conservative', 'zero_times'], \n",
    "        default_subplots_args=dict(n_x=2, n_y=2, row_major=True, sharex=True), \n",
    "        leg_i_plot=1, \n",
    "        leg_kwargs=dict(ncols=1, fontsize=15, bbox_to_anchor=(1, 1.2)), \n",
    "        ci_info_fontsize=16, \n",
    "        left_text_x=0.915  \n",
    "    )\n",
    "\n",
    "    fig, axs[3] = plot_n_PNs_w_power_srs(\n",
    "        n_PNs_w_power_srs=n_PNs_w_power_srs, \n",
    "        simp_freq='1T', \n",
    "        threshold=n_PNs_w_power_threshold, \n",
    "        fig_num=fig_num, \n",
    "        fig_ax=(fig, axs[3]), \n",
    "        threshold_color='magenta'\n",
    "    )\n",
    "\n",
    "    fig_num += 1\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    if include_suboutg_endpt_plots:\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df_dovs_beg is not None:\n",
    "        fig, axs = plot_all_out_not_NEW(\n",
    "            fig_num              = fig_num, \n",
    "            ami_df_i             = ami_df_i, \n",
    "            ami_df_i_out         = ami_df_i_out, \n",
    "            ami_df_i_not_out     = ami_df_i_not_out, \n",
    "            dovs_outg_t_beg      = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end      = dovs_outg_t_end, \n",
    "            cnsrvtv_out_t_beg    = cnsrvtv_out_t_beg, \n",
    "            cnsrvtv_out_t_end    = cnsrvtv_out_t_end, \n",
    "            means_df             = means_df_dovs_beg, \n",
    "            outg_rec_nb          = outg_rec_nb, \n",
    "            outage_nb            = outage_nb, \n",
    "            n_PNs_dovs           = n_PNs_dovs, \n",
    "            ci_dovs              = ci_dovs, \n",
    "            cmi_dovs             = cmi_dovs, \n",
    "            ci_ami               = ci_ami_dovs_beg, \n",
    "            cmi_ami              = cmi_ami_dovs_beg, \n",
    "            name                 = 'AMI w/ DOVS t_beg', \n",
    "            results_2_dict       = dict(\n",
    "                ci_ami   = ci_ami, \n",
    "                cmi_ami  = cmi_ami, \n",
    "                means_df = means_df, \n",
    "                name = 'AMI'\n",
    "            ), \n",
    "            expand_time          = pd.Timedelta('1 hour'), \n",
    "            mean_keys_to_include = ['winner']\n",
    "        )\n",
    "\n",
    "        fig_num += 1\n",
    "        pdf_dovs_beg.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df is not None and include_suboutg_endpt_plots:\n",
    "        fig, axs = plot_suboutg_endpts(\n",
    "            fig_num               = fig_num, \n",
    "            ami_df_i              = ami_df_i, \n",
    "            means_df              = means_df, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_w_db_lbl, \n",
    "            dovs_outg_t_beg       = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end       = dovs_outg_t_end, \n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            expand_time           = pd.Timedelta('15 minutes'), \n",
    "            mean_keys_to_include  = ['winner', 'conservative', 'zero_times']\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        _, fig, ax = build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df, \n",
    "            ami_df_i, \n",
    "            return_pct=True, \n",
    "            simp_freq='1T', \n",
    "            threshold=n_PNs_w_power_threshold, \n",
    "            fig_num=fig_num, \n",
    "            title=f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col='PN', \n",
    "            t_min_col='winner_min', \n",
    "            t_max_col='winner_max', \n",
    "            i_outg_col='i_outg', \n",
    "            PN_col_ami_df='aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        _, fig, ax = build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df_dovs_beg, \n",
    "            ami_df_i, \n",
    "            return_pct=True, \n",
    "            simp_freq='1T', \n",
    "            threshold=n_PNs_w_power_threshold, \n",
    "            fig_num=fig_num, \n",
    "            title=f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col='PN', \n",
    "            t_min_col='winner_min', \n",
    "            t_max_col='winner_max', \n",
    "            i_outg_col='i_outg', \n",
    "            PN_col_ami_df='aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power_dovs_beg.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "detailed_summary_df          = pd.concat(all_detailed_summary_dfs)\n",
    "detailed_summary_df_dovs_beg = pd.concat(all_detailed_summary_dfs_dovs_beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23be694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()\n",
    "pdf_dovs_beg.close()\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_2.close()\n",
    "pdf_n_w_power.close()\n",
    "pdf_n_w_power_dovs_beg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cmi_summary_df['ci_dovs']         = ci_cmi_summary_df['ci_dovs'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami']          = ci_cmi_summary_df['ci_ami'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami_dovs_beg'] = ci_cmi_summary_df['ci_ami_dovs_beg'].astype(float)\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami']\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami_dovs_beg']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami_dovs_beg']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami_dovs_beg'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami_dovs_beg']\n",
    "#-----\n",
    "# For plotting purposes, make a outg_rec_in column which is simply 0 to delta_df.shape[0]-1\n",
    "ci_cmi_summary_df['outg_rec_int'] = range(ci_cmi_summary_df.shape[0])\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_summary_df.to_pickle(os.path.join(save_dir, r'detailed_summary.pkl'))\n",
    "detailed_summary_df_dovs_beg.to_pickle(os.path.join(save_dir, r'detailed_summary_dovs_beg.pkl'))\n",
    "ci_cmi_summary_df.to_pickle(os.path.join(save_dir, r'ci_cmi_summary.pkl'))\n",
    "#-----\n",
    "detailed_summary_df.to_csv(os.path.join(save_dir, r'detailed_summary.csv'))\n",
    "detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, r'detailed_summary_dovs_beg.csv'))\n",
    "ci_cmi_summary_df.to_csv(os.path.join(save_dir, r'ci_cmi_summary.csv'))\n",
    "#-----\n",
    "# For Mico and Amanda\n",
    "detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, f'detailed_summary_dovs_beg_{save_subdir}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57ce29",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34202760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01868c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba471e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
