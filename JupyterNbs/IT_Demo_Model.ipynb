{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68627217",
   "metadata": {},
   "source": [
    "# SEE 'Directions for running' below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051005d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./model_end_events_for_outages_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9764e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "from EEMSP import EEMSP\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132b712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1318039",
   "metadata": {},
   "source": [
    "# Directions for running:\n",
    "\n",
    "For the purposes of this demonstration, let's assume your AEP User ID is s123456, and your local Documents directory\n",
    "is located at C:\\Users\\s123456\\Documents\n",
    "\n",
    "1. If not already done, clone the Analysis GitHub repo (https://github.aepsc.com/s346557/Analysis).\n",
    "<br>- I will assume the repo was cloned into the Documents directory, i.e. I assume your local copy of the repo is located at C:\\Users\\s123456\\Documents\\Analysis (and therefore, this Jupyter notebook should be located at C:\\Users\\s123456\\Documents\\Analysis\\JupyterNbs\\IT_Demo.ipynb)\n",
    "<br><br>\n",
    "\n",
    "2. Create a simple text file containing your AEP passwords.\n",
    "- I suggest you use the file pwd_file_template.txt in the Analysis directory (C:\\Users\\s123456\\Documents\\Analysis\\pwd_file_template.txt) to create your own password file.\n",
    "    - DO NOT ALTER the pwd_file_template.txt file, create a new pwd_file.txt file!\n",
    "- I further suggest you name your password file pwd_file.txt and place it in the Analysis directory (C:\\Users\\s123456\\Documents\\Analysis\\pwd_file.txt).\n",
    "    - The Git repo is set up to ignore pwd_file.txt in the Analysis directory, so your information will not be pushed up to the repo if saved in this manner.\n",
    "- NOTE: At one point, my Athena and Oracle passwords were different, which is why there is a 'Main' and 'Oracle' entry in the password file.  Likely you will put the same password for both entries.\n",
    "<br><br>\n",
    "\n",
    "3. IF NOT ALREADY DONE, run the method Utilities_config.generate_initial_config_file to initiate your config.yaml file\n",
    "- I suggest you input arguments for all three parameters (aep_user_id, pwd_file_path, and local_data_dir)\n",
    "    - If no aep_user_id is given, the code will attempt to determine your AEP User ID from the contents of your C:\\Users directory\n",
    "    - If no pwd_file_path is given, it is assumed to exist, be named pwd_file.txt, and be located in the Analysis directory (C:\\Users\\s123456\\Documents\\Analysis\\pwd_file.txt)\n",
    "    - If local_data_dir is not None, it should point to a directory when you plan to store any results (my personal local_data_dir is located at C:\\Users\\s346557\\Documents\\LocalData\\).\n",
    "        - If you are not planning to save or load any files locally, I believe this can be kept as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fd339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867f5cb9",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# ONLY NEED TO RUN ONCE!\n",
    "So, if you have already run Utilities_config.generate_initial_config_file (and your configuration has not changed since), there is no need to run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97af9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219dc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_config:\n",
    "    # REPLACE VALUES BELOW WITH YOUR OWN\n",
    "    aep_user_id = 's123456'\n",
    "    pwd_file_path = r'C:\\Users\\s3123456\\Documents\\Analysis\\pwd_file.txt'\n",
    "    local_data_dir = r'C:\\Users\\s123456\\Documents\\LocalData'\n",
    "\n",
    "    Utilities_config.generate_initial_config_file(\n",
    "        aep_user_id=aep_user_id, \n",
    "        pwd_file_path=pwd_file_path, \n",
    "        local_data_dir=local_data_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da44278",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe383fee",
   "metadata": {},
   "source": [
    "# SET model_dir TO YOUR LOCAL VALUE!!!!!\n",
    "This directory should house the following files:\n",
    "- forest_clf.joblib\n",
    "- scaler.joblib\n",
    "- eemsp_encoder.joblib\n",
    "- data_structure_df.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\Models\\All_EEMSP_agg_Top10_v2'\n",
    "model_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20231201\\Models\\All_EEMSP_agg_Top10_v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a527d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a632a1",
   "metadata": {},
   "source": [
    "# Randomly chosen trsf_pole_nbs\n",
    "I randomly choses the trsf_pole_nbs below from a dataset I was working with.\n",
    "</br>The purpose is simply to create a smaller, more manageable, dataset to work with for this demo (as opposed to, e.g., taking all Ohio data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf_pole_nbs = [\n",
    "#     '1881678764270',\n",
    "#     '1783411710022',\n",
    "#     '41830153D30129',\n",
    "#     '1872247711298',\n",
    "#     '1820228711653',\n",
    "#     '1924989734074',\n",
    "#     '1834492774877',\n",
    "#     '1853148757927',\n",
    "#     '1840493692059',\n",
    "#     '41810769C10088',\n",
    "#     '1882624786848',\n",
    "#     '1867392684831',\n",
    "#     '1951078726448',\n",
    "#     '40820458D10181',\n",
    "#     '41840501D30023',\n",
    "#     '41810982D20079',\n",
    "#     '1899769749646',\n",
    "#     '41830806B20022',\n",
    "#     '40820458A40051',\n",
    "#     '1894765679964',\n",
    "#     '1914519715083',\n",
    "#     '2295283520733',\n",
    "#     '1865162714841',\n",
    "#     '1819362730022',\n",
    "#     '39830853B40009',\n",
    "#     '1842568672564',\n",
    "#     '41840982B20038',\n",
    "#     '1827991743027',\n",
    "#     '1864172691901',\n",
    "#     '1839189769213',\n",
    "#     '1872465763559',\n",
    "#     '1878400683201',\n",
    "#     '41810796A20156',\n",
    "#     '1905880759206',\n",
    "#     '1839712741136',\n",
    "#     '41810748B40188',\n",
    "#     '41810958D40169',\n",
    "#     '1829134693468',\n",
    "#     '40820506D10218',\n",
    "#     '1887542761309',\n",
    "#     '1871334715206',\n",
    "#     '1904835767206',\n",
    "#     '1902838697810',\n",
    "#     '40820507A10072',\n",
    "#     '41810819C40139',\n",
    "#     '1865431765527',\n",
    "#     '1891170737034',\n",
    "#     '40820707C20002',\n",
    "#     '1836231721573',\n",
    "#     '1912124700405',\n",
    "#     '1842330805220',\n",
    "#     '1866130766088',\n",
    "#     '40820588D30084',\n",
    "#     '41840898A10069',\n",
    "#     '1871696719469',\n",
    "#     '41810794A40161',\n",
    "#     '41811008A20198',\n",
    "#     '1875598765170',\n",
    "#     '1861922686377',\n",
    "#     '1948667782803',\n",
    "#     '40820506D40238',\n",
    "#     '41840898C20057',\n",
    "#     '1833284756491',\n",
    "#     '39830855D10027',\n",
    "#     '40820507B20057',\n",
    "#     '1856743480538',\n",
    "#     '1914662698440',\n",
    "#     '1832714711800',\n",
    "#     '40820660D10199',\n",
    "#     '40820507C10103',\n",
    "#     '41830440D40074',\n",
    "#     '41810796A40071',\n",
    "#     '1859120778206',\n",
    "#     '1866200767783',\n",
    "#     '41830750A30052',\n",
    "#     '1919909700535',\n",
    "#     '1868442737650',\n",
    "#     '1879608712393',\n",
    "#     '40820507A40022',\n",
    "#     '1823173736584',\n",
    "#     '1885575704441',\n",
    "#     '1853216748770',\n",
    "#     '40810165C10068',\n",
    "#     '1829736736745',\n",
    "#     '41840874B30085',\n",
    "#     '1867971718645',\n",
    "#     '40820482B20025',\n",
    "#     '41810748D20072',\n",
    "#     '1877687713638',\n",
    "#     '1835644777440',\n",
    "#     '1870217709319',\n",
    "#     '41840874B30044',\n",
    "#     '40810190A10166',\n",
    "#     '1796307716407',\n",
    "#     '1875834764859',\n",
    "#     '40810002A10009',\n",
    "#     '1881341721010',\n",
    "#     '40820506D10055',\n",
    "#     '1898393738979',\n",
    "#     '40820507C30093'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_aws = Utilities.get_athena_prod_aws_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbddc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_pole_nbs_df = MeterPremise.get_distinct_trsf_pole_nbs(\n",
    "    conn_aws=conn_aws, \n",
    "    states='OH'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf_pole_nbs = trsf_pole_nbs_df.sample(n=10000)['trsf_pole_nb'].tolist()\n",
    "trsf_pole_nbs = trsf_pole_nbs_df.sample(n=100)['trsf_pole_nb'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf_pole_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a03ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4c327c",
   "metadata": {},
   "source": [
    "# Prediction Date\n",
    "This corresponds essentially to the day on which the model will be run/data evaluated.\n",
    "</br>Data will be collected for a period spanning 31 days before the prediction date up to 1 day before.\n",
    "</br>Eventually, the data will be grouped into the 5-day periods:'01-06 Days', '06-11 Days', '11-16 Days', '16-21 Days', '21-26 Days','26-31 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date = pd.to_datetime('2023-06-01')\n",
    "date_range = [\n",
    "    prediction_date-pd.Timedelta('31D'), \n",
    "    prediction_date-pd.Timedelta('1D')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trsf_pole_nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ce167",
   "metadata": {},
   "source": [
    "# Grab the data from meter_events.events_summary_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_aws = Utilities.get_athena_prod_aws_connection()\n",
    "#-----\n",
    "end_events_sql_function_kwargs=dict(\n",
    "    schema_name='meter_events', \n",
    "    table_name='events_summary_vw', \n",
    "    cols_of_interest=['*'], \n",
    "    date_range=date_range, \n",
    "    trsf_pole_nbs=trsf_pole_nbs, \n",
    "    opco='oh'\n",
    ")\n",
    "#-----\n",
    "end_events = AMIEndEvents(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args = dict(conn_db=conn_aws), \n",
    "    build_sql_function=AMIEndEvents_SQL.build_sql_end_events, \n",
    "    build_sql_function_kwargs=end_events_sql_function_kwargs, \n",
    "    init_df_in_constructor=True, \n",
    "    save_args=False\n",
    ")\n",
    "ede_df = end_events.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ede_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfab684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41376294",
   "metadata": {},
   "source": [
    "# Also need meter_events.event_summ_regex_setup\n",
    "to convert the column names in rcpx from cr# to curated reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_trans_dict = curated reasons translation dictionary\n",
    "sql = \"\"\"\n",
    "SELECT * FROM meter_events.event_summ_regex_setup\n",
    "\"\"\"\n",
    "regex_setup_df = pd.read_sql(sql, conn_aws, dtype=str)\n",
    "cr_trans_dict = {x[0]:x[1] for x in regex_setup_df[['pivot_id', 'regex_report_title']].values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_trans_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c60c6",
   "metadata": {},
   "source": [
    "# Build rcpx_0\n",
    "Construct rcpx_0 by aggregating ede_df by trsf_pole_nb and by 5-day frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='5D'\n",
    "group_cols=['trsf_pole_nb']\n",
    "group_freq=pd.Grouper(freq=freq, key='aep_event_dt')\n",
    "#-------------------------\n",
    "# Convert aep_event_dt to datetime object\n",
    "ede_df['aep_event_dt'] = pd.to_datetime(ede_df['aep_event_dt'])\n",
    "\n",
    "# Will no longer need the following columns\n",
    "cols_to_drop = ['serialnumber', 'aep_premise_nb', 'aep_opco']\n",
    "\n",
    "agg_dict = {col:np.sum for col in ede_df.drop(columns=cols_to_drop+['trsf_pole_nb', 'aep_event_dt']).columns.tolist()}\n",
    "agg_dict['xf_meter_cnt'] = np.max\n",
    "#-------------------------\n",
    "rcpx_0 = ede_df.drop(columns=cols_to_drop).groupby(group_cols+[group_freq]).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06cf8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e9e984b",
   "metadata": {},
   "source": [
    "# Project out xf_meter_cnt, as it will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_meter_cnt_srs = rcpx_0.droplevel(1, axis=0)['xf_meter_cnt'].reset_index().drop_duplicates().set_index('trsf_pole_nb').squeeze()\n",
    "assert(xf_meter_cnt_srs.shape[0]==xf_meter_cnt_srs.index.nunique())\n",
    "all_trsf_pole_nbs = rcpx_0.index.get_level_values(0).unique().tolist()\n",
    "xf_meter_cnt_srs.name='nSNs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ad0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_meter_cnt_srs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb81e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7c9e05d",
   "metadata": {},
   "source": [
    "# Need data_structure_df\n",
    "In general, not all curated reasons will be included in the model.\n",
    "</br>Typically, 10 commong curated reasons will be included, and all others will be grouped together in \"Other Reasons\".\n",
    "</br>Furthermore, some reasons may be combined together, others may be completely removed.\n",
    "</br>For these reasons, it is beneficial to have some sample data (taken from when the model was created) to utilize in structuring the new data in the same fashion.\n",
    "</br>Additionally, the data will be used to ensure the ordering of columns is correct before the data are fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ad9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structure_df = pd.read_pickle(os.path.join(model_dir, 'data_structure_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2e616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf5e5c7",
   "metadata": {},
   "source": [
    "# Transform rcpx_0 to the form expected by the model\n",
    "i.e., similar to data_structure_df.\n",
    "</br>This is essentially just changing rcpo_0 from long form to wide form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build time_pds_rename\n",
    "#-----\n",
    "# We will need to convert the time periods, which are currently housed in the 'aep_event_dt' index of \n",
    "#   rcpx_0 from their specific dates to the names expected by the model.\n",
    "# In rcpx_0, after grouping by the 5-day intervals, the values of 'aep_event_dt' are equal to the beginning\n",
    "#   dates of the given interval.\n",
    "# These will be converted to the titles contained in final_time_pds below\n",
    "# NOTE: This is probably not 100% necessary, but is useful nonetheless\n",
    "#-------------------------\n",
    "curr_time_pds = natsorted(rcpx_0.index.get_level_values(1).unique())\n",
    "# There should be 6 time periods, each of width 5 days\n",
    "for i in range(len(curr_time_pds)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    assert(curr_time_pds[i]-curr_time_pds[i-1]==pd.Timedelta('5D'))\n",
    "#-----\n",
    "final_time_pds = [\n",
    "    '01-06 Days',\n",
    "    '06-11 Days',\n",
    "    '11-16 Days',\n",
    "    '16-21 Days',\n",
    "    '21-26 Days',\n",
    "    '26-31 Days',\n",
    "]\n",
    "#-----\n",
    "time_pds_rename = dict(zip(curr_time_pds, final_time_pds))\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00f6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above, this is essentially just changing rcpo_0 from long form to wide form\n",
    "# This will probably be formalized further in the future (i.e., function(s) developed to handle)\n",
    "rename_cols = {\n",
    "    'events_tot':'total_counts', \n",
    "    'xf_meter_cnt':'nSNs'\n",
    "}\n",
    "\n",
    "total_counts_col = 'total_counts'\n",
    "nSNs_col         = 'nSNs'\n",
    "non_reason_cols = [nSNs_col, total_counts_col]\n",
    "\n",
    "include_power_down_minus_up=False\n",
    "#-------------------------\n",
    "rcpx_0=rcpx_0.rename(columns=rename_cols)\n",
    "#-------------------------\n",
    "pd_dfs = []\n",
    "for date_pd_i in curr_time_pds:\n",
    "    # Grab the proper time period name from final_time_pd_i\n",
    "    final_time_pd_i = time_pds_rename[date_pd_i]\n",
    "    #-----\n",
    "    # Get the expected columns for this time period from data_structure_df\n",
    "    final_reason_cols_i = data_structure_df[final_time_pd_i].columns.tolist()\n",
    "    final_reason_cols_i = [x for x in final_reason_cols_i if x not in non_reason_cols+['Other Reasons']]\n",
    "    #-------------------------\n",
    "    # Project out the current time period (date_pd_i) from rcpx_0 by selecting the appropriate\n",
    "    #   values from the 'aep_event_dt' index (i.e., index level 1)\n",
    "    rcpx_0_pd_i = rcpx_0[rcpx_0.index.get_level_values(1)==date_pd_i].copy()\n",
    "    rcpx_0_pd_i = rcpx_0_pd_i.droplevel(1, axis=0)\n",
    "    #-------------------------\n",
    "    # Make sure all trsf_pole_nbs have an entry in rcpx_0_pd_i:\n",
    "    #   If a trsf_pole_nb didn't register any events in a given time period, it will not be included in the projection.\n",
    "    #   However, the final format requires each transformer have entries for each time period\n",
    "    #   Therefore, we identify the trsf_pole_nbs missing from rcpx_0_pd_i (no_events_pd_i) and add approriate rows\n",
    "    #     containing all 0 values for the counts\n",
    "    no_events_pd_i = list(set(all_trsf_pole_nbs).difference(set(rcpx_0_pd_i.index.get_level_values(0).unique())))\n",
    "    no_events_pd_i_df = pd.DataFrame(\n",
    "        columns=rcpx_0.columns, \n",
    "        index=no_events_pd_i, \n",
    "        data=np.zeros((len(no_events_pd_i), rcpx_0.shape[1]))\n",
    "    )\n",
    "    #-----\n",
    "    # Use xf_meter_cnt_srs to fill the 'nSNs' column in no_events_pd_i_df\n",
    "    # NOTE: This is probably not strictly necessary, as the 'nSNs' column won't be used here,\n",
    "    #         since the data are not normalized.\n",
    "    no_events_pd_i_df = no_events_pd_i_df.drop(columns=['nSNs']).merge(\n",
    "        xf_meter_cnt_srs, \n",
    "        left_index=True, \n",
    "        right_index=True, \n",
    "        how='left'\n",
    "    )\n",
    "    # Sanity check on the merge\n",
    "    assert(no_events_pd_i_df['nSNs'].notna().all())\n",
    "    #-----\n",
    "    # Combine rcpx_0_pd_i and no_events_pd_i_df\n",
    "    assert(len(set(rcpx_0_pd_i.columns).symmetric_difference(set(no_events_pd_i_df.columns)))==0)\n",
    "    no_events_pd_i_df = no_events_pd_i_df[rcpx_0_pd_i.columns]\n",
    "    rcpx_0_pd_i = pd.concat([rcpx_0_pd_i, no_events_pd_i_df])\n",
    "    #-------------------------\n",
    "    # Rename the cr# columns to their full curated reasons\n",
    "    rcpx_0_pd_i=rcpx_0_pd_i.rename(columns=cr_trans_dict)\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    # Any columns without a curated reason (i.e., those with column name = ''), have not been observed\n",
    "    #   yet in the data, and therefore the sume of the counts should be 0.\n",
    "    # These empty columns are not needed, so drop\n",
    "    assert(rcpx_0_pd_i[''].sum().sum()==0)\n",
    "    rcpx_0_pd_i=rcpx_0_pd_i.drop(columns=[''])\n",
    "    #-------------------------\n",
    "    # Any curated reasons containing 'cleared' or 'Test Mode' or not included in the analysis, so remove\n",
    "    rcpx_0_pd_i = MECPODf.remove_reasons_from_rcpo_df(\n",
    "        rcpo_df=rcpx_0_pd_i, \n",
    "        regex_patterns_to_remove=['.*cleared.*', '.*Test Mode.*'], \n",
    "        ignore_case=True\n",
    "    )\n",
    "    #-----\n",
    "    # After irrelevant cleared and test columns removed, need to recalculate events_tot to accurately\n",
    "    #   reflect the total number of relevant events\n",
    "    assert(total_counts_col in non_reason_cols)\n",
    "    rcpx_0_pd_i[total_counts_col] = rcpx_0_pd_i.drop(columns=non_reason_cols).sum(axis=1)\n",
    "    #-------------------------\n",
    "    # Combine similar reasons (e.g., all 'Tamper' type reasons are combined into 1)\n",
    "    # See MECPODf.combine_cpo_df_reasons for more information\n",
    "    rcpx_0_pd_i = MECPODf.combine_cpo_df_reasons(rcpo_df=rcpx_0_pd_i)\n",
    "    #-------------------------\n",
    "    # Include the difference in power-up and power-down, if desired (typically turned off) \n",
    "    if include_power_down_minus_up:\n",
    "        rcpx_0_pd_i = MECPODf.delta_cpo_df_reasons(\n",
    "            rcpo_df=rcpx_0_pd_i, \n",
    "            reasons_1='Primary Power Down',\n",
    "            reasons_2='Primary Power Up',\n",
    "            delta_reason_name='Power Down Minus Up'\n",
    "        )\n",
    "    #-------------------------\n",
    "    # Make sure rcpx_0_pd_i contains the expected final reason columns.\n",
    "    # Once this is assured, project out these reasons and combine all other reasons into\n",
    "    #   the 'Other Reasons' columns\n",
    "    # See MECPODf.get_reasons_subset_from_cpo_df for more info\n",
    "    assert(len(set(final_reason_cols_i).difference(set(rcpx_0_pd_i.columns.tolist())))==0)\n",
    "    rcpx_0_pd_i = MECPODf.get_reasons_subset_from_cpo_df(\n",
    "        cpo_df=rcpx_0_pd_i, \n",
    "        reasons_to_include=final_reason_cols_i, \n",
    "        combine_others=True, \n",
    "        output_combine_others_col='Other Reasons', \n",
    "        SNs_tags=None, \n",
    "        is_norm=False, \n",
    "        counts_col='nSNs', \n",
    "        normalize_by_nSNs_included=False, \n",
    "        level_0_raw_col = 'counts', \n",
    "        level_0_nrm_col = 'counts_norm', \n",
    "        cols_to_ignore = ['total_counts'], \n",
    "        include_counts_col_in_output=True\n",
    "    )    \n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    # Don't want nSNs in each pd individually\n",
    "    rcpx_0_pd_i = rcpx_0_pd_i.drop(columns=[nSNs_col])\n",
    "    #-------------------------\n",
    "    # Add the correct time period name as level 0 of the columns\n",
    "    rcpx_0_pd_i = Utilities_df.prepend_level_to_MultiIndex(\n",
    "        df=rcpx_0_pd_i, \n",
    "        level_val=final_time_pd_i, \n",
    "        level_name=None, \n",
    "        axis=1\n",
    "    )\n",
    "    #-------------------------\n",
    "    pd_dfs.append(rcpx_0_pd_i)\n",
    "    \n",
    "# Make sure all dfs in pd_dfs look correct\n",
    "shape_0 = pd_dfs[0].shape\n",
    "index_0 = pd_dfs[0].index\n",
    "for i in range(len(pd_dfs)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    assert(pd_dfs[i].shape==shape_0)\n",
    "    assert(len(set(index_0).symmetric_difference(set(pd_dfs[i].index)))==0)\n",
    "    #-----\n",
    "    # Aligning the indices is not strictly necessary, as pd.concat should handle that\n",
    "    # But, it's best to be safe\n",
    "    pd_dfs[i] = pd_dfs[i].loc[index_0]\n",
    "    \n",
    "# Build rcpx_final by combining all dfs in pd_dfs\n",
    "rcpx_final = pd.concat(pd_dfs, axis=1)\n",
    "\n",
    "# Include back in the number of SNs per transformer (from xf_meter_cnt_srs)\n",
    "rcpx_final=rcpx_final.merge(\n",
    "    xf_meter_cnt_srs.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n",
    "# Sanity check on the merge\n",
    "assert(rcpx_final['nSNs'].notna().all().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401148db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9278f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3912673",
   "metadata": {},
   "source": [
    "# Normalize by nSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kind of silly, but below I cannot simply use 'rcpx_final[final_time_pds] = ...'\n",
    "#   This will result in: \"ValueError: Columns must be same length as key\", because final_time_pds\n",
    "#   has only, e.g., 6 elements but rcpx_final[final_time_pds] contains, e.g., 72 columns\n",
    "# Instead, must use 'rcpx_final[rcpx_final[final_time_pds].columns] = ..'\n",
    "rcpx_final[rcpx_final[final_time_pds].columns] = rcpx_final[final_time_pds].divide(rcpx_final[('nSNs', 'nSNs')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8472e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10c1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2246ee7",
   "metadata": {},
   "source": [
    "# Build EEMSP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79315f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_aws = Utilities.get_athena_prod_aws_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682519d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_eemsp = True\n",
    "mult_strategy='agg'\n",
    "#-------------------------\n",
    "cols_of_interest_eemsp = [\n",
    "    'location_nb', \n",
    "    'mfgr_nm', \n",
    "    'install_dt', \n",
    "    'last_trans_desc', \n",
    "    'eqtype_id', \n",
    "    'coolant', \n",
    "    'info', \n",
    "    'kva_size',\n",
    "    'phase_cnt', \n",
    "    'prim_voltage', \n",
    "    'protection', \n",
    "    'pru_number', \n",
    "    'sec_voltage', \n",
    "    'special_char', \n",
    "    'taps', \n",
    "    'xftype'\n",
    "]\n",
    "cols_of_interest_eemsp_full = cols_of_interest_eemsp + ['latest_status', 'removal_dt', 'serial_nb']\n",
    "#-------------------------\n",
    "sql_EEMSP = \"\"\"\n",
    "SELECT {} \n",
    "FROM meter_events.eems_transformer_nameplate\n",
    "WHERE location_nb IN ({})\n",
    "AND install_dt <= '{}'\n",
    "AND (removal_dt IS NULL OR removal_dt > '{}')\n",
    "\"\"\".format(\n",
    "    Utilities_sql.join_list(cols_of_interest_eemsp_full, quotes_needed=False), \n",
    "    Utilities_sql.join_list(trsf_pole_nbs, quotes_needed=True), \n",
    "    date_range[0], \n",
    "    date_range[1]\n",
    ")\n",
    "print(sql_EEMSP)\n",
    "#-------------------------\n",
    "df_eemsp = pd.read_sql_query(sql_EEMSP, conn_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eemsp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f4c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb9c4ff1",
   "metadata": {},
   "source": [
    "# Reduce down df_eemsp so there is a single entry for each transformer\n",
    "reduce1_eemsp_for_outg_trsf reduces df_eemsp down to contain only entries for transformers which were active during the date(s) in question.\n",
    "</br>No need to run reduce1_eemsp_for_outg_trsf for this case, as all share the same date restrictions which were already imposed in sql_EEMSP.\n",
    "</br>(For model development/training, this step would be necessary, as the data utilized there have many different date restrictions, and df_eemsp cannot simply be built with the date restrictions)\n",
    "\n",
    "reduce2_eemsp_for_outg_trsf futher reduces df_eemsp down so there is a single entry for each transformer.\n",
    "</br>How exactly this is achieved is dictated mainly by the \"mult_strategy\" parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60797c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce2_eemsp_for_outg_trsf was designed to be used with outg_rec_nb/no_outg_rec_nb.\n",
    "# outg_rec_nb is not necessary here, but we need a temporary column anyway to make the function happy.\n",
    "# I'll update the code in the future so this unnecessary step won't be needed\n",
    "df_eemsp['outg_rec_nb'] = df_eemsp['location_nb']\n",
    "#-----\n",
    "df_eemsp_reduce2 = reduce2_eemsp_for_outg_trsf(\n",
    "    df_eemsp=df_eemsp, \n",
    "    mult_strategy='agg', \n",
    "    include_n_eemsp=True, \n",
    "    outg_rec_nb_col='outg_rec_nb', \n",
    "    location_nb_col='location_nb', \n",
    "    numeric_cols = ['kva_size'], \n",
    "    dt_cols = ['install_dt', 'removal_dt'], \n",
    "    ignore_cols = ['serial_nb'], \n",
    "    cat_cols_as_strings=True\n",
    ")\n",
    "#-------------------------\n",
    "# No matter of the mult_strategy used, at this point df_eemsp_reduce2 should only have a single\n",
    "#   entry for each outg_rec_nb, location_nb pair\n",
    "assert(all(df_eemsp_reduce2[['outg_rec_nb', 'location_nb']].value_counts()==1))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Clean up df_eemsp_reduce2 and merge with rcpx_final\n",
    "#--------------------------------------------------\n",
    "# Can't simply take df_eemsp_reduce2[cols_of_interest_eemsp] because we need also the new column\n",
    "#   OUTG_REC_NB_TO_MERGE (and any others which may be added in the future)\n",
    "cols_to_drop = list(set(cols_of_interest_eemsp_full).difference(set(cols_of_interest_eemsp)))\n",
    "cols_to_drop = [x for x in cols_to_drop if x in df_eemsp_reduce2.columns]\n",
    "if len(cols_to_drop)>0:\n",
    "    df_eemsp_reduce2 = df_eemsp_reduce2.drop(columns=cols_to_drop)\n",
    "#-------------------------\n",
    "assert(df_eemsp_reduce2.shape[0]==df_eemsp_reduce2.groupby(['outg_rec_nb', 'location_nb']).ngroups)\n",
    "print(f\"df_eemsp_reduce2['location_nb'].nunique() = {df_eemsp_reduce2['location_nb'].nunique()}\")\n",
    "print(f\"len(trsf_pole_nbs)                        = {len(trsf_pole_nbs)}\")\n",
    "print(f\"Diff                                      = {len(trsf_pole_nbs)-df_eemsp_reduce2['location_nb'].nunique()}\")\n",
    "print()\n",
    "#-------------------------\n",
    "# Make all EEMSP columns (except n_eemsp) uppercase to match what was done in model development (where EEMSP)\n",
    "#   data were grabbed from the Oracle database, and columns were all uppercase)\n",
    "df_eemsp_reduce2 = Utilities_df.make_all_column_names_uppercase(df_eemsp_reduce2, cols_to_exclude=['n_eemsp'])\n",
    "\n",
    "# Similar to the case with 'outg_rec_nb' column in df_eemsp above, merge_rcpx_with_eemsp was designed to be \n",
    "#   used with outg_rec_nb/no_outg_rec_nb.\n",
    "# As such, rcpx_final needs an additional column (in this case, it is easier to add another level to the index)\n",
    "# I'll update the code in the future so this unnecessary step won't be needed\n",
    "rcpx_final = rcpx_final.set_index([rcpx_final.index, rcpx_final.index])\n",
    "#-------------------------\n",
    "print(\"\\nShapes BEFORE merging\")\n",
    "print(f\"rcpx_final.shape = {rcpx_final.shape}\")\n",
    "#-------------------------\n",
    "rcpx_final = merge_rcpx_with_eemsp(\n",
    "    df_rcpx=rcpx_final, \n",
    "    df_eemsp=df_eemsp_reduce2, \n",
    "    outg_rec_nb_idfr_rcpx ='index_0', \n",
    "    trsf_pole_nb_idfr_rcpx='index_1', \n",
    "    outg_rec_nb_idfr_eemsp='OUTG_REC_NB', \n",
    "    location_nb_idfr_eemsp='LOCATION_NB', \n",
    "    set_index=True\n",
    ")\n",
    "#-------------------------\n",
    "print(\"\\nShapes AFTER merging\")\n",
    "print(f\"rcpx_final.shape = {rcpx_final.shape}\")\n",
    "#-------------------------\n",
    "# Drop the unnecessary index level that was added above and is no longer needed\n",
    "rcpx_final=rcpx_final.droplevel(0, axis=0)\n",
    "\n",
    "# Convert INSTALL_DT to age in years\n",
    "rcpx_final[('EEMSP_0', 'INSTALL_DT')] = (prediction_date-rcpx_final[('EEMSP_0', 'INSTALL_DT')]).dt.total_seconds()/(60*60*24*365)\n",
    "\n",
    "# Add month\n",
    "rcpx_final[('dummy_lvl_0', 'outg_month')] = prediction_date.month\n",
    "#-------------------------\n",
    "# Make sure rcpx_final has the correct columns in the correct order\n",
    "assert(len(set(data_structure_df.columns).symmetric_difference(set(rcpx_final.columns)))==0)\n",
    "rcpx_final=rcpx_final[data_structure_df.columns]\n",
    "X_test = rcpx_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316568f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e08c24d1",
   "metadata": {},
   "source": [
    "# Load Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = joblib.load(os.path.join(model_dir, 'forest_clf.joblib'))\n",
    "scaler     = joblib.load(os.path.join(model_dir, 'scaler.joblib'))\n",
    "eemsp_enc  = joblib.load(os.path.join(model_dir, 'eemsp_encoder.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2da13",
   "metadata": {},
   "source": [
    "# Transformations/scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "cols_to_encode = data_structure_df['EEMSP_0'].columns\n",
    "numeric_cols = ['KVA_SIZE', 'INSTALL_DT']\n",
    "cols_to_encode = [x for x in cols_to_encode if x not in numeric_cols]\n",
    "assert(len(set(eemsp_enc.feature_names_in_).symmetric_difference(cols_to_encode))==0)\n",
    "assert(set(X_test['EEMSP_0'].columns).difference(eemsp_enc.feature_names_in_)==set(numeric_cols))\n",
    "#-----\n",
    "cols_to_encode = [('EEMSP_0', x) for x in cols_to_encode if x not in numeric_cols]\n",
    "X_test[cols_to_encode] = X_test[cols_to_encode].astype(str)\n",
    "X_test[cols_to_encode] = eemsp_enc.transform(X_test[cols_to_encode].droplevel(0, axis=1))\n",
    "#----------\n",
    "X_test = scaler.transform(X_test)\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b06895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# Outages Predicted: {y_pred.sum()}\")\n",
    "print(f\"# Predictions:       {y_pred.shape[0]}\")\n",
    "print(f\"%:                   {100*y_pred.sum()/y_pred.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e282d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dfda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predictions column in rcpx_final\n",
    "assert(rcpx_final.shape[0]==y_pred.shape[0])\n",
    "rcpx_final['y_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final[rcpx_final['y_pred']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f2ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp_install_time_col = 'inst_ts'\n",
    "df_mp_removal_time_col = 'rmvl_ts'\n",
    "dt_0 = prediction_date\n",
    "dt_1 = prediction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b90570",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "    trsf_pole_nbs=rcpx_final.index.tolist(), \n",
    "    join_curr_hist=True, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    assume_one_xfmr_per_PN=True, \n",
    "    drop_approx_duplicates=True, \n",
    "    drop_approx_duplicates_args=None, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb'\n",
    ")\n",
    "\n",
    "# Only want meters active at the relevant time period\n",
    "mp_df = mp_df[(mp_df[df_mp_install_time_col]<=pd.to_datetime(dt_0)) & \n",
    "              (mp_df[df_mp_removal_time_col].fillna(pd.Timestamp.max)>pd.to_datetime(dt_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f33663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        premise_nbs=mp_df['prem_nb'].unique().tolist(), \n",
    "        date_range=[\n",
    "            prediction_date-pd.Timedelta('31D'), \n",
    "            prediction_date+pd.Timedelta('31D')\n",
    "        ], \n",
    "        field_to_split='premise_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated=False\n",
    ")\n",
    "dovs_df = dovs.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df = pd.merge(\n",
    "    dovs_df, \n",
    "    mp_df[['prem_nb', 'trsf_pole_nb']].drop_duplicates(), \n",
    "    left_on='PREMISE_NB', \n",
    "    right_on='prem_nb', \n",
    "    how='left'\n",
    ")\n",
    "dovs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df_pred1 = mp_df[mp_df['trsf_pole_nb'].isin(rcpx_final[rcpx_final['y_pred']==1].index.tolist())].copy()\n",
    "dovs_df_pred1 = dovs_df[dovs_df['PREMISE_NB'].isin(mp_df_pred1['prem_nb'].unique().tolist())]\n",
    "#-----\n",
    "mp_df_pred0 = mp_df[mp_df['trsf_pole_nb'].isin(rcpx_final[rcpx_final['y_pred']==0].index.tolist())].copy()\n",
    "dovs_df_pred0 = dovs_df[dovs_df['PREMISE_NB'].isin(mp_df_pred0['prem_nb'].unique().tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ef5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66392fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_pred1['DT_OFF_TS_FULL'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75983ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_pred0['DT_OFF_TS_FULL'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7d2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_pred1['DT_OFF_TS_FULL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb57aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(dovs_df_pred1['DT_OFF_TS_FULL'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred1.plot.scatter(ax=ax, x='DT_OFF_TS_FULL', y='CI_NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred1.plot.scatter(ax=ax, x='DT_OFF_TS_FULL', y='CMI_NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_pred1.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred1.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['OUTG_REC_NB'].count().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred0.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['OUTG_REC_NB'].count().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74cd089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad847a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred1.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['CI_NB'].sum().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred0.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['CI_NB'].sum().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447979cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a770f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20067",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred1.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['CMI_NB'].sum().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = Plot_General.default_subplots()\n",
    "dovs_df_pred0.groupby(pd.Grouper(freq='1D', key='DT_OFF_TS_FULL'))['CMI_NB'].sum().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aac3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8ef15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34720935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['OUTG_REC_NB'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e32b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['trsf_pole_nb'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final[rcpx_final['y_pred']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dovs_df['trsf_pole_nb'].unique()).intersection(set(rcpx_final[rcpx_final['y_pred']==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(rcpx_final[rcpx_final['y_pred']==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(dovs_df['trsf_pole_nb'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bae35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4155b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dovs_df['trsf_pole_nb'].unique()).intersection(set(rcpx_final.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d074d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b901fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73f15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47048600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
