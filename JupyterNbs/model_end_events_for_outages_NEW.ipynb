{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb520489",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./model_end_events_for_outages_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5755605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "from functools import reduce\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "from EEMSP import EEMSP\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from MECPOCollection import MECPOCollection\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from OutageModeler import OutageModeler\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSingleSlicer as DFSingleSlicer\n",
    "from CustomJSON import CustomEncoder, CustomWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459065",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dae38-9ed4-431f-a449-7f2f92363b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb10d8-0602-4899-8eb0-9ef7b8a16373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38085a78-ad70-4cb5-8cf3-c8fc0aa0156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Parameters: General\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# save_base_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20231201\\Models'\n",
    "save_base_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20240907\\Models'\n",
    "#-----\n",
    "# save_sub_dir  = None\n",
    "# save_sub_dir = 'All_EEMSP_agg_Top10_v5'\n",
    "save_sub_dir = 'All_EEMSP_agg_Top10_noMonth_20250219'\n",
    "#-----\n",
    "include_prbl = True\n",
    "verbose      = True\n",
    "force_fresh_data_build = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975af6a-84e0-4cd5-ba6f-7b621da79ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Parameters: Building/grabbing MECPOCollection objects (and merged_dfs, etc.)\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# The following can be set individually for _outg/_otbl/_prbl if needed:\n",
    "#     acq_run_date, data_date_ranges, data_dir_base\n",
    "#   e.g., one can use acq_run_date to set for all, or acq_run_date_outg to set _outg individually\n",
    "# Slightly special case:\n",
    "#  grp_by_cols_bsln can be used to set grp_by_cols_otbl and grp_by_cols_prbl, but grp_by_cols_outg must be set separately\n",
    "#---------------------------------------------------------------------------\n",
    "save_data = True\n",
    "\n",
    "acq_run_date              = '20240907'\n",
    "data_date_ranges          = [\n",
    "    ['2023-04-01', '2024-08-31'], \n",
    "]\n",
    "#-----\n",
    "cpx_dfs_name              = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "#-----\n",
    "data_dir_base             = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data'\n",
    "#-----\n",
    "grp_by_cols_outg          = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "grp_by_cols_bsln          = ['trsf_pole_nb', 'no_outg_rec_nb']\n",
    "#-----\n",
    "std_dict_grp_by_cols_outg = {\n",
    "    'outg_rec_nb'  : 'outg_rec_nb', \n",
    "    'trsf_pole_nb' : 'trsf_pole_nb'\n",
    "}\n",
    "std_dict_grp_by_cols_bsln = {\n",
    "    'no_outg_rec_nb'  : 'outg_rec_nb', \n",
    "    'trsf_pole_nb'    : 'trsf_pole_nb'\n",
    "}\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb992c6-0a95-497f-9b2f-b3729560e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THESE SHOULD BE ADDED TO MODEL_SUMMARY_DICT AND AUTOMATICALLY EXTRACTED!!!!!\n",
    "# freq                        = '5D', \n",
    "# group_cols                  = ['trsf_pole_nb'], \n",
    "# date_col                    = 'aep_event_dt', \n",
    "# normalize_by_SNs            = True, \n",
    "# include_power_down_minus_up = False, \n",
    "# regex_patterns_to_remove    = ['.*cleared.*', '.*Test Mode.*'], \n",
    "# combine_cpo_df_reasons      = True, \n",
    "# include_n_eemsp             = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc062e-2e7b-452b-99c1-90473954dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "freq='5D'\n",
    "days_min_max_outg_td_windows=[\n",
    "    [1,6], [6,11], [11,16], [16,21], [21,26], [26,31]\n",
    "]\n",
    "old_to_new_keys_dict = None\n",
    "#-------------------------\n",
    "normalize_by_time_interval  = True\n",
    "#-------------------------\n",
    "include_power_down_minus_up = False\n",
    "#-------------------------\n",
    "regex_to_remove_patterns    = ['.*cleared.*', '.*Test Mode.*']\n",
    "regex_to_remove_ignore_case = True\n",
    "#-------------------------\n",
    "max_total_counts = None\n",
    "# max_total_counts=150\n",
    "# max_total_counts={\n",
    "#     '01-05 Days':150, \n",
    "#     '06-10 Days':150, \n",
    "#     '11-15 Days':150, \n",
    "#     '16-20 Days':150,\n",
    "#     '21-25 Days':150, \n",
    "#     '26-30 Days':150\n",
    "# }\n",
    "how_max_total_counts='any'\n",
    "#-------------------------  \n",
    "mecpo_idx_for_ordering = 0\n",
    "#------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a6aa1-6668-4972-9139-59f846e32665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Parameters: Building the final train/test/holdout datasets and running model fit\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "save_model = True\n",
    "\n",
    "# random_state = None\n",
    "random_state = 42\n",
    "#-------------------------\n",
    "n_top_reasons_to_inclue = 10\n",
    "# n_top_reasons_to_inclue = None\n",
    "combine_others          = True\n",
    "#-------------------------\n",
    "merge_eemsp = True\n",
    "eemsp_mult_strategy='agg'\n",
    "#-------------------------\n",
    "include_month = False\n",
    "#-------------------------\n",
    "an_keys_to_drop = None\n",
    "# an_keys_to_drop = ['00-01 Days']\n",
    "# an_keys_to_drop = ['01-06 Days']\n",
    "#-------------------------\n",
    "date_0_train   = pd.to_datetime('2023-04-01')\n",
    "date_1_train   = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_test    = pd.to_datetime('2023-04-01')\n",
    "date_1_test    = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_holdout = None\n",
    "date_1_holdout = None\n",
    "\n",
    "#-------------------------\n",
    "test_size                = 0.33\n",
    "get_train_test_by_date   = False\n",
    "split_train_test_by_outg = True \n",
    "#-------------------------\n",
    "create_validation_set = False\n",
    "val_size              = 0.10 #w.r.t to train size (i.e., w.r.t 1.0-test_size)\n",
    "#-------------------------\n",
    "run_scaler=True\n",
    "#-------------------------\n",
    "run_PCA = False\n",
    "pca_n_components=0.95\n",
    "#-------------------------\n",
    "remove_others_from_outages=False\n",
    "#-------------------------\n",
    "# min_pct_target_1 = 25\n",
    "min_pct_target_1 = None\n",
    "#-------------------------\n",
    "reduce_train_size = False\n",
    "red_test_size = 0.75 #Amount kept will be 1.0-red_test_size\n",
    "#-------------------------\n",
    "outgs_slicer = OutageModeler.get_dummy_slicer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb011722-c374-4a97-a95d-a122d0812544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa757a67-47ab-46c3-a882-ef85f3822f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_0 = OutageModeler(\n",
    "    include_prbl                 = include_prbl, \n",
    "    save_base_dir                = save_base_dir, \n",
    "    save_sub_dir                 = save_sub_dir, \n",
    "    force_fresh_data_build       = force_fresh_data_build, \n",
    "    verbose                      = verbose, \n",
    "    #\n",
    "    acq_run_date                 = acq_run_date, \n",
    "    data_date_ranges             = data_date_ranges, \n",
    "    cpx_dfs_name                 = cpx_dfs_name, \n",
    "    data_dir_base                = data_dir_base, \n",
    "    grp_by_cols_outg             = grp_by_cols_outg,   \n",
    "    grp_by_cols_bsln             = grp_by_cols_bsln, \n",
    "    std_dict_grp_by_cols_outg    = std_dict_grp_by_cols_outg, \n",
    "    std_dict_grp_by_cols_bsln    = std_dict_grp_by_cols_bsln, \n",
    "    #\n",
    "    freq                         = freq, \n",
    "    days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "    old_to_new_keys_dict         = None, \n",
    "    normalize_by_time_interval   = normalize_by_time_interval, \n",
    "    include_power_down_minus_up  = include_power_down_minus_up, \n",
    "    regex_to_remove_patterns     = regex_to_remove_patterns, \n",
    "    regex_to_remove_ignore_case  = regex_to_remove_ignore_case, \n",
    "    max_total_counts             = max_total_counts, \n",
    "    how_max_total_counts         = how_max_total_counts, \n",
    "    mecpo_idx_for_ordering       = mecpo_idx_for_ordering, \n",
    "    #\n",
    "    random_state                 = random_state, \n",
    "    n_top_reasons_to_inclue      = n_top_reasons_to_inclue, \n",
    "    combine_others               = combine_others, \n",
    "    merge_eemsp                  = merge_eemsp, \n",
    "    eemsp_mult_strategy          = eemsp_mult_strategy, \n",
    "    include_month                = include_month, \n",
    "    an_keys_to_drop              = an_keys_to_drop, \n",
    "    date_0_train                 = date_0_train, \n",
    "    date_1_train                 = date_1_train, \n",
    "    date_0_test                  = date_0_test, \n",
    "    date_1_test                  = date_1_test, \n",
    "    date_0_holdout               = date_0_holdout, \n",
    "    date_1_holdout               = date_1_holdout, \n",
    "    test_size                    = test_size, \n",
    "    get_train_test_by_date       = get_train_test_by_date, \n",
    "    split_train_test_by_outg     = split_train_test_by_outg, \n",
    "    create_validation_set        = create_validation_set, \n",
    "    val_size                     = val_size, \n",
    "    run_scaler                   = run_scaler, \n",
    "    run_PCA                      = run_PCA, \n",
    "    pca_n_components             = pca_n_components,\n",
    "    remove_others_from_outages   = remove_others_from_outages, \n",
    "    min_pct_target_1             = min_pct_target_1, \n",
    "    reduce_train_size            = reduce_train_size, \n",
    "    red_test_size                = red_test_size, \n",
    "    outgs_slicer                 = outgs_slicer, \n",
    ")\n",
    "outg_mdlr_0.compile_data(\n",
    "    assert_can_model  = True, \n",
    "    print_dumb_scores = True, \n",
    "    verbose           = True\n",
    ")\n",
    "\n",
    "#-----\n",
    "# Initialize model and run fit\n",
    "#-----\n",
    "\n",
    "outg_mdlr_0.init_model_clf(\n",
    "    model_type = 'random_forest', \n",
    "    n_estimators = 1000, \n",
    "    max_depth    = 25, \n",
    "    criterion    = 'gini',  \n",
    "    class_weight = None,   \n",
    "    n_jobs       = None, \n",
    ")\n",
    "\n",
    "# outg_mdlr_0.init_model_clf(\n",
    "#     model_type = 'random_forest', \n",
    "#     n_estimators = 10, \n",
    "#     max_depth    = 5, \n",
    "#     criterion    = 'gini',  \n",
    "#     class_weight = None,   \n",
    "#     n_jobs       = None, \n",
    "# )\n",
    "\n",
    "outg_mdlr_0.fit(verbose=True)\n",
    "outg_mdlr_0.predict(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143a47c-c4fd-4b0b-8024-c24126dfc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097973a-eac4-4f42-a721-0e316380638e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf9a3a-250e-4031-a22d-7fdc7309309d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9c52e-4897-4685-b4ae-34f4bc72d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outg_mdlr_0.save_model()\n",
    "# outg_mdlr_0.save_summary_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0ae8e-5296-433e-9cfb-244572d3adff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa551e8-70ae-4666-8a6a-bf825c5a2f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e3afd-9cf9-4910-927e-73f10bba3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "trsf_loc_info_df = outg_mdlr_0.compile_trsf_location_info_df()\n",
    "#-------------------------\n",
    "trsf_loc_info_df = DOVSOutages.remove_trsf_pole_nb_without_numeric_digit(\n",
    "    df               = trsf_loc_info_df, \n",
    "    trsf_pole_nb_col = 'trsf_pole_nb'\n",
    ")\n",
    "#-------------------------\n",
    "# The dataset doesn't really matter, nor does the zip+4, so drop\n",
    "trsf_loc_info_df = trsf_loc_info_df.drop(columns=['dataset', 'zip+4']).drop_duplicates().reset_index(drop=True)\n",
    "#-------------------------\n",
    "# For our purposes here, we want each trsf_pole_nb to correspond to exactly one zip code.\n",
    "# The location of the trsf_pole_nb is inferred from the connected meters, meaning that some poles\n",
    "#   can span multiple zip codes.\n",
    "# To solve this, for each trsf_pole_nb, we will simply keep only the entry with the largest nPNs value.\n",
    "# Things are complicated slightly by the fact that we also track the date_pd now, for cases where multiple\n",
    "#   date periods are combined for an analysis.\n",
    "# Therefore, for each (trsf_pole_nb, date_pd) we will keep the entry with the largest nPNs value.\n",
    "# This should remain stable over different date periods, but it will be interesting to check this in the future\n",
    "trsf_loc_info_df = trsf_loc_info_df.loc[trsf_loc_info_df.groupby(['trsf_pole_nb', 'date_pd'])['nPNs_xfmri_sa4i'].idxmax()].reset_index(drop=True)\n",
    "assert(trsf_loc_info_df[['trsf_pole_nb', 'date_pd']].value_counts().shape[0] == trsf_loc_info_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547367b-dfa9-4794-aece-e7d94ded0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df['county_nm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b3513-f705-4dac-a97e-a0d63ac1eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df['county_nm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f9174-e55f-47ad-aa24-ec77b47508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b7878-1afe-44bc-b843-550f72aab9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ea2ab-4408-4303-8d35-03628ce7bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_i = '43214'\n",
    "trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip']==zip_i]['trsf_pole_nb'].unique().tolist()\n",
    "\n",
    "zip_slcr_i = DFSlicer(\n",
    "    single_slicers      = [dict(\n",
    "        column              = ('index', 'trsf_pole_nb'), \n",
    "        value               = trsf_pole_nbs_i, \n",
    "        comparison_operator = 'isin'\n",
    "    )], \n",
    "    name                = zip_i, \n",
    "    apply_not           = False, \n",
    "    join_single_slicers = 'and'    \n",
    ")\n",
    "\n",
    "outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i)\n",
    "#-----\n",
    "# In general, need a way of determining which functions need called\n",
    "outg_mdlr_i.finalize_data(\n",
    "    assert_can_model  = True, \n",
    "    print_dumb_scores = True, \n",
    "    verbose           = True\n",
    ")\n",
    "outg_mdlr_i.init_model_clf()\n",
    "outg_mdlr_i.fit()\n",
    "outg_mdlr_i.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5213b-a4bf-4877-b100-7974d6bf55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_i.df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163e830-896e-4c58-a52a-dab36514fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adf068-aa74-4bdb-ae5a-947779d47b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_pop_df = pd.read_pickle(r'C:\\Users\\s346557\\Downloads\\zip_pop_df.pkl')\n",
    "#-----\n",
    "zip_clusters_df = zip_pop_df.groupby(['cluster_5']).agg({\n",
    "    'zip' : list, \n",
    "    'population' : 'sum'\n",
    "})\n",
    "zip_clusters_df = zip_clusters_df.rename(columns={'zip':'zips'})\n",
    "#-----\n",
    "zip_clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed6aaa-3a99-4d93-99a6-8c2ca23be856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf62514a-aae8-4ec7-ac50-92a88ef71903",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d062294-fa6a-4fff-8c85-43e2d1f20ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df = trsf_loc_info_df.loc[~trsf_loc_info_df['trsf_pole_nb'].isin(['NETWORK', 'PRIMARY', ' '])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e03370-99e4-4bb0-bfa7-4915945771bd",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f14f0-7d22-4630-8d8c-7ebb337fb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff399695-220f-4059-ad04-9c9b41efc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df_wgrps = pd.merge(\n",
    "    trsf_loc_info_df, \n",
    "    zip_clusters_df.explode('zips').reset_index().drop(columns=['population']), \n",
    "    how      = 'left', \n",
    "    left_on  = 'zip', \n",
    "    right_on = 'zips'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d98ea8-47e4-4152-8e98-c45e27d9f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df_wgrps['cluster_5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444564e6-6f63-473e-a9ce-4ad4f61e351d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b68fc-5086-4d9c-a3e4-087998f2f6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # OLD\n",
    "# ledger = dict()\n",
    "# for i_clstr, row_i in zip_clusters_df.iterrows():\n",
    "#     zips_i = row_i['zips']\n",
    "#     print(i_clstr)\n",
    "#     print(zips_i)\n",
    "#     print()\n",
    "#     try:\n",
    "#         trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip'].isin(zips_i)]['trsf_pole_nb'].unique().tolist()\n",
    "#         #-----\n",
    "#         # Each trsf_pole_nb should be mapped to only one model\n",
    "#         assert(set(ledger.keys()).intersection(set(trsf_pole_nbs_i))==set())\n",
    "#         #-----\n",
    "#         # Update the ledger with the new pole_nb/cluster information\n",
    "#         ledger.update({pole_j:i_clstr for pole_j in trsf_pole_nbs_i})        \n",
    "#         zip_slcr_i = DFSlicer(\n",
    "#             single_slicers      = [dict(\n",
    "#                 column              = ('index', 'trsf_pole_nb'), \n",
    "#                 value               = trsf_pole_nbs_i, \n",
    "#                 comparison_operator = 'isin'\n",
    "#             )], \n",
    "#             name                = str(zips_i), \n",
    "#             apply_not           = False, \n",
    "#             join_single_slicers = 'and'    \n",
    "#         )\n",
    "        \n",
    "#         outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i, save_model=True, new_save_sub_dir=str(i_clstr))\n",
    "#         #-----\n",
    "#         # In general, need a way of determining which functions need called\n",
    "#         outg_mdlr_i.build_train_test_data()\n",
    "#         outg_mdlr_i.finalize_train_test_data()\n",
    "#         outg_mdlr_i.init_model_clf()\n",
    "#         outg_mdlr_i.fit()\n",
    "#         outg_mdlr_i.predict()\n",
    "#     except:\n",
    "#         print('FAILED!!!!!')\n",
    "#     print('\\n'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855ad9d-6808-4825-88a2-3b382bf93570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a874f14-2659-4237-bae3-ddce043dffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger = zip_pop_df.set_index('zip')['cluster_5'].to_dict()\n",
    "for i_clstr, row_i in zip_clusters_df.iterrows():\n",
    "    zips_i = row_i['zips']\n",
    "    print(i_clstr)\n",
    "    print(zips_i)\n",
    "    print()\n",
    "    try:\n",
    "        trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip'].isin(zips_i)]['trsf_pole_nb'].unique().tolist()\n",
    "        #-----    \n",
    "        zip_slcr_i = DFSlicer(\n",
    "            single_slicers      = [dict(\n",
    "                column              = ('index', 'trsf_pole_nb'), \n",
    "                value               = trsf_pole_nbs_i, \n",
    "                comparison_operator = 'isin'\n",
    "            )], \n",
    "            name                = str(zips_i), \n",
    "            apply_not           = False, \n",
    "            join_single_slicers = 'and'    \n",
    "        )\n",
    "        \n",
    "        outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i, save_model=True, new_save_sub_dir=str(i_clstr))\n",
    "        #-----\n",
    "        # In general, need a way of determining which functions need called\n",
    "        outg_mdlr_i.finalize_data(\n",
    "            assert_can_model  = False, \n",
    "            print_dumb_scores = True, \n",
    "            verbose           = True\n",
    "        )\n",
    "        if not outg_mdlr_i.can_model:\n",
    "            print('Cannot model!!!!! Skipping')\n",
    "            print('\\n'*5)\n",
    "            continue\n",
    "        outg_mdlr_i.init_model_clf()\n",
    "        outg_mdlr_i.fit()\n",
    "        outg_mdlr_i.predict()\n",
    "    except:\n",
    "        print('FAILED!!!!!')\n",
    "    print('\\n'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fe64b-fc7f-4b41-aa7e-f14ea9efab6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daa86f-ba0b-43a4-b98f-87f34d628e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outg_mdlr_i.save_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecef020-0502-4764-94ee-5d92e82a213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomWriter.output_dict_to_json(\n",
    "    os.path.join(outg_mdlr_i.save_base_dir, 'ledger.json'), \n",
    "    ledger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4bec72-f83a-4a9c-82d8-707783c3cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outg_mdlr_0.save_model()\n",
    "# outg_mdlr_0.save_summary_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc86-3304-413b-ac9b-6ded59197ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_i.save_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379c545-a809-4763-859c-041dc67af3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_i = '43235'\n",
    "trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip']==zip_i]['trsf_pole_nb'].unique().tolist()\n",
    "\n",
    "zip_slcr_i = DFSlicer(\n",
    "    single_slicers      = [dict(\n",
    "        column              = ('index', 'trsf_pole_nb'), \n",
    "        value               = trsf_pole_nbs_i, \n",
    "        comparison_operator = 'isin'\n",
    "    )], \n",
    "    name                = zip_i, \n",
    "    apply_not           = False, \n",
    "    join_single_slicers = 'and'    \n",
    ")\n",
    "\n",
    "outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i)\n",
    "#-----\n",
    "# In general, need a way of determining which functions need called\n",
    "outg_mdlr_i.build_train_test_data()\n",
    "outg_mdlr_i.finalize_train_test_data()\n",
    "outg_mdlr_i.init_model_clf()\n",
    "outg_mdlr_i.fit()\n",
    "outg_mdlr_i.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64927e-99f5-4a55-bf04-4c31183f674c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fac408-3b9f-4258-bfb4-75ca08291d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_i = '43235'\n",
    "trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip']==zip_i]['trsf_pole_nb'].unique().tolist()\n",
    "\n",
    "zip_slcr_i = DFSlicer(\n",
    "    single_slicers      = [dict(\n",
    "        column              = ('index', 'trsf_pole_nb'), \n",
    "        value               = trsf_pole_nbs_i, \n",
    "        comparison_operator = 'isin'\n",
    "    )], \n",
    "    name                = zip_i, \n",
    "    apply_not           = False, \n",
    "    join_single_slicers = 'and'    \n",
    ")\n",
    "\n",
    "outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i)\n",
    "#-----\n",
    "# In general, need a way of determining which functions need called\n",
    "outg_mdlr_i.build_train_test_data()\n",
    "outg_mdlr_i.finalize_train_test_data()\n",
    "outg_mdlr_i.init_model_clf(\n",
    "    model_type = 'random_forest', \n",
    "    n_estimators = 100, \n",
    "    max_depth    = 25, \n",
    "    criterion    = 'gini',  #'gini' or 'entropy', \n",
    "    class_weight = None,   # None or 'balanced'\n",
    "    n_jobs       = None,     \n",
    ")\n",
    "outg_mdlr_i.fit()\n",
    "outg_mdlr_i.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92adb8f-c06e-4be3-aad0-76ac28aa4a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2a0f4-8e70-417f-986a-678348d1907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_i = '43148'\n",
    "trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['zip']==zip_i]['trsf_pole_nb'].unique().tolist()\n",
    "\n",
    "zip_slcr_i = DFSlicer(\n",
    "    single_slicers      = [dict(\n",
    "        column              = ('index', 'trsf_pole_nb'), \n",
    "        value               = trsf_pole_nbs_i, \n",
    "        comparison_operator = 'isin'\n",
    "    )], \n",
    "    name                = zip_i, \n",
    "    apply_not           = False, \n",
    "    join_single_slicers = 'and'    \n",
    ")\n",
    "\n",
    "outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i)\n",
    "#-----\n",
    "# In general, need a way of determining which functions need called\n",
    "outg_mdlr_i.build_train_test_data()\n",
    "outg_mdlr_i.finalize_train_test_data()\n",
    "outg_mdlr_i.init_model_clf()\n",
    "outg_mdlr_i.fit()\n",
    "outg_mdlr_i.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf48401-d667-48ca-acef-ba686776322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_i.merged_df_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd0b66-1df4-4276-932e-84fbbdf1b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_i.merged_df_otbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e70cc-dead-4c9d-b863-75dd5dbc4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr_i.time_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb2849-3b8b-4bc0-a742-02bf33b1458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4eef5-9462-4483-99dd-b993fc709181",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'COLUMBUS'\n",
    "trsf_pole_nbs_i = trsf_loc_info_df[trsf_loc_info_df['city']==city]['trsf_pole_nb'].unique().tolist()\n",
    "\n",
    "zip_slcr_i = DFSlicer(\n",
    "    single_slicers      = [dict(\n",
    "        column              = ('index', 'trsf_pole_nb'), \n",
    "        value               = trsf_pole_nbs_i, \n",
    "        comparison_operator = 'isin'\n",
    "    )], \n",
    "    name                = city, \n",
    "    apply_not           = False, \n",
    "    join_single_slicers = 'and'    \n",
    ")\n",
    "\n",
    "outg_mdlr_i = outg_mdlr_0.slice_off_model(zip_slcr_i)\n",
    "#-----\n",
    "# In general, need a way of determining which functions need called\n",
    "outg_mdlr_i.build_train_test_data()\n",
    "outg_mdlr_i.finalize_train_test_data()\n",
    "outg_mdlr_i.init_model_clf(\n",
    "    model_type = 'random_forest', \n",
    "    n_estimators = 100, \n",
    "    max_depth    = 10, \n",
    "    criterion    = 'gini',  #'gini' or 'entropy', \n",
    "    class_weight = None,   # None or 'balanced'\n",
    "    n_jobs       = None,     \n",
    ")\n",
    "outg_mdlr_i.fit()\n",
    "outg_mdlr_i.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f016a2-c2dc-42bc-9961-2d30603a88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_loc_info_df[trsf_loc_info_df['city']==city]['zip'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ee2af-6a21-4db7-996e-249b37151df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483ce4e-e21d-4188-98ae-41e6270d7104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973a8b5-a48d-43ab-8079-830077310851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d5ab4-a137-43a7-9895-5f245ab8481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662e758-13e5-4f2f-b1ed-02c43afb9711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a274a-2c29-4dba-b955-f6e770e55236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ddf7f-476b-472b-b00d-cbe61b9811cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515bf8cf-47be-4682-ad85-bcf2469476d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20231201\\Models\\All_EEMSP_agg_Top10_v5\\data_structure_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e29d1-ec93-4ce8-8828-1843d3c796f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(idk.columns.get_level_values(1).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd064717-4e96-4aca-9ea7-5ae9f962e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ddf71-9ae4-4e80-bf2c-e188f9364554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85a033-5875-4e75-9747-7009a6ed9a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "200719d2-6baf-4861-a71b-7f0bcb21afaf",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
