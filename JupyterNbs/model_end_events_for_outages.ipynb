{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50003e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb520489",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./model_end_events_for_outages_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5755605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "from functools import reduce\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "from EEMSP import EEMSP\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from MECPOCollection import MECPOCollection\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from OutageModeler import OutageModeler\n",
    "from OMInput import OMInput\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from CustomJSON import CustomEncoder, CustomWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459065",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "data_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data'\n",
    "\n",
    "# save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\Models_00_05'\n",
    "# save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\Models'\n",
    "save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20231221\\Models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d97a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "save_model   = False\n",
    "\n",
    "# save_dir_model = None\n",
    "save_dir_model = 'All_EEMSP_agg_Top10_v3'\n",
    "if save_dir_model is None:\n",
    "    save_dir_model = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir_model = os.path.join(save_dir_model_base, save_dir_model)\n",
    "#-----\n",
    "if not os.path.exists(save_dir_model) and (save_results or save_model):\n",
    "    os.makedirs(save_dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_mecpo_colls = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    verbose = True\n",
    "    #----- Outages -------------------------------------------------------------\n",
    "    # run_date_outg = '20230615'\n",
    "    # event_date_ranges_outg = [\n",
    "    #     ['2020-01-01', '2020-12-31'],\n",
    "    #     ['2021-01-01', '2021-12-31'], \n",
    "    #     ['2022-01-01', '2022-09-30'], \n",
    "    # ]\n",
    "    # run_date_outg = '20231201'\n",
    "    # event_date_ranges_outg = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_outg = '20240908'\n",
    "    event_date_ranges_outg = [\n",
    "        ['2023-04-01', '2024-08-31'], \n",
    "    ]\n",
    "    grp_by_cols_outg = ['outg_rec_nb', 'trsf_pole_nb']    \n",
    "    #----- No Outages ----------------------------------------------------------\n",
    "    # run_date_no_outg = '20230512'\n",
    "    # event_date_ranges_no_outg = [\n",
    "    #     ['2022-01-01', '2022-12-31'], \n",
    "    # ]\n",
    "    # run_date_no_outg = '20231201'\n",
    "    # event_date_ranges_no_outg = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_no_outg = '20240908'\n",
    "    event_date_ranges_no_outg = [\n",
    "        ['2023-04-01', '2024-08-31'], \n",
    "    ]\n",
    "    grp_by_cols_no_outg = ['trsf_pole_nb', 'no_outg_rec_nb']    \n",
    "    #----- No Outages Pristine -------------------------------------------------\n",
    "    # run_date_no_outg_prstn = '20230301'\n",
    "    # event_date_ranges_no_outg_prstn = [\n",
    "    #     ['2022-01-01', '2022-12-31'], \n",
    "    # ]\n",
    "    # run_date_no_outg_prstn = '20231201'\n",
    "    # event_date_ranges_no_outg_prstn = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_no_outg_prstn = '20240908'\n",
    "    event_date_ranges_no_outg_prstn = [\n",
    "        ['2023-04-01', '2024-08-31'], \n",
    "    ]\n",
    "    grp_by_cols_no_outg_prstn = ['trsf_pole_nb', 'no_outg_rec_nb']    \n",
    "    #---------------------------------------------------------------------------\n",
    "    normalize_by_time_interval  = True\n",
    "    #-----\n",
    "    include_power_down_minus_up = False\n",
    "    pd_col = 'Primary Power Down'\n",
    "    pu_col = 'Primary Power Up'\n",
    "    pd_m_pu_col = 'Power Down Minus Up'\n",
    "    #-----\n",
    "    regex_to_remove_patterns    = ['.*cleared.*', '.*Test Mode.*']\n",
    "    regex_to_remove_ignore_case = True\n",
    "    #---------------------------------------------------------------------------\n",
    "    max_total_counts = None\n",
    "    # max_total_counts=150\n",
    "    # max_total_counts={\n",
    "    #     '01-05 Days':150, \n",
    "    #     '06-10 Days':150, \n",
    "    #     '11-15 Days':150, \n",
    "    #     '16-20 Days':150,\n",
    "    #     '21-25 Days':150, \n",
    "    #     '26-30 Days':150\n",
    "    # }\n",
    "    how_max_total_counts='any'\n",
    "    #---------------------------------------------------------------------------    \n",
    "    rcpo_dfs_name_outg          = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "    rcpo_dfs_name_no_outg       = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "    rcpo_dfs_name_no_outg_prstn = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "\n",
    "    mecpo_idx_for_ordering = 0\n",
    "    #-------------------------\n",
    "    icpo_dfs_name_outg          = 'i'+rcpo_dfs_name_outg[1:]\n",
    "    icpo_dfs_name_no_outg       = 'i'+rcpo_dfs_name_no_outg[1:]\n",
    "    icpo_dfs_name_no_outg_prstn = 'i'+rcpo_dfs_name_no_outg_prstn[1:]    \n",
    "    #---------------------------------------------------------------------------\n",
    "    freq='5D'\n",
    "    days_min_max_outg_td_windows=[\n",
    "        [1,6], [6,11], [11,16], [16,21], [21,26], [26,31]\n",
    "    ]\n",
    "    old_to_new_keys_dict = {\n",
    "        'outg_td_window_1_to_6_days'  :'01-06 Days',\n",
    "        'outg_td_window_6_to_11_days' :'06-11 Days',\n",
    "        'outg_td_window_11_to_16_days':'11-16 Days',\n",
    "        'outg_td_window_16_to_21_days':'16-21 Days',\n",
    "        'outg_td_window_21_to_26_days':'21-26 Days',\n",
    "        'outg_td_window_26_to_31_days':'26-31 Days'\n",
    "    }\n",
    "\n",
    "    #-------------------------\n",
    "    assert(len(old_to_new_keys_dict)==len(days_min_max_outg_td_windows))\n",
    "    #-------------------------\n",
    "    # Sanity check\n",
    "    for window_i in days_min_max_outg_td_windows:\n",
    "        assert(pd.Timedelta(f'{window_i[1]}D')-pd.Timedelta(f'{window_i[0]}D')==pd.Timedelta(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95028959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    pkl_dirs_dict_full = OMInput.static_get_rcpo_pkl_base_dirs(\n",
    "        dataset          = 'outg', \n",
    "        acq_run_date     = run_date_outg, \n",
    "        data_date_ranges = event_date_ranges_outg, \n",
    "        grp_by_cols      = grp_by_cols_outg, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #-----\n",
    "    pkl_dirs_dict_no_outg = OMInput.static_get_rcpo_pkl_base_dirs(\n",
    "        dataset          = 'otbl', \n",
    "        acq_run_date     = run_date_no_outg, \n",
    "        data_date_ranges = event_date_ranges_no_outg, \n",
    "        grp_by_cols      = grp_by_cols_no_outg, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #-----\n",
    "    pkl_dirs_dict_no_outg_prstn = OMInput.static_get_rcpo_pkl_base_dirs(\n",
    "        dataset          = 'prbl', \n",
    "        acq_run_date     = run_date_no_outg_prstn, \n",
    "        data_date_ranges = event_date_ranges_no_outg_prstn, \n",
    "        grp_by_cols      = grp_by_cols_no_outg_prstn, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    ede_data_dirs_full          = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_full.values()]\n",
    "    ede_data_dirs_no_outg       = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_no_outg.values()]\n",
    "    ede_data_dirs_no_outg_prstn = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_no_outg_prstn.values()]\n",
    "    #-----\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_full]))\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_no_outg]))\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_no_outg_prstn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a97d9b-01f4-4f97-8e49-ac440afc364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dirs_dict_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd094780",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    mecpo_build_info_dict = dict()\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['run_date_outg']                   = run_date_outg\n",
    "    mecpo_build_info_dict['event_date_ranges_outg']          = event_date_ranges_outg\n",
    "    mecpo_build_info_dict['grp_by_cols_outg']                = grp_by_cols_outg\n",
    "    #-----\n",
    "    mecpo_build_info_dict['run_date_no_outg']                = run_date_no_outg\n",
    "    mecpo_build_info_dict['event_date_ranges_no_outg']       = event_date_ranges_no_outg\n",
    "    mecpo_build_info_dict['grp_by_cols_no_outg']             = grp_by_cols_no_outg\n",
    "    #-----\n",
    "    mecpo_build_info_dict['run_date_no_outg_prstn']          = run_date_no_outg_prstn\n",
    "    mecpo_build_info_dict['event_date_ranges_no_outg_prstn'] = event_date_ranges_no_outg_prstn\n",
    "    mecpo_build_info_dict['grp_by_cols_no_outg_prstn']       = grp_by_cols_no_outg_prstn\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['normalize_by_time_interval']      = normalize_by_time_interval\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['include_power_down_minus_up']     = include_power_down_minus_up\n",
    "    mecpo_build_info_dict['pd_col']                          = pd_col\n",
    "    mecpo_build_info_dict['pu_col']                          = pu_col\n",
    "    mecpo_build_info_dict['pd_m_pu_col']                     = pd_m_pu_col\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['regex_to_remove_patterns']        = regex_to_remove_patterns\n",
    "    mecpo_build_info_dict['regex_to_remove_ignore_case']     = regex_to_remove_ignore_case\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['max_total_counts']                = max_total_counts\n",
    "    mecpo_build_info_dict['how_max_total_counts']            = how_max_total_counts\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['mecpo_idx_for_ordering']          = mecpo_idx_for_ordering\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_outg']              = rcpo_dfs_name_outg\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_no_outg']           = rcpo_dfs_name_no_outg\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_no_outg_prstn']     = rcpo_dfs_name_no_outg_prstn\n",
    "    #-----\n",
    "    mecpo_build_info_dict['icpo_dfs_name_outg']              = icpo_dfs_name_outg\n",
    "    mecpo_build_info_dict['icpo_dfs_name_no_outg']           = icpo_dfs_name_no_outg\n",
    "    mecpo_build_info_dict['icpo_dfs_name_no_outg_prstn']     = icpo_dfs_name_no_outg_prstn\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['freq'] = freq\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['days_min_max_outg_td_windows']    = days_min_max_outg_td_windows\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['old_to_new_keys_dict']            = old_to_new_keys_dict\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_full']              = pkl_dirs_dict_full\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_no_outg']           = pkl_dirs_dict_no_outg\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_no_outg_prstn']     = pkl_dirs_dict_no_outg_prstn\n",
    "    #-----\n",
    "    mecpo_build_info_dict['ede_data_dirs_full']              = ede_data_dirs_full\n",
    "    mecpo_build_info_dict['ede_data_dirs_no_outg']           = ede_data_dirs_no_outg\n",
    "    mecpo_build_info_dict['ede_data_dirs_no_outg_prstn']     = ede_data_dirs_no_outg_prstn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccb439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15f94421",
   "metadata": {},
   "source": [
    "# Build MECPOCollection objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f945458",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build MECPOCollection objects\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----- Outages ------------------------------------\n",
    "    mecpo_coll_full = OMInput.static_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'outg', \n",
    "        acq_run_date                 = run_date_outg, \n",
    "        data_date_ranges             = event_date_ranges_outg, \n",
    "        grp_by_cols                  = grp_by_cols_outg, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'Outages (All Xfmrs)', \n",
    "        barplot_kwargs_shared        = dict(facecolor='red'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )\n",
    "    \n",
    "    #----- No Outages ---------------------------------\n",
    "    mecpo_coll_no_outg = OMInput.static_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'otbl', \n",
    "        acq_run_date                 = run_date_no_outg, \n",
    "        data_date_ranges             = event_date_ranges_no_outg, \n",
    "        grp_by_cols                  = grp_by_cols_no_outg, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'No Outages', \n",
    "        barplot_kwargs_shared        = dict(facecolor='orange'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )    \n",
    "    \n",
    "    #----- No Outages Pristine ------------------------\n",
    "    mecpo_coll_no_outg_prstn = OMInput.static_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'prbl', \n",
    "        acq_run_date                 = run_date_no_outg_prstn, \n",
    "        data_date_ranges             = event_date_ranges_no_outg_prstn, \n",
    "        grp_by_cols                  = grp_by_cols_no_outg_prstn, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'No Outages', \n",
    "        barplot_kwargs_shared        = dict(facecolor='orange'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27910d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea60bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('Starting shapes:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_full')\n",
    "        for an_key in mecpo_coll_full.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_full.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg')\n",
    "        for an_key in mecpo_coll_no_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg}' shape: {mecpo_coll_no_outg.get_cpo_df(an_key, rcpo_dfs_name_no_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg_prstn')\n",
    "        for an_key in mecpo_coll_no_outg_prstn.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg_prstn}' shape: {mecpo_coll_no_outg_prstn.get_cpo_df(an_key, rcpo_dfs_name_no_outg_prstn).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Similarity operations\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # First, make columns equal between MECPOAn objects within each MECPOCollection\n",
    "    mecpo_coll_full.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "    mecpo_coll_no_outg.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "    mecpo_coll_no_outg_prstn.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "\n",
    "    #-------------------------\n",
    "    # Now, make columns equal between the MECPOCollections\n",
    "    MECPOCollection.make_cpo_columns_equal_between_mecpo_colls(\n",
    "        mecpo_colls = [\n",
    "            mecpo_coll_full, \n",
    "            mecpo_coll_no_outg, \n",
    "            mecpo_coll_no_outg_prstn\n",
    "        ], \n",
    "        drop_empty_cpo_dfs=True\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # If not all same cpo_df names are used between collections, then one should call \n",
    "    #   MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls.\n",
    "    if not(rcpo_dfs_name_outg==rcpo_dfs_name_no_outg==rcpo_dfs_name_no_outg_prstn):\n",
    "        MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls(\n",
    "            mecpo_colls_with_cpo_df_names = [\n",
    "                [mecpo_coll_full,          rcpo_dfs_name_outg], \n",
    "                [mecpo_coll_no_outg,       rcpo_dfs_name_no_outg], \n",
    "                [mecpo_coll_no_outg_prstn, rcpo_dfs_name_no_outg_prstn]\n",
    "            ], \n",
    "            segregate_by_mecpo_an_keys=False\n",
    "        )\n",
    "    #-------------------------\n",
    "    if not(icpo_dfs_name_outg==icpo_dfs_name_no_outg==icpo_dfs_name_no_outg_prstn):\n",
    "        MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls(\n",
    "            mecpo_colls_with_cpo_df_names = [\n",
    "                [mecpo_coll_full,          icpo_dfs_name_outg], \n",
    "                [mecpo_coll_no_outg,       icpo_dfs_name_no_outg], \n",
    "                [mecpo_coll_no_outg_prstn, icpo_dfs_name_no_outg_prstn]\n",
    "            ], \n",
    "            segregate_by_mecpo_an_keys=False\n",
    "        )\n",
    "        \n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('\\n\\nAfter making columns equal amongst collections:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_full')\n",
    "        for an_key in mecpo_coll_full.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_full.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg')\n",
    "        for an_key in mecpo_coll_no_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg}' shape: {mecpo_coll_no_outg.get_cpo_df(an_key, rcpo_dfs_name_no_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg_prstn')\n",
    "        for an_key in mecpo_coll_no_outg_prstn.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg_prstn}' shape: {mecpo_coll_no_outg_prstn.get_cpo_df(an_key, rcpo_dfs_name_no_outg_prstn).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Remove and/or combine reasons\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #-------------------------\n",
    "    # Remove all reasons containing 'cleared'\n",
    "    mecpo_coll_full.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "    mecpo_coll_no_outg.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "    mecpo_coll_no_outg_prstn.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # Combine reasons using the standard combine (see dflt_patterns_and_replace in MECPODf.combine_cpo_df_reasons\n",
    "    #   for the list of default patterns_and_replace)\n",
    "    red_to_org_cols_dicts_full = mecpo_coll_full.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    )\n",
    "    red_to_org_cols_dicts_no_outg = mecpo_coll_no_outg.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    ) \n",
    "    red_to_org_cols_dicts_no_outg_prstn = mecpo_coll_no_outg_prstn.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Build power down minus power up counts\n",
    "    if include_power_down_minus_up:\n",
    "        mecpo_coll_full.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        mecpo_coll_no_outg.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        mecpo_coll_no_outg_prstn.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        \n",
    "    #-------------------------\n",
    "    # Don't want to include SNs or nSNs cols (and similar) in plotting, so remove\n",
    "    mecpo_coll_full.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    mecpo_coll_no_outg.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    mecpo_coll_no_outg_prstn.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    \n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('\\n\\nAfter removing and/or combining reasons:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_full')\n",
    "        for an_key in mecpo_coll_full.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_full.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg')\n",
    "        for an_key in mecpo_coll_no_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg}' shape: {mecpo_coll_no_outg.get_cpo_df(an_key, rcpo_dfs_name_no_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_no_outg_prstn')\n",
    "        for an_key in mecpo_coll_no_outg_prstn.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_no_outg_prstn}' shape: {mecpo_coll_no_outg_prstn.get_cpo_df(an_key, rcpo_dfs_name_no_outg_prstn).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Get merged DFs from collections\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    merged_df_full = mecpo_coll_full.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_outg, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "    merged_df_no_outg = mecpo_coll_no_outg.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_no_outg, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "    merged_df_no_outg_prstn = mecpo_coll_no_outg_prstn.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_no_outg_prstn, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # Make sure all SNs columns are removed\n",
    "    merged_df_full          = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_full)\n",
    "    merged_df_no_outg       = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_no_outg)\n",
    "    merged_df_no_outg_prstn = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_no_outg_prstn)\n",
    "    \n",
    "    #-------------------------\n",
    "    # Sort columns and make sure all columns equal for all\n",
    "    merged_df_full          = merged_df_full[merged_df_full.columns.sort_values()]\n",
    "    merged_df_no_outg       = merged_df_no_outg[merged_df_no_outg.columns.sort_values()]\n",
    "    merged_df_no_outg_prstn = merged_df_no_outg_prstn[merged_df_no_outg_prstn.columns.sort_values()]\n",
    "    #-----\n",
    "    assert(all(merged_df_no_outg.columns==merged_df_full.columns))\n",
    "    assert(all(merged_df_no_outg.columns==merged_df_no_outg_prstn.columns))\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build counts series\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    counts_series_full          = mecpo_coll_full.get_counts_series(rcpo_dfs_name_outg, False)\n",
    "    counts_series_no_outg       = mecpo_coll_no_outg.get_counts_series(rcpo_dfs_name_no_outg, False)\n",
    "    counts_series_no_outg_prstn = mecpo_coll_no_outg_prstn.get_counts_series(rcpo_dfs_name_no_outg_prstn, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848c0c2-c7ce-4287-bda9-e198b6ee2ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4b8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f36d3d",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# SAVE OR LOAD\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    merged_df_full.to_pickle(os.path.join(save_dir_model_base, 'merged_df_full.pkl'))\n",
    "    merged_df_no_outg.to_pickle(os.path.join(save_dir_model_base, 'merged_df_no_outg.pkl'))\n",
    "    merged_df_no_outg_prstn.to_pickle(os.path.join(save_dir_model_base, 'merged_df_no_outg_prstn.pkl'))\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_full.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_full, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_no_outg.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_no_outg, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_no_outg_prstn.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_no_outg_prstn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_full.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_full, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_no_outg.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_no_outg, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_no_outg_prstn.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_no_outg_prstn, handle, protocol=pickle.HIGHEST_PROTOCOL)     \n",
    "    #-------------------------\n",
    "    CustomWriter.output_dict_to_json(\n",
    "        os.path.join(save_dir_model_base, 'mecpo_build_info_dict.json'), \n",
    "        mecpo_build_info_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92933a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not build_mecpo_colls:\n",
    "    merged_df_full=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_full.pkl'))\n",
    "    merged_df_no_outg=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_no_outg.pkl'))\n",
    "    merged_df_no_outg_prstn=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_no_outg_prstn.pkl'))\n",
    "    #-------------------------\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_full.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_full = pickle.load(handle)\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_no_outg.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_no_outg = pickle.load(handle)\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_no_outg_prstn.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_no_outg_prstn = pickle.load(handle)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_full.pkl'), 'rb') as handle:\n",
    "        counts_series_full = pickle.load(handle)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_no_outg.pkl'), 'rb') as handle:\n",
    "        counts_series_no_outg = pickle.load(handle)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_no_outg_prstn.pkl'), 'rb') as handle:\n",
    "        counts_series_no_outg_prstn = pickle.load(handle)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_build_info_dict.json'), 'rb') as handle:\n",
    "        mecpo_build_info_dict = json.load(handle)\n",
    "\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    merged_df_no_outg_prstn.index.names     = ['trsf_pole_nb', 'no_outg_rec_nb']\n",
    "    counts_series_no_outg_prstn.index.names = ['trsf_pole_nb', 'no_outg_rec_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30565e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_no_outg.shape)\n",
    "print(merged_df_no_outg_prstn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "natsorted(merged_df_full.columns.get_level_values(1).unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658dcfe",
   "metadata": {},
   "source": [
    "### Initiate summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd574252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building time infos and EEMSP takes a while, so I suggest building these\n",
    "#   once, saving them, and loading each time\n",
    "# ==> These should generally be set to False\n",
    "build_time_infos_dfs = False\n",
    "build_eemsp          = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "random_state = None\n",
    "#-------------------------\n",
    "n_top_reasons_to_inclue = 10\n",
    "# n_top_reasons_to_inclue = None\n",
    "combine_others          = True\n",
    "#-------------------------\n",
    "merge_eemsp = True\n",
    "mult_strategy='agg'\n",
    "#-------------------------\n",
    "include_month = True\n",
    "#-------------------------\n",
    "an_keys_to_drop = None\n",
    "# an_keys_to_drop = ['00-01 Days']\n",
    "# an_keys_to_drop = ['01-06 Days']\n",
    "#-------------------------\n",
    "# date_0_train   = pd.to_datetime('2023-04-01')\n",
    "# date_1_train   = pd.to_datetime('2023-09-30')\n",
    "# #-----\n",
    "# date_0_test    = pd.to_datetime('2023-04-01')\n",
    "# date_1_test    = pd.to_datetime('2023-09-30')\n",
    "# #-----\n",
    "# date_0_HOLDOUT = pd.to_datetime('2022-06-01')\n",
    "# date_1_HOLDOUT = pd.to_datetime('2023-09-30')\n",
    "\n",
    "date_0_train   = pd.to_datetime('2023-04-01')\n",
    "date_1_train   = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_test    = pd.to_datetime('2023-04-01')\n",
    "date_1_test    = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_HOLDOUT = pd.to_datetime('2022-06-01')\n",
    "date_1_HOLDOUT = pd.to_datetime('2023-11-30')\n",
    "\n",
    "#-------------------------\n",
    "test_size                = 0.33\n",
    "get_train_test_by_date   = False\n",
    "split_train_test_by_outg = True \n",
    "#-------------------------\n",
    "create_validation_set = False\n",
    "val_size              = 0.10 #w.r.t to train size (i.e., w.r.t 1.0-test_size)\n",
    "#-------------------------\n",
    "run_scaler=True\n",
    "#-------------------------\n",
    "run_PCA = False\n",
    "pca_n_components=0.95\n",
    "#-------------------------\n",
    "remove_others_from_outages=False\n",
    "#-------------------------\n",
    "# min_pct_target_1 = 25\n",
    "min_pct_target_1 = None\n",
    "#-------------------------\n",
    "reduce_train_size = False\n",
    "red_test_size = 0.75 #Amount kept will be 1.0-red_test_size\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac83ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfmr_equip_typ_nms_of_interest = ['TRANSFORMER, OH', 'TRANSFORMER, UG']\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_full_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'EQUIP_TYP_NM'), \n",
    "#             value=xfmr_equip_typ_nms_of_interest, \n",
    "#             comparison_operator='isin'\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_full_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MNR_CAUSE_NM'), \n",
    "#             value='EQUIPMENT FAILURE', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "slicer = DFSlicer()\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'EQUIP_TYP_NM'), \n",
    "#             value='CONDUCTOR OVERHEAD', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_full_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'OUTG_REC_NB'), \n",
    "#             value=outgs_w_single_xfmr, \n",
    "#             comparison_operator='isin'\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "# merged_df_full_w_DOVS[('outg_dummy_lvl_0', 'OUTG_REC_NB')] = merged_df_full_w_DOVS.index.get_level_values(0)\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MJR_CAUSE_NM'), \n",
    "#             value='DISTRIBUTION LINE', \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MNR_CAUSE_NM'), \n",
    "#             value='EQUIPMENT FAILURE', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c6b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55135877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e79c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "an_keys = natsorted(merged_df_full.columns.get_level_values(0).unique().tolist())\n",
    "assert(an_keys==natsorted(merged_df_no_outg.columns.get_level_values(0).unique().tolist()))\n",
    "assert(an_keys==natsorted(merged_df_no_outg_prstn.columns.get_level_values(0).unique().tolist()))\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "summary_dict = dict()\n",
    "#-------------------------\n",
    "summary_dict['an_keys']                    = an_keys\n",
    "#-------------------------\n",
    "summary_dict['random_state']               = random_state\n",
    "#-------------------------\n",
    "summary_dict['n_top_reasons_to_inclue']    = n_top_reasons_to_inclue\n",
    "summary_dict['combine_others']             = combine_others\n",
    "#-------------------------\n",
    "summary_dict['merge_eemsp']                = merge_eemsp\n",
    "summary_dict['eemsp_mult_strategy']        = mult_strategy\n",
    "#-------------------------\n",
    "summary_dict['include_month']              = include_month\n",
    "#-------------------------\n",
    "summary_dict['an_keys_to_drop']            = an_keys_to_drop\n",
    "#-------------------------\n",
    "# NOTE: Timestamp is not JSON serializable, hence the need for strftime below\n",
    "summary_dict['date_0_train']               = date_0_train.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_train']               = date_1_train.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-----\n",
    "summary_dict['date_0_test']                = date_0_test.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_test']                = date_1_test.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-----\n",
    "summary_dict['date_0_HOLDOUT']             = date_0_HOLDOUT.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_HOLDOUT']             = date_1_HOLDOUT.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-------------------------\n",
    "summary_dict['test_size']                  = test_size\n",
    "summary_dict['get_train_test_by_date']     = get_train_test_by_date\n",
    "summary_dict['split_train_test_by_outg']   = split_train_test_by_outg\n",
    "#-------------------------\n",
    "summary_dict['create_validation_set']      = create_validation_set\n",
    "summary_dict['val_size']                   = val_size\n",
    "#-------------------------\n",
    "summary_dict['run_scaler']                 = run_scaler\n",
    "#-------------------------\n",
    "summary_dict['run_PCA']                    = run_PCA\n",
    "summary_dict['pca_n_components']           = pca_n_components\n",
    "#-------------------------\n",
    "summary_dict['slicer']                     = slicer.as_dict()\n",
    "#-------------------------\n",
    "summary_dict['remove_others_from_outages'] = remove_others_from_outages\n",
    "#-------------------------\n",
    "summary_dict['min_pct_target_1']           = min_pct_target_1\n",
    "#-------------------------\n",
    "summary_dict['reduce_train_size']          = reduce_train_size\n",
    "summary_dict['red_test_size']              = red_test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe444b-a78e-45ea-b612-c31b700a53ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368cb77d",
   "metadata": {},
   "source": [
    "### !!!!!!! No outage data have indices backwards from outages!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b21959",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_no_outg = merged_df_no_outg.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "counts_series_no_outg = counts_series_no_outg.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb']).squeeze()\n",
    "#-----\n",
    "merged_df_no_outg_prstn = merged_df_no_outg_prstn.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "counts_series_no_outg_prstn = counts_series_no_outg_prstn.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d90550",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.columns.get_level_values(1).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf77a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c08e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(save_dir_model_base).name=='Models' or Path(save_dir_model_base).name=='Models_00_05':\n",
    "    is_norm=True\n",
    "elif Path(save_dir_model_base).name=='Models_raw' or Path(save_dir_model_base).name=='Models_00_05_raw':\n",
    "    is_norm=False\n",
    "else:\n",
    "    assert(0)\n",
    "\n",
    "if n_top_reasons_to_inclue is not None:\n",
    "    # NOTE: Cannot do get_top_reasons_subset_from_merged_cpo_df for each, as they will then in general have unequal columns!\n",
    "    merged_df_full, [merged_df_no_outg, merged_df_no_outg_prstn] = MECPOCollection.get_top_reasons_subset_from_merged_cpo_df_and_project_from_others(\n",
    "        merged_cpo_df             = merged_df_full,\n",
    "        other_dfs_w_counts_series = [ \n",
    "            [merged_df_no_outg, counts_series_no_outg], \n",
    "            [merged_df_no_outg_prstn, counts_series_no_outg_prstn]\n",
    "        ], \n",
    "        how                       = 'per_mecpo_an', \n",
    "        n_reasons_to_include      = n_top_reasons_to_inclue,\n",
    "        combine_others            = combine_others,\n",
    "        output_combine_others_col = 'Other Reasons',\n",
    "        SNs_tags                  = None, \n",
    "        is_norm                   = is_norm, \n",
    "        counts_series             = counts_series_full\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe263b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_no_outg.shape)\n",
    "print(merged_df_no_outg_prstn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_no_outg.shape)\n",
    "print(merged_df_no_outg_prstn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62249ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_full)\n",
    "merged_df_no_outg=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_no_outg)\n",
    "merged_df_no_outg_prstn=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_no_outg_prstn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_no_outg.shape)\n",
    "print(merged_df_no_outg_prstn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(set(merged_df_full.index).difference(set(counts_series_full.index)))==0)\n",
    "assert(len(set(merged_df_no_outg.index).difference(set(counts_series_no_outg.index)))==0)\n",
    "assert(len(set(merged_df_no_outg_prstn.index).difference(set(counts_series_no_outg_prstn.index)))==0)\n",
    "\n",
    "merged_df_full = pd.merge(\n",
    "    merged_df_full, \n",
    "    counts_series_full.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')\n",
    "\n",
    "merged_df_no_outg = pd.merge(\n",
    "    merged_df_no_outg, \n",
    "    counts_series_no_outg.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')\n",
    "\n",
    "merged_df_no_outg_prstn = pd.merge(\n",
    "    merged_df_no_outg_prstn, \n",
    "    counts_series_no_outg_prstn.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b826bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_no_outg.shape)\n",
    "print(merged_df_no_outg_prstn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_full.shape)\n",
    "print(merged_df_full.index.get_level_values(0).nunique())\n",
    "print(merged_df_full.index.get_level_values(1).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.index.get_level_values(1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf90da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_full['01-05 Days']\n",
    "# merged_df_full['00-01 Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bfd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8022c703",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606ec35",
   "metadata": {},
   "source": [
    "# Build/grab time_info DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979b070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_time_infos_dfs:\n",
    "    time_infos_df_outg = build_outg_time_infos_df(\n",
    "        rcpx_df=merged_df_full.copy(), \n",
    "        outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "        dummy_col_levels_prefix='dummy_lvl_',     \n",
    "    )\n",
    "    time_infos_df_outg.to_pickle(os.path.join(save_dir_model_base, 'time_infos_df_outg.pkl'))    \n",
    "    #-------------------------\n",
    "    ede_data_dirs_no_outg       = mecpo_build_info_dict['ede_data_dirs_no_outg'] \n",
    "    ede_data_dirs_no_outg_prstn = mecpo_build_info_dict['ede_data_dirs_no_outg_prstn'] \n",
    "    #-----\n",
    "    no_outg_time_infos_df = build_no_outg_time_infos_df(\n",
    "        ede_data_dirs_no_outg=ede_data_dirs_no_outg,\n",
    "        save_path=os.path.join(save_dir_model_base, 'no_outg_time_infos_df.pkl')\n",
    "    )\n",
    "    #-----\n",
    "    no_outg_time_infos_prstn_df = build_no_outg_time_infos_df(\n",
    "        ede_data_dirs_no_outg=ede_data_dirs_no_outg_prstn,\n",
    "        save_path=os.path.join(save_dir_model_base, 'no_outg_time_infos_prstn_df.pkl')\n",
    "    )\n",
    "else:\n",
    "    time_infos_df_outg          = pd.read_pickle(os.path.join(save_dir_model_base, 'time_infos_df_outg.pkl'))\n",
    "    no_outg_time_infos_df       = pd.read_pickle(os.path.join(save_dir_model_base, 'no_outg_time_infos_df.pkl'))\n",
    "    no_outg_time_infos_prstn_df = pd.read_pickle(os.path.join(save_dir_model_base, 'no_outg_time_infos_prstn_df.pkl'))\n",
    "#-------------------------\n",
    "if 'is_first_after_outg' in no_outg_time_infos_df.index.names:\n",
    "    no_outg_time_infos_df = no_outg_time_infos_df.droplevel(level='is_first_after_outg', axis=0)\n",
    "#-----\n",
    "if 'is_first_after_outg' in no_outg_time_infos_prstn_df.index.names:\n",
    "    no_outg_time_infos_prstn_df = no_outg_time_infos_prstn_df.droplevel(level='is_first_after_outg', axis=0)\n",
    "    \n",
    "#-------------------------\n",
    "# NOTE: After new DFs are built and saved (using build_no_outg_time_infos_df), the if statements\n",
    "#         below will no longer be necessary\n",
    "# Typically, want index as ['no_outg_rec_nb', 'trsf_pole_nb']\n",
    "if no_outg_time_infos_df.index.names!=['no_outg_rec_nb', 'trsf_pole_nb']:\n",
    "    no_outg_time_infos_df = no_outg_time_infos_df.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "#-----\n",
    "if no_outg_time_infos_prstn_df.index.names!=['no_outg_rec_nb', 'trsf_pole_nb']:\n",
    "    no_outg_time_infos_prstn_df = no_outg_time_infos_prstn_df.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "    \n",
    "#-------------------------\n",
    "# Make sure time info found for all\n",
    "# For the baseline data, typically the time dfs will have more entries than the data\n",
    "#   This can result from, e.g., transformers not registering any events, in which case\n",
    "#     they obviously will not be found in the data, but will be found in the time dfs because\n",
    "#     those are built through the collection of run SQL queries\n",
    "assert(len(set(merged_df_full.index).difference(set(time_infos_df_outg.index)))==0)\n",
    "assert(len(set(merged_df_no_outg.index).difference(set(no_outg_time_infos_df.index)))==0)\n",
    "assert(len(set(merged_df_no_outg_prstn.index).difference(set(no_outg_time_infos_prstn_df.index)))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67754ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b7fac1",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c5e72",
   "metadata": {},
   "source": [
    "# EEMSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b93a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "cols_of_interest_eemsp = [\n",
    "    'LOCATION_NB', \n",
    "    'MFGR_NM', \n",
    "    'INSTALL_DT', \n",
    "    'LAST_TRANS_DESC', \n",
    "    'EQTYPE_ID', \n",
    "    'COOLANT', \n",
    "    'INFO', \n",
    "    'KVA_SIZE',\n",
    "    'PHASE_CNT', \n",
    "    'PRIM_VOLTAGE', \n",
    "    'PROTECTION', \n",
    "    'PRU_NUMBER', \n",
    "    'SEC_VOLTAGE', \n",
    "    'SPECIAL_CHAR', \n",
    "    'TAPS', \n",
    "    'XFTYPE'\n",
    "]\n",
    "cols_of_interest_eemsp_full = cols_of_interest_eemsp + ['LATEST_STATUS', 'REMOVAL_DT', 'SERIAL_NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c58cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Grab or build df_eemsp_full\n",
    "    #--------------------------------------------------\n",
    "    trsf_pole_nbs = list(set(\n",
    "        merged_df_full.index.get_level_values(1).unique().tolist()+\n",
    "        merged_df_no_outg.index.get_level_values(1).unique().tolist()+\n",
    "        merged_df_no_outg_prstn.index.get_level_values(1).unique().tolist()\n",
    "    ))\n",
    "    #-------------------------\n",
    "    if build_eemsp:\n",
    "        conn_eemsp = Utilities.get_eemsp_oracle_connection()\n",
    "        df_eemsp_OG = build_df_eemsp(conn_eemsp, trsf_pole_nbs, batch_size=1000, verbose=True, n_update=10)\n",
    "        df_eemsp_OG.to_pickle(os.path.join(save_dir_model_base, 'df_eemsp_OG.pkl'))\n",
    "    else:\n",
    "        df_eemsp_OG = pd.read_pickle(os.path.join(save_dir_model_base, 'df_eemsp_OG.pkl'))\n",
    "    #-------------------------\n",
    "    df_eemsp_full = df_eemsp_OG.copy()\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build time_infos_df\n",
    "    #--------------------------------------------------\n",
    "    time_infos_df_no_outg = build_no_outg_time_infos_df_for_eemsp(\n",
    "        no_outg_time_infos_df=no_outg_time_infos_df\n",
    "    )\n",
    "    #-----\n",
    "    time_infos_df_no_outg_prstn = build_no_outg_time_infos_df_for_eemsp(\n",
    "        no_outg_time_infos_df=no_outg_time_infos_prstn_df\n",
    "    )\n",
    "    #-------------------------\n",
    "    time_infos_df = build_time_infos_df_for_eemsp(\n",
    "        time_infos_df_outg=time_infos_df_outg, \n",
    "        time_infos_df_no_outg=time_infos_df_no_outg, \n",
    "        time_infos_df_no_outg_prstn=time_infos_df_no_outg_prstn\n",
    "    )\n",
    "    #-------------------------\n",
    "    assert(time_infos_df.shape[0]==time_infos_df.reset_index().drop_duplicates().shape[0])\n",
    "    #-----\n",
    "    del time_infos_df_outg\n",
    "    del time_infos_df_no_outg\n",
    "    del time_infos_df_no_outg_prstn\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Run reduce1 (or grab reduced df, depending on build_eemsp), keeping only entries from df_eemsp_full \n",
    "    #   active at the correct time periods\n",
    "    #--------------------------------------------------\n",
    "    if build_eemsp:\n",
    "        df_eemsp_full = df_eemsp_full[cols_of_interest_eemsp_full].copy()\n",
    "        #-----\n",
    "        df_eemsp_reduce1 = EEMSP.reduce1_eemsp_for_outg_trsf(\n",
    "            time_infos_df=time_infos_df, \n",
    "            df_eemsp=df_eemsp_full, \n",
    "            outg_rec_nb_idfr  = 'index_0', \n",
    "            trsf_pole_nb_idfr = 'index_1', \n",
    "            dt_min_col = 't_min', \n",
    "            dt_max_col = 't_max', \n",
    "\n",
    "            eemsp_location_nb_col = 'LOCATION_NB', \n",
    "            eemsp_install_dt_col  = 'INSTALL_DT', \n",
    "            eemsp_removal_dt_col  = 'REMOVAL_DT', \n",
    "            return_eemsp_outg_rec_nb_col = 'OUTG_REC_NB_TO_MERGE'\n",
    "        )\n",
    "        df_eemsp_reduce1.to_pickle(os.path.join(save_dir_model_base, 'df_eemsp_reduce1.pkl'))\n",
    "    else:\n",
    "        df_eemsp_reduce1 = pd.read_pickle(os.path.join(save_dir_model_base, 'df_eemsp_reduce1.pkl'))\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Run reduce2 (or grab reduced df, depending on build_eemsp and whether or not reduced2 df exists), \n",
    "    #   keeping only one entry per outg_rec_nb, location_nb (trsf_pole_nb) group\n",
    "    #--------------------------------------------------\n",
    "    if(\n",
    "        not build_eemsp and \n",
    "        os.path.exists(os.path.join(save_dir_model_base, f'df_eemsp_reduce2_{mult_strategy}.pkl'))\n",
    "    ):\n",
    "        df_eemsp_reduce2 = pd.read_pickle(os.path.join(save_dir_model_base, f'df_eemsp_reduce2_{mult_strategy}.pkl'))\n",
    "    else:\n",
    "        df_eemsp_reduce2 = EEMSP.reduce2_eemsp_for_outg_trsf(\n",
    "            df_eemsp        = df_eemsp_reduce1.copy(), \n",
    "            mult_strategy   = mult_strategy, \n",
    "            include_n_eemsp=True, \n",
    "            grp_by_cols=['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB'], \n",
    "            numeric_cols = ['KVA_SIZE'], \n",
    "            dt_cols = ['INSTALL_DT', 'REMOVAL_DT'], \n",
    "            ignore_cols = ['SERIAL_NB'], \n",
    "            cat_cols_as_strings=True\n",
    "        )\n",
    "        df_eemsp_reduce2.to_pickle(os.path.join(save_dir_model_base, f'df_eemsp_reduce2_{mult_strategy}.pkl'))  \n",
    "    #-------------------------\n",
    "    # No matter of the mult_strategy used, at this point df_eemsp_reduce2 should only have a single\n",
    "    #   entry for each outg_rec_nb, location_nb pair\n",
    "    assert(all(df_eemsp_reduce2[['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB']].value_counts()==1))\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Clean up df_eemsp_reduce2 and merge with merged_df_full, merged_df_no_outg, and merged_df_no_outg_prstn\n",
    "    #--------------------------------------------------\n",
    "    # Can't simply take df_eemsp_reduce2[cols_of_interest_eemsp] because we need also the new column\n",
    "    #   OUTG_REC_NB_TO_MERGE (and ant others which may be added in the future)\n",
    "    cols_to_drop = list(set(cols_of_interest_eemsp_full).difference(set(cols_of_interest_eemsp)))\n",
    "    cols_to_drop = [x for x in cols_to_drop if x in df_eemsp_reduce2.columns]\n",
    "    if len(cols_to_drop)>0:\n",
    "        df_eemsp_reduce2 = df_eemsp_reduce2.drop(columns=cols_to_drop)\n",
    "    #-------------------------\n",
    "    assert(df_eemsp_reduce2.shape[0]==df_eemsp_reduce2.groupby(['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB']).ngroups)\n",
    "    print(f\"df_eemsp_reduce2['LOCATION_NB'].nunique() = {df_eemsp_reduce2['LOCATION_NB'].nunique()}\")\n",
    "    print(f\"len(trsf_pole_nbs)                        = {len(trsf_pole_nbs)}\")\n",
    "    print(f\"Diff                                      = {len(trsf_pole_nbs)-df_eemsp_reduce2['LOCATION_NB'].nunique()}\")\n",
    "    print()\n",
    "    #-------------------------\n",
    "    print(\"\\nShapes BEFORE merging\")\n",
    "    print(f\"merged_df_full.shape          = {merged_df_full.shape}\")\n",
    "    print(f\"merged_df_no_outg.shape       = {merged_df_no_outg.shape}\")\n",
    "    print(f\"merged_df_no_outg_prstn.shape = {merged_df_no_outg_prstn.shape}\")\n",
    "    #-------------------------\n",
    "    merged_df_full = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_full, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df_no_outg = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_no_outg, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df_no_outg_prstn = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_no_outg_prstn, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['OUTG_REC_NB_TO_MERGE', 'LOCATION_NB'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    print(\"\\nShapes AFTER merging\")\n",
    "    print(f\"merged_df_full.shape          = {merged_df_full.shape}\")\n",
    "    print(f\"merged_df_no_outg.shape       = {merged_df_no_outg.shape}\")\n",
    "    print(f\"merged_df_no_outg_prstn.shape = {merged_df_no_outg_prstn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962f5b2-d696-4d17-958d-4c0e39b6be88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986381b8-6ac0-4382-a00a-4b964baf58f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    fig,ax = Plot_General.default_subplots()\n",
    "    Plot_Hist.plot_hist(\n",
    "        ax=ax, \n",
    "        df=df_eemsp_reduce1.groupby('LOCATION_NB').size().to_frame(), \n",
    "        x_col=0, \n",
    "        min_max_and_bin_size=(0,10,1), \n",
    "        plot_sns=True, \n",
    "        hist_plot_kwargs=dict(discrete=True)\n",
    "    )\n",
    "    ax.set_title('# Xfmrs at Pole Location (Only those with >1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    fig,ax = Plot_General.default_subplots()\n",
    "    Plot_Hist.plot_hist(\n",
    "        ax=ax, \n",
    "        df=df_eemsp_reduce1.groupby(['LOCATION_NB', 'OUTG_REC_NB_TO_MERGE']).size().to_frame(), \n",
    "        x_col=0, \n",
    "        min_max_and_bin_size=(0,10,1), \n",
    "        plot_sns=True, \n",
    "        hist_plot_kwargs=dict(discrete=True)\n",
    "    )\n",
    "    ax.set_title('# Xfmrs at Pole Location (Only those with >1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d71a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    del df_eemsp_OG\n",
    "    del df_eemsp_full\n",
    "    del df_eemsp_reduce1\n",
    "    del df_eemsp_reduce2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f66bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c9d02be",
   "metadata": {},
   "source": [
    "# TODO: Make more concrete methods for transforming install_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c386d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full = pd.merge(\n",
    "    merged_df_full, \n",
    "    Utilities_df.prepend_level_to_MultiIndex(\n",
    "        df=time_infos_df,\n",
    "        level_val='time_info',\n",
    "        level_name=None,\n",
    "        axis=1\n",
    "    ), \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n",
    "assert(merged_df_full['time_info'].isna().sum().sum()==0)\n",
    "merged_df_full[('EEMSP_0', 'INSTALL_DT')] = (merged_df_full[('time_info', 't_min')] - merged_df_full[('EEMSP_0', 'INSTALL_DT')]).dt.total_seconds()/(60*60*24*365)\n",
    "merged_df_full = merged_df_full.drop(columns=['time_info'])\n",
    "#-------------------------\n",
    "merged_df_no_outg.index.names = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "merged_df_no_outg = pd.merge(\n",
    "    merged_df_no_outg, \n",
    "    Utilities_df.prepend_level_to_MultiIndex(\n",
    "        df=time_infos_df,\n",
    "        level_val='time_info',\n",
    "        level_name=None,\n",
    "        axis=1\n",
    "    ), \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n",
    "merged_df_no_outg.index.names = ['no_outg_rec_nb', 'trsf_pole_nb']\n",
    "assert(merged_df_no_outg['time_info'].isna().sum().sum()==0)\n",
    "merged_df_no_outg[('EEMSP_0', 'INSTALL_DT')] = (merged_df_no_outg[('time_info', 't_min')] - merged_df_no_outg[('EEMSP_0', 'INSTALL_DT')]).dt.total_seconds()/(60*60*24*365)\n",
    "merged_df_no_outg = merged_df_no_outg.drop(columns=['time_info'])\n",
    "#-------------------------\n",
    "merged_df_no_outg_prstn.index.names = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "merged_df_no_outg_prstn = pd.merge(\n",
    "    merged_df_no_outg_prstn, \n",
    "    Utilities_df.prepend_level_to_MultiIndex(\n",
    "        df=time_infos_df,\n",
    "        level_val='time_info',\n",
    "        level_name=None,\n",
    "        axis=1\n",
    "    ), \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n",
    "merged_df_no_outg_prstn.index.names = ['no_outg_rec_nb', 'trsf_pole_nb']\n",
    "assert(merged_df_no_outg_prstn['time_info'].isna().sum().sum()==0)\n",
    "merged_df_no_outg_prstn[('EEMSP_0', 'INSTALL_DT')] = (merged_df_no_outg_prstn[('time_info', 't_min')] - merged_df_no_outg_prstn[('EEMSP_0', 'INSTALL_DT')]).dt.total_seconds()/(60*60*24*365)\n",
    "merged_df_no_outg_prstn = merged_df_no_outg_prstn.drop(columns=['time_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d6919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING SCHEDULED OUTAGES\n",
    "\n",
    "print(f'merged_df_full.shape = {merged_df_full.shape}')\n",
    "\n",
    "merged_df_full =  MECPODf.get_cpo_df_subset_excluding_mjr_mnr_causes( \n",
    "    cpo_df=merged_df_full, \n",
    "    mjr_mnr_causes_to_exclude=None, \n",
    "    mjr_causes_to_exclude=None,\n",
    "    mnr_causes_to_exclude=['SCO', 'SO'], \n",
    "    outg_rec_nb_col='index'\n",
    ")\n",
    "\n",
    "print(f'merged_df_full.shape = {merged_df_full.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full.index.get_level_values(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c2a41",
   "metadata": {},
   "source": [
    "# Add month info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984c188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if include_month:\n",
    "    merged_df_full_wd = DOVSOutages.append_outg_dt_off_ts_full_to_df(\n",
    "        df=merged_df_full.copy(), \n",
    "        outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "        dummy_col_levels_prefix='dummy_lvl_'\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df_no_outg_wd = merge_cpx_df_w_time_infos(\n",
    "        cpx_df=merged_df_no_outg.copy(), \n",
    "        time_infos_df=no_outg_time_infos_df, \n",
    "        time_infos_drop_dupls_subset=['index', 't_min']\n",
    "    )\n",
    "    #-----\n",
    "    merged_df_no_outg_prstn_wd = merge_cpx_df_w_time_infos(\n",
    "        cpx_df=merged_df_no_outg_prstn.copy(), \n",
    "        time_infos_df=no_outg_time_infos_prstn_df, \n",
    "        time_infos_drop_dupls_subset=['index', 't_min']\n",
    "    )\n",
    "    #-------------------------\n",
    "    if ('is_outg', 'is_outg') in merged_df_full_wd.columns:\n",
    "        merged_df_full_wd = Utilities_df.move_cols_to_back(merged_df_full_wd, [('is_outg', 'is_outg')])\n",
    "    if ('is_outg', 'is_outg') in merged_df_no_outg_wd.columns:\n",
    "        merged_df_no_outg_wd = Utilities_df.move_cols_to_back(merged_df_no_outg_wd, [('is_outg', 'is_outg')])\n",
    "    if ('is_outg', 'is_outg') in merged_df_no_outg_prstn_wd.columns:\n",
    "        merged_df_no_outg_prstn_wd = Utilities_df.move_cols_to_back(merged_df_no_outg_prstn_wd, [('is_outg', 'is_outg')])\n",
    "    #-------------------------\n",
    "    # Change outage time to just month of outage\n",
    "    merged_df_full_wd[('dummy_lvl_0', 'outg_month')] = merged_df_full_wd[('dummy_lvl_0', 'DT_OFF_TS_FULL')].dt.month\n",
    "\n",
    "    merged_df_no_outg_wd[('dummy_lvl_0', 'outg_month')] = merged_df_no_outg_wd[('dummy_lvl_0', 't_min')].dt.month\n",
    "    merged_df_no_outg_prstn_wd[('dummy_lvl_0', 'outg_month')] = merged_df_no_outg_prstn_wd[('dummy_lvl_0', 't_min')].dt.month\n",
    "\n",
    "    #-------------------------\n",
    "    merged_df_full_wd = merged_df_full_wd.drop(columns=[('dummy_lvl_0', 'DT_OFF_TS_FULL')])\n",
    "    merged_df_no_outg_wd = merged_df_no_outg_wd.drop(columns=[('dummy_lvl_0', 't_min'), ('dummy_lvl_0', 't_max'), ('dummy_lvl_0', 'prem_nbs')])\n",
    "    merged_df_no_outg_prstn_wd = merged_df_no_outg_prstn_wd.drop(columns=[('dummy_lvl_0', 't_min'), ('dummy_lvl_0', 't_max'), ('dummy_lvl_0', 'prem_nbs')])\n",
    "    #-------------------------\n",
    "    merged_df_full=merged_df_full_wd.copy()\n",
    "    merged_df_no_outg=merged_df_no_outg_wd.copy()\n",
    "    merged_df_no_outg_prstn=merged_df_no_outg_prstn_wd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ff3bc-7026-4283-b2de-b55c2b89d3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9c011c",
   "metadata": {},
   "source": [
    "# !~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NETWORK and PRIMARY trsf_pole_nbs\n",
    "# merged_df_no_outg=merged_df_no_outg.loc[~merged_df_no_outg.index.get_level_values(0).isin(['NETWORK', 'PRIMARY'])]\n",
    "# merged_df_no_outg_prstn=merged_df_no_outg_prstn.loc[~merged_df_no_outg_prstn.index.get_level_values(0).isin(['NETWORK', 'PRIMARY'])]\n",
    "merged_df_no_outg=merged_df_no_outg.loc[~merged_df_no_outg.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]\n",
    "merged_df_no_outg_prstn=merged_df_no_outg_prstn.loc[~merged_df_no_outg_prstn.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]\n",
    "#-----\n",
    "merged_df_full=merged_df_full[~merged_df_full.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd880459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DOVS info to be used for setting target values\n",
    "merged_df_full_w_DOVS = DOVSOutages.append_outg_info_to_df(\n",
    "    df=merged_df_full.copy(), \n",
    "    outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    ")\n",
    "merged_df_full_w_DOVS=merged_df_full_w_DOVS[['outg_dummy_lvl_0']]\n",
    "merged_df_full_w_DOVS[('is_outg', 'is_outg')]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108122e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'from_outg' information so I can track how many are in target=1 and target=0 \n",
    "merged_df_full[('from_outg', 'from_outg')]          = 1\n",
    "merged_df_no_outg[('from_outg', 'from_outg')]       = 0\n",
    "merged_df_no_outg_prstn[('from_outg', 'from_outg')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a39550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad5546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44544757",
   "metadata": {},
   "source": [
    "# Drop any time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if an_keys_to_drop is not None:\n",
    "    merged_df_full          = merged_df_full.drop(columns=an_keys_to_drop, level=0)\n",
    "    merged_df_no_outg       = merged_df_no_outg.drop(columns=an_keys_to_drop, level=0)\n",
    "    merged_df_no_outg_prstn = merged_df_no_outg_prstn.drop(columns=an_keys_to_drop, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108941b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_train_test_by_date:\n",
    "    merged_df_full_train = get_cpx_outg_df_subset_by_outg_datetime(\n",
    "        cpx_outg_df=merged_df_full.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_train, \n",
    "        outg_rec_nb_idfr='index', \n",
    "        return_notin_also=False\n",
    "    )\n",
    "    merged_df_full_test = get_cpx_outg_df_subset_by_outg_datetime(\n",
    "        cpx_outg_df=merged_df_full.copy(), \n",
    "        date_0 = date_0_test,\n",
    "        date_1 = date_1_test, \n",
    "        outg_rec_nb_idfr='index', \n",
    "        return_notin_also=False\n",
    "    )\n",
    "else:\n",
    "    merged_df_full_train_test = get_cpx_outg_df_subset_by_outg_datetime(\n",
    "        cpx_outg_df=merged_df_full.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_test, \n",
    "        outg_rec_nb_idfr='index', \n",
    "        return_notin_also=False\n",
    "    )\n",
    "    #-----\n",
    "    if split_train_test_by_outg:\n",
    "        merged_df_full_train, merged_df_full_test = train_test_split_df_by_outage(\n",
    "            df=merged_df_full_train_test, \n",
    "            outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        merged_df_full_train, merged_df_full_test = train_test_split(\n",
    "            merged_df_full_train_test, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "#-------------------------    \n",
    "merged_df_full_HOLDOUT = get_cpx_outg_df_subset_by_outg_datetime(\n",
    "    cpx_outg_df=merged_df_full.copy(), \n",
    "    date_0 = date_0_HOLDOUT,\n",
    "    date_1 = date_1_HOLDOUT, \n",
    "    outg_rec_nb_idfr='index', \n",
    "    return_notin_also=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a95c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d63d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_train_test_by_date:\n",
    "    merged_df_no_outg_train = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_df.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_train, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "    merged_df_no_outg_test = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_df.copy(), \n",
    "        date_0 = date_0_test,\n",
    "        date_1 = date_1_test, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "else:\n",
    "    merged_df_no_outg_train_test = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_df.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_test, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "    #-----\n",
    "    if split_train_test_by_outg:\n",
    "        merged_df_no_outg_train, merged_df_no_outg_test = train_test_split_df_by_outage(\n",
    "            df=merged_df_no_outg_train_test, \n",
    "            outg_rec_nb_idfr=('index', 'no_outg_rec_nb'), \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        merged_df_no_outg_train, merged_df_no_outg_test = train_test_split(\n",
    "            merged_df_no_outg_train_test, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "#-------------------------   \n",
    "merged_df_no_outg_HOLDOUT = get_cpx_baseline_df_subset_by_datetime(\n",
    "    cpx_bsln_df = merged_df_no_outg.copy(), \n",
    "    bsln_time_infos_df = no_outg_time_infos_df.copy(), \n",
    "    date_0 = date_0_HOLDOUT,\n",
    "    date_1 = date_1_HOLDOUT, \n",
    "    bsln_time_infos_time_col='t_min', \n",
    "    return_notin_also=False, \n",
    "    merge_time_info_to_cpx_bsln_df=False\n",
    ")\n",
    "#--------------------------------------------------   \n",
    "if get_train_test_by_date:\n",
    "    merged_df_no_outg_prstn_train = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg_prstn.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_prstn_df.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_train, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "    merged_df_no_outg_prstn_test = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg_prstn.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_prstn_df.copy(), \n",
    "        date_0 = date_0_test,\n",
    "        date_1 = date_1_test, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "else:\n",
    "    merged_df_no_outg_prstn_train_test = get_cpx_baseline_df_subset_by_datetime(\n",
    "        cpx_bsln_df = merged_df_no_outg_prstn.copy(), \n",
    "        bsln_time_infos_df = no_outg_time_infos_prstn_df.copy(), \n",
    "        date_0 = date_0_train,\n",
    "        date_1 = date_1_test, \n",
    "        bsln_time_infos_time_col='t_min', \n",
    "        return_notin_also=False, \n",
    "        merge_time_info_to_cpx_bsln_df=False\n",
    "    )\n",
    "    if split_train_test_by_outg:\n",
    "        merged_df_no_outg_prstn_train, merged_df_no_outg_prstn_test = train_test_split_df_by_outage(\n",
    "            df=merged_df_no_outg_prstn_train_test, \n",
    "            outg_rec_nb_idfr=('index', 'no_outg_rec_nb'), \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        merged_df_no_outg_prstn_train, merged_df_no_outg_prstn_test = train_test_split(\n",
    "            merged_df_no_outg_prstn_train_test, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "#-------------------------   \n",
    "merged_df_no_outg_prstn_HOLDOUT = get_cpx_baseline_df_subset_by_datetime(\n",
    "    cpx_bsln_df = merged_df_no_outg_prstn.copy(), \n",
    "    bsln_time_infos_df = no_outg_time_infos_prstn_df.copy(), \n",
    "    date_0 = date_0_HOLDOUT,\n",
    "    date_1 = date_1_HOLDOUT, \n",
    "    bsln_time_infos_time_col='t_min', \n",
    "    return_notin_also=False, \n",
    "    merge_time_info_to_cpx_bsln_df=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bc47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtnl_baseline_train = pd.concat([merged_df_no_outg_train, merged_df_no_outg_prstn_train])\n",
    "# addtnl_baseline_train = addtnl_baseline_train.sample(frac=0.10)\n",
    "\n",
    "addtnl_baseline_test = pd.concat([merged_df_no_outg_test, merged_df_no_outg_prstn_test])\n",
    "# addtnl_baseline_test = addtnl_baseline_test.sample(frac=0.10)\n",
    "\n",
    "addtnl_baseline_HOLDOUT = pd.concat([merged_df_no_outg_HOLDOUT, merged_df_no_outg_prstn_HOLDOUT])\n",
    "# addtnl_baseline_HOLDOUT = addtnl_baseline_HOLDOUT.sample(frac=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff99aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_train   = pd.concat([merged_df_full_train, addtnl_baseline_train])\n",
    "full_data_df_test    = pd.concat([merged_df_full_test, addtnl_baseline_test])\n",
    "full_data_df_HOLDOUT = pd.concat([merged_df_full_HOLDOUT, addtnl_baseline_HOLDOUT])\n",
    "\n",
    "#Shuffle the data\n",
    "full_data_df_train   = full_data_df_train.sample(frac=1)\n",
    "full_data_df_test    = full_data_df_test.sample(frac=1)\n",
    "full_data_df_HOLDOUT = full_data_df_HOLDOUT.sample(frac=1)\n",
    "\n",
    "full_data_df = pd.concat([full_data_df_train, full_data_df_test, full_data_df_HOLDOUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf029347",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ca611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6b82dac",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ad362",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    cols_to_encode = full_data_df['EEMSP_0'].columns\n",
    "    numeric_cols = ['KVA_SIZE', 'INSTALL_DT']\n",
    "    cols_to_encode = [('EEMSP_0', x) for x in cols_to_encode if x not in numeric_cols]\n",
    "    #-------------------------\n",
    "    full_data_df[cols_to_encode]         = full_data_df[cols_to_encode].astype(str)\n",
    "    full_data_df_train[cols_to_encode]   = full_data_df_train[cols_to_encode].astype(str)\n",
    "    full_data_df_test[cols_to_encode]    = full_data_df_test[cols_to_encode].astype(str)\n",
    "    full_data_df_HOLDOUT[cols_to_encode] = full_data_df_HOLDOUT[cols_to_encode].astype(str)\n",
    "    #-------------------------\n",
    "    eemsp_enc = preprocessing.OrdinalEncoder(\n",
    "        handle_unknown='use_encoded_value', \n",
    "        unknown_value=-1\n",
    "    )\n",
    "    # NOTE: In order for eemsp_enc to include the feature_names_in_ attribute (which I would like to use\n",
    "    #         in model deployment to ensure the EEMSP data form matches that expected by eemsp_end), the\n",
    "    #         feature names must be string.\n",
    "    #       Hence the need for .droplevel(0, axis=1) below (the use within the transform call is not strictly\n",
    "    #         needed, but prevents a warning message from being output)\n",
    "    eemsp_enc.fit(full_data_df[cols_to_encode].droplevel(0, axis=1))\n",
    "    #-----\n",
    "    full_data_df_train[cols_to_encode]   = eemsp_enc.transform(full_data_df_train[cols_to_encode].droplevel(0, axis=1))\n",
    "    full_data_df_test[cols_to_encode]    = eemsp_enc.transform(full_data_df_test[cols_to_encode].droplevel(0, axis=1))\n",
    "    full_data_df_HOLDOUT[cols_to_encode] = eemsp_enc.transform(full_data_df_HOLDOUT[cols_to_encode].droplevel(0, axis=1))\n",
    "    #-------------------------\n",
    "    if save_model:\n",
    "        joblib.dump(eemsp_enc, os.path.join(save_dir_model, 'eemsp_encoder.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218600b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if merge_eemsp:\n",
    "# #     full_data_df         = full_data_df.drop(columns=[('key_0', '')])\n",
    "# #     full_data_df_train   = full_data_df_train.drop(columns=[('key_0', '')])\n",
    "# #     full_data_df_test    = full_data_df_test.drop(columns=[('key_0', '')])\n",
    "# #     full_data_df_HOLDOUT = full_data_df_HOLDOUT.drop(columns=[('key_0', '')])\n",
    "    \n",
    "# #     le = preprocessing.LabelEncoder()\n",
    "# #     cols_to_encode = full_data_df['EEMSP'].columns\n",
    "# #     for col in cols_to_encode:\n",
    "# #         le.fit(full_data_df[('EEMSP', col)])\n",
    "# #         #-----\n",
    "# #         full_data_df_train[('EEMSP', col)]   = le.transform(full_data_df_train[('EEMSP', col)])\n",
    "# #         full_data_df_test[('EEMSP', col)]    = le.transform(full_data_df_test[('EEMSP', col)])\n",
    "# #         full_data_df_HOLDOUT[('EEMSP', col)] = le.transform(full_data_df_HOLDOUT[('EEMSP', col)])\n",
    "\n",
    "# if merge_eemsp:\n",
    "#     eemsp_label_encoders = dict()\n",
    "#     cols_to_encode = full_data_df['EEMSP_0'].columns\n",
    "#     numeric_cols = ['KVA_SIZE', 'INSTALL_DT']\n",
    "#     cols_to_encode = [x for x in cols_to_encode if x not in numeric_cols]\n",
    "#     for col in cols_to_encode:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         #-----\n",
    "#         full_data_df[('EEMSP_0', col)]         = full_data_df[('EEMSP_0', col)].astype(str)\n",
    "#         full_data_df_train[('EEMSP_0', col)]   = full_data_df_train[('EEMSP_0', col)].astype(str)\n",
    "#         full_data_df_test[('EEMSP_0', col)]    = full_data_df_test[('EEMSP_0', col)].astype(str)\n",
    "#         full_data_df_HOLDOUT[('EEMSP_0', col)] = full_data_df_HOLDOUT[('EEMSP_0', col)].astype(str)\n",
    "#         #-----\n",
    "#         le.fit(full_data_df[('EEMSP_0', col)])\n",
    "#         #-----\n",
    "#         full_data_df_train[('EEMSP_0', col)]   = le.transform(full_data_df_train[('EEMSP_0', col)])\n",
    "#         full_data_df_test[('EEMSP_0', col)]    = le.transform(full_data_df_test[('EEMSP_0', col)])\n",
    "#         full_data_df_HOLDOUT[('EEMSP_0', col)] = le.transform(full_data_df_HOLDOUT[('EEMSP_0', col)])\n",
    "#         #-----\n",
    "#         assert(col not in eemsp_label_encoders.keys())\n",
    "#         eemsp_label_encoders[col] = le\n",
    "        \n",
    "#     if save_model:\n",
    "#         with open(os.path.join(save_dir_model, 'eemsp_label_encoders.pkl'), 'wb') as handle:\n",
    "#             pickle.dump(eemsp_label_encoders, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea910c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83e219c",
   "metadata": {},
   "source": [
    "# Set target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38132d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_save_dir_base = r'C:\\Users\\s346557\\Documents\\AnalysisNote\\X_Results\\X_2_OutageMeterEvents\\Figures\\ConfusionMatrices'\n",
    "# # fig_save_subdir = 'Target_eq_1_ALL_w_EEMSP'\n",
    "# fig_save_subdir = 'Target_eq_1_ALL'\n",
    "# # fig_save_subdir = 'trsf_nb_eq_LocID_w_EEMSP'\n",
    "# fig_save_dir = os.path.join(fig_save_dir_base, fig_save_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961effe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef54235",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full_w_DOVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_n_xfmrs = get_n_trsf_poles_per_outg(\n",
    "    df=merged_df_full, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "outgs_w_single_xfmr = outg_n_xfmrs[outg_n_xfmrs==1].index.tolist()\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full_w_DOVS_i = slicer.set_simple_column_value(df=merged_df_full_w_DOVS.copy(), column=('is_outg', 'is_outg'), value=1)\n",
    "full_outg_idxs_i = merged_df_full_w_DOVS_i[merged_df_full_w_DOVS_i[('is_outg', 'is_outg')]==1].index\n",
    "\n",
    "#NOTE: To achieve exclusion equal to that in set_target_val_1_by_idx, one could use:\n",
    "#        full_outg_idxs_exclude_i = merged_df_full_w_DOVS_i[merged_df_full_w_DOVS_i[('is_outg', 'is_outg')]==0].index\n",
    "#      then use .drop(index=list(set(full_data_df_i.index).intersection(set(full_outg_idxs_exclude_i))))\n",
    "#      However, as noted in the function, the methods in set_target_val_1_by_idx are probably safer/more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a8286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "full_data_df_i         = full_data_df.copy()\n",
    "full_data_df_train_i   = full_data_df_train.copy()\n",
    "full_data_df_test_i    = full_data_df_test.copy()\n",
    "full_data_df_HOLDOUT_i = full_data_df_HOLDOUT.copy()\n",
    "#-------------------------\n",
    "full_data_df_i = set_target_val_1_by_idx(\n",
    "    df=full_data_df_i,\n",
    "    val_1_idxs=full_outg_idxs_i,\n",
    "    remove_others_from_outages=remove_others_from_outages, \n",
    "    target_col=('is_outg', 'is_outg'), \n",
    "    from_outg_col=('from_outg', 'from_outg')\n",
    ")\n",
    "#-----\n",
    "full_data_df_train_i = set_target_val_1_by_idx(\n",
    "    df=full_data_df_train_i,\n",
    "    val_1_idxs=full_outg_idxs_i,\n",
    "    remove_others_from_outages=remove_others_from_outages, \n",
    "    target_col=('is_outg', 'is_outg'), \n",
    "    from_outg_col=('from_outg', 'from_outg')\n",
    ")\n",
    "#-----\n",
    "full_data_df_test_i = set_target_val_1_by_idx(\n",
    "    df=full_data_df_test_i,\n",
    "    val_1_idxs=full_outg_idxs_i,\n",
    "    remove_others_from_outages=remove_others_from_outages, \n",
    "    target_col=('is_outg', 'is_outg'), \n",
    "    from_outg_col=('from_outg', 'from_outg')\n",
    ")\n",
    "#-----\n",
    "full_data_df_HOLDOUT_i = set_target_val_1_by_idx(\n",
    "    df=full_data_df_HOLDOUT_i,\n",
    "    val_1_idxs=full_outg_idxs_i,\n",
    "    remove_others_from_outages=remove_others_from_outages, \n",
    "    target_col=('is_outg', 'is_outg'), \n",
    "    from_outg_col=('from_outg', 'from_outg')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea0e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632f9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "n_outg_target_1_train = full_data_df_train_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_train = full_data_df_train_i[\n",
    "    (full_data_df_train_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_train_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_train = full_data_df_train_i[full_data_df_train_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_train_i.shape[0]==n_outg_target_1_train+n_outg_target_0_train+n_bsln_train)\n",
    "pct_target_1_train = 100*n_outg_target_1_train/(n_outg_target_1_train+n_outg_target_0_train+n_bsln_train)\n",
    "#-----\n",
    "print('\\n----- TRAIN -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_train}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_train}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_train/(n_outg_target_1_train+n_outg_target_0_train)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_train}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_train}%\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "n_outg_target_1_test = full_data_df_test_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_test = full_data_df_test_i[\n",
    "    (full_data_df_test_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_test_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_test = full_data_df_test_i[full_data_df_test_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_test_i.shape[0]==n_outg_target_1_test+n_outg_target_0_test+n_bsln_test)\n",
    "pct_target_1_test = 100*n_outg_target_1_test/(n_outg_target_1_test+n_outg_target_0_test+n_bsln_test)\n",
    "#-----\n",
    "print('\\n----- TEST -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_test}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_test}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_test/(n_outg_target_1_test+n_outg_target_0_test)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_test}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_test}%\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "n_outg_target_1_HOLDOUT = full_data_df_HOLDOUT_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_HOLDOUT = full_data_df_HOLDOUT_i[\n",
    "    (full_data_df_HOLDOUT_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_HOLDOUT_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_HOLDOUT = full_data_df_HOLDOUT_i[full_data_df_HOLDOUT_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_HOLDOUT_i.shape[0]==n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT+n_bsln_HOLDOUT)\n",
    "pct_target_1_HOLDOUT = 100*n_outg_target_1_HOLDOUT/(n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT+n_bsln_HOLDOUT)\n",
    "#-----\n",
    "print('\\n----- HOLDOUT -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_HOLDOUT}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_HOLDOUT}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_HOLDOUT/(n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_HOLDOUT}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_HOLDOUT}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6258def",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    full_data_df_train_i[('is_outg', 'is_outg')].sum()==0 or \n",
    "    full_data_df_test_i[('is_outg', 'is_outg')].sum()==0 or \n",
    "    full_data_df_HOLDOUT_i[('is_outg', 'is_outg')].sum()==0\n",
    "):\n",
    "    print('Not enough target value==1 in train, test, and/or holdout')\n",
    "    print(f\"#target==1 train:   {full_data_df_train_i[('is_outg', 'is_outg')].sum()}\")\n",
    "    print(f\"#target==1 test:    {full_data_df_test_i[('is_outg', 'is_outg')].sum()}\")\n",
    "    print(f\"#target==1 holdout: {full_data_df_HOLDOUT_i[('is_outg', 'is_outg')].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_train_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e1964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_pct_target_1 is not None:\n",
    "    full_data_df_train_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_train_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----\n",
    "    full_data_df_test_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_test_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----\n",
    "    full_data_df_HOLDOUT_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_HOLDOUT_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a57eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "n_outg_target_1_train = full_data_df_train_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_train = full_data_df_train_i[\n",
    "    (full_data_df_train_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_train_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_train = full_data_df_train_i[full_data_df_train_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_train_i.shape[0]==n_outg_target_1_train+n_outg_target_0_train+n_bsln_train)\n",
    "pct_target_1_train = 100*n_outg_target_1_train/(n_outg_target_1_train+n_outg_target_0_train+n_bsln_train)\n",
    "#-----\n",
    "print('\\n----- TRAIN -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_train}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_train}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_train/(n_outg_target_1_train+n_outg_target_0_train)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_train}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_train}%\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "n_outg_target_1_test = full_data_df_test_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_test = full_data_df_test_i[\n",
    "    (full_data_df_test_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_test_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_test = full_data_df_test_i[full_data_df_test_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_test_i.shape[0]==n_outg_target_1_test+n_outg_target_0_test+n_bsln_test)\n",
    "pct_target_1_test = 100*n_outg_target_1_test/(n_outg_target_1_test+n_outg_target_0_test+n_bsln_test)\n",
    "#-----\n",
    "print('\\n----- TEST -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_test}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_test}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_test/(n_outg_target_1_test+n_outg_target_0_test)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_test}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_test}%\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "n_outg_target_1_HOLDOUT = full_data_df_HOLDOUT_i[('is_outg', 'is_outg')].sum()\n",
    "n_outg_target_0_HOLDOUT = full_data_df_HOLDOUT_i[\n",
    "    (full_data_df_HOLDOUT_i[('from_outg', 'from_outg')]==1) & \n",
    "    (full_data_df_HOLDOUT_i[('is_outg', 'is_outg')]==0)\n",
    "].shape[0]\n",
    "n_bsln_HOLDOUT = full_data_df_HOLDOUT_i[full_data_df_HOLDOUT_i[('from_outg', 'from_outg')]==0].shape[0]\n",
    "assert(full_data_df_HOLDOUT_i.shape[0]==n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT+n_bsln_HOLDOUT)\n",
    "pct_target_1_HOLDOUT = 100*n_outg_target_1_HOLDOUT/(n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT+n_bsln_HOLDOUT)\n",
    "#-----\n",
    "print('\\n----- HOLDOUT -----')\n",
    "print(f\"# direct outages (target = 1):      {n_outg_target_1_HOLDOUT}\")\n",
    "print(f\"# indirect outages (target = 0):    {n_outg_target_0_HOLDOUT}\")\n",
    "print(f\"\\t% direct = {100*n_outg_target_1_HOLDOUT/(n_outg_target_1_HOLDOUT+n_outg_target_0_HOLDOUT)}\")\n",
    "print(f\"# additional baseline (target = 0): {n_bsln_HOLDOUT}\")\n",
    "print(f\"%(target==1):                       {pct_target_1_HOLDOUT}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('from_outg', 'from_outg') in full_data_df_i.columns.tolist():\n",
    "    full_data_df_i = full_data_df_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_train_i.columns.tolist():\n",
    "    full_data_df_train_i = full_data_df_train_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_test_i.columns.tolist():\n",
    "    full_data_df_test_i = full_data_df_test_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_HOLDOUT_i.columns.tolist():\n",
    "    full_data_df_HOLDOUT_i = full_data_df_HOLDOUT_i.drop(columns=[('from_outg', 'from_outg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d98635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd269a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reduce_train_size:\n",
    "    if split_train_test_by_outg:\n",
    "        full_data_df_train_i, _ = train_test_split_df_by_outage(\n",
    "            df=full_data_df_train_i, \n",
    "            outg_rec_nb_idfr='index_0', \n",
    "            test_size=red_test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        full_data_df_train_i, _ = train_test_split(\n",
    "            full_data_df_train_i, \n",
    "            test_size=red_test_size, \n",
    "            random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fba3de",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb58344",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_train_i.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a314ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugh = full_data_df_train_i.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugh[ugh>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba33a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_data_df_train_i.shape[0])\n",
    "full_data_df_train_i = full_data_df_train_i.dropna()\n",
    "print(full_data_df_train_i.shape[0])\n",
    "print()\n",
    "#-----\n",
    "print(full_data_df_test_i.shape[0])\n",
    "full_data_df_test_i = full_data_df_test_i.dropna()\n",
    "print(full_data_df_test_i.shape[0])\n",
    "print()\n",
    "#-----\n",
    "print(full_data_df_HOLDOUT_i.shape[0])\n",
    "full_data_df_HOLDOUT_i = full_data_df_HOLDOUT_i.dropna()\n",
    "print(full_data_df_HOLDOUT_i.shape[0])\n",
    "print()\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b564a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc17335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data_df_train_i   = full_data_df_train_i.drop(columns=('dummy_lvl_0', 'outg_month'))\n",
    "# full_data_df_test_i    = full_data_df_test_i.drop(columns=('dummy_lvl_0', 'outg_month'))\n",
    "# full_data_df_HOLDOUT_i = full_data_df_HOLDOUT_i.drop(columns=('dummy_lvl_0', 'outg_month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(full_data_df_train_i.columns.tolist()).symmetric_difference(set(full_data_df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "X_train_OG = full_data_df_train_i.iloc[:, :-1].copy()\n",
    "y_train    = full_data_df_train_i.iloc[:, -1].copy()\n",
    "\n",
    "X_test_OG = full_data_df_test_i.iloc[:, :-1].copy()\n",
    "y_test    = full_data_df_test_i.iloc[:, -1].copy()\n",
    "\n",
    "X_HOLDOUT = full_data_df_HOLDOUT_i.iloc[:, :-1]\n",
    "y_HOLDOUT = full_data_df_HOLDOUT_i.iloc[:, -1]\n",
    "#-------------------------\n",
    "if save_model:\n",
    "    X_train_OG.head().to_pickle(os.path.join(save_dir_model, 'data_structure_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(2,2, return_flattened_axes=True)\n",
    "#-------------------------\n",
    "sns.countplot(ax=axs[0], x = ('is_outg', 'is_outg'), data=full_data_df_i)\n",
    "axs[0].set_title('Full Data');\n",
    "axs[0].set_xlabel('Is Outage');\n",
    "axs[0].set_ylim([1.05*x for x in axs[0].get_ylim()])\n",
    "for p in axs[0].patches:\n",
    "    pct = (p.get_height()/full_data_df_i.shape[0]).round(5)\n",
    "    txt = f'{pct}%'\n",
    "    txt_x = p.get_x() \n",
    "    txt_y = 1.025*p.get_height()\n",
    "    axs[0].text(txt_x,txt_y,txt)\n",
    "#-------------------------\n",
    "sns.countplot(ax=axs[1], x = ('is_outg', 'is_outg'), data=y_train.to_frame())\n",
    "axs[1].set_title('Training Data');\n",
    "axs[1].set_xlabel('Is Outage');\n",
    "axs[1].set_ylim([1.05*x for x in axs[1].get_ylim()])\n",
    "for p in axs[1].patches:\n",
    "    pct = (p.get_height()/y_train.shape[0]).round(5)\n",
    "    txt = f'{pct}%'\n",
    "    txt_x = p.get_x() \n",
    "    txt_y = 1.025*p.get_height()\n",
    "    axs[1].text(txt_x,txt_y,txt)\n",
    "#-------------------------\n",
    "sns.countplot(ax=axs[2], x = ('is_outg', 'is_outg'), data=y_test.to_frame())\n",
    "axs[2].set_title('Testing Data');\n",
    "axs[2].set_xlabel('Is Outage');\n",
    "axs[2].set_ylim([1.05*x for x in axs[2].get_ylim()])\n",
    "for p in axs[2].patches:\n",
    "    pct = (p.get_height()/y_test.shape[0]).round(5)\n",
    "    txt = f'{pct}%'\n",
    "    txt_x = p.get_x() \n",
    "    txt_y = 1.025*p.get_height()\n",
    "    axs[2].text(txt_x,txt_y,txt)\n",
    "#-------------------------\n",
    "sns.countplot(ax=axs[3], x = ('is_outg', 'is_outg'), data=y_HOLDOUT.to_frame())\n",
    "axs[3].set_title('Holdout Data');\n",
    "axs[3].set_xlabel('Is Outage');\n",
    "axs[3].set_ylim([1.05*x for x in axs[3].get_ylim()])\n",
    "for p in axs[3].patches:\n",
    "    pct = (p.get_height()/y_HOLDOUT.shape[0]).round(5)\n",
    "    txt = f'{pct}%'\n",
    "    txt_x = p.get_x() \n",
    "    txt_y = 1.025*p.get_height()\n",
    "    axs[3].text(txt_x,txt_y,txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45927394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67150a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "if create_validation_set:\n",
    "    if split_train_test_by_outg:\n",
    "        X_train_OG, X_val_OG, y_train, y_val = train_test_split_df_group(\n",
    "            X=X_train_OG, \n",
    "            y=y_train, \n",
    "            groups=X_train_OG.index.get_level_values(0), \n",
    "            test_size=val_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        X_train_OG, X_val_OG, y_train, y_val = train_test_split(X_train_OG, y_train, test_size=val_size, random_state=random_state)\n",
    "#-------------------------\n",
    "if run_scaler:\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_OG)\n",
    "    #-----\n",
    "    if create_validation_set:\n",
    "        X_val   = scaler.transform(X_val_OG)\n",
    "    X_test  = scaler.transform(X_test_OG)\n",
    "    X_HOLDOUT   = scaler.transform(X_HOLDOUT)\n",
    "    #-----\n",
    "    if save_model:\n",
    "        joblib.dump(scaler, os.path.join(save_dir_model, 'scaler.joblib'))\n",
    "else:\n",
    "    X_train = X_train_OG\n",
    "    if create_validation_set:\n",
    "        X_val   = X_val_OG\n",
    "    X_test  = X_test_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4dfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_PCA:\n",
    "    # First, generate a PCA plot, showing the explained variance on the y-axis and number of components on x\n",
    "    # This is simply to check that the number of components kept looks correct\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    plt.plot(cumsum)\n",
    "    \n",
    "    # Now, run the PCA with pca_n_components and perform transforms\n",
    "    pca=PCA(n_components=pca_n_components)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    print(f'PCA n-components       = {pca.n_components_}')\n",
    "    print(f'PCA explained variance = {pca.explained_variance_ratio_.sum()}')\n",
    "    #-----\n",
    "    if create_validation_set:\n",
    "        X_val      = pca.transform(X_val)\n",
    "    X_test     = pca.transform(X_test)\n",
    "    X_HOLDOUT  = pca.transform(X_HOLDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92971c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "806e071f",
   "metadata": {},
   "source": [
    "# Dumb Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2dc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_clf = DumbClassifier()\n",
    "cross_val_score(dumb_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = dumb_clf.predict(X_test)\n",
    "# print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "# print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "# print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9092fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0202b280",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40851f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_clf = RandomForestClassifier(n_estimators = 100)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, criterion='entropy', n_jobs=-1)\n",
    "\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=-1)\n",
    "forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=None)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=None, class_weight='balanced')\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=None, n_jobs=None) #probably dont want max_depth=None\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 5000, max_depth=50, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8d5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097f0b8-5ec7-4269-b564-0a50e5871613",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_mecpx_build_info_dict(self):\n",
    "        r\"\"\"\n",
    "        \"\"\"\n",
    "        #-------------------------\n",
    "        assert(self.is_save_base_dir_loaded())\n",
    "        tpath = os.path.join(self.save_base_dir, 'mecpo_build_info_dict.json')\n",
    "        assert(os.path.exists(tpath))\n",
    "        #-----\n",
    "        tmp_f = open(tpath)\n",
    "        self.mecpo_build_info_dict = json.load(tmp_f)\n",
    "        tmp_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5c3de-a6af-487b-835f-9169d9fc1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # model_summary_dict, data_structure_df, model_clf MUST be present\n",
    "        assert(os.path.exists(os.path.join(model_dir, model_summary_dict_fname)))\n",
    "        tmp_f = open(os.path.join(model_dir, model_summary_dict_fname))\n",
    "        self.model_summary_dict = json.load(tmp_f)\n",
    "        tmp_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b404c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine mecpo_build_info_dict and summary_dict\n",
    "assert(set(mecpo_build_info_dict.keys()).intersection(set(summary_dict.keys()))==set())\n",
    "summary_dict = summary_dict | mecpo_build_info_dict\n",
    "#-------------------------\n",
    "if save_results:\n",
    "    CustomWriter.output_dict_to_json(\n",
    "        os.path.join(save_dir_model, 'summary_dict.json'), \n",
    "        summary_dict\n",
    "    )\n",
    "#-----\n",
    "if save_model:\n",
    "    joblib.dump(forest_clf, os.path.join(save_dir_model, 'forest_clf.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = forest_clf.predict(X_train)\n",
    "print('*****'*5)\n",
    "print('TRAINING DATASET')\n",
    "print('*****'*5)\n",
    "print(f\"#(target==1): {y_train.sum()}\")\n",
    "print(f\"#(target==0): {y_train.shape[0]-y_train.sum()}\")\n",
    "print(f\"%(target==1): {100*(y_train.sum()/(y_train.shape[0]))}\")\n",
    "print('-----'*5)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_train, y_pred_train))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_train, y_pred_train))\n",
    "print()\n",
    "\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "print('*****'*5)\n",
    "print('TESTING DATASET')\n",
    "print('*****'*5)\n",
    "print(f\"#(target==1): {y_test.sum()}\")\n",
    "print(f\"#(target==0): {y_test.shape[0]-y_test.sum()}\")\n",
    "print(f\"%(target==1): {100*(y_test.sum()/(y_test.shape[0]))}\")\n",
    "print('-----'*5)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "# y_pred_HOLDOUT = forest_clf.predict(X_HOLDOUT)\n",
    "# print('*****'*5)\n",
    "# print('HOLDOOUT DATASET')\n",
    "# print('*****'*5)\n",
    "# print(f\"#(target==1): {y_HOLDOUT.sum()}\")\n",
    "# print(f\"#(target==0): {y_HOLDOUT.shape[0]-y_HOLDOUT.sum()}\")\n",
    "# print(f\"%(target==1): {100*(y_HOLDOUT.sum()/(y_HOLDOUT.shape[0]))}\")\n",
    "# print('-----'*5)\n",
    "# print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_HOLDOUT, y_pred_HOLDOUT))\n",
    "# print(\"PRECISION OF THE MODEL: \", precision_score(y_HOLDOUT, y_pred_HOLDOUT))\n",
    "# print(\"RECALL    OF THE MODEL: \", recall_score(y_HOLDOUT, y_pred_HOLDOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_n_xfmrs = get_n_trsf_poles_per_outg(\n",
    "    df=merged_df_full, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "outgs_w_single_xfmr = outg_n_xfmrs[outg_n_xfmrs==1].index.tolist()\n",
    "#-------------------------\n",
    "n_dir_indir_tp_fn_train = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_train_i, \n",
    "    y_pred=y_pred_train, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "#-----\n",
    "n_dir_indir_tp_fn_test = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_test_i, \n",
    "    y_pred=y_pred, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fafbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs    = save_results\n",
    "fig_save_dir = save_dir_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = Plot_General.default_subplots(\n",
    "#     n_x=1, \n",
    "#     n_y=3, \n",
    "#     fig_num=fig_num, \n",
    "#     unit_figsize_width=6., \n",
    "#     unit_figsize_height=4., \n",
    "# )\n",
    "# Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_train, \n",
    "#     y_pred=y_pred_train, \n",
    "#     title='Train', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[0]\n",
    "# )\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_test, \n",
    "#     y_pred=y_pred, \n",
    "#     title='Test', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[1]\n",
    "# )\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_HOLDOUT, \n",
    "#     y_pred=y_pred_HOLDOUT, \n",
    "#     title='Holdout', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[2]\n",
    "# )\n",
    "# #-----\n",
    "# if save_figs:\n",
    "#     if not os.path.exists(fig_save_dir):\n",
    "#         os.makedirs(fig_save_dir)\n",
    "#     Plot_General.save_fig(\n",
    "#         fig=fig, \n",
    "#         save_dir=fig_save_dir, \n",
    "#         save_name='ConfusionMatrices.png', \n",
    "#         bbox_inches='tight'\n",
    "#     )\n",
    "# #-----\n",
    "# fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c605150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=2, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_train\n",
    ")\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_test, \n",
    "    y_pred=y_pred, \n",
    "    title='Test', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[1], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_test\n",
    ")\n",
    "#-----\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name='ConfusionMatrices.png', \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "#-----\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b296345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf272d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd9db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29755903",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_train = cross_val_predict(forest_clf, X_train, y_train, cv=3, method='predict_proba')\n",
    "#-----\n",
    "y_scores_train=y_probs_train[:,1]\n",
    "#-----\n",
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "fpr_train, tpr_train, threshold_train = roc_curve(y_train, y_scores_train)\n",
    "plot_roc_curve(fpr_train, tpr_train)\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f13065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_test = cross_val_predict(forest_clf, X_test, y_test, cv=3, method='predict_proba')\n",
    "#-----\n",
    "y_scores_test=y_probs_test[:,1]\n",
    "#-----\n",
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "fpr_test, tpr_test, threshold_test = roc_curve(y_test, y_scores_test)\n",
    "plot_roc_curve(fpr_test, tpr_test)\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(y_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5de3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9ade6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = list(zip(full_data_df.columns, forest_clf.feature_importances_))\n",
    "# importances\n",
    "\n",
    "assert(len(full_data_df_train_i.columns[:-1])==len(forest_clf.feature_importances_))\n",
    "importances = list(zip(full_data_df_train_i.columns[:-1], forest_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1d73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances_srtd = sorted(importances, key=lambda x: x[1], reverse=True)\n",
    "importances_srtd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    pd.DataFrame(importances_srtd, columns=['feature', 'forest_importance']).to_csv(\n",
    "        os.path.join(save_dir_model, 'forest_importances.csv')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_srtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8196b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reason, importance in importances_srtd:\n",
    "    print(f\"{reason}:\\t{importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2e254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_to_include=None\n",
    "n_to_include=20\n",
    "#-------------------------\n",
    "assert(len(full_data_df_train_i.columns[:-1])==len(forest_clf.feature_importances_))\n",
    "importances = forest_clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest_clf.estimators_], axis=0)\n",
    "feature_names = full_data_df_train_i.columns[:-1].tolist()\n",
    "#-------------------------\n",
    "forest_importances = pd.DataFrame(\n",
    "    data={\n",
    "        'name':feature_names, \n",
    "        'importance':importances, \n",
    "        'std':std\n",
    "    }, \n",
    ")\n",
    "forest_importances=forest_importances.sort_values(by=['importance'], ascending=False)\n",
    "if n_to_include is not None:\n",
    "    forest_importances = forest_importances.iloc[:n_to_include]\n",
    "#-------------------------\n",
    "fig, ax = Plot_General.default_subplots(fig_num=fig_num)\n",
    "forest_importances.plot.bar(ax=ax, x='name', y='importance', yerr='std', legend=False)\n",
    "#-----\n",
    "title = \"Feature importances\"\n",
    "if n_to_include is not None:\n",
    "    title += f\" (Top {n_to_include})\"\n",
    "ax.set_title(title, fontdict=dict(fontsize=24))\n",
    "ax.set_ylabel(\"Importance\", fontdict=dict(fontsize=16))\n",
    "ax.set_xlabel(\"Feature\", fontdict=dict(fontsize=16))\n",
    "\n",
    "#-----\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name='FeatureImportances.png', \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "#-----\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_to_include=None\n",
    "n_to_include=20\n",
    "#-------------------------\n",
    "assert(len(full_data_df_train_i.columns[:-1])==len(forest_clf.feature_importances_))\n",
    "importances = forest_clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest_clf.estimators_], axis=0)\n",
    "feature_names = full_data_df_train_i.columns[:-1].tolist()\n",
    "#-------------------------\n",
    "forest_importances = pd.DataFrame(\n",
    "    data={\n",
    "        'name':feature_names, \n",
    "        'importance':importances, \n",
    "        'std':std\n",
    "    }, \n",
    ")\n",
    "forest_importances=forest_importances.sort_values(by=['importance'], ascending=False)\n",
    "if n_to_include is not None:\n",
    "    forest_importances = forest_importances.iloc[:n_to_include]\n",
    "#-------------------------\n",
    "fig, ax = Plot_General.default_subplots(fig_num=fig_num)\n",
    "forest_importances.plot.barh(ax=ax, x='name', y='importance', xerr='std', legend=False)\n",
    "#-----\n",
    "title = \"Feature importances\"\n",
    "if n_to_include is not None:\n",
    "    title += f\" (Top {n_to_include})\"\n",
    "ax.set_title(title, fontdict=dict(fontsize=24))\n",
    "ax.set_xlabel(\"Importance\", fontdict=dict(fontsize=16))\n",
    "ax.set_ylabel(\"Feature\", fontdict=dict(fontsize=16))\n",
    "\n",
    "#-----\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name='FeatureImportances_Horz.png', \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "#-----\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7cec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdaab94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_train = forest_clf.predict_proba(X_train)\n",
    "# y_scores = cross_val_predict(forest_clf, X_train, y_train, cv=3, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633881f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores_train[:,1])\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c72cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_test = forest_clf.predict_proba(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores_test[:,1])\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5b9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd8721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59118471",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=1, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "axs=[axs]\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_train\n",
    ")\n",
    "\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.2\n",
    "y_pred_train_t_i = (y_scores_train[:,1]>=threshold).astype(int)\n",
    "\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=1, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "axs=[axs]\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train_t_i, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=None\n",
    ")\n",
    "\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea994a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b96f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_test = forest_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dda553",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.2\n",
    "y_pred_test_t_i = (y_scores_test[:,1]>=threshold).astype(int)\n",
    "\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=1, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "axs=[axs]\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_test, \n",
    "    y_pred=y_pred_test_t_i, \n",
    "    title='Test', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=None\n",
    ")\n",
    "\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1ef60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bedee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baaabe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd161ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a180350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca698ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_latex_rf_importances_table(\n",
    "    importances_srtd, \n",
    "    n_round=10, \n",
    "    periods = [    \n",
    "        '01-05 Days',\n",
    "        '06-10 Days',\n",
    "        '11-15 Days',\n",
    "        '16-20 Days',\n",
    "        '21-25 Days',\n",
    "        '26-30 Days'\n",
    "    ], \n",
    "    save_path=None\n",
    "):\n",
    "    #-------------------------\n",
    "    latex_head = ['Period', 'Reason', 'Importance']\n",
    "    latex = r\"\"\"\n",
    "    \\begin{longtable}{|c|c|c|}\n",
    "      \\hline\n",
    "    \"\"\"\n",
    "    latex += \"  \" + ' & '.join(latex_head) + r'\\\\' + '\\n' + r'  \\hline' + '\\n'\n",
    "    #-------------------------\n",
    "    for col_i, importance_i in importances_srtd:\n",
    "        #----------\n",
    "        if col_i[0] in periods:\n",
    "            period_i=col_i[0]\n",
    "        else:\n",
    "            period_i=''\n",
    "        #----------\n",
    "        reason_i = col_i[1]\n",
    "        #----------\n",
    "        latex += r\"  {period_i} & {reason_i} & {importance_i:.{n_round}e}\\\\\".format(\n",
    "            period_i=period_i, reason_i=reason_i, importance_i=importance_i, n_round=n_round\n",
    "        )\n",
    "        latex += '\\n' + r'  \\hline' + '\\n'\n",
    "    #-------------------------\n",
    "    latex += r\"\\end{longtable}\"\n",
    "    #-------------------------\n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(latex)\n",
    "    #-------------------------\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00df654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex = build_latex_rf_importances_table(\n",
    "#     importances_srtd, \n",
    "#     save_path=r'C:\\Users\\s346557\\Downloads\\test_latex.txt'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dcc0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d17171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567b1eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189d438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7114e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9ce86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f74200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_clf.estimators_\n",
    "est_depths = [estimator.get_depth() for estimator in forest_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(est_depths, reverse=False)[0])\n",
    "print(sorted(est_depths, reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c59d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "# # NOTE: Can be a single dict, or a list of dicts\n",
    "forest_param_grid = { \n",
    "    'n_estimators': [100, 200, 500, 1000, 2000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [10, 20, 30, 40, 50],\n",
    "    'criterion' :['gini', 'entropy', 'log_loss'], \n",
    "    'bootstrap':[True,False]\n",
    "}\n",
    "\n",
    "# # forest_param_grid = { \n",
    "# #     'n_estimators': [500, 1000],\n",
    "# #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "# #     'bootstrap':[True,False]\n",
    "# # }\n",
    "\n",
    "# # forest_grid_search = GridSearchCV(\n",
    "# #     forest_clf, forest_param_grid, cv=3, \n",
    "# #     scoring=None, \n",
    "# #     return_train_score=True\n",
    "# # )\n",
    "\n",
    "forest_grid_search = RandomizedSearchCV(\n",
    "    forest_clf, forest_param_grid, cv=3, \n",
    "    scoring=None, \n",
    "    return_train_score=True, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "forest_grid_search.fit(X_train, y_train)\n",
    "print(time.time()-start)\n",
    "\n",
    "print(forest_grid_search.best_params_)\n",
    "print(forest_grid_search.best_estimator_)\n",
    "y_pred = forest_grid_search.best_estimator_.predict(X_test)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(x) for x in np.linspace(10, 50, num = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa652a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# #-------------------------\n",
    "# # Create the random grid\n",
    "# forest_param_grid = {\n",
    "#     'n_estimators': n_estimators,\n",
    "#     'max_features': max_features,\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "#     'bootstrap': bootstrap\n",
    "# }\n",
    "\n",
    "# forest_grid_search = RandomizedSearchCV(\n",
    "#     forest_clf, forest_param_grid, cv=3, \n",
    "#     scoring=None, \n",
    "#     return_train_score=True\n",
    "# )\n",
    "# #-------------------------\n",
    "# start = time.time()\n",
    "# forest_grid_search.fit(X_train, y_train)\n",
    "# print(time.time()-start)\n",
    "\n",
    "# print(forest_grid_search.best_params_)\n",
    "# print(forest_grid_search.best_estimator_)\n",
    "# y_pred = forest_grid_search.best_estimator_.predict(X_test)\n",
    "# print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "# print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "# print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24adde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccc1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f362a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_scaler:\n",
    "    assert((scaler.transform(full_data_df_test_i.iloc[:, :-1])==X_test).all())\n",
    "else:\n",
    "    assert(full_data_df_test_i.iloc[:, :-1].equals(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f38453",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_i[('is_outg', 'is_outg')].equals(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4db8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af51aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_by_confusion_result = get_X_entries_by_binary_confusion_matrix_result(X_test, y_test, y_pred)\n",
    "X_by_confusion_result = convert_X_by_confusion_results_to_dfs(\n",
    "    X_by_confusion_result=X_by_confusion_result, \n",
    "    full_data_df=full_data_df_test_i, \n",
    "    run_PCA=run_PCA, \n",
    "    run_scaler=run_scaler    \n",
    ")\n",
    "\n",
    "X_tp = X_by_confusion_result['X_tp']\n",
    "X_tn = X_by_confusion_result['X_tn']\n",
    "X_fp = X_by_confusion_result['X_fp']\n",
    "X_fn = X_by_confusion_result['X_fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc873f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12beb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUCK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec505a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_i_by_cnfsn_res = get_df_subset_by_binary_confusion_matrix_result(\n",
    "    data_df=full_data_df_test_i, \n",
    "    y_pred=y_pred, \n",
    "    y_col=('is_outg', 'is_outg')\n",
    ")\n",
    "full_data_df_test_tp = full_data_df_test_i_by_cnfsn_res['TP']\n",
    "full_data_df_test_tn = full_data_df_test_i_by_cnfsn_res['TN']\n",
    "full_data_df_test_fp = full_data_df_test_i_by_cnfsn_res['FP']\n",
    "full_data_df_test_fn = full_data_df_test_i_by_cnfsn_res['FN']\n",
    "#-------------------------\n",
    "full_data_df_test_tp = DOVSOutages.append_outg_info_to_df(\n",
    "    df=full_data_df_test_tp, \n",
    "#     outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    ")\n",
    "#-----\n",
    "full_data_df_test_fn = DOVSOutages.append_outg_info_to_df(\n",
    "    df=full_data_df_test_fn, \n",
    "#     outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    ")\n",
    "#-------------------------\n",
    "if full_data_df_test_tp.index.names[0] is None:\n",
    "    full_data_df_test_tp.index.names = ['outg_rec_nb', full_data_df_test_tp.index.names[1]]\n",
    "if full_data_df_test_fn.index.names[0] is None:\n",
    "    full_data_df_test_fn.index.names = ['outg_rec_nb', full_data_df_test_fn.index.names[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717037e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_tp.sample(n=100).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_tn.sample(n=100).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba7f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xfmrs_per_outg = get_n_trsf_poles_per_outg(\n",
    "    df=merged_df_full, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "n_xfmrs_per_outg.name = 'n_xfmrs_in_outg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Need to drop duplicates so that outages are not weighted by\n",
    "#       the number of transformers in outage\n",
    "#--------------------------------------------------\n",
    "#--------------------------------------------------\n",
    "dovs_df_test_tp = full_data_df_test_tp['outg_dummy_lvl_0'].copy()\n",
    "#-----\n",
    "n_xfmrs_in_outg_tp = get_n_trsf_poles_per_outg(\n",
    "    df=dovs_df_test_tp, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "n_xfmrs_in_outg_tp.name = 'n_xfmrs_in_outg_cnfsn_grp'\n",
    "#-----\n",
    "dovs_df_test_tp=dovs_df_test_tp.droplevel(level=1, axis=0).drop_duplicates()\n",
    "assert(dovs_df_test_tp.shape[0]==n_xfmrs_in_outg_tp.shape[0])\n",
    "og_len = dovs_df_test_tp.shape[0]\n",
    "dovs_df_test_tp = pd.merge(dovs_df_test_tp, n_xfmrs_in_outg_tp, left_index=True, right_index=True, how='inner')\n",
    "dovs_df_test_tp = pd.merge(dovs_df_test_tp, n_xfmrs_per_outg,   left_index=True, right_index=True, how='inner')\n",
    "assert(dovs_df_test_tp.shape[0]==og_len)\n",
    "#--------------------------------------------------\n",
    "#--------------------------------------------------\n",
    "dovs_df_test_fn = full_data_df_test_fn['outg_dummy_lvl_0'].copy()\n",
    "#-----\n",
    "n_xfmrs_in_outg_fn = get_n_trsf_poles_per_outg(\n",
    "    df=dovs_df_test_fn, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "n_xfmrs_in_outg_fn.name = 'n_xfmrs_in_outg_cnfsn_grp'\n",
    "#-----\n",
    "dovs_df_test_fn=dovs_df_test_fn.droplevel(level=1, axis=0).drop_duplicates()\n",
    "assert(dovs_df_test_fn.shape[0]==n_xfmrs_in_outg_fn.shape[0])\n",
    "og_len = dovs_df_test_fn.shape[0]\n",
    "dovs_df_test_fn = pd.merge(dovs_df_test_fn, n_xfmrs_in_outg_fn, left_index=True, right_index=True, how='inner')\n",
    "dovs_df_test_fn = pd.merge(dovs_df_test_fn, n_xfmrs_per_outg,   left_index=True, right_index=True, how='inner')\n",
    "assert(dovs_df_test_fn.shape[0]==og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp[dovs_df_test_tp['n_xfmrs_in_outg']!=dovs_df_test_tp['n_xfmrs_in_outg_cnfsn_grp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71738690",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_fn[dovs_df_test_fn['n_xfmrs_in_outg']!=dovs_df_test_fn['n_xfmrs_in_outg_cnfsn_grp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb20289",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dovs_df_test_tp[dovs_df_test_tp['n_xfmrs_in_outg']!=dovs_df_test_tp['n_xfmrs_in_outg_cnfsn_grp']].index).difference(\n",
    "    set(dovs_df_test_fn[dovs_df_test_fn['n_xfmrs_in_outg']!=dovs_df_test_fn['n_xfmrs_in_outg_cnfsn_grp']].index)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341147c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp_tmp = dovs_df_test_tp.copy()\n",
    "dovs_df_test_fn_tmp = dovs_df_test_fn.copy()\n",
    "#-----\n",
    "dovs_df_test_tp_tmp['Cnfsn']='TP'\n",
    "dovs_df_test_fn_tmp['Cnfsn']='FN'\n",
    "#-----\n",
    "dovs_df_test_tp_fn = pd.concat([dovs_df_test_tp_tmp, dovs_df_test_fn_tmp])\n",
    "del dovs_df_test_tp_tmp\n",
    "del dovs_df_test_fn_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01292f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp_fn = DOVSOutages.set_mjr_mnr_cause_nm_col(\n",
    "    dovs_df_test_tp_fn, \n",
    "    mjr_mnr_cause_nm_col='MJR_MNR_CAUSE_CD', \n",
    "    mjr_cause_nm_col='MJR_CAUSE_CD', \n",
    "    mnr_cause_nm_col='MNR_CAUSE_CD'\n",
    ")\n",
    "#-----\n",
    "dovs_df_test_tp = DOVSOutages.set_mjr_mnr_cause_nm_col(\n",
    "    dovs_df_test_tp, \n",
    "    mjr_mnr_cause_nm_col='MJR_MNR_CAUSE_CD', \n",
    "    mjr_cause_nm_col='MJR_CAUSE_CD', \n",
    "    mnr_cause_nm_col='MNR_CAUSE_CD'\n",
    ")\n",
    "#-----\n",
    "dovs_df_test_fn = DOVSOutages.set_mjr_mnr_cause_nm_col(\n",
    "    dovs_df_test_fn, \n",
    "    mjr_mnr_cause_nm_col='MJR_MNR_CAUSE_CD', \n",
    "    mjr_cause_nm_col='MJR_CAUSE_CD', \n",
    "    mnr_cause_nm_col='MNR_CAUSE_CD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f443c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffadaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    hue='Cnfsn', \n",
    "    order='avg_y', \n",
    "    batch_size=40,\n",
    "    batch_absorb_last_pair_pct=0.50, \n",
    "    sharex=True, \n",
    "    fig_num=1, \n",
    "    hue_palette=dict(TP='green', FN='red'), \n",
    "    log_y_box=False,\n",
    "    log_y_counts=False\n",
    "):\n",
    "    r\"\"\"\n",
    "    order \n",
    "        Intent/in general: must be ['avg_y', 'counts_x'] or any in list + a hue value\n",
    "            e.g., hue_vals are usually TP and FN, so one could set order='avg_y TP'\n",
    "        However: User can supply own list of x_col values if, e.g., he wants his own custom ordering\n",
    "            OR if he only wants to plot a subset of the values.\n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    hue_vals = dovs_df[hue].unique().tolist()\n",
    "    #-----\n",
    "    assert(Utilities.is_object_one_of_types(order, [str, list]))\n",
    "    if isinstance(order, str):\n",
    "        accptbl_orders = ['avg_y', 'counts_x']\n",
    "        accptbl_orders += [\n",
    "            accptbl_order + f' {hue_val}' \n",
    "            for accptbl_order in accptbl_orders \n",
    "            for hue_val in hue_vals\n",
    "        ]\n",
    "        #-----\n",
    "        assert(order in accptbl_orders)\n",
    "        #-------------------------\n",
    "        order_type_and_hue = re.findall(r\"(avg_y|counts_x)\\s?(.*)\", order, flags=0)\n",
    "        assert(len(order_type_and_hue)==1 and len(order_type_and_hue[0])==2)\n",
    "        order_type, order_hue = order_type_and_hue[0]\n",
    "        #-------------------------\n",
    "        if order_hue:\n",
    "            order_df = dovs_df[dovs_df[hue]==order_hue]\n",
    "        else:\n",
    "            order_df = dovs_df\n",
    "        #-------------------------\n",
    "        # Order by data in order_df, BUT need to ensure all values from dovs_df are included,\n",
    "        #   hence the set operations.\n",
    "        if order_type=='avg_y':\n",
    "            order = order_df[[x_col, y_col]].groupby(x_col).mean().sort_values(by=y_col, ascending=False).index.tolist()\n",
    "            order += list(set(dovs_df[[x_col, y_col]].groupby(x_col).mean().sort_values(by=y_col, ascending=False).index.tolist()).difference(order))\n",
    "        elif order_type=='counts_x':\n",
    "            order = order_df[x_col].value_counts().index.tolist()\n",
    "            order += list(set(dovs_df[x_col].value_counts().index.tolist()).difference(order))\n",
    "        else:\n",
    "            assert(0)\n",
    "        #   AND!!!!! NaN values are not caught by first set operation above, hence the need for the second below\n",
    "        order += list(set(dovs_df[x_col].unique().tolist()).difference(order))\n",
    "        #-------------------------\n",
    "        assert(len(order)==dovs_df[x_col].nunique(dropna=False))\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    if batch_size is None or batch_size==0:\n",
    "        batch_idxs = [[0, len(order)]]\n",
    "    else:\n",
    "        batch_idxs = Utilities.get_batch_idx_pairs(\n",
    "            n_total=len(order), \n",
    "            batch_size=batch_size, \n",
    "            absorb_last_pair_pct=batch_absorb_last_pair_pct\n",
    "        )\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if sharex==True:\n",
    "        sharex='col'\n",
    "    fig, axs = Plot_General.default_subplots(n_x=len(batch_idxs), n_y=2, fig_num=fig_num, return_flattened_axes=False, sharex=sharex)\n",
    "    if axs.ndim==1:\n",
    "        axs = np.expand_dims(axs, 1)\n",
    "    #-------------------------\n",
    "    for i_plot_col, (idx_0, idx_1) in enumerate(batch_idxs):\n",
    "        sns.countplot(\n",
    "            ax=axs[0][i_plot_col], \n",
    "            data=dovs_df,\n",
    "            x=x_col, \n",
    "            hue=hue, \n",
    "            order=order[idx_0:idx_1], \n",
    "            palette=hue_palette\n",
    "        )\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            axs[0][i_plot_col], \n",
    "            draw_legend=True, \n",
    "            legend_args=dict(loc='upper right', fontsize=20), \n",
    "            title_args=dict(label=f'{x_col}s in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "            xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "            ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "            tick_args=dict(axis='x', labelrotation=90)\n",
    "        )\n",
    "        if log_y_counts:\n",
    "            axs[0][i_plot_col].set_yscale('log')\n",
    "        #-------------------------\n",
    "        sns.boxplot(\n",
    "            ax=axs[1][i_plot_col], \n",
    "            data=dovs_df,\n",
    "            x=x_col, \n",
    "            y=y_col, \n",
    "            hue=hue, \n",
    "            order=order[idx_0:idx_1], \n",
    "            palette=hue_palette, \n",
    "            flierprops = dict(marker='x', markersize=3), \n",
    "            showmeans=True, \n",
    "            meanprops = dict(marker='o', markerfacecolor='white', markeredgecolor='black', markersize=5)\n",
    "        )\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            axs[1][i_plot_col], \n",
    "            draw_legend=True, \n",
    "            legend_args=dict(loc='upper right', fontsize=20), \n",
    "            title_args=dict(label=f'{y_col} vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "            xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "            ylabel_args=dict(ylabel=y_col, loc='top', fontdict=dict(fontsize=16)), \n",
    "            tick_args=dict(axis='x', labelrotation=90)\n",
    "        )\n",
    "        if log_y_box:\n",
    "            axs[1][i_plot_col].set_yscale('log')\n",
    "    #-------------------------\n",
    "    Plot_General.adjust_subplots_args(fig, dict(hspace=0.3))\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dovs_cmi_ci_boxplots_with_countplots(\n",
    "    dovs_df,\n",
    "    x_col,\n",
    "    hue='Cnfsn', \n",
    "    order='avg_y', \n",
    "    batch_size=40,\n",
    "    batch_absorb_last_pair_pct=0.50, \n",
    "    sharex=True, \n",
    "    fig_num=1, \n",
    "    hue_palette=dict(TP='green', FN='red'), \n",
    "    log_y_box=False,\n",
    "    log_y_counts=False\n",
    "):\n",
    "    r\"\"\"\n",
    "    order \n",
    "        Intent/in general: must be ['avg_y', 'counts_x'] or any in list + a hue value\n",
    "            e.g., hue_vals are usually TP and FN, so one could set order='avg_y TP'\n",
    "        Order will be taken from CMI_NB (not CI_NB)...can be extended to both functionality later if needed\n",
    "        However: User can supply own list of x_col values if, e.g., he wants his own custom ordering\n",
    "            OR if he only wants to plot a subset of the values.\n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    hue_vals = dovs_df[hue].unique().tolist()\n",
    "    #-----\n",
    "    assert(Utilities.is_object_one_of_types(order, [str, list]))\n",
    "    if isinstance(order, str):\n",
    "        accptbl_orders = ['avg_y', 'counts_x']\n",
    "        accptbl_orders += [\n",
    "            accptbl_order + f' {hue_val}' \n",
    "            for accptbl_order in accptbl_orders \n",
    "            for hue_val in hue_vals\n",
    "        ]\n",
    "        #-----\n",
    "        assert(order in accptbl_orders)\n",
    "        #-------------------------\n",
    "        order_type_and_hue = re.findall(r\"(avg_y|counts_x)\\s?(.*)\", order, flags=0)\n",
    "        assert(len(order_type_and_hue)==1 and len(order_type_and_hue[0])==2)\n",
    "        order_type, order_hue = order_type_and_hue[0]\n",
    "        #-------------------------\n",
    "        if order_hue:\n",
    "            order_df = dovs_df[dovs_df[hue]==order_hue]\n",
    "        else:\n",
    "            order_df = dovs_df\n",
    "        #-------------------------\n",
    "        # Order by data in order_df, BUT need to ensure all values from dovs_df are included,\n",
    "        #   hence the set operations.\n",
    "        if order_type=='avg_y':\n",
    "            order = order_df[[x_col, 'CMI_NB']].groupby(x_col).mean().sort_values(by='CMI_NB', ascending=False).index.tolist()\n",
    "            order += list(set(dovs_df[[x_col, 'CMI_NB']].groupby(x_col).mean().sort_values(by='CMI_NB', ascending=False).index.tolist()).difference(order))\n",
    "        elif order_type=='counts_x':\n",
    "            order = order_df[x_col].value_counts().index.tolist()\n",
    "            order += list(set(dovs_df[x_col].value_counts().index.tolist()).difference(order))\n",
    "        else:\n",
    "            assert(0)\n",
    "        #   AND!!!!! NaN values are not caught by first set operation above, hence the need for the second below\n",
    "        order += list(set(dovs_df[x_col].unique().tolist()).difference(order))\n",
    "        #-------------------------\n",
    "        assert(len(order)==dovs_df[x_col].nunique(dropna=False))\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    if batch_size is None or batch_size==0:\n",
    "        batch_idxs = [[0, len(order)]]\n",
    "    else:\n",
    "        batch_idxs = Utilities.get_batch_idx_pairs(\n",
    "            n_total=len(order), \n",
    "            batch_size=batch_size, \n",
    "            absorb_last_pair_pct=batch_absorb_last_pair_pct\n",
    "        )\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if sharex==True:\n",
    "        sharex='col'\n",
    "    fig, axs = Plot_General.default_subplots(n_x=len(batch_idxs), n_y=3, fig_num=fig_num, return_flattened_axes=False, sharex=sharex)\n",
    "    if axs.ndim==1:\n",
    "        axs = np.expand_dims(axs, 1)\n",
    "    #-------------------------\n",
    "    for i_plot_col, (idx_0, idx_1) in enumerate(batch_idxs):\n",
    "        sns.countplot(\n",
    "            ax=axs[0][i_plot_col], \n",
    "            data=dovs_df,\n",
    "            x=x_col, \n",
    "            hue=hue, \n",
    "            order=order[idx_0:idx_1], \n",
    "            palette=hue_palette\n",
    "        )\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            axs[0][i_plot_col], \n",
    "            draw_legend=True, \n",
    "            legend_args=dict(loc='upper right', fontsize=20), \n",
    "            title_args=dict(label=f'{x_col}s in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "            xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "            ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "            tick_args=dict(axis='x', labelrotation=90)\n",
    "        )\n",
    "        if log_y_counts:\n",
    "            axs[0][i_plot_col].set_yscale('log')\n",
    "        #-------------------------\n",
    "        sns.boxplot(\n",
    "            ax=axs[1][i_plot_col], \n",
    "            data=dovs_df,\n",
    "            x=x_col, \n",
    "            y='CI_NB', \n",
    "            hue=hue, \n",
    "            order=order[idx_0:idx_1], \n",
    "            palette=hue_palette, \n",
    "            flierprops = dict(marker='x', markersize=3), \n",
    "            showmeans=True, \n",
    "            meanprops = dict(marker='o', markerfacecolor='white', markeredgecolor='black', markersize=5)\n",
    "        )\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            axs[1][i_plot_col], \n",
    "            draw_legend=True, \n",
    "            legend_args=dict(loc='upper right', fontsize=20), \n",
    "            title_args=dict(label=f'CI_NB vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "            xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "            ylabel_args=dict(ylabel='CI_NB', loc='top', fontdict=dict(fontsize=16)), \n",
    "            tick_args=dict(axis='x', labelrotation=90)\n",
    "        )\n",
    "        if log_y_box:\n",
    "            axs[1][i_plot_col].set_yscale('log')\n",
    "        #-------------------------\n",
    "        sns.boxplot(\n",
    "            ax=axs[2][i_plot_col], \n",
    "            data=dovs_df,\n",
    "            x=x_col, \n",
    "            y='CMI_NB', \n",
    "            hue=hue, \n",
    "            order=order[idx_0:idx_1], \n",
    "            palette=hue_palette, \n",
    "            flierprops = dict(marker='x', markersize=3), \n",
    "            showmeans=True, \n",
    "            meanprops = dict(marker='o', markerfacecolor='white', markeredgecolor='black', markersize=5)\n",
    "        )\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            axs[2][i_plot_col], \n",
    "            draw_legend=True, \n",
    "            legend_args=dict(loc='upper right', fontsize=20), \n",
    "            title_args=dict(label=f'CMI_NB vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "            xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "            ylabel_args=dict(ylabel='CMI_NB', loc='top', fontdict=dict(fontsize=16)), \n",
    "            tick_args=dict(axis='x', labelrotation=90)\n",
    "        )\n",
    "        if log_y_box:\n",
    "            axs[2][i_plot_col].set_yscale('log')\n",
    "    #-------------------------\n",
    "    Plot_General.adjust_subplots_args(fig, dict(hspace=0.3))\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd375e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4353b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5347f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'MNR_CAUSE_CD'\n",
    "y_col = 'CI_NB'\n",
    "#-----\n",
    "# Order by data in dovs_df_test_tp, BUT need to ensure all values from dovs_df_test_tp_fn are included,\n",
    "#   hence the set operation\n",
    "order = dovs_df_test_tp[[x_col, y_col]].groupby(x_col).mean().sort_values(by=y_col, ascending=False).index.tolist()\n",
    "order += list(set(dovs_df_test_tp_fn[x_col].unique().tolist()).difference(order))\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "sns.boxplot(\n",
    "    ax=axs, \n",
    "    data=dovs_df_test_tp_fn,\n",
    "    x=x_col, \n",
    "    y=y_col, \n",
    "    hue='Cnfsn', \n",
    "    order=order, \n",
    "    palette=dict(TP='green', FN='red'), \n",
    "    flierprops = dict(marker='x', markersize=3), \n",
    "    showmeans=True, \n",
    "    meanprops = dict(marker='o', markerfacecolor='white', markeredgecolor='black', markersize=5)\n",
    ");\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{y_col} vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel=y_col, loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=45)\n",
    ")\n",
    "axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_fn[dovs_df_test_fn['MNR_CAUSE_CD']=='FO'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfe3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006042c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'MNR_CAUSE_CD'\n",
    "y_col = 'CI_NB'\n",
    "#-----\n",
    "# Order by data in dovs_df_test_tp, BUT need to ensure all values from dovs_df_test_tp_fn are included,\n",
    "#   hence the set operation\n",
    "order = dovs_df_test_tp[[x_col, y_col]].groupby(x_col).mean().sort_values(by=y_col, ascending=False).index.tolist()\n",
    "order += list(set(dovs_df_test_tp_fn[x_col].unique().tolist()).difference(order))\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "sns.pointplot(\n",
    "    ax=axs, \n",
    "    data=dovs_df_test_tp_fn,\n",
    "    x=x_col, \n",
    "    y=y_col, \n",
    "    hue='Cnfsn', \n",
    "    order=order, \n",
    "    palette=dict(TP='green', FN='red'), \n",
    "    dodge=0.5\n",
    ");\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{y_col} vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel=y_col, loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=45)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd43911",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'MNR_CAUSE_CD'\n",
    "y_col = 'CI_NB'\n",
    "#-----\n",
    "# Order by data in dovs_df_test_tp, BUT need to ensure all values from dovs_df_test_tp_fn are included,\n",
    "#   hence the set operation\n",
    "order = dovs_df_test_tp[[x_col, y_col]].groupby(x_col).mean().sort_values(by=y_col, ascending=False).index.tolist()\n",
    "order += list(set(dovs_df_test_tp_fn[x_col].unique().tolist()).difference(order))\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "bplot = sns.boxplot(\n",
    "    ax=axs, \n",
    "    data=dovs_df_test_tp_fn,\n",
    "    x=x_col, \n",
    "    y=y_col, \n",
    "    hue='Cnfsn', \n",
    "    order=order, \n",
    "    palette=dict(TP='green', FN='red'), \n",
    "    flierprops = dict(marker='x', markersize=3), \n",
    "    showmeans=True, \n",
    "    meanprops = dict(marker='o', markerfacecolor='white', markeredgecolor='black', markersize=5), \n",
    "    showfliers=False\n",
    ");\n",
    "children = axs.get_children()\n",
    "sns.pointplot(\n",
    "    ax=axs, \n",
    "    data=dovs_df_test_tp_fn,\n",
    "    x=x_col, \n",
    "    y=y_col, \n",
    "    hue='Cnfsn', \n",
    "    order=order, \n",
    "    palette=dict(TP='green', FN='red'), \n",
    "    dodge=0.4, \n",
    "    join=True, \n",
    "    errorbar='ci', \n",
    "    capsize=0.2, \n",
    "    linestyles='dotted'\n",
    ");\n",
    "\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{y_col} vs. {x_col} in Outages', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel=y_col, loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=45)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_fn[dovs_df_test_fn['MNR_CAUSE_CD']=='FO'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.get_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72089af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86922661",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = bplot.get_children()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.get_children()[0].get_offsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c037bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.get_children()[1].get_offsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd31b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk.get_offsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6410bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86e5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ea471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594de620",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf29c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11b214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715eefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_box=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a02cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_box=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=None, \n",
    "    log_y_box=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c408c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=20, \n",
    "    log_y_box=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32884aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_cmi_ci_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=20, \n",
    "    log_y_box=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04107e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_cmi_ci_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    hue='Cnfsn', \n",
    "    order='counts_x', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_box=True, \n",
    "    log_y_counts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee9b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a61c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca849987",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y', \n",
    "    sharex=True, \n",
    "    batch_size=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='counts_x', \n",
    "    sharex=True, \n",
    "    log_y_box=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726dec11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ccd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='counts_x', \n",
    "    sharex=True, \n",
    "    batch_size=40\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c56563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66c751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0054159",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=False, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbee503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450defc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='DVC_TYP_NM',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180fb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb662a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='DVC_TYP_NM',\n",
    "    y_col='CI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615bf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0482adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='EQUIP_TYP_NM',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a7f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04932f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='EQUIP_TYP_NM',\n",
    "    y_col='CI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf4745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='MJR_MNR_CAUSE_CD',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=None, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec488a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81bf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb65c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5309ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dovs_df_test_tp[dovs_df_test_tp['MJR_MNR_CAUSE_CD']=='DL-EQF']['CMI_NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp[dovs_df_test_tp['MJR_MNR_CAUSE_CD']=='DL-EQF']['CMI_NB'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0110257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b25995",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp[dovs_df_test_tp['MJR_MNR_CAUSE_CD']=='DS-WU']['CMI_NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112403d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_test_tp[dovs_df_test_tp['MJR_MNR_CAUSE_CD']=='DS-WU']['CMI_NB'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a8f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d13f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1672b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833cbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a4086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = draw_dovs_boxplots_with_countplots(\n",
    "    dovs_df=dovs_df_test_tp_fn,\n",
    "    x_col='EQUIP_TYP_NM',\n",
    "    y_col='CMI_NB', \n",
    "    hue='Cnfsn', \n",
    "    order='avg_y TP', \n",
    "    sharex=True, \n",
    "    batch_size=40, \n",
    "    log_y_counts=True\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'{y_col}_vs_{x_col}.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e6078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd1d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d64303",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=2, n_y=2, fig_num=1, return_flattened_axes=True, row_major=True)\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[0],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CMI_NB', \n",
    "    min_max_and_bin_size=[0, 4e4, 4e4/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# CMI_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CMI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[1],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CMI_NB', \n",
    "    min_max_and_bin_size=[0, 2e6, 2e6/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# CMI_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CMI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[1].set_yscale('log')\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[2],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CMI_NB', \n",
    "    min_max_and_bin_size=[0, 4e4, 4e4/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# CMI_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CMI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[3],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CMI_NB', \n",
    "    min_max_and_bin_size=[0, 2e6, 2e6/50], \n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# CMI_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CMI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[3].set_yscale('log')\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'CMI_NB_hist.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=2, n_y=2, fig_num=1, return_flattened_axes=True, row_major=True)\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[0],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CI_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# CI_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[1],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CI_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# CI_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[1].set_yscale('log')\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[2],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CI_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# CI_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[3],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='CI_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# CI_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# CI_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[3].set_yscale('log')\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'CI_NB_hist.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c6e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647107df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=2, n_y=2, fig_num=1, return_flattened_axes=True, row_major=True)\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[0],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[1],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[1].set_yscale('log')\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[2],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[3],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[3].set_yscale('log')\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'STEP_DRTN_NB_hist.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd441fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=2, n_y=2, fig_num=1, return_flattened_axes=True, row_major=True)\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[0],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')], \n",
    "        [dovs_df_test_tp_fn, dict(label='TP+FN', color='yellow')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[1],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')], \n",
    "        [dovs_df_test_tp_fn, dict(label='TP+FN', color='yellow')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[1].set_yscale('log')\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[2],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')], \n",
    "        [dovs_df_test_tp_fn, dict(label='TP+FN', color='yellow')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e2, 5e2/25],\n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[3],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')], \n",
    "        [dovs_df_test_tp_fn, dict(label='TP+FN', color='yellow')]\n",
    "    ],\n",
    "    x_col='STEP_DRTN_NB', \n",
    "    min_max_and_bin_size=[0, 5e3, 5e3/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='density', \n",
    "    draw_side_by_side=True, \n",
    "    title_args=dict(label='# STEP_DRTN_NB in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# STEP_DRTN_NB', loc='center', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "axs[3].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51ef9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2da6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs,\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ], \n",
    "    x_col='n_xfmrs_in_outg', \n",
    "    min_max_and_bin_size=[0, 50, 50/10], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# Transformers in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# Transformers', loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a294e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs,\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='n_xfmrs_in_outg', \n",
    "    min_max_and_bin_size=[0, 50, 50/10], \n",
    "    include_over_underflow=True, \n",
    "    stat='density',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# Transformers in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# Transformers', loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=2, fig_num=1, return_flattened_axes=True, row_major=True)\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[0],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='n_xfmrs_in_outg', \n",
    "    min_max_and_bin_size=[0, 50, 50/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='count',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# Transformers in Outage (counts)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# Transformers', loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "Plot_Hist.plot_multiple_hists(\n",
    "    ax=axs[1],\n",
    "    dfs_w_args=[\n",
    "        [dovs_df_test_tp, dict(label='TP', color='green')], \n",
    "        [dovs_df_test_fn, dict(label='FN', color='red')]\n",
    "    ],\n",
    "    x_col='n_xfmrs_in_outg', \n",
    "    min_max_and_bin_size=[0, 50, 50/25], \n",
    "    include_over_underflow=True, \n",
    "    stat='density',\n",
    "    draw_side_by_side=True, \n",
    "    draw_legend=True, \n",
    "    title_args=dict(label='# Transformers in Outage (density)', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel='# Transformers', loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Density', loc='top', fontdict=dict(fontsize=16))\n",
    ")\n",
    "#-------------------------\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name=f'n_xfmrs_in_outg_hist.png', \n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dda4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0499e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c028b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5a9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff069b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7d763b",
   "metadata": {},
   "source": [
    "# EEMSP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some funky stuff was done to EEMSP values in order to make them work with the modelling methods (e.g.,\n",
    "#   INSTALL_DT converted to relative int, etc.)\n",
    "# So, if EEMSP already in full_data_df_test_i, let's drop it and start fresh\n",
    "if 'EEMSP' in full_data_df_test_i.columns:\n",
    "    full_data_df_test_i = full_data_df_test_i.drop(columns='EEMSP')\n",
    "df_eemsp_OG = pd.read_pickle(os.path.join(save_dir_model_base, 'df_eemsp_OG.pkl'))\n",
    "df_eemsp = df_eemsp_OG.copy()\n",
    "#-------------------------\n",
    "# TODO!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Currently, simply taking the first entry wrt LOCATION_NB\n",
    "df_eemsp = df_eemsp.sort_values(by=['LOCATION_NB', 'INSTALL_DT'], ignore_index=True)\n",
    "df_eemsp = df_eemsp.groupby('LOCATION_NB', as_index=False).first()\n",
    "#-------------------------\n",
    "cols_of_interest_eemsp = [\n",
    "    'LOCATION_NB', \n",
    "    'MFGR_NM', \n",
    "    'INSTALL_DT', \n",
    "    'LAST_TRANS_DESC', \n",
    "    'EQTYPE_ID', \n",
    "    'COOLANT', \n",
    "    'INFO', \n",
    "    'KVA_SIZE',\n",
    "    'PHASE_CNT', \n",
    "    'PRIM_VOLTAGE', \n",
    "    'PROTECTION', \n",
    "    'PRU_NUMBER', \n",
    "    'SEC_VOLTAGE', \n",
    "    'SPECIAL_CHAR', \n",
    "    'TAPS', \n",
    "    'XFTYPE'\n",
    "]\n",
    "# df_eemsp=df_eemsp[df_eemsp['REMOVAL_DT'].isna()]\n",
    "df_eemsp=df_eemsp[cols_of_interest_eemsp]\n",
    "#-------------------------\n",
    "print(f\"full_data_df_test_i.shape = {full_data_df_test_i.shape}\")\n",
    "#-------------------------\n",
    "df_eemsp = Utilities_df.prepend_level_to_MultiIndex(df_eemsp, level_val='EEMSP', axis=1)\n",
    "#-------------------------\n",
    "full_data_df_test_i = pd.merge(\n",
    "    full_data_df_test_i, \n",
    "    df_eemsp.set_index(('EEMSP', 'LOCATION_NB')), \n",
    "    left_on=full_data_df_test_i.index.get_level_values(1), \n",
    "    right_index=True, \n",
    "    how='inner'\n",
    ")\n",
    "#-------------------------\n",
    "print(f\"full_data_df_test_i.shape = {full_data_df_test_i.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test_i[['is_outg', 'y_pred', 'EEMSP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test = full_data_df_test_i[['is_outg', 'y_pred', 'EEMSP']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test[('res_type', 'res_type')]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test.loc[\n",
    "    (eemsp_df_test[('is_outg', 'is_outg')]==1) & \n",
    "    (eemsp_df_test[('y_pred', 'y_pred')]==1),\n",
    "    ('res_type', 'res_type')\n",
    "] = 'TP'\n",
    "#-----\n",
    "eemsp_df_test.loc[\n",
    "    (eemsp_df_test[('is_outg', 'is_outg')]==0) & \n",
    "    (eemsp_df_test[('y_pred', 'y_pred')]==0),\n",
    "    ('res_type', 'res_type')\n",
    "] = 'TN'\n",
    "#-----\n",
    "eemsp_df_test.loc[\n",
    "    (eemsp_df_test[('is_outg', 'is_outg')]==0) & \n",
    "    (eemsp_df_test[('y_pred', 'y_pred')]==1),\n",
    "    ('res_type', 'res_type')\n",
    "] = 'FP'\n",
    "#-----\n",
    "eemsp_df_test.loc[\n",
    "    (eemsp_df_test[('is_outg', 'is_outg')]==1) & \n",
    "    (eemsp_df_test[('y_pred', 'y_pred')]==0),\n",
    "    ('res_type', 'res_type')\n",
    "] = 'FN'\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test = eemsp_df_test[['EEMSP', 'res_type', 'is_outg']].copy()\n",
    "eemsp_df_test.columns = eemsp_df_test.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# NOTE: In general, there will be duplicate entries for transformers!\n",
    "#       One could remove the duplicates via, e.g., \n",
    "#         dev_eemsp_df_test.reset_index().drop(columns=['outg_rec_nb']).drop_duplicates()\n",
    "#       However, duplicates would still remain due to a trsf_pole_nb having various res_types\n",
    "#         (e.g., TP, FN, TN, FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766a297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9728109",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'KVA_SIZE'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='res_type', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "    hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'KVA_SIZE'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0611503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7be97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "eemsp_df_test.groupby('res_type')['KVA_SIZE'].value_counts(normalize=True).rename('Whatev').reset_index().pipe((sns.barplot,'data'), x='KVA_SIZE',y='Whatev',hue='res_type',hue_order=['TP', 'FN', 'TN', 'FP'], ax=axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "eemsp_df_test.groupby('res_type')['KVA_SIZE'].value_counts(normalize=False).rename('Whatev').reset_index().pipe((sns.barplot,'data'), x='KVA_SIZE',y='Whatev',hue='res_type',hue_order=['TP', 'FN', 'TN', 'FP'], ax=axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dcc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a241f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "eemsp_df_test.groupby('res_type')['MFGR_NM'].value_counts(normalize=True).rename('Whatev').reset_index().pipe((sns.barplot,'data'), x='MFGR_NM',y='Whatev',hue='res_type',hue_order=['TP', 'FN', 'TN', 'FP'], ax=axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "eemsp_df_test.groupby('res_type')['MFGR_NM'].value_counts(normalize=False).rename('Whatev').reset_index().pipe((sns.barplot,'data'), x='MFGR_NM',y='Whatev',hue='res_type',hue_order=['TP', 'FN', 'TN', 'FP'], ax=axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f570812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "eemsp_df_test['INSTALL_DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eemsp_df_test['INSTALL_DT'].dt.strftime('%Y-%m')\n",
    "eemsp_df_test['INSTALL_YEAR'] = eemsp_df_test['INSTALL_DT'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'MFGR_NM'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_col = 'INSTALL_DT'\n",
    "\n",
    "# fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "# #-------------------------\n",
    "# sns.countplot(\n",
    "#     ax=axs, \n",
    "#     data=eemsp_df_test,\n",
    "#     x=x_col, \n",
    "#     hue='is_outg', \n",
    "# #     order=order[idx_0:idx_1], \n",
    "# #     palette=dict(TP='green', FN='red')\n",
    "# #     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    "# )\n",
    "# Plot_General.set_general_plotting_args(\n",
    "#     axs, \n",
    "#     draw_legend=True, \n",
    "#     legend_args=dict(loc='upper right', fontsize=20), \n",
    "#     title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "#     xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "#     ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "#     tick_args=dict(axis='x', labelrotation=90)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'INSTALL_YEAR'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694eb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'INSTALL_YEAR'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")\n",
    "axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b389e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_col = 'EQTYPE_ID'\n",
    "\n",
    "# fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "# #-------------------------\n",
    "# sns.countplot(\n",
    "#     ax=axs, \n",
    "#     data=eemsp_df_test,\n",
    "#     x=x_col, \n",
    "#     hue='is_outg', \n",
    "# #     order=order[idx_0:idx_1], \n",
    "# #     palette=dict(TP='green', FN='red')\n",
    "# #     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    "# )\n",
    "# Plot_General.set_general_plotting_args(\n",
    "#     axs, \n",
    "#     draw_legend=True, \n",
    "#     legend_args=dict(loc='upper right', fontsize=20), \n",
    "#     title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "#     xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "#     ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "#     tick_args=dict(axis='x', labelrotation=90)\n",
    "# )\n",
    "# axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'XFTYPE'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")\n",
    "axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'KVA_SIZE'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")\n",
    "axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = 'COOLANT'\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "#-------------------------\n",
    "sns.countplot(\n",
    "    ax=axs, \n",
    "    data=eemsp_df_test,\n",
    "    x=x_col, \n",
    "    hue='is_outg', \n",
    "#     order=order[idx_0:idx_1], \n",
    "#     palette=dict(TP='green', FN='red')\n",
    "#     hue_order=['TP', 'FN', 'TN', 'FP']\n",
    ")\n",
    "Plot_General.set_general_plotting_args(\n",
    "    axs, \n",
    "    draw_legend=True, \n",
    "    legend_args=dict(loc='upper right', fontsize=20), \n",
    "    title_args=dict(label=f'{x_col} for Result Types', fontdict=dict(fontweight='semibold', fontsize=16)), \n",
    "    xlabel_args=dict(xlabel=x_col, loc='right', fontdict=dict(fontsize=16)), \n",
    "    ylabel_args=dict(ylabel='Counts', loc='top', fontdict=dict(fontsize=16)), \n",
    "    tick_args=dict(axis='x', labelrotation=90)\n",
    ")\n",
    "axs.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db4d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f028c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574b3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5187a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b751fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "Plot_Bar.plot_barplot(\n",
    "    axs, \n",
    "    X_fn, \n",
    "    order=reason_order, \n",
    "    n_bars_to_include=10, \n",
    "    replace_xtick_labels_with_ints=True, \n",
    "    add_xtick_labels_legend_textbox=True, \n",
    "    fig=fig, \n",
    "    xtick_labels_legend_textbox_kwargs=dict(fontsize=10), \n",
    "    tick_args=[dict(axis='x', labelrotation=90, labelsize=15), \n",
    "               dict(axis='y', labelsize=15)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25d67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5505d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050680e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad495605",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "Plot_Bar.plot_multiple_barplots(\n",
    "    axs, \n",
    "    [\n",
    "        (X_tp, dict(label='X_tp', color='green')), \n",
    "        (X_fn, dict(label='X_fn', edgecolor='green', fill=False, hatch='//')), \n",
    "        (X_tn, dict(label='X_tn', color='red')), \n",
    "        (X_fp, dict(label='X_fp', edgecolor='red', fill=False, hatch='//'))\n",
    "    ], \n",
    "    order=reason_order, \n",
    "    n_bars_to_include=20, \n",
    "    draw_side_by_side=True, \n",
    "    replace_xtick_labels_with_ints=True, \n",
    "    add_xtick_labels_legend_textbox=True, \n",
    "    fig=fig, \n",
    "    xtick_labels_legend_textbox_kwargs=dict(fontsize=10, n_cols=2), \n",
    "    tick_args=[dict(axis='x', labelrotation=90, labelsize=15), \n",
    "               dict(axis='y', labelsize=15)], \n",
    "    draw_legend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7173e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f39e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_n_reasons_per_plot=True\n",
    "n_reasons_per_plot = 20\n",
    "n_reasons_total_to_plot = None # If None, plot all\n",
    "n_x = 2\n",
    "include_xtick_labels_legend = False\n",
    "\n",
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "#-----\n",
    "fig,axs = draw_X_by_binary_confusion_result(\n",
    "    fig_num=0, \n",
    "    X_tp_w_args=X_tp, \n",
    "    X_fn_w_args=X_fn, \n",
    "    X_tn_w_args=X_tn, \n",
    "    X_fp_w_args=X_fp, \n",
    "    n_reasons_per_plot=n_reasons_per_plot, \n",
    "    n_reasons_total_to_plot=n_reasons_total_to_plot, \n",
    "    reason_order=reason_order, \n",
    "    n_x=n_x, \n",
    "    include_xtick_labels_legend=include_xtick_labels_legend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd509a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_n_reasons_per_plot=True\n",
    "n_reasons_per_plot = 20\n",
    "n_reasons_total_to_plot = None # If None, plot all\n",
    "n_x = 2\n",
    "include_xtick_labels_legend = False\n",
    "\n",
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "#-----\n",
    "fig,axs = draw_X_by_binary_confusion_result(\n",
    "    fig_num=0, \n",
    "    X_tp_w_args=X_tp, \n",
    "    X_fn_w_args=X_fn, \n",
    "    X_tn_w_args=None, \n",
    "    X_fp_w_args=None, \n",
    "    n_reasons_per_plot=n_reasons_per_plot, \n",
    "    n_reasons_total_to_plot=n_reasons_total_to_plot, \n",
    "    reason_order=reason_order, \n",
    "    n_x=n_x, \n",
    "    include_xtick_labels_legend=include_xtick_labels_legend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_n_reasons_per_plot=True\n",
    "n_reasons_per_plot = 20\n",
    "n_reasons_total_to_plot = None # If None, plot all\n",
    "n_x = 2\n",
    "include_xtick_labels_legend = False\n",
    "\n",
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "#-----\n",
    "fig,axs = draw_X_by_binary_confusion_result(\n",
    "    fig_num=0, \n",
    "    X_tp_w_args=None, \n",
    "    X_fn_w_args=None, \n",
    "    X_tn_w_args=X_tn, \n",
    "    X_fp_w_args=X_fp, \n",
    "    n_reasons_per_plot=n_reasons_per_plot, \n",
    "    n_reasons_total_to_plot=n_reasons_total_to_plot, \n",
    "    reason_order=reason_order, \n",
    "    n_x=n_x, \n",
    "    include_xtick_labels_legend=include_xtick_labels_legend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197b14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a83393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada_clf = AdaBoostClassifier(\n",
    "#     RandomForestClassifier(n_estimators = 1000, n_jobs=-1),\n",
    "#     n_estimators=200,\n",
    "#     algorithm='SAMME.R'\n",
    "#     learning_rate=0.5\n",
    "# )\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=3), \n",
    "    n_estimators=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db246dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ada_clf.fit(X_train, y_train)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ada_clf.predict(X_train)\n",
    "print('TRAINING DATASET')\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_train, y_pred_train))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "print('TESTING DATASET')\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c73ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2872e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a8f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5195d85",
   "metadata": {},
   "source": [
    "# Neural Net: Keras Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa364cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "# model.add(keras.layers.Dense(X_train.shape[1], activation='relu'))\n",
    "# model.add(keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(keras.layers.Dense(4, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "# model.add(keras.layers.Dense(X_train.shape[1], activation='relu'))\n",
    "# model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(keras.layers.Dense(4, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "# model.add(keras.layers.Dense(X_train.shape[1], activation='relu'))\n",
    "# model.add(keras.layers.Dense(1600, activation='relu'))\n",
    "# model.add(keras.layers.Dense(400, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "# model.add(keras.layers.Dense(X_train.shape[1], activation='relu'))\n",
    "# model.add(keras.layers.Dense(4096, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "# model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(keras.layers.Dense(4, activation='relu'))\n",
    "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(keras.layers.Dense(X_train.shape[1], kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(4096, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(1024, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(256, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(128, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(256, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(16, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(4, kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e75994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss='binary_crossentropy', \n",
    "#     optimizer='sgd', \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    loss = \"binary_crossentropy\", \n",
    "    optimizer = opt, \n",
    "    metrics=[tf.keras.metrics.Precision()]\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=[tf.keras.metrics.Recall()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd81073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = model.predict(X_train).flatten()\n",
    "y_pred_train = (y_pred_prob_train>0.5).astype(int)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_train, y_pred_train))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb36d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "# y_pred = model.predict_classes(X_test) #'Sequential' object has no attribute 'predict_classes'\n",
    "y_pred = (y_pred_prob>0.5).astype(int)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72255bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_HOLDOUT = model.predict(X_HOLDOUT).flatten()\n",
    "y_pred_HOLDOUT = (y_pred_prob_HOLDOUT>0.5).astype(int)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_HOLDOUT, y_pred_HOLDOUT))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_HOLDOUT, y_pred_HOLDOUT))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_HOLDOUT, y_pred_HOLDOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74451c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c690e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1192eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecde7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b43a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred, normalize='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44174d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    display_labels=['No Outg.','Outage']\n",
    ")\n",
    "cmd.plot()\n",
    "# cmd.ax_.set(xlabel='Predicted', ylabel='True')\n",
    "cmd.ax_.set_xlabel('Predicted', fontsize=16)\n",
    "cmd.ax_.set_ylabel('True', fontsize=16)\n",
    "cmd.ax_.set_title('Test', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded59d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed56c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c728458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_by_confusion_result = get_X_entries_by_binary_confusion_matrix_result(X_test, y_test, y_pred)\n",
    "X_by_confusion_result = convert_X_by_confusion_results_to_dfs(\n",
    "    X_by_confusion_result=X_by_confusion_result, \n",
    "    full_data_df=full_data_df, \n",
    "    run_PCA=run_PCA, \n",
    "    run_scaler=run_scaler    \n",
    ")\n",
    "\n",
    "X_tp = X_by_confusion_result['X_tp']\n",
    "X_tn = X_by_confusion_result['X_tn']\n",
    "X_fp = X_by_confusion_result['X_fp']\n",
    "X_fn = X_by_confusion_result['X_fn']\n",
    "\n",
    "optimize_n_reasons_per_plot=True\n",
    "n_reasons_per_plot = 20\n",
    "n_reasons_total_to_plot = None # If None, plot all\n",
    "n_x = 2\n",
    "include_xtick_labels_legend = False\n",
    "\n",
    "if run_PCA:\n",
    "    # All Dfs should have same column order already, so don't matter which \n",
    "    #   is used below\n",
    "    reason_order = X_tp.columns.tolist()\n",
    "else:\n",
    "    reason_order = [x[0] for x in importances_srtd]\n",
    "#-----\n",
    "fig,axs = draw_X_by_binary_confusion_result(\n",
    "    fig_num=0, \n",
    "    X_tp_w_args=X_tp, \n",
    "    X_fn_w_args=X_fn, \n",
    "    X_tn_w_args=X_tn, \n",
    "    X_fp_w_args=X_fp, \n",
    "    n_reasons_per_plot=n_reasons_per_plot, \n",
    "    n_reasons_total_to_plot=n_reasons_total_to_plot, \n",
    "    reason_order=reason_order, \n",
    "    n_x=n_x, \n",
    "    include_xtick_labels_legend=include_xtick_labels_legend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2715c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "X_fn.T.plot.line(ax=ax, alpha=0.1, color='red', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "X_tp.T.plot.line(ax=ax, alpha=0.1, color='red', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f7bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce39161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6ffdef",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = full_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev_df.columns[dev_df.mean()==0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.columns[dev_df.mean()==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.drop(columns=dev_df.columns[dev_df.mean()==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888e5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ca0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = dev_df.corr()\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df['01-05 Days'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, unit_figsize_width=28, unit_figsize_height=12)\n",
    "plt.matshow(corr_df, fignum=fig.number)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[corr_df.columns[0]]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78bc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[corr_df.columns[0]].index[corr_df[corr_df.columns[0]]>0.5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab461a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a5be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c8ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "for reason in corr_df.columns:\n",
    "    correlated = corr_df[reason].index[corr_df[reason]>0.5].tolist()\n",
    "    # Reason always perfectly correlated with itself, obviously.\n",
    "    # So, remove this\n",
    "    correlated.remove(reason)\n",
    "    print(f'reason = {reason}')\n",
    "    print('Correlated:')\n",
    "    print(*correlated, sep='\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c89142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4704b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aafc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_i = dev_df['01-05 Days'].corr()\n",
    "corr_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, unit_figsize_width=28, unit_figsize_height=12)\n",
    "plt.matshow(corr_df_i, fignum=fig.number)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill diagonal and upper half with NaNs\n",
    "mask = np.zeros_like(corr_df_i, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr_df_i[mask] = np.nan\n",
    "fig, ax = Plot_General.default_subplots(n_x=1, n_y=1, unit_figsize_width=28, unit_figsize_height=12)\n",
    "plt.matshow(corr_df_i, fignum=fig.number)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_i.columns[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_df_i.iloc[6,2])\n",
    "print(corr_df_i.columns[6])\n",
    "print(corr_df_i.iloc[6].index[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "for reason in corr_df_i.columns:\n",
    "    correlated = corr_df_i[reason].index[corr_df_i[reason]>0.5].tolist()\n",
    "    # Reason always perfectly correlated with itself, obviously.\n",
    "    # So, remove this\n",
    "    # DIAGONAL NOT INCLUDED HERE!\n",
    "    if reason in correlated:\n",
    "        correlated.remove(reason)\n",
    "    if len(correlated)>0:\n",
    "        print(f'reason = {reason}')\n",
    "        print('Correlated:')\n",
    "        print(*correlated, sep='\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81247d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37080f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceadca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bead0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795a99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391eb3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44763a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24525f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e66128f3",
   "metadata": {},
   "source": [
    "# Other stuff (Impact estimate below this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa504b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "# dbscan = DBSCAN(eps=0.05, min_samples=132) # 2*n_features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aea337",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'DATA SIZE: {len(dbscan.labels_)}')\n",
    "print(f'ANOMALIES: {sum(dbscan.labels_==-1)}')\n",
    "print(f'N_GROUPS:  {max(dbscan.labels_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1307367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e05b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_w_db = list(zip(y_train, dbscan.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_idxs = [i for i,x in enumerate(y_train_w_db) if x[1]==-1]\n",
    "print(y_train[anomaly_idxs].sum())\n",
    "print(len(anomaly_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d554950",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = 0\n",
    "n_pct_eq_0 = 0\n",
    "idxs_w_pct_eq_0 = []\n",
    "idxs_w_pct_eq_1 = []\n",
    "for i in range(-1, max(dbscan.labels_)):\n",
    "    print(i)\n",
    "    subset = [x for x in y_train_w_db if x[1]==i]\n",
    "    print(f'len(subset) = {len(subset)}')\n",
    "    sum_i = sum([x[0] for x in subset])\n",
    "    print(f'Sum = {sum_i}')\n",
    "    pct_i = sum_i/len(subset)\n",
    "    print(f'Pct = {pct_i}')\n",
    "    max_pct = max_pct if max_pct>pct_i else pct_i\n",
    "    print()\n",
    "    \n",
    "    if pct_i==0:\n",
    "        n_pct_eq_0+=1\n",
    "        idxs_w_pct_eq_0.append(i)\n",
    "        \n",
    "    if pct_i==1:\n",
    "        idxs_w_pct_eq_1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeda9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(idxs_w_pct_eq_0))\n",
    "print(len(idxs_w_pct_eq_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7135c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_w_pct_eq_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_pct_eq_0)\n",
    "print(max(dbscan.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74745f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dbscan.labels_==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.core_sample_indices_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dbscan.core_sample_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dbscan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ede291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48fb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628139d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd222644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62389caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = knn.predict(X_train)\n",
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred_proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ba217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_test = copy.deepcopy(X_test)\n",
    "dev_y_test = copy.deepcopy(y_test)\n",
    "we=knn.kneighbors(dev_X_test, n_neighbors=1)\n",
    "we = list(zip(we[0].flatten(), we[1].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(we, columns=['y_dist', 'y_pred'])\n",
    "y_df['y_actl'] = dev_y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9833644",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(dev_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.merge(X_df, y_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da41666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82081c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_0 = [x for x in we if x[1] in idxs_w_pct_eq_0]\n",
    "we_1 = [x for x in we if x[1] in idxs_w_pct_eq_1]\n",
    "\n",
    "print(len(we_0))\n",
    "print(len(we_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0100ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['y_pred'].isin(idxs_w_pct_eq_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba583ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['eq_0_cand'] = X_df['y_pred'].isin(idxs_w_pct_eq_0)\n",
    "X_df['eq_1_cand'] = X_df['y_pred'].isin(idxs_w_pct_eq_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc73091",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[(X_df['eq_0_cand']==True) & (X_df['y_actl']==0)]['y_dist'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4028ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[(X_df['eq_0_cand']==True) & (X_df['y_actl']!=0)]['y_dist'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d257808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b73694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[(X_df['eq_1_cand']==True) & (X_df['y_actl']==1)]['y_dist'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[(X_df['eq_1_cand']==True) & (X_df['y_actl']!=1)]['y_dist'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c92f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c61ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[(X_df['eq_0_cand']==True) & (X_df['y_actl']==0) & (X_df['y_dist']<2.087953)]['y_actl'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b66ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_0_subset = X_df[(X_df['eq_0_cand']==True) & (X_df['y_actl']==0) & (X_df['y_dist']<2.087953)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_0_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b956ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_0_subset = y_df.loc[X_df_0_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.drop(\n",
    "#     index=X_df_0_subset.index, \n",
    "#     columns=['y_dist', 'y_pred', 'y_actl', 'eq_0_cand', 'eq_1_cand']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77a5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=X_df.drop(index=X_df_0_subset.index)\n",
    "X_df = X_df.drop(columns=['y_dist', 'y_pred', 'y_actl', 'eq_0_cand', 'eq_1_cand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=y_df.drop(index=X_df_0_subset.index)\n",
    "y_df=y_df.drop(columns=['y_dist', 'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_df.drop(\n",
    "#     index=X_df_0_subset.index, \n",
    "#     columns=['y_dist', 'y_pred']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e17dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32554fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(X_train.shape[1], activation='relu'))\n",
    "# model.add(keras.layers.Dense(4096, activation='relu'))\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_prob = model.predict(X_df.values).flatten()\n",
    "\n",
    "# y_pred = model.predict_classes(X_test) #'Sequential' object has no attribute 'predict_classes'\n",
    "y_pred = (y_pred_prob>0.5).astype(int)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_df.values, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_df.values, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_df.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a66b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60707b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dca011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307bdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efae06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_prob = model.predict(X_df.values).flatten()\n",
    "\n",
    "# # y_pred = model.predict_classes(X_test) #'Sequential' object has no attribute 'predict_classes'\n",
    "# y_pred = (y_pred_prob>0.5).astype(int)\n",
    "# print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_df.values, y_pred))\n",
    "# print(\"PRECISION OF THE MODEL: \", precision_score(y_df.values, y_pred))\n",
    "# print(\"RECALL    OF THE MODEL: \", recall_score(y_df.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_0_subset=X_df_0_subset.drop(columns=['y_dist', 'y_pred', 'y_actl', 'eq_0_cand', 'eq_1_cand'])\n",
    "assert(all(X_df_0_subset.columns==X_df.columns))\n",
    "X_df_final = pd.concat([X_df, X_df_0_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_0_subset=y_df_0_subset.drop(columns=['y_dist', 'y_pred'])\n",
    "assert(all(y_df_0_subset.columns==y_df.columns))\n",
    "y_df_final = pd.concat([y_df, y_df_0_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final=np.append(y_pred, [0]*len(y_df_0_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33265922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_df_final.values, y_pred_final))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_df_final.values, y_pred_final))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_df_final.values, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c4476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452e132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c39fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30462903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcf09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29201c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmeans.fit_predict(X_train)\n",
    "y_train_w_km = list(zip(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = 0\n",
    "n_pct_eq_0 = 0\n",
    "for i in range(max(y_pred)):\n",
    "    print(i)\n",
    "    subset = [x for x in y_train_w_km if x[1]==i]\n",
    "    print(f'len(subset) = {len(subset)}')\n",
    "    sum_i = sum([x[0] for x in subset])\n",
    "    print(f'Sum = {sum_i}')\n",
    "    pct_i = sum_i/len(subset)\n",
    "    print(f'Pct = {pct_i}')\n",
    "    max_pct = max_pct if max_pct>pct_i else pct_i\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    if pct_i==0:\n",
    "        n_pct_eq_0+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a34340",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_pct_eq_0)\n",
    "print(max(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6b172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e37eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2aed89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121418f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_train = copy.deepcopy(X_train)\n",
    "dev_y_train = copy.deepcopy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_train['01-05 Days'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8afdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_reasons = [\n",
    "    'Error occurred when attempting to synch meter time with NIC time for device', \n",
    "    'Under Voltage for meter', \n",
    "    'Primary Power Down occurred for meter', \n",
    "    'Primary Power Up occurred for meter', \n",
    "    'Last Gasp - NIC power lost for device'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b19c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_train.columns[dev_X_train.columns.get_level_values(1).isin(tmp_reasons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cols = dev_X_train.columns[dev_X_train.columns.get_level_values(1).isin(tmp_reasons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_counts = (dev_X_train[tmp_cols]>0.10).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d738ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_idxs = tmp_counts.index[tmp_counts>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a05952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y_train.loc[tmp_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tmp_idxs))\n",
    "print(dev_y_train.loc[tmp_idxs].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670f815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50eac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33daf3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3206b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d420879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1a546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X_train[tmp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72937fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_pd_i = (dev_X_train[tmp_cols]['01-05 Days']>0.10).sum(axis=1)\n",
    "counts_per_pd_i.name = '01-05 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f8447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e5f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_pd = []\n",
    "pds = dev_X_train.columns.get_level_values(0).unique().tolist()\n",
    "for pd_i in pds:\n",
    "    counts_per_pd_i = (dev_X_train[tmp_cols][pd_i]>0.10).sum(axis=1)\n",
    "    counts_per_pd_i.name = pd_i  \n",
    "    counts_per_pd.append(counts_per_pd_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9def29",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_pd = reduce(lambda left,right: pd.merge(left, right, left_index=True, right_index=True, how='inner'), counts_per_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96229193",
   "metadata": {},
   "outputs": [],
   "source": [
    "(counts_per_pd>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_day_counts = (counts_per_pd>3).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_idxs = tmp_day_counts.index[tmp_day_counts>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c39965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tmp_idxs))\n",
    "print(dev_y_train.loc[tmp_idxs].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ed48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_pd.loc[tmp_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe226af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8df84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33802424",
   "metadata": {},
   "source": [
    "# Impact Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61545647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_HOLDOUT.shape)\n",
    "print(y_HOLDOUT.shape)\n",
    "print(full_data_df_HOLDOUT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8de4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_HOLDOUT.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0054f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_by_confusion_result = get_X_entries_by_binary_confusion_matrix_result(X_HOLDOUT, y_HOLDOUT, y_pred_HOLDOUT)\n",
    "X_by_confusion_result = convert_X_by_confusion_results_to_dfs(\n",
    "    X_by_confusion_result=X_by_confusion_result, \n",
    "    full_data_df=full_data_df_HOLDOUT, \n",
    "    run_PCA=run_PCA, \n",
    "    run_scaler=run_scaler    \n",
    ")\n",
    "\n",
    "X_tp = X_by_confusion_result['X_tp']\n",
    "X_tn = X_by_confusion_result['X_tn']\n",
    "X_fp = X_by_confusion_result['X_fp']\n",
    "X_fn = X_by_confusion_result['X_fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TP', X_tp.shape)\n",
    "print('TN', X_tn.shape)\n",
    "print('FP', X_fp.shape)\n",
    "print('FN', X_fn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2775349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_HOLDOUT.shape)\n",
    "print(y_HOLDOUT.shape)\n",
    "print(full_data_df_HOLDOUT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ca8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Set y_pred column in full_data_df_HOLDOUT\n",
    "assert(X_HOLDOUT.shape[0]==y_HOLDOUT.shape[0]==full_data_df_HOLDOUT.shape[0])\n",
    "assert(X_HOLDOUT.shape[1]+1==full_data_df_HOLDOUT.shape[1])\n",
    "assert(full_data_df_HOLDOUT[('is_outg', 'is_outg')].equals(y_HOLDOUT))\n",
    "full_data_df_HOLDOUT[(('y_pred','y_pred'))]=y_pred_HOLDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Restore MultiIndex index of full_data_df_HOLDOUT which was lost when outages and non-outages were combined.\n",
    "#   Non-outages will have None (I believe converted to NaN) for level 0 index value (i.e., for the outg_rec_nb index)\n",
    "full_data_df_HOLDOUT.index = pd.MultiIndex.from_tuples([x if isinstance(x,tuple) else (None, x) for x in full_data_df_HOLDOUT.index.tolist()])\n",
    "full_data_df_HOLDOUT.index.names=['outg_rec_nb', 'trsf_pole_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Split full_data_df_HOLDOUT into tp, tn, fp, fn\n",
    "#----------\n",
    "full_data_tp = full_data_df_HOLDOUT[\n",
    "    (full_data_df_HOLDOUT[('is_outg', 'is_outg')]==1) & \n",
    "    (full_data_df_HOLDOUT[('y_pred', 'y_pred')]  ==1)\n",
    "].copy()\n",
    "#----------\n",
    "full_data_tn = full_data_df_HOLDOUT[\n",
    "    (full_data_df_HOLDOUT[('is_outg', 'is_outg')]==0) & \n",
    "    (full_data_df_HOLDOUT[('y_pred', 'y_pred')]  ==0)\n",
    "].copy()\n",
    "#----------\n",
    "full_data_fp = full_data_df_HOLDOUT[\n",
    "    (full_data_df_HOLDOUT[('is_outg', 'is_outg')]==0) & \n",
    "    (full_data_df_HOLDOUT[('y_pred', 'y_pred')]  ==1)\n",
    "].copy()\n",
    "#----------\n",
    "full_data_fn = full_data_df_HOLDOUT[\n",
    "    (full_data_df_HOLDOUT[('is_outg', 'is_outg')]==1) & \n",
    "    (full_data_df_HOLDOUT[('y_pred', 'y_pred')]  ==0)\n",
    "].copy()\n",
    "#----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'full_data_tp.shape[0] = {full_data_tp.shape[0]}')\n",
    "print(f'full_data_tn.shape[0] = {full_data_tn.shape[0]}')\n",
    "print(f'full_data_fp.shape[0] = {full_data_fp.shape[0]}')\n",
    "print(f'full_data_fn.shape[0] = {full_data_fn.shape[0]}')\n",
    "print()\n",
    "print('tp and fn should be true outages, therefore should have index level 0 values (for outg_rec_nb)')\n",
    "print(f'#NaNs TP: {full_data_tp.index.get_level_values(0).isna().sum()}')\n",
    "print(f'#NaNs FN: {full_data_fn.index.get_level_values(0).isna().sum()}')\n",
    "print()\n",
    "print('tn and fp should NOT be outages, therefore should have only NaN index level 0 values (for outg_rec_nb)')\n",
    "print(f'#not-NaNs TN: {full_data_tn.index.get_level_values(0).notna().sum()}')\n",
    "print(f'#not-NaNs FP: {full_data_fp.index.get_level_values(0).notna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715acb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4b107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dovs_outgs_tp = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=full_data_tp.index.get_level_values(0).unique().tolist(), \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        batch_size=1000, \n",
    "        verbose=True,\n",
    "        n_update=1\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_outgs_df_tp = dovs_outgs_tp.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edf6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_fn = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=full_data_fn.index.get_level_values(0).unique().tolist(), \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        batch_size=1000, \n",
    "        verbose=True,\n",
    "        n_update=1\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_outgs_df_fn = dovs_outgs_fn.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_fn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a165f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd648a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp[['CI_NB', 'CMI_NB']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_fn[['CI_NB', 'CMI_NB']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Utilities_df.consolidate_column_of_lists(dovs_outgs_df_tp, 'premise_nbs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5f336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xfmr_crct_inspct = full_data_tp.index.get_level_values(1).nunique()\n",
    "print(f'Number of transformers crews correctly sent to:   {n_xfmr_crct_inspct}')\n",
    "#-----\n",
    "n_xfmr_incrct_inspct = full_data_fp.index.get_level_values(1).nunique()\n",
    "print(f'Number of transformers crews incorrectly sent to: {n_xfmr_incrct_inspct}')\n",
    "#-----\n",
    "print()\n",
    "print(f\"Total CI possibly avoided:  {dovs_outgs_df_tp['CI_NB'].sum()}\")\n",
    "print(f\"Total CMI possibly avoided: {dovs_outgs_df_tp['CMI_NB'].sum()}\")\n",
    "#-----\n",
    "print()\n",
    "print(f\"Total CI possibly missed:  {dovs_outgs_df_fn['CI_NB'].sum()}\")\n",
    "print(f\"Total CMI possibly missed: {dovs_outgs_df_fn['CMI_NB'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9f30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e54bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nbs_tp = full_data_tp.index.get_level_values(0).unique().tolist()\n",
    "outg_rec_nbs_fn = full_data_fn.index.get_level_values(0).unique().tolist()\n",
    "#-----\n",
    "print(f'len(outg_rec_nbs_tp) = {len(outg_rec_nbs_tp)}')\n",
    "print(f'len(outg_rec_nbs_fn) = {len(outg_rec_nbs_fn)}')\n",
    "print(f'Intersection: {len(set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn)))}')\n",
    "print(f'In TP not FN: {len(set(outg_rec_nbs_tp).difference(set(outg_rec_nbs_fn)))}')\n",
    "print(f'In FN not TP: {len(set(outg_rec_nbs_fn).difference(set(outg_rec_nbs_tp)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bcde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fck = dovs_outgs_df_tp.loc[set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn))].copy()\n",
    "fck[fck['EQUIP_TYP_NM'].isin(['TRANSFORMER, OH', 'TRANSFORMER, UG'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56359ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_i = '12818346'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ebb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp.loc[outg_rec_nb_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a6ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_tp.loc[outg_rec_nb_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data_fn.loc[outg_rec_nb_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT.loc[outg_rec_nb_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp.loc[outg_rec_nb_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c044d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7696207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2aed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG = full_data_df_HOLDOUT[full_data_df_HOLDOUT[('is_outg', 'is_outg')]==1].copy()\n",
    "#-----\n",
    "full_data_df_HOLDOUT_OUTG = DOVSOutages.append_outg_info_to_df(\n",
    "    df=full_data_df_HOLDOUT_OUTG, \n",
    "    outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613695bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG[full_data_df_HOLDOUT_OUTG.index.get_level_values(0).notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c615958",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG[full_data_df_HOLDOUT_OUTG.index.get_level_values(1)==full_data_df_HOLDOUT_OUTG['LOCATION_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9be5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG[\n",
    "    (full_data_df_HOLDOUT_OUTG['MJR_CAUSE_CD']=='DL') & \n",
    "    (full_data_df_HOLDOUT_OUTG['MNR_CAUSE_CD']=='EQF') & \n",
    "    (full_data_df_HOLDOUT_OUTG['EQUIP_TYP_NM'].isin(['TRANSFORMER, OH', 'TRANSFORMER, UG']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11257d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG[\n",
    "    (full_data_df_HOLDOUT_OUTG['MJR_CAUSE_CD']=='DL') & \n",
    "    (full_data_df_HOLDOUT_OUTG['MNR_CAUSE_CD']=='EQF') & \n",
    "    (full_data_df_HOLDOUT_OUTG['EQUIP_TYP_NM'].isin(['TRANSFORMER, OH', 'TRANSFORMER, UG'])) & \n",
    "    (full_data_df_HOLDOUT_OUTG.index.get_level_values(1)==full_data_df_HOLDOUT_OUTG['LOCATION_ID'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57703e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_HOLDOUT_OUTG[\n",
    "    (full_data_df_HOLDOUT_OUTG['MJR_CAUSE_CD']=='DL') & \n",
    "    (full_data_df_HOLDOUT_OUTG['MNR_CAUSE_CD']=='EQF') & \n",
    "    (full_data_df_HOLDOUT_OUTG['EQUIP_TYP_NM'].isin(['TRANSFORMER, OH', 'TRANSFORMER, UG'])) & \n",
    "    (full_data_df_HOLDOUT_OUTG.index.get_level_values(1)!=full_data_df_HOLDOUT_OUTG['LOCATION_ID'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dee944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ead0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922d6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eebe7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nbs_tp = full_data_tp.index.get_level_values(0).unique().tolist()\n",
    "outg_rec_nbs_fn = full_data_fn.index.get_level_values(0).unique().tolist()\n",
    "#-----\n",
    "print(f'len(outg_rec_nbs_tp) = {len(outg_rec_nbs_tp)}')\n",
    "print(f'len(outg_rec_nbs_fn) = {len(outg_rec_nbs_fn)}')\n",
    "print(f'Intersection: {len(set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn)))}')\n",
    "print(f'In TP not FN: {len(set(outg_rec_nbs_tp).difference(set(outg_rec_nbs_fn)))}')\n",
    "print(f'In FN not TP: {len(set(outg_rec_nbs_fn).difference(set(outg_rec_nbs_tp)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc2ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of outages in TP & FN: {len(set(outg_rec_nbs_tp+outg_rec_nbs_fn))}')\n",
    "print()\n",
    "print(f'Number of outages in TP:      {len(outg_rec_nbs_tp)}')\n",
    "print(f'Number of outages ONLY in TP: {len(set(outg_rec_nbs_tp).difference(set(outg_rec_nbs_fn)))}')\n",
    "print()\n",
    "print(f'Number of outages in FN:      {len(outg_rec_nbs_fn)}')\n",
    "print(f'Number of outages ONLY in FN: {len(set(outg_rec_nbs_fn).difference(set(outg_rec_nbs_tp)))}')\n",
    "print()\n",
    "print(f'Number of outages in both TP and FN: {len(set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_df_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbe8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_tp = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "#         outg_rec_nbs=full_data_tp.index.get_level_values(0).unique().tolist(),\n",
    "        outg_rec_nbs=list(set(outg_rec_nbs_tp).difference(set(outg_rec_nbs_fn))), \n",
    "        field_to_split='outg_rec_nbs'\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_outgs_df_tp = dovs_outgs_tp.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_fn = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "#         outg_rec_nbs=full_data_fn.index.get_level_values(0).unique().tolist(), \n",
    "        outg_rec_nbs=list(set(outg_rec_nbs_fn).difference(set(outg_rec_nbs_tp))), \n",
    "        field_to_split='outg_rec_nbs'\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_outgs_df_fn = dovs_outgs_fn.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17028457",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs_tpfn = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict( \n",
    "        outg_rec_nbs=list(set(outg_rec_nbs_tp).intersection(set(outg_rec_nbs_fn))), \n",
    "        field_to_split='outg_rec_nbs'\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_outgs_df_tpfn = dovs_outgs_tpfn.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ea852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dovs_outgs_fp = DOVSOutages(\n",
    "#     df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "#     contstruct_df_args=None, \n",
    "#     init_df_in_constructor=True,\n",
    "#     build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "#     build_sql_function_kwargs=dict(\n",
    "#         outg_rec_nbs=full_data_fp.index.get_level_values(0).unique().tolist(), \n",
    "#         field_to_split='outg_rec_nbs'\n",
    "#     ), \n",
    "#     build_consolidated=True\n",
    "# )\n",
    "# dovs_outgs_df_fp = dovs_outgs_fp.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75274cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('COMPLETELY IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning all meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_tp['CI_NB'].sum():,}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_tp['CMI_NB'].sum():,}\")\n",
    "print()\n",
    "print('-'*50)\n",
    "print('PARTIALLY IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning some (but not all) meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_tpfn['CI_NB'].sum():,}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_tpfn['CMI_NB'].sum():,}\")\n",
    "print()\n",
    "print('-'*50)\n",
    "print('NOT IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning none of the meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_fn['CI_NB'].sum():,}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_fn['CMI_NB'].sum():,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('COMPLETELY IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning all meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_tp['CI_NB'].sum():e}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_tp['CMI_NB'].sum():e}\")\n",
    "print()\n",
    "print('-'*50)\n",
    "print('PARTIALLY IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning some (but not all) meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_tpfn['CI_NB'].sum():e}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_tpfn['CMI_NB'].sum():e}\")\n",
    "print()\n",
    "print('-'*50)\n",
    "print('NOT IDENTIFIED OUTAGES')\n",
    "print('\\tMeaning none of the meters affected by outage predict the outage')\n",
    "print(f\"Total CI:  {dovs_outgs_df_fn['CI_NB'].sum():e}\")\n",
    "print(f\"Total CMI: {dovs_outgs_df_fn['CMI_NB'].sum():e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xfmr_crct_inspct = full_data_tp.index.get_level_values(1).nunique()\n",
    "print(f'Number of transformers crews correctly sent to:   {n_xfmr_crct_inspct}')\n",
    "#-----\n",
    "n_xfmr_incrct_inspct = full_data_fp.index.get_level_values(1).nunique()\n",
    "print(f'Number of transformers crews incorrectly sent to: {n_xfmr_incrct_inspct}')\n",
    "#-----\n",
    "print()\n",
    "print(f\"Total CI possibly avoided:  {dovs_outgs_df_tp['CI_NB'].sum()}\")\n",
    "print(f\"Total CMI possibly avoided: {dovs_outgs_df_tp['CMI_NB'].sum()}\")\n",
    "#-----\n",
    "print()\n",
    "print(f\"Total CI possibly missed:  {dovs_outgs_df_fn['CI_NB'].sum()}\")\n",
    "print(f\"Total CMI possibly missed: {dovs_outgs_df_fn['CMI_NB'].sum()}\")\n",
    "#-----\n",
    "print()\n",
    "print(f\"Total CI possibly missed:  {dovs_outgs_df_tpfn['CI_NB'].sum()}\")\n",
    "print(f\"Total CMI possibly missed: {dovs_outgs_df_tpfn['CMI_NB'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6c245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973ed4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b8b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197274b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da68e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pct_col(df, col='SUM_CMI_NB', pct_col='pct_cmi_nb'): \n",
    "    df[pct_col] = 100*df[col]/df[col].sum()\n",
    "    return df\n",
    "\n",
    "# def draw_outages_summary_barplot(fig, ax, df, \n",
    "#                                  x_col='MJR_MNR_CAUSE_NM', y_col='pct_cmi_nb', \n",
    "#                                  sort_values=True, y_threshold=None, abbr_leg_str=None, \n",
    "#                                  include_labels='include', \n",
    "#                                  x_tick_new_labels_dict=None, return_x_values_included=False, \n",
    "#                                  **kwargs):\n",
    "#     # Current kwargs keys: 'palette_dict', 'xlabel' 'ylabel', 'x_tick_rotation', 'title', 'title_font_size'\n",
    "#     # y_threshold:\n",
    "#     #     if y_threshold is not None, it should be a dict with keys = ['threshold_col', 'threshold_val']\n",
    "#     #       e.g. y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':1.0}\n",
    "#     # include_labels: \n",
    "#     #     can equal 'include', 'exclude', 'passive' (CASE INSENSITIVE)\n",
    "#     include_labels = include_labels.lower()\n",
    "#     possible_include_labels = ['include', 'exclude', 'passive']\n",
    "#     if include_labels not in possible_include_labels:\n",
    "#         possible_include_labels = 'include'\n",
    "#     #---------------\n",
    "#     if y_threshold is not None:\n",
    "#         assert('threshold_col' in y_threshold and 'threshold_val' in y_threshold)\n",
    "#         df_to_plot = df[df[y_threshold['threshold_col']] > y_threshold['threshold_val']].copy()\n",
    "#     else:\n",
    "#         df_to_plot = df.copy()\n",
    "#     #---------------\n",
    "#     if sort_values:\n",
    "#         df_to_plot = df_to_plot.sort_values(by=y_col, ascending=False)\n",
    "#     #---------------\n",
    "#     sns.barplot(ax=ax, x=x_col, y=y_col, data=df_to_plot, \n",
    "#                 palette=kwargs.get('palette_dict', None))\n",
    "#     #---------------\n",
    "#     if include_labels=='include':\n",
    "#         ax.set_ylabel(kwargs.get('ylabel', y_col), fontsize=24, x=0.0, y=0.8, ha='left', va='bottom')\n",
    "#         ax.set_xlabel(kwargs.get('xlabel', x_col), fontsize=24, x=0.9, y=0.0, ha='right', va='top')   \n",
    "#         ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "#         x_tick_rotation = kwargs.get('x_tick_rotation', 90)\n",
    "#         ax.tick_params(axis='x', labelrotation=x_tick_rotation, labelsize=12.0, direction='in')\n",
    "#         if x_tick_rotation != 0 and x_tick_rotation != 90:\n",
    "#             #-- Align rotated labels with ticks at end, not center\n",
    "#             for label in ax.xaxis.get_majorticklabels():\n",
    "#                 label.set_horizontalalignment('right')\n",
    "\n",
    "#         if x_tick_new_labels_dict is not None:\n",
    "#             labels = [x.get_text() for x in ax.get_xticklabels()]\n",
    "#             new_labels = [x_tick_new_labels_dict[x] for x in labels]\n",
    "#             ax.set_xticklabels(new_labels)\n",
    "#     elif include_labels=='exclude':\n",
    "#         ax.set(xticklabels=[])\n",
    "#         ax.set(yticklabels=[])\n",
    "#         ax.set(xlabel=None)\n",
    "#         ax.set(ylabel=None)\n",
    "#     else:\n",
    "#         assert(include_labels=='passive')\n",
    "#     #---------------\n",
    "#     if abbr_leg_str is not None:\n",
    "#         ax.text(1.025, 0.9, abbr_leg_str, transform=ax.transAxes, fontsize=20, ha='left', va='top')\n",
    "#     ax.set_title(kwargs.get('title', None), fontsize=kwargs.get('title_font_size', 40))\n",
    "#     if return_x_values_included:\n",
    "#         return fig, ax, df_to_plot[x_col].unique().tolist()\n",
    "#     else:\n",
    "#         return fig,ax\n",
    "\n",
    "\n",
    "\n",
    "def draw_outages_summary_barplot(\n",
    "    fig, \n",
    "    ax, \n",
    "    df, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold=None, \n",
    "    order=None,\n",
    "    abbr_leg_str=None, \n",
    "    include_labels='include', \n",
    "    x_tick_new_labels_dict=None, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=None, \n",
    "    relative_position_idx=None,\n",
    "    **kwargs\n",
    "):\n",
    "    r\"\"\"\n",
    "    Current kwargs keys: \n",
    "        palette_dict\n",
    "        xlabel\n",
    "        ylabel\n",
    "        x_tick_rotation\n",
    "        title\n",
    "        title_font_size\n",
    "        hatch\n",
    "        \n",
    "    y_threshold:\n",
    "        if y_threshold is not None, it should be a dict with keys = ['threshold_col', 'threshold_val']\n",
    "          e.g. y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':1.0}\n",
    "    include_labels: \n",
    "        can equal 'include', 'exclude', 'passive' (CASE INSENSITIVE)\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    # If order is given, both y_threshold and sort_values will be ignored\n",
    "    # NOTE: Through order one can also set the number of reasons to be included\n",
    "    if order is not None:\n",
    "        if sort_values:\n",
    "            print('Warning: order is not None, so sort_values will be ignored')\n",
    "            sort_values=False\n",
    "        if y_threshold is not None:\n",
    "            print('Warning: order is not None, so y_threshold will be ignored')\n",
    "            y_threshold = None\n",
    "    #---------------------------\n",
    "    n_patches_beg = len(ax.patches) # Needed in case adjust_bar_and_line_positions_and_widths used\n",
    "    #-------------------------\n",
    "    include_labels = include_labels.lower()\n",
    "    possible_include_labels = ['include', 'exclude', 'passive']\n",
    "    if include_labels not in possible_include_labels:\n",
    "        possible_include_labels = 'include'\n",
    "    #---------------\n",
    "    if y_threshold is not None:\n",
    "        assert('threshold_col' in y_threshold and 'threshold_val' in y_threshold)\n",
    "        df_to_plot = df[df[y_threshold['threshold_col']] > y_threshold['threshold_val']].copy()\n",
    "    else:\n",
    "        df_to_plot = df.copy()\n",
    "    #---------------\n",
    "    if sort_values:\n",
    "        df_to_plot = df_to_plot.sort_values(by=y_col, ascending=False)\n",
    "    #---------------\n",
    "    sns.barplot(\n",
    "        ax=ax, \n",
    "        x=x_col, \n",
    "        y=y_col, \n",
    "        data=df_to_plot, \n",
    "        order=order, \n",
    "        palette=kwargs.get('palette_dict', None), \n",
    "        hatch=kwargs.get('hatch', None))\n",
    "    #---------------------------\n",
    "    n_patches_end = len(ax.patches) # Needed in case properties of over/underflow bins need changed\n",
    "    #---------------------------\n",
    "    if div_drawn_width_by is not None:\n",
    "        if relative_position_idx is None:\n",
    "            relative_position_idx = 0\n",
    "        ax = Plot_Bar.adjust_bar_and_line_positions_and_widths(\n",
    "            ax=ax, \n",
    "            div_width_by=div_drawn_width_by, \n",
    "            position_idx=relative_position_idx, \n",
    "            i_patch_beg=n_patches_beg, \n",
    "            i_patch_end=n_patches_end, \n",
    "            orient='v'\n",
    "        )\n",
    "    #---------------\n",
    "    if include_labels=='include':\n",
    "        ax.set_ylabel(kwargs.get('ylabel', y_col), fontsize=24, x=0.0, y=0.8, ha='left', va='bottom')\n",
    "        ax.set_xlabel(kwargs.get('xlabel', x_col), fontsize=24, x=0.9, y=0.0, ha='right', va='top')   \n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "        x_tick_rotation = kwargs.get('x_tick_rotation', 90)\n",
    "        ax.tick_params(axis='x', labelrotation=x_tick_rotation, labelsize=12.0, direction='in')\n",
    "        if x_tick_rotation != 0 and x_tick_rotation != 90:\n",
    "            #-- Align rotated labels with ticks at end, not center\n",
    "            for label in ax.xaxis.get_majorticklabels():\n",
    "                label.set_horizontalalignment('right')\n",
    "\n",
    "        if x_tick_new_labels_dict is not None:\n",
    "            labels = [x.get_text() for x in ax.get_xticklabels()]\n",
    "            new_labels = [x_tick_new_labels_dict[x] for x in labels]\n",
    "            ax.set_xticklabels(new_labels)\n",
    "    elif include_labels=='exclude':\n",
    "        ax.set(xticklabels=[])\n",
    "        ax.set(yticklabels=[])\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(ylabel=None)\n",
    "    else:\n",
    "        assert(include_labels=='passive')\n",
    "    #---------------\n",
    "    if abbr_leg_str is not None:\n",
    "        ax.text(1.025, 0.9, abbr_leg_str, transform=ax.transAxes, fontsize=20, ha='left', va='top')\n",
    "    ax.set_title(kwargs.get('title', None), fontsize=kwargs.get('title_font_size', 40))\n",
    "    if return_x_values_included:\n",
    "        return fig, ax, df_to_plot[x_col].unique().tolist()\n",
    "    else:\n",
    "        return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mjr_cause_cd_to_nm_dict = DOVSOutages.get_mjr_cause_cd_to_nm_dict()\n",
    "mjr_cause_nm_abbr_dict = {v:k for k,v in mjr_cause_cd_to_nm_dict.items()}\n",
    "max_len_abbr = len(max(list(mjr_cause_nm_abbr_dict.values()), key = len))\n",
    "abbr_leg_str = ''\n",
    "for mjr_cause in mjr_cause_nm_abbr_dict:\n",
    "    abbr_leg_str += '{}: {}\\n'.format(mjr_cause_nm_abbr_dict[mjr_cause].ljust(max_len_abbr), mjr_cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eeb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgs_tp_mjr_mnr = dovs_outgs_df_tp.groupby(['MJR_CAUSE_CD', 'MNR_CAUSE_CD', 'MJR_CAUSE_NM', 'MNR_CAUSE_NM'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tp_mjr_mnr = set_pct_col(outgs_tp_mjr_mnr, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_tp_mjr_mnr = set_pct_col(outgs_tp_mjr_mnr, col='CI_NB', pct_col='pct_ci_nb')\n",
    "outgs_tp_mjr_mnr = DOVSOutages.set_mjr_mnr_cause_nm_col(outgs_tp_mjr_mnr, set_null_to_NA=True, mjr_cause_nm_abbr_dict=mjr_cause_nm_abbr_dict)\n",
    "#-------------------------\n",
    "# outgs_tp_eqp_type = dovs_outgs_df_tp[(dovs_outgs_df_tp['MJR_CAUSE_CD']=='DL') & (dovs_outgs_df_tp['MNR_CAUSE_CD']=='EQF')].copy()\n",
    "# outgs_tp_eqp_type = outgs_tp_eqp_type.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tp_eqp_type = dovs_outgs_df_tp.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tp_eqp_type = set_pct_col(outgs_tp_eqp_type, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_tp_eqp_type = set_pct_col(outgs_tp_eqp_type, col='CI_NB', pct_col='pct_ci_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffc1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgs_fn_mjr_mnr = dovs_outgs_df_fn.groupby(['MJR_CAUSE_CD', 'MNR_CAUSE_CD', 'MJR_CAUSE_NM', 'MNR_CAUSE_NM'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_fn_mjr_mnr = set_pct_col(outgs_fn_mjr_mnr, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_fn_mjr_mnr = set_pct_col(outgs_fn_mjr_mnr, col='CI_NB', pct_col='pct_ci_nb')\n",
    "outgs_fn_mjr_mnr = DOVSOutages.set_mjr_mnr_cause_nm_col(outgs_fn_mjr_mnr, set_null_to_NA=True, mjr_cause_nm_abbr_dict=mjr_cause_nm_abbr_dict)\n",
    "#-------------------------\n",
    "# outgs_fn_eqp_type = dovs_outgs_df_fn[(dovs_outgs_df_fn['MJR_CAUSE_CD']=='DL') & (dovs_outgs_df_fn['MNR_CAUSE_CD']=='EQF')].copy()\n",
    "# outgs_fn_eqp_type = outgs_fn_eqp_type.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_fn_eqp_type = dovs_outgs_df_fn.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_fn_eqp_type = set_pct_col(outgs_fn_eqp_type, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_fn_eqp_type = set_pct_col(outgs_fn_eqp_type, col='CI_NB', pct_col='pct_ci_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f110476",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgs_tpfn_mjr_mnr = dovs_outgs_df_tpfn.groupby(['MJR_CAUSE_CD', 'MNR_CAUSE_CD', 'MJR_CAUSE_NM', 'MNR_CAUSE_NM'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tpfn_mjr_mnr = set_pct_col(outgs_tpfn_mjr_mnr, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_tpfn_mjr_mnr = set_pct_col(outgs_tpfn_mjr_mnr, col='CI_NB', pct_col='pct_ci_nb')\n",
    "outgs_tpfn_mjr_mnr = DOVSOutages.set_mjr_mnr_cause_nm_col(outgs_tpfn_mjr_mnr, set_null_to_NA=True, mjr_cause_nm_abbr_dict=mjr_cause_nm_abbr_dict)\n",
    "#-------------------------\n",
    "# outgs_tpfn_eqp_type = dovs_outgs_df_tpfn[(dovs_outgs_df_tpfn['MJR_CAUSE_CD']=='DL') & (dovs_outgs_df_tpfn['MNR_CAUSE_CD']=='EQF')].copy()\n",
    "# outgs_tpfn_eqp_type = outgs_tpfn_eqp_type.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tpfn_eqp_type = dovs_outgs_df_tpfn.groupby(['EQUIP_TYP_NM', 'SHORT_NM_EQP_TYP'])[['CI_NB', 'CMI_NB']].apply(sum).reset_index()\n",
    "outgs_tpfn_eqp_type = set_pct_col(outgs_tpfn_eqp_type, col='CMI_NB', pct_col='pct_cmi_nb')\n",
    "outgs_tpfn_eqp_type = set_pct_col(outgs_tpfn_eqp_type, col='CI_NB', pct_col='pct_ci_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058873e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e175f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_tp_mjr_mnr, \n",
    "                                       x_col='MJR_MNR_CAUSE_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Major-Minor Cause', title='Outage CMI by Cause', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_fn_mjr_mnr, \n",
    "                                       x_col='MJR_MNR_CAUSE_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Major-Minor Cause', title='Outage CMI by Cause', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_tpfn_mjr_mnr, \n",
    "                                       x_col='MJR_MNR_CAUSE_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Major-Minor Cause', title='Outage CMI by Cause', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba338c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_causes_tp_cmi = outgs_tp_mjr_mnr[outgs_tp_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_tp_ci  = outgs_tp_mjr_mnr[outgs_tp_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_tp_cmi = top_causes_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_tp_ci  = top_causes_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes_fn_cmi = outgs_fn_mjr_mnr[outgs_fn_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_fn_ci  = outgs_fn_mjr_mnr[outgs_fn_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_fn_cmi = top_causes_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_fn_ci  = top_causes_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes_tpfn_cmi = outgs_tpfn_mjr_mnr[outgs_tpfn_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_tpfn_ci  = outgs_tpfn_mjr_mnr[outgs_tpfn_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_tpfn_cmi = top_causes_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_tpfn_ci  = top_causes_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes = pd.concat([top_causes_tp_cmi, top_causes_tp_ci, top_causes_fn_cmi, top_causes_fn_ci, top_causes_tpfn_cmi, top_causes_tpfn_ci])\n",
    "top_causes = top_causes.groupby('MJR_MNR_CAUSE_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_causes['MJR_MNR_CAUSE_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_ci_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='/', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='\\\\\\\\', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "Plot_General.save_fig(fig, r'C:\\Users\\s346557\\Documents\\Presentations\\OutagePredictions\\MeterEvents\\Initial_Impact_Assessment\\Figures\\Full', 'CI_by_cause.png')\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b192cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_causes_tp_cmi = outgs_tp_mjr_mnr[outgs_tp_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_tp_ci  = outgs_tp_mjr_mnr[outgs_tp_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_tp_cmi = top_causes_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_tp_ci  = top_causes_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes_fn_cmi = outgs_fn_mjr_mnr[outgs_fn_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_fn_ci  = outgs_fn_mjr_mnr[outgs_fn_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_fn_cmi = top_causes_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_fn_ci  = top_causes_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes_tpfn_cmi = outgs_tpfn_mjr_mnr[outgs_tpfn_mjr_mnr['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_cmi_nb']]\n",
    "top_causes_tpfn_ci  = outgs_tpfn_mjr_mnr[outgs_tpfn_mjr_mnr['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['MJR_MNR_CAUSE_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_causes_tpfn_cmi = top_causes_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_causes_tpfn_ci  = top_causes_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_causes = pd.concat([top_causes_tp_cmi, top_causes_tp_ci, top_causes_fn_cmi, top_causes_fn_ci, top_causes_tpfn_cmi, top_causes_tpfn_ci])\n",
    "top_causes = top_causes.groupby('MJR_MNR_CAUSE_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_causes['MJR_MNR_CAUSE_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CMI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='/', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CMI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='\\\\\\\\', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_mjr_mnr, \n",
    "    x_col='MJR_MNR_CAUSE_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Major-Minor Cause', \n",
    "    title='Outage CMI by Cause', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "Plot_General.save_fig(fig, r'C:\\Users\\s346557\\Documents\\Presentations\\OutagePredictions\\MeterEvents\\Initial_Impact_Assessment\\Figures\\Full', 'CMI_by_cause.png')\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce47631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eed93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8548dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ee500",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_tp_eqp_type, \n",
    "                                       x_col='EQUIP_TYP_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Equipment Type', title='Outage CI by Equip. Type)', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf54341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_fn_eqp_type, \n",
    "                                       x_col='EQUIP_TYP_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Equipment Type', title='Outage CI by Equip. Type', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b78118",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cutoff = 1.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "fig, ax = draw_outages_summary_barplot(fig, ax, outgs_tpfn_eqp_type, \n",
    "                                       x_col='EQUIP_TYP_NM', y_col='pct_cmi_nb', \n",
    "                                       y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "                                       ylabel='% CMI', xlabel='Equipment Type', title='Outage CI by Equip. Type', \n",
    "                                       x_tick_rotation=90, \n",
    "#                                        palette_dict=palette_dict, order=tmp_reasons\n",
    "                                      )\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_equip_types_tp_cmi = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tp_ci  = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tp_cmi = top_equip_types_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tp_ci  = top_equip_types_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_fn_cmi = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_fn_ci  = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_fn_cmi = top_equip_types_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_fn_ci  = top_equip_types_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_tpfn_cmi = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tpfn_ci  = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tpfn_cmi = top_equip_types_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tpfn_ci  = top_equip_types_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types = pd.concat([top_equip_types_tp_cmi, top_equip_types_tp_ci, top_equip_types_fn_cmi, top_equip_types_fn_ci, top_equip_types_tpfn_cmi, top_equip_types_tpfn_ci])\n",
    "top_equip_types = top_equip_types.groupby('EQUIP_TYP_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_equip_types['EQUIP_TYP_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_ci_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='/', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='\\\\\\\\', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "Plot_General.save_fig(fig, r'C:\\Users\\s346557\\Documents\\Presentations\\OutagePredictions\\MeterEvents\\Initial_Impact_Assessment\\Figures\\Full', 'CI_by_eqp_type.png')\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_equip_types_tp_cmi = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tp_ci  = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tp_cmi = top_equip_types_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tp_ci  = top_equip_types_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_fn_cmi = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_fn_ci  = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_fn_cmi = top_equip_types_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_fn_ci  = top_equip_types_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_tpfn_cmi = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tpfn_ci  = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tpfn_cmi = top_equip_types_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tpfn_ci  = top_equip_types_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types = pd.concat([top_equip_types_tp_cmi, top_equip_types_tp_ci, top_equip_types_fn_cmi, top_equip_types_fn_ci, top_equip_types_tpfn_cmi, top_equip_types_tpfn_ci])\n",
    "top_equip_types = top_equip_types.groupby('EQUIP_TYP_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_equip_types['EQUIP_TYP_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='/', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='\\\\\\\\', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "Plot_General.save_fig(fig, r'C:\\Users\\s346557\\Documents\\Presentations\\OutagePredictions\\MeterEvents\\Initial_Impact_Assessment\\Figures\\Full', 'CMI_by_eqp_type.png')\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e69b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99094238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde43fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_equip_types_tp_cmi = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tp_ci  = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tp_cmi = top_equip_types_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tp_ci  = top_equip_types_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_fn_cmi = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_fn_ci  = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_fn_cmi = top_equip_types_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_fn_ci  = top_equip_types_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_tpfn_cmi = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tpfn_ci  = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tpfn_cmi = top_equip_types_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tpfn_ci  = top_equip_types_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types = pd.concat([top_equip_types_tp_cmi, top_equip_types_tp_ci, top_equip_types_fn_cmi, top_equip_types_fn_ci, top_equip_types_tpfn_cmi, top_equip_types_tpfn_ci])\n",
    "top_equip_types = top_equip_types.groupby('EQUIP_TYP_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_equip_types['EQUIP_TYP_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_ci_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='/', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='\\\\\\\\', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_ci_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e21fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19282b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_equip_types_tp_cmi = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tp_ci  = outgs_tp_eqp_type[outgs_tp_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tp_cmi = top_equip_types_tp_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tp_ci  = top_equip_types_tp_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_fn_cmi = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_fn_ci  = outgs_fn_eqp_type[outgs_fn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_fn_cmi = top_equip_types_fn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_fn_ci  = top_equip_types_fn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types_tpfn_cmi = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_cmi_nb']>pct_cutoff].sort_values(by='pct_cmi_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_cmi_nb']]\n",
    "top_equip_types_tpfn_ci  = outgs_tpfn_eqp_type[outgs_tpfn_eqp_type['pct_ci_nb']>pct_cutoff].sort_values(by='pct_ci_nb', ascending=False)[['EQUIP_TYP_NM', 'pct_ci_nb']]\n",
    "#-----\n",
    "top_equip_types_tpfn_cmi = top_equip_types_tpfn_cmi.rename(columns={'pct_cmi_nb':'pct'})\n",
    "top_equip_types_tpfn_ci  = top_equip_types_tpfn_ci.rename(columns={'pct_ci_nb':'pct'})\n",
    "#-------------------------\n",
    "top_equip_types = pd.concat([top_equip_types_tp_cmi, top_equip_types_tp_ci, top_equip_types_fn_cmi, top_equip_types_fn_ci, top_equip_types_tpfn_cmi, top_equip_types_tpfn_ci])\n",
    "top_equip_types = top_equip_types.groupby('EQUIP_TYP_NM')['pct'].apply(max).to_frame().reset_index().sort_values(by='pct', ignore_index=True, ascending=False)\n",
    "palette_dict = Plot_General.get_standard_colors_dict(top_equip_types['EQUIP_TYP_NM'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[11, 8.5])\n",
    "legend_elements = []\n",
    "#-------------------------\n",
    "fig, ax, x_values_included = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_fn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=True, \n",
    "    y_threshold={'threshold_col':'pct_cmi_nb', 'threshold_val':pct_cutoff}, \n",
    "    order=None, \n",
    "    return_x_values_included=True, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=0, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'red' for k,v in palette_dict.items()}, \n",
    "    hatch='/'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='red', fill=True, hatch='/', label='FN'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tp_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=1, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'green' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='green', fill=True, hatch='\\\\\\\\', label='TP'))\n",
    "#-------------------------\n",
    "fig, ax = draw_outages_summary_barplot(\n",
    "    fig=fig, \n",
    "    ax=ax, \n",
    "    df=outgs_tpfn_eqp_type, \n",
    "    x_col='EQUIP_TYP_NM', \n",
    "    y_col='pct_cmi_nb', \n",
    "    sort_values=False, \n",
    "    y_threshold=None, \n",
    "    order=x_values_included, \n",
    "    return_x_values_included=False, \n",
    "    div_drawn_width_by=3, \n",
    "    relative_position_idx=2, \n",
    "    ylabel='% CMI', \n",
    "    xlabel='Equipment Type', \n",
    "    title='Outage CMI by Equip. Type', \n",
    "    x_tick_rotation=90, \n",
    "    palette_dict={k:'orange' for k,v in palette_dict.items()}, \n",
    "    hatch='\\\\\\\\'\n",
    ")\n",
    "legend_elements.append(mpatches.Patch(facecolor='orange', fill=True, hatch='\\\\\\\\', label='TP&FN'))\n",
    "#-------------------------\n",
    "ax.legend(\n",
    "    title=None, \n",
    "    handles=legend_elements, \n",
    "    fontsize=20, \n",
    "    title_fontsize=30, \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "\n",
    "#-------------------------\n",
    "fig_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5de75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2633898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff849437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff6c69db",
   "metadata": {},
   "source": [
    "# Addressing Jon's Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff148c",
   "metadata": {},
   "source": [
    "### For every instance in direct outage set, is the device listed as a transformer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a760fb",
   "metadata": {},
   "source": [
    "## !!!!!!!!!!!!!!!! NOTE: DVC_TYP_NM and SHORT_NM_CLR_DEV seem to have 1-1 relationship, so no need to use both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_duplicated_vals_in_df_col_to_empty_str(df, col):\n",
    "    r\"\"\"\n",
    "    Function developed for use in format_groups_and_counts_df_for_table\n",
    "    \"\"\"\n",
    "    df.loc[df[col].duplicated(), col] = ''\n",
    "    return df\n",
    "\n",
    "def format_groups_and_counts_df_for_table(\n",
    "    df, \n",
    "    grp_by_cols\n",
    "):\n",
    "    r\"\"\"\n",
    "    CAN'T SIMPLY USE set_duplicated_vals_in_df_col_to_empty_str, AS I WAS BASICALLY DOING BEFORE\n",
    "    \n",
    "    The DataFrame which is output is essentially df.groupby(grp_by_cols).size().to_frame().\n",
    "    \n",
    "    Format Multi-index nicer, so instead of one column containing tuples of each Multi-index \n",
    "      (e.g., ('TRANSFORMER, OH', 'LINE FUSE')), I'll have multiple columns.\n",
    "    Also, instead of having a bunch of repeats of, e.g., level 0 values, make it such that each\n",
    "      is only printed once.\n",
    "      e.g., instead of:\n",
    "        'TRANSFORMER, OH' 'LINE FUSE'\n",
    "        'TRANSFORMER, OH' 'PRIMARY OPEN'\n",
    "       output this:\n",
    "        'TRANSFORMER, OH' 'LINE FUSE'\n",
    "                          'PRIMARY OPEN'\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    frmttd_df = df.copy()\n",
    "    grp_by_cols_shrnk = copy.deepcopy(grp_by_cols)\n",
    "    while len(grp_by_cols_shrnk)>1:\n",
    "        frmttd_df=frmttd_df.groupby(grp_by_cols_shrnk[:-1]).apply(\n",
    "            lambda x: set_duplicated_vals_in_df_col_to_empty_str(x, grp_by_cols_shrnk[-2])\n",
    "        )\n",
    "        grp_by_cols_shrnk=grp_by_cols_shrnk[:-1]\n",
    "    #-------------------------\n",
    "    return frmttd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25038a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_groups_and_counts_table_from_df(\n",
    "    df, \n",
    "    grp_by_cols, \n",
    "    include_counts=True, \n",
    "    include_pct_counts=True, \n",
    "    max_rows_per_table=None, \n",
    "    fig_num=0, \n",
    "    title=None, \n",
    "    default_subplots_kwargs=None, \n",
    "    save_fig_kwargs=False\n",
    "):\n",
    "    r\"\"\"\n",
    "    The DataFrame which is output is essentially df.groupby(grp_by_cols).size().to_frame().\n",
    "    \n",
    "    Format Multi-index nicer, so instead of one column containing tuples of each Multi-index \n",
    "      (e.g., ('TRANSFORMER, OH', 'LINE FUSE')), I'll have multiple columns.\n",
    "    Also, instead of having a bunch of repeats of, e.g., level 0 values, make it such that each\n",
    "      is only printed once.\n",
    "      e.g., instead of:\n",
    "        'TRANSFORMER, OH' 'LINE FUSE'\n",
    "        'TRANSFORMER, OH' 'PRIMARY OPEN'\n",
    "       output this:\n",
    "        'TRANSFORMER, OH' 'LINE FUSE'\n",
    "                          'PRIMARY OPEN'\n",
    "                          \n",
    "    max_rows_per_table:\n",
    "        Maximum number of rows per table.  \n",
    "        The inclusion of this functionality makes this method appear more complicated than it actually is.\n",
    "        \n",
    "    save_fig_kwargs:\n",
    "        If False, no saving, obviously.\n",
    "        Otherwise, see Plot_General.save_fig for acceptable kwargs.\n",
    "            Note: The first argument to Plot_General.save_fig, i.e. fig, will be added by the function.\n",
    "                  Otherwise, at a minimum, the user must supply save_dir and save_name\n",
    "        If max_rows_per_table is not None, and subsequently multiple figures are built, their names will be appended\n",
    "          with _0 through _{n_images-1}\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    frmttd_df = df.groupby(grp_by_cols).size().to_frame()\n",
    "    frmttd_df = frmttd_df.reset_index()\n",
    "    #-------------------------\n",
    "    if max_rows_per_table is None:\n",
    "        batch_idxs = [[0, frmttd_df.shape[0]]]\n",
    "    else:\n",
    "        batch_idxs = Utilities.get_batch_idx_pairs(frmttd_df.shape[0], batch_size=max_rows_per_table)\n",
    "    #-------------------------\n",
    "    figs_and_axs = []\n",
    "    for i, batch_i in enumerate(batch_idxs):\n",
    "        i_beg = batch_i[0]\n",
    "        i_end = batch_i[1]\n",
    "        frmttd_df_i = frmttd_df.iloc[i_beg:i_end].copy()\n",
    "        #-----\n",
    "        if len(grp_by_cols)>1:\n",
    "#             for col in grp_by_cols[:-1]:\n",
    "#                 frmttd_df_i.loc[frmttd_df_i[col].duplicated(), col] = ''\n",
    "            frmttd_df_i = format_groups_and_counts_df_for_table(\n",
    "                df=frmttd_df_i, \n",
    "                grp_by_cols=grp_by_cols\n",
    "            )\n",
    "        #-----\n",
    "        frmttd_df_i = frmttd_df_i.rename(columns={frmttd_df_i.columns.tolist()[-1]:'Counts'})\n",
    "        if include_pct_counts:\n",
    "            frmttd_df_i['Counts (%)'] = 100*frmttd_df_i['Counts']/frmttd_df_i['Counts'].sum()\n",
    "            frmttd_df_i['Counts (%)'] = frmttd_df_i['Counts (%)'].round(5)\n",
    "        if not include_counts:\n",
    "            frmttd_df_i = frmttd_df_i.drop(columns=['Counts'])\n",
    "        #-------------------------\n",
    "        if default_subplots_kwargs is not None:\n",
    "            assert(isinstance(default_subplots_kwargs, dict))\n",
    "            default_subplots_kwargs = Utilities.supplement_dict_with_default_values(\n",
    "                to_supplmnt_dict=default_subplots_kwargs, \n",
    "                default_values_dict=dict(n_x=1, n_y=1)\n",
    "            )\n",
    "        else:\n",
    "            default_subplots_kwargs = dict(n_x=1, n_y=1)\n",
    "        default_subplots_kwargs['fig_num']=fig_num #Needs to be here so is updated at each iteration\n",
    "        fig,ax=Plot_General.default_subplots(**default_subplots_kwargs)\n",
    "        #-----\n",
    "        ax.axis('off')\n",
    "        ax.table(cellText=frmttd_df_i.values, colLabels=frmttd_df_i.columns, loc='center');\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        #-------------------------\n",
    "        figs_and_axs.append((fig,ax))\n",
    "        fig_num+=1\n",
    "    #-------------------------\n",
    "    if save_fig_kwargs:\n",
    "        assert(\n",
    "            'save_dir' in save_fig_kwargs.keys() and \n",
    "            'save_name' in save_fig_kwargs.keys()\n",
    "        )\n",
    "        ext = Utilities.find_file_extension(file_path_or_name=save_fig_kwargs['save_name'])\n",
    "        for i, (fig_i, ax_i) in enumerate(figs_and_axs):\n",
    "            save_fig_kwargs_i = copy.deepcopy(save_fig_kwargs)\n",
    "            #----------\n",
    "            if len(figs_and_axs)>1:\n",
    "                save_fig_kwargs_i['save_name'] = Utilities.append_to_path(\n",
    "                    save_path=save_fig_kwargs_i['save_name'], \n",
    "                    appendix=f\"_{i}\",\n",
    "                    ext_to_find=ext, \n",
    "                    append_to_end_if_ext_no_found=False\n",
    "                )\n",
    "            #----------\n",
    "            save_fig_kwargs_i['fig'] = fig_i\n",
    "            Plot_General.save_fig(**save_fig_kwargs_i)\n",
    "    #-------------------------\n",
    "    if len(figs_and_axs)==1:\n",
    "        return figs_and_axs[0]\n",
    "    else:\n",
    "        return figs_and_axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_unit_figsize_height_for_groups_and_counts_table(\n",
    "    df, \n",
    "    grp_by_cols, \n",
    "    nbr_rows_per_unit_height, \n",
    "    max_rows_per_table\n",
    "):\n",
    "    n_rows_in_grpd_df = df.groupby(grp_by_cols).size().shape[0]\n",
    "    if max_rows_per_table is None:\n",
    "        unit_figsize_height = n_rows_in_grpd_df/nbr_rows_per_unit_height\n",
    "    else:\n",
    "        if max_rows_per_table>n_rows_in_grpd_df:\n",
    "            unit_figsize_height = n_rows_in_grpd_df/nbr_rows_per_unit_height\n",
    "        else:\n",
    "            unit_figsize_height = max_rows_per_table/nbr_rows_per_unit_height\n",
    "    return unit_figsize_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793782e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20221216\\20220101_20220930\\rcpo_dfs_GRP_BY_OUTG_AND_XFMR\\outg_td_window_1_to_30_days\\rcpo_df_raw.pkl')\n",
    "# qa_df = merged_df_full.copy()\n",
    "# qa_df=Utilities_df.flatten_multiindex_columns(qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414dd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = DOVSOutages.append_outg_info_to_df(\n",
    "    df=qa_df, \n",
    "    outg_rec_nb_idfr=('index', 'outg_rec_nb')\n",
    ")\n",
    "#-------------------------\n",
    "xfmr_equip_typ_nms_of_interest = ['TRANSFORMER, OH', 'TRANSFORMER, UG']\n",
    "qa_df_drct = qa_df[\n",
    "    (qa_df.index.get_level_values(1)==qa_df['LOCATION_ID']) &\n",
    "    (qa_df['EQUIP_TYP_NM'].isin(xfmr_equip_typ_nms_of_interest))\n",
    "]\n",
    "#-------------------------\n",
    "qa_df_drct_loose = qa_df[qa_df.index.get_level_values(1)==qa_df['LOCATION_ID']]\n",
    "#-------------------------\n",
    "qa_df_non_trsfs = qa_df[qa_df.index.get_level_values(1)!=qa_df['LOCATION_ID']].copy()\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_drct.head()['LOCATION_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c48e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_non_trsfs.head()['LOCATION_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bd827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qa_df.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM']).ngroups)\n",
    "print(qa_df.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM', 'SHORT_NM_CLR_DEV']).ngroups)\n",
    "print()\n",
    "print(qa_df_drct.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM']).ngroups)\n",
    "print(qa_df_drct.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM', 'SHORT_NM_CLR_DEV']).ngroups)\n",
    "print()\n",
    "print(qa_df_drct_loose.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM']).ngroups)\n",
    "print(qa_df_drct_loose.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM', 'SHORT_NM_CLR_DEV']).ngroups)\n",
    "print()\n",
    "print(qa_df_non_trsfs.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM']).ngroups)\n",
    "print(qa_df_non_trsfs.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM', 'SHORT_NM_CLR_DEV']).ngroups)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_drct.groupby(['EQUIP_TYP_NM', 'DVC_TYP_NM']).size().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4442c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aff0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = False\n",
    "\n",
    "# A good ratio for number of tables lines per unit figure size height is 4.4\n",
    "nbr_rows_per_unit_height = 4.4\n",
    "\n",
    "max_rows_per_table = None\n",
    "# max_rows_per_table = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab95ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    save_fig_kwargs = dict(\n",
    "        save_dir=r'C:\\Users\\s346557\\Documents\\AnalysisNote\\X_Results\\X_2_OutageMeterEvents\\Figures\\EQUIP_and_DVC_TYPS_in_outages', \n",
    "        save_name='Direct_outages_strict.png'\n",
    "    )\n",
    "else:\n",
    "    save_fig_kwargs=False\n",
    "#-----\n",
    "unit_figsize_height = calc_unit_figsize_height_for_groups_and_counts_table(\n",
    "    df=qa_df_drct, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    nbr_rows_per_unit_height=nbr_rows_per_unit_height, \n",
    "    max_rows_per_table=max_rows_per_table\n",
    ")\n",
    "#-----\n",
    "figs_and_axs = build_groups_and_counts_table_from_df(\n",
    "    df=qa_df_drct, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    include_counts=True, \n",
    "    include_pct_counts=True, \n",
    "    max_rows_per_table=max_rows_per_table, \n",
    "    fig_num=0, \n",
    "    title='Direct Outages (strict)', \n",
    "    default_subplots_kwargs = dict(unit_figsize_height=unit_figsize_height), \n",
    "    save_fig_kwargs=save_fig_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45149e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    save_fig_kwargs = dict(\n",
    "        save_dir=r'C:\\Users\\s346557\\Documents\\AnalysisNote\\X_Results\\X_2_OutageMeterEvents\\Figures\\EQUIP_and_DVC_TYPS_in_outages', \n",
    "        save_name='All_outages.png'\n",
    "    )\n",
    "else:\n",
    "    save_fig_kwargs=False\n",
    "#-----\n",
    "unit_figsize_height = calc_unit_figsize_height_for_groups_and_counts_table(\n",
    "    df=qa_df, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    nbr_rows_per_unit_height=nbr_rows_per_unit_height, \n",
    "    max_rows_per_table=max_rows_per_table\n",
    ")\n",
    "#-----\n",
    "figs_and_axs = build_groups_and_counts_table_from_df(\n",
    "    df=qa_df, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    include_counts=True, \n",
    "    max_rows_per_table=max_rows_per_table, \n",
    "    fig_num=0, \n",
    "    title='All Outages', \n",
    "    default_subplots_kwargs = dict(unit_figsize_height=unit_figsize_height), \n",
    "    save_fig_kwargs=save_fig_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9c91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    save_fig_kwargs = dict(\n",
    "        save_dir=r'C:\\Users\\s346557\\Documents\\AnalysisNote\\X_Results\\X_2_OutageMeterEvents\\Figures\\EQUIP_and_DVC_TYPS_in_outages', \n",
    "        save_name='Direct_outages_loose.png'\n",
    "    )\n",
    "else:\n",
    "    save_fig_kwargs=False\n",
    "#-----\n",
    "unit_figsize_height = calc_unit_figsize_height_for_groups_and_counts_table(\n",
    "    df=qa_df_drct_loose, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    nbr_rows_per_unit_height=nbr_rows_per_unit_height, \n",
    "    max_rows_per_table=max_rows_per_table\n",
    ")\n",
    "#-----\n",
    "figs_and_axs = build_groups_and_counts_table_from_df(\n",
    "    df=qa_df_drct_loose, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    include_counts=True, \n",
    "    max_rows_per_table=max_rows_per_table, \n",
    "    fig_num=0, \n",
    "    title='Direct Outages (loose)', \n",
    "    default_subplots_kwargs = dict(unit_figsize_height=unit_figsize_height), \n",
    "    save_fig_kwargs=save_fig_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    save_fig_kwargs = dict(\n",
    "        save_dir=r'C:\\Users\\s346557\\Documents\\AnalysisNote\\X_Results\\X_2_OutageMeterEvents\\Figures\\EQUIP_and_DVC_TYPS_in_outages', \n",
    "        save_name='Non_transformer_outages.png'\n",
    "    )\n",
    "else:\n",
    "    save_fig_kwargs=False\n",
    "#-----\n",
    "unit_figsize_height = calc_unit_figsize_height_for_groups_and_counts_table(\n",
    "    df=qa_df_non_trsfs, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    nbr_rows_per_unit_height=nbr_rows_per_unit_height, \n",
    "    max_rows_per_table=max_rows_per_table\n",
    ")\n",
    "#-----\n",
    "figs_and_axs = build_groups_and_counts_table_from_df(\n",
    "    df=qa_df_non_trsfs, \n",
    "    grp_by_cols=['EQUIP_TYP_NM', 'DVC_TYP_NM'], \n",
    "    include_counts=True, \n",
    "    max_rows_per_table=max_rows_per_table, \n",
    "    fig_num=0, \n",
    "    title='Direct Outages (loose)', \n",
    "    default_subplots_kwargs = dict(unit_figsize_height=unit_figsize_height), \n",
    "    save_fig_kwargs=save_fig_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c21267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ddc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8b0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_n_xfmrs = get_n_trsf_poles_per_outg(\n",
    "    df=merged_df_full, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "outgs_w_single_xfmr = outg_n_xfmrs[outg_n_xfmrs==1].index.tolist()\n",
    "outg_n_xfmrs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dir_indir_tp_fn_train = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_train_i, \n",
    "    y_pred=y_pred_train, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "#-----\n",
    "n_dir_indir_tp_fn_test = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_test_i, \n",
    "    y_pred=y_pred, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test TP Direct:   {n_dir_indir_tp_fn_test['TP_dir']}\")\n",
    "print(f\"Test TP Indirect: {n_dir_indir_tp_fn_test['TP_indir']}\")\n",
    "print(f\"Test FN Direct:   {n_dir_indir_tp_fn_test['FN_dir']}\")\n",
    "print(f\"Test FN Indirect: {n_dir_indir_tp_fn_test['FN_indir']}\")\n",
    "print()\n",
    "print(f\"Train TP Direct:   {n_dir_indir_tp_fn_train['TP_dir']}\")\n",
    "print(f\"Train TP Indirect: {n_dir_indir_tp_fn_train['TP_indir']}\")\n",
    "print(f\"Train FN Direct:   {n_dir_indir_tp_fn_train['FN_dir']}\")\n",
    "print(f\"Train FN Indirect: {n_dir_indir_tp_fn_train['FN_indir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d7550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876334f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=2, fig_num=1)\n",
    "#-----\n",
    "Plot_Hist.plot_hist(\n",
    "    ax=axs[0], \n",
    "    df=outg_n_xfmrs.to_frame(), \n",
    "    x_col='count',\n",
    "    min_max_and_bin_size=[0, 20, 1], \n",
    "    include_over_underflow=True\n",
    ")\n",
    "axs[0].set_title('# Xfmrs per Outage')\n",
    "axs[0].set_xlabel('# Xfmrs')\n",
    "axs[0].set_ylabel('Counts')\n",
    "#-----\n",
    "Plot_Hist.plot_hist(\n",
    "    ax=axs[1], \n",
    "    df=outg_n_xfmrs.to_frame(), \n",
    "    x_col='count',\n",
    "    min_max_and_bin_size=[0, 200, 1], \n",
    "    include_over_underflow=True\n",
    ")\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_title('# Xfmrs per Outage (Log Scale)')\n",
    "axs[1].set_xlabel('# Xfmrs')\n",
    "axs[1].set_ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f100fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% Outages affecting single Xfmr: {100*(outg_n_xfmrs==1).sum()/outg_n_xfmrs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4e43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./model_end_events_for_outages_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=2, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0]\n",
    ")\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_test, \n",
    "    y_pred=y_pred, \n",
    "    title='Test', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf233b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=1, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "\n",
    "# NOTE: Text stored in cmd.text_ is stored in row-major fashion\n",
    "#       Therefore, when plotting the value, the y-value corresponds to the 0th\n",
    "#         index and the x-value corresponds to the 1st index\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    display_labels=['No Outg.','Outage']\n",
    ")\n",
    "#-----\n",
    "cmd.plot(values_format='', ax=ax, text_kw=dict(fontsize='xx-large'))\n",
    "\n",
    "cmd.ax_.set_xlabel('Predicted', fontsize='xx-large')\n",
    "cmd.ax_.set_ylabel('True', fontsize='xx-large')\n",
    "cmd.ax_.set_title('Test', fontsize='xx-large', fontweight='semibold')\n",
    "# NOTE:\n",
    "# Axes are defined with limits:\n",
    "#   x_lim = (-0.5, 1.5)\n",
    "#   y_lim = (1.5, -0.5)\n",
    "# The axes are defined such that: \n",
    "#   top-left corner     = (-0.5, -0.5)\n",
    "#   bottom-right corner = (1.5, 1.5) \n",
    "#-----\n",
    "# Shift the values up by 0.25 (due to axis defition described above, this involes\n",
    "#   subtracting 0.25)\n",
    "# for txt_i in cmd.text_:\n",
    "#     for txt_ij in txt_i:\n",
    "#         txt_ij.set_y(txt_ij.get_position()[1]-0.25)\n",
    "        \n",
    "    \n",
    "color = get_outg_confusion_matrix_text_colors(cmd)\n",
    "#-----\n",
    "cmd.ax_.text(0,   -0.25, 'TN', ha='center', va='center', color=colors[0,0], fontweight='bold', fontsize='xx-large')\n",
    "cmd.ax_.text(1.0, -0.25, 'FP', ha='center', va='center', color=colors[0,1], fontweight='bold', fontsize='xx-large')\n",
    "\n",
    "cmd.ax_.text(0,    0.75, 'FN', ha='center', va='center', color=colors[1,0], fontweight='bold', fontsize='xx-large')\n",
    "cmd.ax_.text(1.0,  0.75, 'TP', ha='center', va='center', color=colors[1,1], fontweight='bold', fontsize='xx-large')\n",
    "#-----\n",
    "\n",
    "cmd.ax_.text(0,    1.25,  f\"#Dir = {n_dir_indir_tp_fn_test['FN_dir']}\", ha='center', va='center', fontsize='large', color=colors[1,0])\n",
    "cmd.ax_.text(0,    1.375, f\"#Indir = {n_dir_indir_tp_fn_test['FN_indir']}\", ha='center', va='center', fontsize='large', color=colors[1,0])\n",
    "\n",
    "cmd.ax_.text(1.0,    1.25,  f\"#Dir = {n_dir_indir_tp_fn_test['TP_dir']}\", ha='center', va='center', fontsize='large', color=colors[1,0])\n",
    "cmd.ax_.text(1.0,    1.375, f\"#Indir = {n_dir_indir_tp_fn_test['TP_indir']}\", ha='center', va='center', fontsize='large', color=colors[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_fmt     = '{:.4e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897e0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=1, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "\n",
    "# NOTE: Text stored in cmd.text_ is stored in row-major fashion\n",
    "#       Therefore, when plotting the value, the y-value corresponds to the 0th\n",
    "#         index and the x-value corresponds to the 1st index\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    display_labels=['No Outg.','Outage']\n",
    ")\n",
    "#-----\n",
    "cmd.plot(values_format='', ax=ax, text_kw=dict(fontsize='xx-large'))\n",
    "\n",
    "cmd.ax_.set_xlabel('Predicted', fontsize='xx-large')\n",
    "cmd.ax_.set_ylabel('True', fontsize='xx-large')\n",
    "cmd.ax_.set_title('Test', fontsize='xx-large', fontweight='semibold')\n",
    "# NOTE:\n",
    "# Axes are defined with limits:\n",
    "#   x_lim = (-0.5, 1.5)\n",
    "#   y_lim = (1.5, -0.5)\n",
    "# The axes are defined such that: \n",
    "#   top-left corner     = (-0.5, -0.5)\n",
    "#   bottom-right corner = (1.5, 1.5) \n",
    "#-----\n",
    "# Shift the values up by 0.25 (due to axis defition described above, this involes\n",
    "#   subtracting 0.25)\n",
    "# for txt_i in cmd.text_:\n",
    "#     for txt_ij in txt_i:\n",
    "#         txt_ij.set_y(txt_ij.get_position()[1]-0.25)\n",
    "        \n",
    "    \n",
    "color = get_outg_confusion_matrix_text_colors(cmd)\n",
    "#-----\n",
    "cmd.ax_.text(0,   -0.25, 'TN', ha='center', va='center', color=colors[0,0], fontweight='bold', fontsize='xx-large')\n",
    "cmd.ax_.text(1.0, -0.25, 'FP', ha='center', va='center', color=colors[0,1], fontweight='bold', fontsize='xx-large')\n",
    "\n",
    "cmd.ax_.text(0,    0.75, 'FN', ha='center', va='center', color=colors[1,0], fontweight='bold', fontsize='xx-large')\n",
    "cmd.ax_.text(1.0,  0.75, 'TP', ha='center', va='center', color=colors[1,1], fontweight='bold', fontsize='xx-large')\n",
    "#-----\n",
    "#----------\n",
    "# FN\n",
    "cmd.ax_.text(0,   1.25,  \"#Dir = {}\".format(txt_fmt).format(n_dir_indir_tp_fn_test['FN_dir']), \n",
    "             ha='center', va='center', fontsize='medium', color=colors[1,0])\n",
    "cmd.ax_.text(0,   1.375, \"#Indir = {}\".format(txt_fmt).format(n_dir_indir_tp_fn_test['FN_indir']), \n",
    "             ha='center', va='center', fontsize='medium', color=colors[1,0])\n",
    "#----------\n",
    "# TP\n",
    "cmd.ax_.text(1.0, 1.25,  \"#Dir = {}\".format(txt_fmt).format(n_dir_indir_tp_fn_test['TP_dir']), \n",
    "             ha='center', va='center', fontsize='medium', color=colors[1,1])\n",
    "cmd.ax_.text(1.0, 1.375, \"#Indir = {}\".format(txt_fmt).format(n_dir_indir_tp_fn_test['TP_indir']), \n",
    "             ha='center', va='center', fontsize='medium', color=colors[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=2, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_train\n",
    ")\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_test, \n",
    "    y_pred=y_pred, \n",
    "    title='Test', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[1], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c027dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d41fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753202ee",
   "metadata": {},
   "source": [
    "# Compare CI to number of PNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59230e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df_full.index.get_level_values(0).unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28364c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dovs_df = DOVSOutages.build_consolidated_outage_df(\n",
    "    contstruct_df_args=None, \n",
    "    build_sql_function=None, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs = merged_df_full.index.get_level_values(0).unique().tolist(), \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        verbose=True\n",
    "    ), \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['nPNs'] = dovs_df['premise_nbs'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['delta_nPNs_CI'] = dovs_df['nPNs']-dovs_df['CI_NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ebe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['delta_nPNs_CI'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df[dovs_df['delta_nPNs_CI']==dovs_df['delta_nPNs_CI'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df_full[merged_df_full.index.get_level_values(0)=='12907253'].index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df[dovs_df['delta_nPNs_CI']==dovs_df['delta_nPNs_CI'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df_full[merged_df_full.index.get_level_values(0)=='12824481'].index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aaff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe09edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df['delta_nPNs_CI'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72362365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't seem to be a huge deal\n",
    "# Maybe we should just filter out outages having a large delta?\n",
    "# This is much much easier than full in=depth analysis using check_DOVS methods\n",
    "\n",
    "fig, axs = Plot_General.default_subplots(n_x=1, n_y=1, fig_num=1)\n",
    "axs=[axs]\n",
    "#-----\n",
    "Plot_Hist.plot_hist(\n",
    "    ax=axs[0], \n",
    "    df=dovs_df, \n",
    "    x_col='delta_nPNs_CI',\n",
    "    min_max_and_bin_size=[-5, 10, 1], \n",
    "    include_over_underflow=True\n",
    ")\n",
    "axs[0].set_title('#PNs-CI_NB')\n",
    "axs[0].set_xlabel('$\\Delta$PN')\n",
    "axs[0].set_ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dovs_df['delta_nPNs_CI']==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9124a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full['EEMSP_0'].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d293d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full['EEMSP_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c3509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bbf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6cc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2471300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b955db1",
   "metadata": {},
   "source": [
    "# Data for Ed Schwartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90188064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outg_rec_and_trsf_pole_nbs_in_files(\n",
    "    outg_rec_and_trsf_pole_nbs, \n",
    "    data_dir, \n",
    "    is_baseline=False, \n",
    "    file_path_glob=r'end_events_[0-9]*.csv', \n",
    "    verbose=True, \n",
    "    n_update=100\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    summary_paths = AMIEndEvents.get_summary_paths_for_data_in_dir(\n",
    "        data_dir=data_dir, \n",
    "        file_path_glob=file_path_glob, \n",
    "        return_dict=True\n",
    "    )\n",
    "    assert(len(summary_paths)>0)\n",
    "    #-------------------------\n",
    "    start=time.time()\n",
    "    return_paths = []\n",
    "    for i,(data_path_i, summary_path_i) in enumerate(summary_paths.items()):\n",
    "        if verbose and i%n_update==0:\n",
    "            print(f\"{i} of {len(summary_paths)}\")\n",
    "        #-------------------------\n",
    "        assert(os.path.exists(summary_path_i))\n",
    "        #-------------------------\n",
    "        f = open(summary_path_i)\n",
    "        summary_json_data = json.load(f)\n",
    "        assert('sql_statement' in summary_json_data)\n",
    "        sql_statement = summary_json_data['sql_statement']\n",
    "        #-------------------------\n",
    "        f.close()\n",
    "        #-------------------------\n",
    "        # Find the last instance of \"SELECT * FROM USG_X\" to extract how many sets of \n",
    "        # t_min,t_max,prem_nbs to expect.\n",
    "        # If not found, expect only one\n",
    "        pattern = r\"SELECT \\* FROM .*_(\\d*)$\"\n",
    "        found_all = re.findall(pattern, sql_statement)\n",
    "        if len(found_all)==0:\n",
    "            n_groups_expected = 1\n",
    "        else:\n",
    "            assert(len(found_all)==1)\n",
    "            n_groups_expected = int(found_all[0])+1\n",
    "        #-------------------------\n",
    "        pattern = r\"'(.*)' AS OUTG_REC_NB_GPD_FOR_SQL,[\\s\\S]+?'(.*)' AS trsf_pole_nb_GPD_FOR_SQL\"\n",
    "        if is_baseline:\n",
    "            pattern = r\"'(.*)' AS trsf_pole_nb_GPD_FOR_SQL,[\\s\\S]+?'(.*)' AS no_outg_rec_nb_GPD_FOR_SQL\"\n",
    "        found = re.findall(pattern, sql_statement)\n",
    "        assert(len(found)==n_groups_expected)\n",
    "        assert(Utilities.are_list_elements_lengths_homogeneous(found, 2))\n",
    "        if is_baseline:\n",
    "            # Need to switch order (trsf_pole_nb, rec_nb) --> (rec_nb, trsf_pole_nb)\n",
    "            found = [(x[1], x[0]) for x in found]\n",
    "        #-------------------------\n",
    "        if len(set(outg_rec_and_trsf_pole_nbs).intersection(set(found)))>0:\n",
    "            return_paths.append(data_path_i)\n",
    "    if verbose:\n",
    "        print(f\"time = {time.time()-start}\")\n",
    "    #-------------------------\n",
    "    return return_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_outg_rec_and_trsf_pole_nbs(\n",
    "    df, \n",
    "    outg_rec_and_trsf_pole_nbs, \n",
    "    outg_rec_nb_col='OUTG_REC_NB_GPD_FOR_SQL', \n",
    "    trsf_pole_nb_col='trsf_pole_nb_GPD_FOR_SQL', \n",
    "    rename_cols=True, \n",
    "    drop_is_first_after_outg=True\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(outg_rec_nb_col in df.columns)\n",
    "    assert(trsf_pole_nb_col in df.columns)\n",
    "    #-----\n",
    "    # outg_rec_and_trsf_pole_nbs must be a list of tuples (NOT a list of lists!!)\n",
    "    assert(Utilities.are_all_list_elements_of_type(outg_rec_and_trsf_pole_nbs, tuple))\n",
    "    assert(Utilities.are_list_elements_lengths_homogeneous(outg_rec_and_trsf_pole_nbs, 2))\n",
    "    #-------------------------\n",
    "    slicers = []\n",
    "    for outg_rec_nb_i, trsf_pole_nb_i in outg_rec_and_trsf_pole_nbs:\n",
    "        slicer_i = DFSlicer(\n",
    "            single_slicers = [\n",
    "                dict(\n",
    "                    column=outg_rec_nb_col, \n",
    "                    value=outg_rec_nb_i, \n",
    "                    comparison_operator='=='\n",
    "                ), \n",
    "                dict(\n",
    "                    column=trsf_pole_nb_col, \n",
    "                    value=trsf_pole_nb_i, \n",
    "                    comparison_operator='=='\n",
    "                )\n",
    "            ], \n",
    "            name=None, \n",
    "            apply_not=False, \n",
    "            join_single_slicers='and'\n",
    "        )\n",
    "        #-----\n",
    "        slicers.append(slicer_i)\n",
    "    #-------------------------   \n",
    "    return_df = DFSlicer.combine_slicers_and_perform_slicing(\n",
    "        df=df, \n",
    "        slicers=slicers, \n",
    "        join_slicers='or', \n",
    "        apply_not=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    if rename_cols:\n",
    "        return_df = return_df.rename(columns={\n",
    "            outg_rec_nb_col:'rec_nb',\n",
    "            trsf_pole_nb_col:'trsf_pole_nb'\n",
    "        })\n",
    "    #-------------------------\n",
    "    if drop_is_first_after_outg:\n",
    "        if 'is_first_after_outg' in return_df.columns:\n",
    "            return_df = return_df.drop(columns=['is_first_after_outg'])\n",
    "        if 'is_first_after_outg_GPD_FOR_SQL' in return_df.columns:\n",
    "            return_df = return_df.drop(columns=['is_first_after_outg_GPD_FOR_SQL'])\n",
    "    #-------------------------\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16739ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((full_data_df_test_i[('is_outg', 'is_outg')]==y_test).all())\n",
    "scores_df_test = full_data_df_test_i[[('is_outg', 'is_outg')]].copy()\n",
    "scores_df_test = scores_df_test.droplevel(0, axis=1)\n",
    "scores_df_test['y_pred']   = y_pred\n",
    "scores_df_test['y_scores'] = y_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c07507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weird, not sure why the y_scored and y_pred disagree for some...\n",
    "scores_df_test[np.round(scores_df_test['y_scores'])!=scores_df_test['y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c793922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a99f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the baseline data, the data are stored on the U drive.\n",
    "#   However, the summary files are available locally, and are much faster to query through when looking\n",
    "#     for specific entries than those on the U drive.\n",
    "#   So, the local summary files will be used, but the data will ultimately be grabbed from the U drive\n",
    "#-------------------------\n",
    "data_dir_outg         = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\20220101_20221231\\Outgs_Full\\EndEvents'\n",
    "#-----\n",
    "data_dir_bsln         = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230512\\20220101_20221231\\NoOutgs\\EndEvents'\n",
    "data_dir_U_bsln       = r'U:\\CloudData\\dovs_and_end_events_data\\20230512\\20220101_20221231\\NoOutgs\\EndEvents'\n",
    "#-----\n",
    "data_dir_bsln_prstn   = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230301\\20220101_20221231\\NoOutgs_Pristine\\EndEvents'\n",
    "data_dir_U_bsln_prstn = r'U:\\CloudData\\dovs_and_end_events_data\\20230301\\20220101_20221231\\NoOutgs_Pristine\\EndEvents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b68b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be a list of tuples (NOT a list of lists!!)\n",
    "# outg_rec_and_trsf_pole_nbs = [\n",
    "#     ('12580837', '1863938736669'), \n",
    "#     ('12580900', '40830909D30135' )\n",
    "# ]\n",
    "\n",
    "# save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\forEd\\Outages'\n",
    "# scores_df_test=scores_df_test.sort_values(by=['y_scores'], ascending=False)\n",
    "# outg_rec_and_trsf_pole_nbs = scores_df_test[\n",
    "#     (scores_df_test['is_outg']==scores_df_test['y_pred']) &\n",
    "#     (scores_df_test['is_outg']==1)\n",
    "# ].iloc[:50].index.tolist()\n",
    "\n",
    "save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\forEd\\Baseline'\n",
    "scores_df_test=scores_df_test.sort_values(by=['y_scores'], ascending=True)\n",
    "outg_rec_and_trsf_pole_nbs = scores_df_test[\n",
    "    (scores_df_test['is_outg']==scores_df_test['y_pred']) &\n",
    "    (scores_df_test['is_outg']==0)\n",
    "].iloc[:50].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d63a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cca99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model_df = full_data_df_test_i.copy()\n",
    "return_model_df.index.names = ['rec_nb', 'trsf_pole_nb']\n",
    "return_model_df=return_model_df.reset_index()\n",
    "return_model_df = project_outg_rec_and_trsf_pole_nbs(\n",
    "    df=return_model_df, \n",
    "    outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "    outg_rec_nb_col=('rec_nb', ''), \n",
    "    trsf_pole_nb_col=('trsf_pole_nb', '')\n",
    ")\n",
    "return_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paths_outg = find_outg_rec_and_trsf_pole_nbs_in_files(\n",
    "    outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "    data_dir=data_dir_outg,\n",
    "    is_baseline=False, \n",
    "    file_path_glob=r'end_events_[0-9]*.csv', \n",
    "    verbose=True, \n",
    "    n_update=1000\n",
    ")\n",
    "#-----\n",
    "relevant_paths_bsln = find_outg_rec_and_trsf_pole_nbs_in_files(\n",
    "    outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "    data_dir=data_dir_bsln, \n",
    "    is_baseline=True, \n",
    "    file_path_glob=r'end_events_[0-9]*.csv', \n",
    "    verbose=True, \n",
    "    n_update=1000\n",
    ")\n",
    "#-----\n",
    "relevant_paths_bsln_prstn = find_outg_rec_and_trsf_pole_nbs_in_files(\n",
    "    outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "    data_dir=data_dir_bsln_prstn, \n",
    "    is_baseline=True, \n",
    "    file_path_glob=r'end_events_[0-9]*.csv', \n",
    "    verbose=True, \n",
    "    n_update=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(relevant_paths_outg)       = {len(relevant_paths_outg)}')\n",
    "print(f'len(relevant_paths_bsln)       = {len(relevant_paths_bsln)}')\n",
    "print(f'len(relevant_paths_bsln_prstn) = {len(relevant_paths_bsln_prstn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above, for the baseline data the local summary files will be queried, \n",
    "#   but the data will ultimately be grabbed from the U drive\n",
    "relevant_paths_bsln = [os.path.join(data_dir_U_bsln, Path(path_i).name) \n",
    "                       for path_i in relevant_paths_bsln]\n",
    "relevant_paths_bsln_prstn = [os.path.join(data_dir_U_bsln_prstn, Path(path_i).name) \n",
    "                             for path_i in relevant_paths_bsln_prstn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "relevant_dfs = []\n",
    "#-------------------------\n",
    "for path_i in relevant_paths_outg:\n",
    "    df_i = pd.read_csv(path_i, dtype=str, index_col=0)\n",
    "    #-----\n",
    "    df_i = project_outg_rec_and_trsf_pole_nbs(\n",
    "        df=df_i, \n",
    "        outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "        outg_rec_nb_col='OUTG_REC_NB_GPD_FOR_SQL', \n",
    "        trsf_pole_nb_col='trsf_pole_nb_GPD_FOR_SQL'\n",
    "    )\n",
    "    relevant_dfs.append(df_i)\n",
    "#-------------------------\n",
    "for path_i in relevant_paths_bsln:\n",
    "    df_i = pd.read_csv(path_i, dtype=str, index_col=0)\n",
    "    #-----\n",
    "    df_i = project_outg_rec_and_trsf_pole_nbs(\n",
    "        df=df_i, \n",
    "        outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "        outg_rec_nb_col='no_outg_rec_nb_GPD_FOR_SQL', \n",
    "        trsf_pole_nb_col='trsf_pole_nb_GPD_FOR_SQL'\n",
    "    )\n",
    "    relevant_dfs.append(df_i)\n",
    "#-------------------------    \n",
    "for path_i in relevant_paths_bsln_prstn:\n",
    "    df_i = pd.read_csv(path_i, dtype=str, index_col=0)\n",
    "    #-----\n",
    "    df_i = project_outg_rec_and_trsf_pole_nbs(\n",
    "        df=df_i, \n",
    "        outg_rec_and_trsf_pole_nbs=outg_rec_and_trsf_pole_nbs, \n",
    "        outg_rec_nb_col='no_outg_rec_nb_GPD_FOR_SQL', \n",
    "        trsf_pole_nb_col='trsf_pole_nb_GPD_FOR_SQL'\n",
    "    )\n",
    "    relevant_dfs.append(df_i)\n",
    "#--------------------------------------------------\n",
    "expected_cols  = relevant_dfs[0].columns\n",
    "for i,df_i in enumerate(relevant_dfs):\n",
    "    assert(len(set(df_i.columns).symmetric_difference(set(expected_cols)))==0)\n",
    "    relevant_dfs[i] = df_i[expected_cols]\n",
    "final_df = pd.concat(relevant_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf85ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a250a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(set(final_df[['rec_nb', 'trsf_pole_nb']].value_counts().index).symmetric_difference(\n",
    "    set(outg_rec_and_trsf_pole_nbs)\n",
    "))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(save_dir, 'raw_meter_events.csv'))\n",
    "final_df.to_pickle(os.path.join(save_dir, 'raw_meter_events.pkl'))\n",
    "#-----\n",
    "Utilities_df.flatten_multiindex_columns(\n",
    "    return_model_df, join_str=', ', reverse_order=False, inplace=False\n",
    ").to_csv(os.path.join(save_dir, 'model_features.csv'))\n",
    "return_model_df.to_pickle(os.path.join(save_dir, 'model_features.pkl'))\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559c24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f15d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa713d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdffea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba7bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
