{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444718d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "from Utilities_df import DFConstructType\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b46d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "#-----\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#-----\n",
    "import scipy\n",
    "from scipy import signal\n",
    "#-----\n",
    "from tensorflow import keras\n",
    "#-----\n",
    "# from tslearn.shapelets import LearningShapelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c915d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e61d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def get_outg_confusion_matrix_text_colors(\n",
    "    cmd\n",
    "):\n",
    "    r\"\"\"\n",
    "    Basically taken from sklearn.metrics.ConfusionMatrixDisplay.plot\n",
    "    Colors are needed so my additional text matches what's provided by sklearn method.\n",
    "    \n",
    "    SHOULD BE CALLED AFTER sklearn.metrics.ConfusionMatrixDisplay.plot!\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    cm = cmd.confusion_matrix\n",
    "    assert(cm.shape[0]==2)\n",
    "    n_classes = cm.shape[0]\n",
    "    #-------------------------\n",
    "    cmap_min, cmap_max = cmd.im_.cmap(0), cmd.im_.cmap(1.0)\n",
    "    thresh = (cm.max() + cm.min()) / 2.0\n",
    "    #-------------------------\n",
    "    colors = np.empty((2,2), dtype=object)\n",
    "    for i,j in product(range(2), range(2)):\n",
    "        color = cmap_max if cm[i, j] < thresh else cmap_min\n",
    "        colors[i,j] = color\n",
    "    #-------------------------\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ccfaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(\n",
    "    y, \n",
    "    y_pred, \n",
    "    title=None, \n",
    "    normalize=None, \n",
    "    scientific=True, \n",
    "    ax=None, \n",
    "    text_kw=dict(fontsize='xx-large'), \n",
    "    target_eq_1_name='Outage', \n",
    "    target_eq_0_name='Baseline'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Visualize confusion matrix for outages using sklearn.metrics.ConfusionMatrixDisplay\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    cmd = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(y, y_pred, normalize=normalize), \n",
    "        display_labels=[target_eq_0_name, target_eq_1_name]\n",
    "    )\n",
    "    #-----\n",
    "    if scientific:\n",
    "        cmd.plot(values_format='.3e', ax=ax, text_kw=text_kw)\n",
    "    else:\n",
    "        cmd.plot(values_format='', ax=ax, text_kw=text_kw)\n",
    "    #-------------------------\n",
    "    cmd.ax_.set_xlabel('Predicted', fontsize='xx-large')\n",
    "    cmd.ax_.set_ylabel('True', fontsize='xx-large')\n",
    "    cmd.ax_.set_title(title, fontsize='xx-large', fontweight='semibold')\n",
    "    #ax.set_size_inches(12, 10)\n",
    "    #-------------------------\n",
    "    if scientific:\n",
    "        txt_fmt     = '{:.4e}'\n",
    "        pct_txt_fmt = txt_fmt\n",
    "    else:\n",
    "        txt_fmt     = '{}'\n",
    "        pct_txt_fmt = '{:.4f}'\n",
    "    #-----\n",
    "    ax = cmd.ax_\n",
    "    ax.text(1.5, 0.9, \"# Entries:  {}\".format(txt_fmt).format(y.shape[0]), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.8, \"# {}:  {}\".format(target_eq_1_name, txt_fmt).format(y.sum()), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.7, \"# {}: {}\".format(target_eq_0_name, txt_fmt).format(y.shape[0]-y.sum()), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.6, \"% {}:  {}\".format(target_eq_1_name, pct_txt_fmt).format(100*y.sum()/y.shape[0]), fontsize=14, transform=ax.transAxes)\n",
    "    #-------------------------\n",
    "    ax.text(1.5, 0.4, \"ACCURACY:  {:.4f}\".format(accuracy_score(y, y_pred)), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.3, \"PRECISION:  {:.4f}\".format(precision_score(y, y_pred)), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.2, \"RECALL:       {:.4f}\".format(recall_score(y, y_pred)), fontsize=14, transform=ax.transAxes)\n",
    "    ax.text(1.5, 0.1, \"F1:               {:.4f}\".format(f1_score(y, y_pred)), fontsize=14, transform=ax.transAxes)\n",
    "    #--------------------------------------------------\n",
    "    # Include TN, FP, FN, TP labels\n",
    "    # NOTES:\n",
    "    #   Text stored in cmd.text_ is stored in row-major fashion\n",
    "    #   Therefore, when plotting the value, the y-value corresponds to the 0th\n",
    "    #     index and the x-value corresponds to the 1st index\n",
    "    #\n",
    "    #   Axes are defined with limits:\n",
    "    #     x_lim = (-0.5, 1.5)\n",
    "    #     y_lim = (1.5, -0.5)\n",
    "    #   The axes are defined such that: \n",
    "    #     top-left corner     = (-0.5, -0.5)\n",
    "    #     bottom-right corner = (1.5, 1.5) \n",
    "    #-----\n",
    "    colors = get_outg_confusion_matrix_text_colors(cmd)\n",
    "    cat_fontsize = text_kw.get('fontsize', 'xx-large')\n",
    "    #-----\n",
    "    cmd.ax_.text(0,   -0.25, 'TN', ha='center', va='center', color=colors[0,0], fontweight='bold', fontsize=cat_fontsize)\n",
    "    cmd.ax_.text(1.0, -0.25, 'FP', ha='center', va='center', color=colors[0,1], fontweight='bold', fontsize=cat_fontsize)\n",
    "\n",
    "    cmd.ax_.text(0,    0.75, 'FN', ha='center', va='center', color=colors[1,0], fontweight='bold', fontsize=cat_fontsize)\n",
    "    cmd.ax_.text(1.0,  0.75, 'TP', ha='center', va='center', color=colors[1,1], fontweight='bold', fontsize=cat_fontsize)    \n",
    "    #--------------------------------------------------\n",
    "    #return ax, cmd.ax_\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfc4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684261f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7650d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ev_submeter_in_pair(\n",
    "    ami_df_i, \n",
    "    pct_0_thresh_main=0.1, \n",
    "    pct_0_thresh_subm=0.6, \n",
    "    enforce_corr=True, \n",
    "    corr_thresh=0.5, \n",
    "    #remove_undetermined=True, \n",
    "    value_col='value', \n",
    "    time_col='index', \n",
    "    PN_col='aep_premise_nb', \n",
    "    SN_col='serialnumber'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Given a pair of meter connected to a single premise, this tries to determine which is the EV submeter in the pair, \n",
    "      and keeps that which is not.\n",
    "    Basically, the submeter only monitors the EV, whereas the other monitors the usage of the entire premise.\n",
    "    Thus, the EV signal should be 0 for a majority of the time, and the two meters should be correlated.\n",
    "    \n",
    "    This is a somewhat specialized function for use with engineering the EV dataset\n",
    "    \n",
    "    ami_df_i:\n",
    "        An AMI DF containing data for a single premise which has two meters\n",
    "        \n",
    "    pct_0_thresh_main:\n",
    "        The maximum allowed percentage of 0 values for a meter to be considered the main meter\n",
    "    pct_0_thresh_subm:\n",
    "        The minimum allowed percentage of 0 values for a meter to be considered the submeter\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(ami_df_i[PN_col].nunique()==1)\n",
    "    assert(pct_0_thresh_main < pct_0_thresh_subm)\n",
    "    #-------------------------\n",
    "    SNs_i = ami_df_i[SN_col].unique().tolist()\n",
    "    assert(len(SNs_i)<=2)\n",
    "    #-------------------------\n",
    "    if len(SNs_i)==1:\n",
    "        return ami_df_i\n",
    "    #-------------------------\n",
    "    ami_df_i_1 = ami_df_i[ami_df_i[SN_col]==SNs_i[0]]\n",
    "    ami_df_i_2 = ami_df_i[ami_df_i[SN_col]==SNs_i[1]]\n",
    "    if time_col=='index':\n",
    "        ami_df_i_1 = ami_df_i_1.sort_index()\n",
    "        ami_df_i_2 = ami_df_i_2.sort_index()\n",
    "    else:\n",
    "        ami_df_i_1 = ami_df_i_1.sort_values(by=[time_col])\n",
    "        ami_df_i_2 = ami_df_i_2.sort_values(by=[time_col])\n",
    "    #--------------------------------------------------\n",
    "    # NOTE: I have seen some SNs which have a bunch of 0.002 values, which, for the purposes here should be treated as 0s\n",
    "    #       This is why I use <0.005 instead of ==0 and >=0.005 instead of !=0 below\n",
    "    #--------------------------------------------------\n",
    "    pct_1 = (ami_df_i_1[value_col]<0.005).sum()/ami_df_i_1.shape[0]\n",
    "    pct_2 = (ami_df_i_2[value_col]<0.005).sum()/ami_df_i_2.shape[0]\n",
    "    #-------------------------\n",
    "    if pct_1 <= pct_0_thresh_main:\n",
    "        defn_1 = 1\n",
    "    elif pct_1 >= pct_0_thresh_subm:\n",
    "        defn_1 = 0\n",
    "    else:\n",
    "        defn_1 = -1\n",
    "    #-----\n",
    "    if pct_2 <= pct_0_thresh_main:\n",
    "        defn_2 = 1\n",
    "    elif pct_2 >= pct_0_thresh_subm:\n",
    "        defn_2 = 0\n",
    "    else:\n",
    "        defn_2 = -1\n",
    "    #-------------------------\n",
    "    if defn_1+defn_2==1:\n",
    "        pass_pcts=True\n",
    "    else:\n",
    "        pass_pcts=False\n",
    "    #-------------------------\n",
    "    if not pass_pcts:\n",
    "        return\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    pass_corr=True\n",
    "    if enforce_corr:\n",
    "        if time_col=='index':\n",
    "            ami_df_i_12 = pd.merge(ami_df_i_1[value_col], ami_df_i_2[value_col], left_index=True, right_index=True, how='outer')\n",
    "        else:\n",
    "            ami_df_i_12 = pd.merge(ami_df_i_1[value_col], ami_df_i_2[value_col], left_on=time_col, right_on=time_col, how='outer')\n",
    "        # For the correlation only using values which are non-zero (and aligning, meaning non-NaN)\n",
    "        ami_df_i_12 = ami_df_i_12[(ami_df_i_12[f'{value_col}_x']>=0.005) & (ami_df_i_12[f'{value_col}_y']>=0.005)]\n",
    "        corr_val = ami_df_i_12[f'{value_col}_x'].corr(ami_df_i_12[f'{value_col}_y'])\n",
    "        if corr_val >= corr_thresh:\n",
    "            pass_corr = True\n",
    "        else:\n",
    "            pass_corr = False\n",
    "            \n",
    "    #--------------------------------------------------\n",
    "    if not (pass_pcts and pass_corr):\n",
    "        return\n",
    "    #-------------------------\n",
    "    if defn_1==1:\n",
    "        assert(defn_2==0) # Sanity check, not needed\n",
    "        return ami_df_i[ami_df_i[SN_col]==SNs_i[0]]\n",
    "    else:\n",
    "        assert(defn_1==0 and defn_2==1) # Sanity check, not needed\n",
    "        return ami_df_i[ami_df_i[SN_col]==SNs_i[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfb0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pairs_w_submeter(\n",
    "    ami_df_i, \n",
    "    pct_0_thresh_main=0.1, \n",
    "    pct_0_thresh_subm=0.6, \n",
    "    enforce_corr=True, \n",
    "    corr_thresh=0.5, \n",
    "    #remove_undetermined=True, \n",
    "    value_col='value', \n",
    "    time_col='index', \n",
    "    PN_col='aep_premise_nb', \n",
    "    SN_col='serialnumber'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Given a pair of meter connected to a single premise, this tries to determine which is the EV submeter in the pair, \n",
    "      and keeps that which is not.\n",
    "    Basically, the submeter only monitors the EV, whereas the other monitors the usage of the entire premise.\n",
    "    Thus, the EV signal should be 0 for a majority of the time, and the two meters should be correlated.\n",
    "    \n",
    "    This is a somewhat specialized function for use with engineering the EV dataset\n",
    "    \n",
    "    ami_df_i:\n",
    "        An AMI DF containing data for a single premise which has two meters\n",
    "        \n",
    "    pct_0_thresh_main:\n",
    "        The maximum allowed percentage of 0 values for a meter to be considered the main meter\n",
    "    pct_0_thresh_subm:\n",
    "        The minimum allowed percentage of 0 values for a meter to be considered the submeter\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(ami_df_i[PN_col].nunique()==1)\n",
    "    assert(pct_0_thresh_main < pct_0_thresh_subm)\n",
    "    #-------------------------\n",
    "    SNs_i = ami_df_i[SN_col].unique().tolist()\n",
    "    assert(len(SNs_i)<=2)\n",
    "    #-------------------------\n",
    "    if len(SNs_i)==1:\n",
    "        return \n",
    "    #-------------------------\n",
    "    ami_df_i_1 = ami_df_i[ami_df_i[SN_col]==SNs_i[0]]\n",
    "    ami_df_i_2 = ami_df_i[ami_df_i[SN_col]==SNs_i[1]]\n",
    "    if time_col=='index':\n",
    "        ami_df_i_1 = ami_df_i_1.sort_index()\n",
    "        ami_df_i_2 = ami_df_i_2.sort_index()\n",
    "    else:\n",
    "        ami_df_i_1 = ami_df_i_1.sort_values(by=[time_col])\n",
    "        ami_df_i_2 = ami_df_i_2.sort_values(by=[time_col])\n",
    "    #--------------------------------------------------\n",
    "    # NOTE: I have seen some SNs which have a bunch of 0.002 values, which, for the purposes here should be treated as 0s\n",
    "    #       This is why I use <0.005 instead of ==0 and >=0.005 instead of !=0 below\n",
    "    #--------------------------------------------------\n",
    "    pct_1 = (ami_df_i_1[value_col]<0.005).sum()/ami_df_i_1.shape[0]\n",
    "    pct_2 = (ami_df_i_2[value_col]<0.005).sum()/ami_df_i_2.shape[0]\n",
    "    #-------------------------\n",
    "    if pct_1 <= pct_0_thresh_main:\n",
    "        defn_1 = 1\n",
    "    elif pct_1 >= pct_0_thresh_subm:\n",
    "        defn_1 = 0\n",
    "    else:\n",
    "        defn_1 = -1\n",
    "    #-----\n",
    "    if pct_2 <= pct_0_thresh_main:\n",
    "        defn_2 = 1\n",
    "    elif pct_2 >= pct_0_thresh_subm:\n",
    "        defn_2 = 0\n",
    "    else:\n",
    "        defn_2 = -1\n",
    "    #-------------------------\n",
    "    if defn_1+defn_2==1:\n",
    "        pass_pcts=True\n",
    "    else:\n",
    "        pass_pcts=False\n",
    "    #-------------------------\n",
    "    if not pass_pcts:\n",
    "        return\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    pass_corr=True\n",
    "    if enforce_corr:\n",
    "        if time_col=='index':\n",
    "            ami_df_i_12 = pd.merge(ami_df_i_1[value_col], ami_df_i_2[value_col], left_index=True, right_index=True, how='outer')\n",
    "        else:\n",
    "            ami_df_i_12 = pd.merge(ami_df_i_1[value_col], ami_df_i_2[value_col], left_on=time_col, right_on=time_col, how='outer')\n",
    "        # For the correlation only using values which are non-zero (and aligning, meaning non-NaN)\n",
    "        ami_df_i_12 = ami_df_i_12[(ami_df_i_12[f'{value_col}_x']>=0.005) & (ami_df_i_12[f'{value_col}_y']>=0.005)]\n",
    "        corr_val = ami_df_i_12[f'{value_col}_x'].corr(ami_df_i_12[f'{value_col}_y'])\n",
    "        if corr_val >= corr_thresh:\n",
    "            pass_corr = True\n",
    "        else:\n",
    "            pass_corr = False\n",
    "            \n",
    "    #--------------------------------------------------\n",
    "    if not (pass_pcts and pass_corr):\n",
    "        return\n",
    "    #-------------------------\n",
    "    if defn_1==1:\n",
    "        assert(defn_2==0) # Sanity check, not needed\n",
    "        ami_df_i_main = ami_df_i[ami_df_i[SN_col]==SNs_i[0]].copy()\n",
    "        ami_df_i_subm = ami_df_i[ami_df_i[SN_col]==SNs_i[1]].copy()\n",
    "    else:\n",
    "        assert(defn_1==0 and defn_2==1) # Sanity check, not needed\n",
    "        ami_df_i_main =  ami_df_i[ami_df_i[SN_col]==SNs_i[1]].copy()\n",
    "        ami_df_i_subm =  ami_df_i[ami_df_i[SN_col]==SNs_i[0]].copy()\n",
    "    #-------------------------\n",
    "    if time_col=='index':\n",
    "        return_ami_df_i = pd.merge(\n",
    "            ami_df_i_main, \n",
    "            ami_df_i_subm[[value_col, SN_col]], \n",
    "            left_index=True, \n",
    "            right_index=True, \n",
    "            how='inner'\n",
    "        )\n",
    "    else:\n",
    "        return_ami_df_i = pd.merge(\n",
    "            ami_df_i_main, \n",
    "            ami_df_i_subm[[value_col, time_col, SN_col]], \n",
    "            left_on=time_col, \n",
    "            right_on=time_col, \n",
    "            how='inner'\n",
    "        )\n",
    "    #----------\n",
    "    return_ami_df_i = return_ami_df_i.rename(columns={\n",
    "        f'{value_col}_x': f'{value_col}_main', \n",
    "        f'{value_col}_y': f'{value_col}_subm', \n",
    "        f'{SN_col}_x': f'{SN_col}_main', \n",
    "        f'{SN_col}_y': f'{SN_col}_subm', \n",
    "    })\n",
    "    #----------\n",
    "    return_ami_df_i[f'{value_col}_delt'] = return_ami_df_i[f'{value_col}_main']-return_ami_df_i[f'{value_col}_subm']\n",
    "    #-------------------------\n",
    "    return return_ami_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a43e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8674ec4",
   "metadata": {},
   "source": [
    "# SEE WEBPAGES\n",
    "https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data\n",
    "https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data/43512887#43512887\n",
    "https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data/56451135#56451135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb421b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class real_time_peak_detection():\n",
    "#     def __init__(self, array, lag, threshold, influence):\n",
    "#         self.y = list(array)\n",
    "#         self.length = len(self.y)\n",
    "#         self.lag = lag\n",
    "#         self.threshold = threshold\n",
    "#         self.influence = influence\n",
    "#         self.signals = [0] * len(self.y)\n",
    "#         self.filteredY = np.array(self.y).tolist()\n",
    "#         self.avgFilter = [0] * len(self.y)\n",
    "#         self.stdFilter = [0] * len(self.y)\n",
    "#         self.avgFilter[self.lag - 1] = np.mean(self.y[0:self.lag]).tolist()\n",
    "#         self.stdFilter[self.lag - 1] = np.std(self.y[0:self.lag]).tolist()\n",
    "\n",
    "#     def thresholding_algo(self, new_value):\n",
    "#         self.y.append(new_value)\n",
    "#         i = len(self.y) - 1\n",
    "#         self.length = len(self.y)\n",
    "#         if i < self.lag:\n",
    "#             return 0\n",
    "#         elif i == self.lag:\n",
    "#             self.signals = [0] * len(self.y)\n",
    "#             self.filteredY = np.array(self.y).tolist()\n",
    "#             self.avgFilter = [0] * len(self.y)\n",
    "#             self.stdFilter = [0] * len(self.y)\n",
    "#             self.avgFilter[self.lag] = np.mean(self.y[0:self.lag]).tolist()\n",
    "#             self.stdFilter[self.lag] = np.std(self.y[0:self.lag]).tolist()\n",
    "#             return 0\n",
    "\n",
    "#         self.signals += [0]\n",
    "#         self.filteredY += [0]\n",
    "#         self.avgFilter += [0]\n",
    "#         self.stdFilter += [0]\n",
    "\n",
    "#         if abs(self.y[i] - self.avgFilter[i - 1]) > (self.threshold * self.stdFilter[i - 1]):\n",
    "\n",
    "#             if self.y[i] > self.avgFilter[i - 1]:\n",
    "#                 self.signals[i] = 1\n",
    "#             else:\n",
    "#                 self.signals[i] = -1\n",
    "\n",
    "#             self.filteredY[i] = self.influence * self.y[i] + \\\n",
    "#                 (1 - self.influence) * self.filteredY[i - 1]\n",
    "#             self.avgFilter[i] = np.mean(self.filteredY[(i - self.lag):i])\n",
    "#             self.stdFilter[i] = np.std(self.filteredY[(i - self.lag):i])\n",
    "#         else:\n",
    "#             self.signals[i] = 0\n",
    "#             self.filteredY[i] = self.y[i]\n",
    "#             self.avgFilter[i] = np.mean(self.filteredY[(i - self.lag):i])\n",
    "#             self.stdFilter[i] = np.std(self.filteredY[(i - self.lag):i])\n",
    "\n",
    "#         return self.signals[i]\n",
    "\n",
    "\n",
    "def thresholding_algo_OLD(y, lag, threshold, influence):\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    for i in range(lag, len(y)):\n",
    "        if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter [i-1]:\n",
    "            if y[i] > avgFilter[i-1]:\n",
    "                signals[i] = 1\n",
    "            else:\n",
    "                signals[i] = -1\n",
    "\n",
    "            filteredY[i] = influence * y[i] + (1 - influence) * filteredY[i-1]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "        else:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))\n",
    "\n",
    "\n",
    "def thresholding_algo(\n",
    "    y, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    #-----\n",
    "    if len(y) < lag:\n",
    "        return dict(signals = np.asarray(np.zeros(len(y))),\n",
    "                    avgFilter = np.asarray(np.mean(y)),\n",
    "                    stdFilter = np.asarray(np.std(y)))\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    non_signal_Y = []\n",
    "    for i in range(lag, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            non_signal_Y.append(y[i])    \n",
    "        else:\n",
    "            if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter[i-1]:\n",
    "                if y[i] > avgFilter[i-1]:\n",
    "                    signals[i] = 1\n",
    "                else:\n",
    "                    signals[i] = -1\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * np.mean(non_signal_Y)\n",
    "            else:\n",
    "                signals[i] = 0\n",
    "                filteredY[i] = y[i]\n",
    "                non_signal_Y.append(y[i])\n",
    "        avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "        stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252703df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_algo_median(\n",
    "    y, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    #-----\n",
    "    if len(y) < lag:\n",
    "        return dict(signals = np.asarray(np.zeros(len(y))),\n",
    "                    avgFilter = np.asarray(np.median(y)),\n",
    "                    stdFilter = np.asarray(np.std(y)))\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.median(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    non_signal_Y = []\n",
    "    for i in range(lag, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            non_signal_Y.append(y[i])    \n",
    "        else:\n",
    "            if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter[i-1]:\n",
    "                if y[i] > avgFilter[i-1]:\n",
    "                    signals[i] = 1\n",
    "                else:\n",
    "                    signals[i] = -1\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * np.median(non_signal_Y)\n",
    "            else:\n",
    "                signals[i] = 0\n",
    "                filteredY[i] = y[i]\n",
    "                non_signal_Y.append(y[i])\n",
    "        avgFilter[i] = np.median(filteredY[(i-lag+1):i+1])\n",
    "        stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b007bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad(y):\n",
    "    return np.mean(np.abs(y - np.mean(y)))\n",
    "\n",
    "def thresholding_algo_mad(\n",
    "    y, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    #-----\n",
    "    if len(y) < lag:\n",
    "        return dict(signals = np.asarray(np.zeros(len(y))),\n",
    "                    avgFilter = np.asarray(np.mean(y)),\n",
    "                    stdFilter = np.asarray(mad(y)))\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = mad(y[0:lag])\n",
    "    non_signal_Y = []\n",
    "    for i in range(lag, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            non_signal_Y.append(y[i])    \n",
    "        else:\n",
    "            if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter[i-1]:\n",
    "                if y[i] > avgFilter[i-1]:\n",
    "                    signals[i] = 1\n",
    "                else:\n",
    "                    signals[i] = -1\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * np.mean(non_signal_Y)\n",
    "            else:\n",
    "                signals[i] = 0\n",
    "                filteredY[i] = y[i]\n",
    "                non_signal_Y.append(y[i])\n",
    "        avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "        stdFilter[i] = mad(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))\n",
    "\n",
    "\n",
    "def thresholding_algo_median_mad(\n",
    "    y, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    #-----\n",
    "    if len(y) < lag:\n",
    "        return dict(signals = np.asarray(np.zeros(len(y))),\n",
    "                    avgFilter = np.asarray(np.median(y)),\n",
    "                    stdFilter = np.asarray(mad(y)))\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.median(y[0:lag])\n",
    "    stdFilter[lag - 1] = mad(y[0:lag])\n",
    "    non_signal_Y = []\n",
    "    for i in range(lag, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            non_signal_Y.append(y[i])    \n",
    "        else:\n",
    "            if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter[i-1]:\n",
    "                if y[i] > avgFilter[i-1]:\n",
    "                    signals[i] = 1\n",
    "                else:\n",
    "                    signals[i] = -1\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * np.median(non_signal_Y)\n",
    "            else:\n",
    "                signals[i] = 0\n",
    "                filteredY[i] = y[i]\n",
    "                non_signal_Y.append(y[i])\n",
    "        avgFilter[i] = np.median(filteredY[(i-lag+1):i+1])\n",
    "        stdFilter[i] = mad(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab475f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b01a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbe359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_signal_groups_in_df_i(\n",
    "    df_i, \n",
    "    SN_col='serialnumber',\n",
    "    signal_col='signals', \n",
    "    return_signal_group_col='signal_grp'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)    \n",
    "    #-------------------------    \n",
    "    drop_idx = False\n",
    "    if df_i.index.name in df_i.columns:\n",
    "        drop_idx = True\n",
    "    signals_df_i = df_i.reset_index(drop=drop_idx)[df_i.reset_index(drop=drop_idx)[signal_col]==1]\n",
    "    #-----\n",
    "    tmp_signal_grp_col = Utilities.generate_random_string()\n",
    "    signals_df_i[tmp_signal_grp_col] = np.nan\n",
    "    #-----\n",
    "    tmp_idx_col = Utilities.generate_random_string()\n",
    "    signals_df_i[tmp_idx_col] = signals_df_i.index\n",
    "    #-----\n",
    "    signals_df_i[tmp_signal_grp_col] = signals_df_i[tmp_idx_col].diff().ne(1).cumsum()\n",
    "    #-------------------------\n",
    "    return_df = df_i.copy()\n",
    "    return_df[return_signal_group_col] = np.nan\n",
    "    return_df.iloc[signals_df_i.index,-1] = signals_df_i[tmp_signal_grp_col]\n",
    "    #-------------------------\n",
    "    return return_df\n",
    "\n",
    "def find_signals_and_set_signal_groups_in_df_i(\n",
    "    df_i, \n",
    "    lag, \n",
    "    threshold,\n",
    "    influence, \n",
    "    signal_abs_threshold, \n",
    "    value_col='mean_TRS value', \n",
    "    SN_col='serialnumber',\n",
    "    signal_col='signals', \n",
    "    return_signal_group_col='signal_grp'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    rtpd_i = thresholding_algo(\n",
    "        y=df_i[value_col].tolist(), \n",
    "        lag=lag,\n",
    "        threshold=threshold, \n",
    "        influence=influence, \n",
    "        signal_abs_threshold=signal_abs_threshold\n",
    "    )\n",
    "    df_i[signal_col] = rtpd_i['signals']    \n",
    "    #-------------------------\n",
    "    return_df = set_signal_groups_in_df_i(\n",
    "        df_i=df_i, \n",
    "        SN_col=SN_col,\n",
    "        signal_col=signal_col, \n",
    "        return_signal_group_col=return_signal_group_col\n",
    "    )\n",
    "    #-------------------------\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daab4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_signals_and_build_df_i_signals_gpd(\n",
    "    df_i, \n",
    "    lag, \n",
    "    threshold,\n",
    "    influence, \n",
    "    signal_abs_threshold, \n",
    "    value_col='mean_TRS value', \n",
    "    SN_col='serialnumber', \n",
    "    time_col='starttimeperiod_local', \n",
    "    signal_col='signals'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    assert(df_i.index.name == time_col)\n",
    "    df_i = df_i.sort_index()\n",
    "    #-------------------------\n",
    "    signal_group_col='signal_grp'\n",
    "    df_i = find_signals_and_set_signal_groups_in_df_i(\n",
    "        df_i=df_i, \n",
    "        lag=lag, \n",
    "        threshold=threshold,\n",
    "        influence=influence, \n",
    "        signal_abs_threshold=signal_abs_threshold, \n",
    "        value_col=value_col, \n",
    "        SN_col=SN_col,\n",
    "        signal_col=signal_col, \n",
    "        return_signal_group_col=signal_group_col\n",
    "    )\n",
    "    #-------------------------\n",
    "    df_i_signals = df_i[df_i[signal_group_col].notna()]\n",
    "    df_i_signals = df_i_signals.drop(columns=[signal_col])\n",
    "    df_i_signals[signal_group_col] = df_i_signals[signal_group_col].astype(int)\n",
    "    df_i_signals = df_i_signals.reset_index()\n",
    "    assert(time_col in df_i_signals.columns.tolist())\n",
    "    #-------------------------\n",
    "    # I think I like the mean of the max, time width of the peak, and the spacing of the peaks\n",
    "    # For the width of the peak, there needs to be a more sophisticated approach.\n",
    "    #   e.g., if the peak is one data point, the width is 0\n",
    "    #   For now, however, I will simply take max-min\n",
    "\n",
    "    df_i_signals_gpd = df_i_signals.groupby([signal_group_col]).agg({\n",
    "        time_col:['mean', 'std', 'min', 'max'], \n",
    "        value_col:['mean', 'std', 'max']\n",
    "    })\n",
    "    df_i_signals_gpd=df_i_signals_gpd.sort_values(by=[(time_col, 'mean')])\n",
    "    df_i_signals_gpd[(time_col, 'max_m_min')] = df_i_signals_gpd[(time_col, 'max')] - df_i_signals_gpd[(time_col, 'min')]\n",
    "    #-------------------------\n",
    "    return df_i_signals_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3354c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d9f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_SN(\n",
    "    df_i, \n",
    "    lag, \n",
    "    threshold,\n",
    "    influence, \n",
    "    signal_abs_threshold, \n",
    "    value_col='mean_TRS value', \n",
    "    SN_col='serialnumber', \n",
    "    time_col='starttimeperiod_local', \n",
    "    signal_col='signals'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    # I think I like the mean of the max, time width of the peak, and the spacing of the peaks\n",
    "    # For the width of the peak, there needs to be a more sophisticated approach.\n",
    "    #   e.g., if the peak is one data point, the width is 0\n",
    "    #   For now, however, I will simply take max-min\n",
    "    \n",
    "    df_i_signals_gpd = find_signals_and_build_df_i_signals_gpd(\n",
    "        df_i=df_i, \n",
    "        lag=lag, \n",
    "        threshold=threshold,\n",
    "        influence=influence, \n",
    "        signal_abs_threshold=signal_abs_threshold, \n",
    "        value_col=value_col, \n",
    "        SN_col=SN_col, \n",
    "        time_col=time_col, \n",
    "        signal_col=signal_col\n",
    "    )\n",
    "    #-------------------------\n",
    "    peak_max_mean     = df_i_signals_gpd[(value_col, 'max')].mean()\n",
    "    peak_width_mean   = df_i_signals_gpd[(time_col, 'max_m_min')].mean()\n",
    "    peak_spacing_mean = df_i_signals_gpd[(time_col, 'mean')].diff().mean()\n",
    "    # Below, the date being used is of no matter, any random date works, it's simply\n",
    "    #   to make pd.to_datetime happy\n",
    "    if df_i_signals_gpd.shape[0]>0:\n",
    "        peak_hour_mean    = pd.to_datetime(\n",
    "            '2023-01-01 ' + df_i_signals_gpd[(time_col, 'mean')].dt.strftime('%H:%M:%S'), \n",
    "            format=\"%Y-%m-%d %H:%M:%S\"\n",
    "        ).mean().round('H').time().hour\n",
    "    else:\n",
    "        peak_hour_mean = np.nan\n",
    "    #-------------------------\n",
    "    features_srs = pd.Series({\n",
    "        'peak_max_mean':     peak_max_mean, \n",
    "        'peak_width_mean':   peak_width_mean, \n",
    "        'peak_spacing_mean': peak_spacing_mean, \n",
    "        'peak_hour_mean':    peak_hour_mean, \n",
    "    })\n",
    "    features_srs.name = df_i[SN_col].unique()[0]\n",
    "    return features_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887484d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_SN_v2(\n",
    "    df_i, \n",
    "    lag, \n",
    "    threshold,\n",
    "    influence, \n",
    "    signal_abs_threshold, \n",
    "    value_col='mean_TRS value', \n",
    "    SN_col='serialnumber', \n",
    "    time_col='starttimeperiod_local', \n",
    "    signal_col='signals'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    assert(df_i.index.name == time_col)\n",
    "    df_i = df_i.sort_index()\n",
    "    #-------------------------\n",
    "    signal_group_col='signal_grp'\n",
    "    df_i = find_signals_and_set_signal_groups_in_df_i(\n",
    "        df_i=df_i, \n",
    "        lag=lag, \n",
    "        threshold=threshold,\n",
    "        influence=influence, \n",
    "        signal_abs_threshold=signal_abs_threshold, \n",
    "        value_col=value_col, \n",
    "        SN_col=SN_col,\n",
    "        signal_col=signal_col, \n",
    "        return_signal_group_col=signal_group_col\n",
    "    )\n",
    "    #-------------------------\n",
    "    df_i_signals = df_i[df_i[signal_group_col].notna()]\n",
    "    df_i_signals = df_i_signals.drop(columns=[signal_col])\n",
    "    df_i_signals[signal_group_col] = df_i_signals[signal_group_col].astype(int)\n",
    "    #-----   \n",
    "    drop_idx = False\n",
    "    if df_i_signals.index.name in df_i_signals.columns:\n",
    "        drop_idx = True\n",
    "    df_i_signals = df_i_signals.reset_index(drop=drop_idx)\n",
    "    assert(time_col in df_i_signals.columns.tolist())\n",
    "    #-------------------------\n",
    "    # Features split into:\n",
    "    #   1. Using all data in peaks pooled together\n",
    "    #   2. First grouping by signal group, then extracting features\n",
    "    #-------------------------\n",
    "    # Features (1):\n",
    "    peak_mean = df_i_signals[value_col].mean()\n",
    "    peak_std  = df_i_signals[value_col].std()\n",
    "    #-------------------------\n",
    "    # Features (2):\n",
    "    #-----\n",
    "    # I think I like the mean of the max, time width of the peak, and the spacing of the peaks\n",
    "    # For the width of the peak, there needs to be a more sophisticated approach.\n",
    "    #   e.g., if the peak is one data point, the width is 0\n",
    "    #   For now, however, I will simply take max-min\n",
    "\n",
    "    df_i_signals_gpd = df_i_signals.groupby([signal_group_col]).agg({\n",
    "        time_col:['mean', 'std', 'min', 'max'], \n",
    "        value_col:['mean', 'std', 'max']\n",
    "    })\n",
    "    df_i_signals_gpd=df_i_signals_gpd.sort_values(by=[(time_col, 'mean')])\n",
    "    df_i_signals_gpd[(time_col, 'max_m_min')] = df_i_signals_gpd[(time_col, 'max')] - df_i_signals_gpd[(time_col, 'min')]\n",
    "    #-------------------------\n",
    "    #-------------------------\n",
    "    peak_max_mean     = df_i_signals_gpd[(value_col, 'max')].mean()\n",
    "    peak_max_std      = df_i_signals_gpd[(value_col, 'max')].std()\n",
    "    #-----\n",
    "    peak_width_mean   = df_i_signals_gpd[(time_col, 'max_m_min')].mean()\n",
    "    peak_width_std    = df_i_signals_gpd[(time_col, 'max_m_min')].std()\n",
    "    #-----\n",
    "    peak_spacing_mean = df_i_signals_gpd[(time_col, 'mean')].diff().mean()\n",
    "    peak_spacing_std  = df_i_signals_gpd[(time_col, 'mean')].diff().std()\n",
    "    #-----\n",
    "    # Below, the date being used is of no matter, any random date works, it's simply\n",
    "    #   to make pd.to_datetime happy\n",
    "    if df_i_signals_gpd.shape[0]>0:\n",
    "        peak_hour_mean    = pd.to_datetime(\n",
    "            '2023-01-01 ' + df_i_signals_gpd[(time_col, 'mean')].dt.strftime('%H:%M:%S'), \n",
    "            format=\"%Y-%m-%d %H:%M:%S\"\n",
    "        ).mean().round('H').time().hour\n",
    "    else:\n",
    "        peak_hour_mean = np.nan\n",
    "    #-------------------------\n",
    "    features_srs = pd.Series({\n",
    "        'peak_mean':         peak_mean, \n",
    "        'peak_std':          peak_std, \n",
    "        #-----\n",
    "        'peak_max_mean':     peak_max_mean, \n",
    "        'peak_max_std':      peak_max_std, \n",
    "        #-----\n",
    "        'peak_width_mean':   peak_width_mean, \n",
    "        'peak_width_std':    peak_width_std, \n",
    "        #-----\n",
    "        'peak_spacing_mean': peak_spacing_mean,\n",
    "        'peak_spacing_std':  peak_spacing_std,\n",
    "        #-----\n",
    "        'peak_hour_mean':    peak_hour_mean, \n",
    "    })\n",
    "    features_srs.name = df_i[SN_col].unique()[0]\n",
    "    return features_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19eea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_in_peak_df(\n",
    "    peak_df\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    if 'peak_mean' in peak_df.columns:\n",
    "        peak_df['peak_mean']         = peak_df['peak_mean'].fillna(0)\n",
    "    #-----\n",
    "    if 'peak_std' in peak_df.columns:\n",
    "        peak_df['peak_std']          = peak_df['peak_std'].fillna(-1)\n",
    "    #-------------------------\n",
    "    if 'peak_max_mean' in peak_df.columns:\n",
    "        peak_df['peak_max_mean']     = peak_df['peak_max_mean'].fillna(0)\n",
    "    #-----\n",
    "    if 'peak_max_std' in peak_df.columns:\n",
    "        peak_df['peak_max_std']      = peak_df['peak_max_std'].fillna(-1)\n",
    "    #-------------------------    \n",
    "    if 'peak_width_mean' in peak_df.columns:\n",
    "        peak_df['peak_width_mean']   = peak_df['peak_width_mean'].fillna(pd.Timedelta(0))\n",
    "#         peak_df['peak_width_mean']   = peak_df['peak_width_mean'].fillna(pd.Timedelta.max)\n",
    "    #-----\n",
    "    if 'peak_width_std' in peak_df.columns:\n",
    "        peak_df['peak_width_std']    = peak_df['peak_width_std'].fillna(pd.Timedelta(-1))\n",
    "#         peak_df['peak_width_std']    = peak_df['peak_width_std'].fillna(pd.Timedelta(0))\n",
    "#         peak_df['peak_width_std']    = peak_df['peak_width_std'].fillna(pd.Timedelta(pd.Timedelta.max))\n",
    "    #-------------------------\n",
    "    if 'peak_spacing_mean' in peak_df.columns:\n",
    "        peak_df['peak_spacing_mean'] = peak_df['peak_spacing_mean'].fillna(pd.Timedelta(0))\n",
    "#         peak_df['peak_spacing_mean'] = peak_df['peak_spacing_mean'].fillna(pd.Timedelta.max)\n",
    "    #-----\n",
    "    if 'peak_spacing_std' in peak_df.columns:\n",
    "        peak_df['peak_spacing_std']  = peak_df['peak_spacing_std'].fillna(pd.Timedelta(-1))\n",
    "#         peak_df['peak_spacing_std']  = peak_df['peak_spacing_std'].fillna(pd.Timedelta(0))\n",
    "#         peak_df['peak_spacing_std']  = peak_df['peak_spacing_std'].fillna(pd.Timedelta(pd.Timedelta.max))\n",
    "    #-------------------------\n",
    "    if 'peak_hour_mean' in peak_df.columns:\n",
    "        peak_df['peak_hour_mean']    = peak_df['peak_hour_mean'].fillna(-1)\n",
    "    #-------------------------\n",
    "    return peak_df\n",
    "\n",
    "\n",
    "def convert_to_seconds_in_peak_df(\n",
    "    peak_df\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    cols_to_convert = ['peak_width_mean', 'peak_width_std', 'peak_spacing_mean', 'peak_spacing_std']\n",
    "    for col in cols_to_convert:\n",
    "        if col in peak_df.columns:\n",
    "            peak_df[col]   = peak_df[col].dt.total_seconds()/60\n",
    "    #-------------------------\n",
    "    return peak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d9786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5e36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c764e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_funky(df_i, n_entries=500, val_col='value', SN_col='serialnumber'):\n",
    "    if df_i.shape[0] < n_entries:\n",
    "        return None\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    vals_i = df_i[val_col].sort_index().iloc[:n_entries].tolist()\n",
    "    return_i = pd.Series(vals_i)\n",
    "    return_i.name = df_i[SN_col].unique()[0]\n",
    "    return return_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce5f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_peaks_OLD(\n",
    "    df, \n",
    "    value_col, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    r\"\"\"\n",
    "    Do not use too small a value for lag!!!!!\n",
    "        This can cause the std values to become very small, causing much to be identified as peaks.\n",
    "        It's not a huge deal when signal_abs_threshold!=0, because this usually gives the algorithm enough\n",
    "          data to work out the rolling mean and std reliably.\n",
    "    \"\"\"\n",
    "    #-----\n",
    "    y = df[value_col].tolist()\n",
    "    #-----\n",
    "    if len(y) <= lag:\n",
    "        return np.asarray(y)\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    \n",
    "\n",
    "    # To avoid possibility of data starting with peak, which can mess up methods (especially if\n",
    "    #   lag is small), start with first value (after lag) less than the mean\n",
    "    # NOTE: The mean here includes all data, so includes peaks as well, so should be larger than the\n",
    "    #         smoothed mean\n",
    "    i_beg = np.argmax((y[lag:] < np.mean(y))) + lag\n",
    "    \n",
    "    non_signal_Y = []\n",
    "    for i in range(i_beg, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = y[i]\n",
    "            filteredY[i] = y[i]\n",
    "        else:\n",
    "            # Only looking for peaks, so don't use abs(y-avg)\n",
    "            if y[i] - avgFilter[i-1] > threshold * stdFilter[i-1]:\n",
    "                #-------------------------\n",
    "                # First, set the signal equal to the rolling average\n",
    "                #-----\n",
    "                # If avgFilter[i-1]==0, try np.mean(avgFilter)\n",
    "                # If both==0, use raw value, y[i]\n",
    "                if avgFilter[i-1]>0:\n",
    "                    signals[i] = avgFilter[i-1]\n",
    "                else:\n",
    "                    if np.mean(avgFilter)>0:\n",
    "                        signals[i] = np.mean(avgFilter)\n",
    "                    else:\n",
    "                        print('Cannot use any averages!')\n",
    "                        signals[i] = y[i]\n",
    "                #-------------------------\n",
    "                # Next, set filteredY\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    tmp_idx = np.random.randint(i-lag, i, 1)[0]\n",
    "                    tmp_mean = filteredY[tmp_idx]\n",
    "                    tmp_std = stdFilter[tmp_idx]\n",
    "                    tmp_val  = np.random.normal(tmp_mean, tmp_std, 1)\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * tmp_val\n",
    "            else:\n",
    "                signals[i] = y[i]\n",
    "                filteredY[i] = y[i]\n",
    "        #-----\n",
    "        # Note: As opposed to other thresholding functions, since any peaks have been reduced to average\n",
    "        #       values, all filteredY are also non_signal_Y (so can be appended here, instead of separately\n",
    "        #       in if/else statements as in other thresholding functions)\n",
    "        non_signal_Y.append(filteredY[i])\n",
    "        #-----\n",
    "        avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "        stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "        \n",
    "    #-------------------------\n",
    "    # Now, go back and perform calculation for initial lag entries using the non_signal_Y\n",
    "    #   for average values\n",
    "    for i in range(0,i_beg):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = y[i]\n",
    "        else:\n",
    "            if y[i] - np.mean(non_signal_Y) > threshold * np.std(non_signal_Y):\n",
    "                # Instead of using the mean of non_signal_Y, randomly draw a mean from avgFilter\n",
    "                signals[i] = np.random.choice(a=avgFilter, size=1)\n",
    "            else:\n",
    "                signals[i] = y[i]\n",
    "\n",
    "    return np.asarray(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8097495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_peaks(\n",
    "    df, \n",
    "    value_col, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold=1.0\n",
    "):\n",
    "    r\"\"\"\n",
    "    Do not use too small a value for lag!!!!!\n",
    "        This can cause the std values to become very small, causing much to be identified as peaks.\n",
    "        It's not a huge deal when signal_abs_threshold!=0, because this usually gives the algorithm enough\n",
    "          data to work out the rolling mean and std reliably.\n",
    "          \n",
    "    NOTE: While dealing with the first lag entries after i_beg, we are still susceptible to peaks contaminating\n",
    "            the data (causing higher means and, more importantly, higher standard deviations)\n",
    "          THEREFORE, if we are within this regime, instead of using mean and standard devation, I will instead\n",
    "            use the median and interquartile range (which are much more robust against outliers)\n",
    "    \"\"\"\n",
    "    #-----\n",
    "    y = df[value_col].tolist()\n",
    "    #-----\n",
    "    if len(y) <= lag:\n",
    "        return np.asarray(y)\n",
    "    #-----\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    \n",
    "\n",
    "    # To avoid possibility of data starting with peak, which can mess up methods (especially if\n",
    "    #   lag is small), start with first value (after lag) less than the mean\n",
    "    # NOTE: The mean here includes all data, so includes peaks as well, so should be larger than the\n",
    "    #         smoothed mean\n",
    "    i_beg = np.argmax((y[lag:] < np.mean(y))) + lag\n",
    "    avgFilter[i_beg - 1] = np.median(y[i_beg-lag:i_beg])\n",
    "    stdFilter[i_beg - 1] = scipy.stats.iqr(y[i_beg-lag:i_beg])\n",
    "    \n",
    "    non_signal_Y = []\n",
    "    for i in range(i_beg, len(y)):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = y[i]\n",
    "            filteredY[i] = y[i]\n",
    "        else:\n",
    "            # Only looking for peaks, so don't use abs(y-avg)\n",
    "            if y[i] - avgFilter[i-1] > threshold * stdFilter[i-1]:\n",
    "                #-------------------------\n",
    "                # First, set the signal equal to the rolling average\n",
    "                #-----\n",
    "                # If avgFilter[i-1]==0, try np.mean(avgFilter)\n",
    "                # If both==0, use raw value, y[i]\n",
    "                if avgFilter[i-1]>0:\n",
    "                    signals[i] = avgFilter[i-1]\n",
    "                else:\n",
    "                    if np.mean(avgFilter)>0:\n",
    "                        signals[i] = np.mean(avgFilter)\n",
    "                    else:\n",
    "                        print('Cannot use any averages!')\n",
    "                        signals[i] = y[i]\n",
    "                #-------------------------\n",
    "                # Next, set filteredY\n",
    "                if len(non_signal_Y)==0:\n",
    "                    filteredY[i] = influence * y[i]\n",
    "                else:\n",
    "                    tmp_idx = np.random.randint(i-lag, i, 1)[0]\n",
    "                    tmp_mean = filteredY[tmp_idx]\n",
    "                    tmp_std = stdFilter[tmp_idx]\n",
    "                    tmp_val  = np.random.normal(tmp_mean, tmp_std, 1)\n",
    "                    filteredY[i] = influence * y[i] + (1 - influence) * tmp_val\n",
    "            else:\n",
    "                signals[i] = y[i]\n",
    "                filteredY[i] = y[i]\n",
    "        #-----\n",
    "        # Note: As opposed to other thresholding functions, since any peaks have been reduced to average\n",
    "        #       values, all filteredY are also non_signal_Y (so can be appended here, instead of separately\n",
    "        #       in if/else statements as in other thresholding functions)\n",
    "        non_signal_Y.append(filteredY[i])\n",
    "        #-----\n",
    "        if i-i_beg > lag:\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "        else:\n",
    "            avgFilter[i] = np.median(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = scipy.stats.iqr(filteredY[(i-lag+1):i+1])            \n",
    "        \n",
    "    #-------------------------\n",
    "    # Now, go back and perform calculation for initial lag entries using the non_signal_Y\n",
    "    #   for average values\n",
    "    for i in range(0,i_beg):\n",
    "        if y[i] < signal_abs_threshold:\n",
    "            signals[i] = y[i]\n",
    "        else:\n",
    "            if y[i] - np.mean(non_signal_Y) > threshold * np.std(non_signal_Y):\n",
    "                # Instead of using the mean of non_signal_Y, randomly draw a mean from avgFilter\n",
    "                signals[i] = np.random.choice(a=avgFilter, size=1)\n",
    "            else:\n",
    "                signals[i] = y[i]\n",
    "\n",
    "    return np.asarray(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de0d1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_algo_df_i(\n",
    "    df_i, \n",
    "    value_col, \n",
    "    lag, \n",
    "    threshold, \n",
    "    influence, \n",
    "    signal_abs_threshold, \n",
    "    smooth_rolling_window, \n",
    "    SN_col='serialnumber', \n",
    "    PN_col='aep_premise_nb', \n",
    "    time_col='starttimeperiod_local', \n",
    "    signal_col_out='signal', \n",
    "    signal_pos_col_out='signal_pos', \n",
    "    signal_binary_col_out='signal_binary', \n",
    "    signal_pos_binary_col_out='signal_pos_binary',  \n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    if df_i.index.name != time_col:\n",
    "        assert(time_col in df_i.columns)\n",
    "        df_i = df_i.set_index(time_col, drop=True)\n",
    "    assert(df_i.index.name == time_col)\n",
    "    df_i = df_i.sort_index()\n",
    "    #-------------------------\n",
    "    # First, smooth out the peaks so the un-biased rolling mean and std can be formed\n",
    "    smooth = smooth_peaks(\n",
    "        df=df_i, \n",
    "        value_col=value_col, \n",
    "        lag=lag, \n",
    "        threshold=threshold, \n",
    "        influence=influence, \n",
    "        signal_abs_threshold=signal_abs_threshold\n",
    "    )\n",
    "    smooth_col = f'{value_col}_smooth'\n",
    "    df_i[smooth_col] = smooth\n",
    "    #-------------------------\n",
    "    # Generate smooth rolling mean and std\n",
    "    smooth_roll_mean_col = f'{value_col}_smooth_roll_mean'\n",
    "    smooth_roll_std_col  = f'{value_col}_smooth_roll_std'\n",
    "    df_i[smooth_roll_mean_col] = df_i[smooth_col].rolling(smooth_rolling_window, center=True).mean()\n",
    "    df_i[smooth_roll_std_col]  = df_i[smooth_col].rolling(smooth_rolling_window, center=True).std()\n",
    "    #-----\n",
    "    # Drop the NaN values at front and back of df_i naturally resulting from rolling window methods\n",
    "    df_i = df_i.dropna(subset=[smooth_roll_mean_col, smooth_roll_std_col]).copy()\n",
    "    #-------------------------\n",
    "    # Generate the signal column, which is defined for each point as the number of (rolling) std deviations \n",
    "    #   away from the (rolling) mean.\n",
    "    # Also generate the binary version of the signal, which is simply whether or not the number of std away from\n",
    "    #   the mean is outside of the threshold.\n",
    "    # Finally, build the positive versions of the above two, which set any values less than the mean equal to 0 (since\n",
    "    #   we are looking for positive peaks)\n",
    "    #-----\n",
    "    df_i[signal_col_out] = (df_i[value_col] - df_i[smooth_roll_mean_col])/df_i[smooth_roll_std_col]\n",
    "\n",
    "    # Probably really only want points which are above the rolling mean, since we're looking for peaks\n",
    "    # For now, keep both signal and signal_pos\n",
    "    df_i[signal_pos_col_out] = df_i[signal_col_out]\n",
    "    df_i.loc[df_i[signal_pos_col_out]<0, signal_pos_col_out] = 0\n",
    "\n",
    "    # Binary results are yes/no of whether peak is found\n",
    "    df_i[signal_binary_col_out]     = np.abs(df_i[signal_col_out]) > threshold\n",
    "    df_i[signal_pos_binary_col_out] = np.abs(df_i[signal_pos_col_out]) > threshold\n",
    "    \n",
    "    #-------------------------\n",
    "    # Generate a couple test series for possible use\n",
    "    df_i['test_final'] = df_i[value_col]\n",
    "    df_i.loc[df_i[signal_binary_col_out]==0, 'test_final'] = df_i.loc[df_i[signal_binary_col_out]==0, smooth_roll_mean_col]\n",
    "    #-----\n",
    "    df_i['test_final2'] = df_i[value_col]\n",
    "    df_i.loc[df_i[signal_binary_col_out]==0, 'test_final2'] = 0\n",
    "    #-----\n",
    "    df_i['test_final_signal'] = df_i[signal_col_out]\n",
    "    df_i.loc[df_i[signal_binary_col_out]==0, 'test_final_signal'] = 0\n",
    "    \n",
    "    #-------------------------\n",
    "    # To save space, don't keep all of columns in df_i, only really keep those build here (plus SN, PN, value)\n",
    "    cols_to_keep = [\n",
    "        SN_col, \n",
    "        PN_col, \n",
    "        value_col, \n",
    "        smooth_col, \n",
    "        smooth_roll_mean_col, \n",
    "        smooth_roll_std_col, \n",
    "        signal_col_out, \n",
    "        signal_pos_col_out, \n",
    "        signal_binary_col_out, \n",
    "        signal_pos_binary_col_out, \n",
    "        'test_final', \n",
    "        'test_final2', \n",
    "        'test_final_signal'\n",
    "    ]\n",
    "    return df_i[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96435abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "512120cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_peak_features_for_df_i(\n",
    "    df_i, \n",
    "    signal_group_col='signal_grp', \n",
    "    value_col='value', \n",
    "    SN_col='serialnumber', \n",
    "    time_col='starttimeperiod_local', \n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    assert(df_i[SN_col].nunique()==1)\n",
    "    #-------------------------\n",
    "    if time_col not in df_i.columns:\n",
    "        assert(time_col==df_i.index.name)\n",
    "        df_i[time_col] = df_i.index\n",
    "    assert(time_col in df_i.columns)\n",
    "    #-------------------------\n",
    "    df_i_signals = df_i[df_i[signal_group_col].notna()].copy()\n",
    "    df_i_signals[signal_group_col] = df_i_signals[signal_group_col].astype(int)\n",
    "    df_i_signals = df_i_signals.reset_index(drop=True)\n",
    "    #-------------------------\n",
    "    # Features split into:\n",
    "    #   1. Using all data in peaks pooled together\n",
    "    #   2. First grouping by signal group, then extracting features\n",
    "    #-------------------------\n",
    "    # Features (1):\n",
    "    peak_mean = df_i_signals[value_col].mean()\n",
    "    peak_std  = df_i_signals[value_col].std()\n",
    "    #-------------------------\n",
    "    # Features (2):\n",
    "    #-----\n",
    "    # I think I like the mean of the max, time width of the peak, and the spacing of the peaks\n",
    "    # For the width of the peak, there needs to be a more sophisticated approach.\n",
    "    #   e.g., if the peak is one data point, the width is 0\n",
    "    #   For now, however, I will simply take max-min\n",
    "\n",
    "    df_i_signals_gpd = df_i_signals.groupby([signal_group_col]).agg({\n",
    "        time_col:['mean', 'std', 'min', 'max'], \n",
    "        value_col:['mean', 'std', 'max']\n",
    "    })\n",
    "    df_i_signals_gpd=df_i_signals_gpd.sort_values(by=[(time_col, 'mean')])\n",
    "    df_i_signals_gpd[(time_col, 'max_m_min')] = df_i_signals_gpd[(time_col, 'max')] - df_i_signals_gpd[(time_col, 'min')]\n",
    "    #-------------------------\n",
    "    #-------------------------\n",
    "    peak_max_mean     = df_i_signals_gpd[(value_col, 'max')].mean()\n",
    "    peak_max_std      = df_i_signals_gpd[(value_col, 'max')].std()\n",
    "    #-----\n",
    "    peak_width_mean   = df_i_signals_gpd[(time_col, 'max_m_min')].mean()\n",
    "    peak_width_std    = df_i_signals_gpd[(time_col, 'max_m_min')].std()\n",
    "    #-----\n",
    "    peak_spacing_mean = df_i_signals_gpd[(time_col, 'mean')].diff().mean()\n",
    "    peak_spacing_std  = df_i_signals_gpd[(time_col, 'mean')].diff().std()\n",
    "    #-----\n",
    "    # Below, the date being used is of no matter, any random date works, it's simply\n",
    "    #   to make pd.to_datetime happy\n",
    "    if df_i_signals_gpd.shape[0]>0:\n",
    "        peak_hour_mean    = pd.to_datetime(\n",
    "            '2023-01-01 ' + df_i_signals_gpd[(time_col, 'mean')].dt.strftime('%H:%M:%S'), \n",
    "            format=\"%Y-%m-%d %H:%M:%S\"\n",
    "        ).mean().round('H').time().hour\n",
    "    else:\n",
    "        peak_hour_mean = np.nan\n",
    "    #-------------------------\n",
    "    features_srs = pd.Series({\n",
    "        'peak_mean':         peak_mean, \n",
    "        'peak_std':          peak_std, \n",
    "        #-----\n",
    "        'peak_max_mean':     peak_max_mean, \n",
    "        'peak_max_std':      peak_max_std, \n",
    "        #-----\n",
    "        'peak_width_mean':   peak_width_mean, \n",
    "        'peak_width_std':    peak_width_std, \n",
    "        #-----\n",
    "        'peak_spacing_mean': peak_spacing_mean,\n",
    "        'peak_spacing_std':  peak_spacing_std,\n",
    "        #-----\n",
    "        'peak_hour_mean':    peak_hour_mean, \n",
    "    })\n",
    "    features_srs.name = df_i[SN_col].unique()[0]\n",
    "    return features_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4b892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59680060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "275c07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ami_df = False\n",
    "files_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Data'\n",
    "pkl_save_dir =  r'C:\\Users\\s346557\\Documents\\LocalData\\EVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "472da5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_ami_df:\n",
    "    ami_df = GenAn.read_df_from_csv_dir_batches(\n",
    "        files_dir=files_dir, \n",
    "        file_path_glob=r'*.csv'\n",
    "    )\n",
    "    #-------------------------\n",
    "    ami_df = ami_df[\n",
    "        (ami_df['aep_derived_uom']=='KWH') & \n",
    "        (ami_df['aep_srvc_qlty_idntfr']=='TOTAL')\n",
    "    ].copy()\n",
    "    #-----\n",
    "    ami_df['timezoneoffset'] = ami_df['starttimeperiod'].str[-6:]\n",
    "    #-------------------------\n",
    "    ami_df = AMINonVee.perform_std_initiation_and_cleaning(\n",
    "        ami_df, \n",
    "        timestamp_col=None\n",
    "    )\n",
    "    #-----\n",
    "    ami_df = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df, \n",
    "        time_col='starttimeperiod', \n",
    "        placement_col='starttimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    ami_df = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df, \n",
    "        time_col='endtimeperiod', \n",
    "        placement_col='endtimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    ami_df=ami_df.set_index('starttimeperiod_local', drop=False)\n",
    "    #-------------------------\n",
    "    ami_df.to_pickle(os.path.join(pkl_save_dir, 'ami_df.pkl'))\n",
    "else:\n",
    "    ami_df = pd.read_pickle(os.path.join(pkl_save_dir, 'ami_df.pkl'))\n",
    "#-------------------------\n",
    "all_trff_dfs = pd.read_pickle(os.path.join(pkl_save_dir, 'all_trff_dfs.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc95004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ami_df['aep_premise_nb'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ebed084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trff_dfs['PREM_NB'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2920ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trff_dfs_found     = all_trff_dfs[all_trff_dfs['PREM_NB'].isin(ami_df['aep_premise_nb'].unique().tolist())]\n",
    "all_trff_dfs_not_found = all_trff_dfs[~all_trff_dfs['PREM_NB'].isin(ami_df['aep_premise_nb'].unique().tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a290b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712\n",
      "245\n",
      "1712\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "print(all_trff_dfs_found['PREM_NB'].nunique())\n",
    "print(all_trff_dfs_not_found['PREM_NB'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "427ddda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712\n",
      "1712\n",
      "2021\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "print(ami_df['aep_premise_nb'].nunique())\n",
    "print(ami_df['serialnumber'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a99efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_df = ami_df.groupby('aep_premise_nb', as_index=False, group_keys=False).apply(\n",
    "    lambda x: remove_ev_submeter_in_pair(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33b404b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n"
     ]
    }
   ],
   "source": [
    "print(ami_df['aep_premise_nb'].nunique())\n",
    "print(ami_df['serialnumber'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a186e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_df_resamples = AMINonVee.build_time_resampled_dfs(\n",
    "    ami_df, \n",
    "    base_freq='15T', \n",
    "    freqs=['H', '2H', '3H', '4H'], \n",
    "    other_grouper_cols=['serialnumber', 'aep_premise_nb']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d7450ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod_local</th>\n",
       "      <th>starttimeperiod_utc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttimeperiod_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-23 03:45:00</th>\n",
       "      <td>2022-05-23 03:45:00</td>\n",
       "      <td>2022-05-23 07:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 20:30:00</th>\n",
       "      <td>2022-05-23 20:30:00</td>\n",
       "      <td>2022-05-24 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 13:00:00</th>\n",
       "      <td>2022-05-23 13:00:00</td>\n",
       "      <td>2022-05-23 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 07:00:00</th>\n",
       "      <td>2022-05-23 07:00:00</td>\n",
       "      <td>2022-05-23 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 21:15:00</th>\n",
       "      <td>2022-05-23 21:15:00</td>\n",
       "      <td>2022-05-24 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 17:00:00</th>\n",
       "      <td>2023-01-22 17:00:00</td>\n",
       "      <td>2023-01-22 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27 01:30:00</th>\n",
       "      <td>2023-01-27 01:30:00</td>\n",
       "      <td>2023-01-27 07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 22:30:00</th>\n",
       "      <td>2023-01-22 22:30:00</td>\n",
       "      <td>2023-01-23 04:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-30 02:45:00</th>\n",
       "      <td>2023-01-30 02:45:00</td>\n",
       "      <td>2023-01-30 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 01:00:00</th>\n",
       "      <td>2023-01-22 01:00:00</td>\n",
       "      <td>2023-01-22 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9399755 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      starttimeperiod_local starttimeperiod_utc\n",
       "starttimeperiod_local                                          \n",
       "2022-05-23 03:45:00     2022-05-23 03:45:00 2022-05-23 07:45:00\n",
       "2022-05-23 20:30:00     2022-05-23 20:30:00 2022-05-24 00:30:00\n",
       "2022-05-23 13:00:00     2022-05-23 13:00:00 2022-05-23 17:00:00\n",
       "2022-05-23 07:00:00     2022-05-23 07:00:00 2022-05-23 11:00:00\n",
       "2022-05-23 21:15:00     2022-05-23 21:15:00 2022-05-24 01:15:00\n",
       "...                                     ...                 ...\n",
       "2023-01-22 17:00:00     2023-01-22 17:00:00 2023-01-22 23:00:00\n",
       "2023-01-27 01:30:00     2023-01-27 01:30:00 2023-01-27 07:30:00\n",
       "2023-01-22 22:30:00     2023-01-22 22:30:00 2023-01-23 04:30:00\n",
       "2023-01-30 02:45:00     2023-01-30 02:45:00 2023-01-30 08:45:00\n",
       "2023-01-22 01:00:00     2023-01-22 01:00:00 2023-01-22 07:00:00\n",
       "\n",
       "[9399755 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod_local</th>\n",
       "      <th>starttimeperiod_utc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttimeperiod_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-23 03:45:00</th>\n",
       "      <td>2022-05-23 03:45:00</td>\n",
       "      <td>2022-05-23 07:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 20:30:00</th>\n",
       "      <td>2022-05-23 20:30:00</td>\n",
       "      <td>2022-05-24 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 13:00:00</th>\n",
       "      <td>2022-05-23 13:00:00</td>\n",
       "      <td>2022-05-23 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 07:00:00</th>\n",
       "      <td>2022-05-23 07:00:00</td>\n",
       "      <td>2022-05-23 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23 21:15:00</th>\n",
       "      <td>2022-05-23 21:15:00</td>\n",
       "      <td>2022-05-24 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 17:00:00</th>\n",
       "      <td>2023-01-22 17:00:00</td>\n",
       "      <td>2023-01-22 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27 01:30:00</th>\n",
       "      <td>2023-01-27 01:30:00</td>\n",
       "      <td>2023-01-27 07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 22:30:00</th>\n",
       "      <td>2023-01-22 22:30:00</td>\n",
       "      <td>2023-01-23 04:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-30 02:45:00</th>\n",
       "      <td>2023-01-30 02:45:00</td>\n",
       "      <td>2023-01-30 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-22 01:00:00</th>\n",
       "      <td>2023-01-22 01:00:00</td>\n",
       "      <td>2023-01-22 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9399755 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      starttimeperiod_local starttimeperiod_utc\n",
       "starttimeperiod_local                                          \n",
       "2022-05-23 03:45:00     2022-05-23 03:45:00 2022-05-23 07:45:00\n",
       "2022-05-23 20:30:00     2022-05-23 20:30:00 2022-05-24 00:30:00\n",
       "2022-05-23 13:00:00     2022-05-23 13:00:00 2022-05-23 17:00:00\n",
       "2022-05-23 07:00:00     2022-05-23 07:00:00 2022-05-23 11:00:00\n",
       "2022-05-23 21:15:00     2022-05-23 21:15:00 2022-05-24 01:15:00\n",
       "...                                     ...                 ...\n",
       "2023-01-22 17:00:00     2023-01-22 17:00:00 2023-01-22 23:00:00\n",
       "2023-01-27 01:30:00     2023-01-27 01:30:00 2023-01-27 07:30:00\n",
       "2023-01-22 22:30:00     2023-01-22 22:30:00 2023-01-23 04:30:00\n",
       "2023-01-30 02:45:00     2023-01-30 02:45:00 2023-01-30 08:45:00\n",
       "2023-01-22 01:00:00     2023-01-22 01:00:00 2023-01-22 07:00:00\n",
       "\n",
       "[9399755 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ami_df[['starttimeperiod_local', 'starttimeperiod_utc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77292cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0c14ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs_prems = all_trff_dfs[all_trff_dfs['EV']==1]['PREM_NB'].unique().tolist()\n",
    "non_prems = all_trff_dfs[all_trff_dfs['EV']==0]['PREM_NB'].unique().tolist()\n",
    "\n",
    "# aep_premise_nb in ami_df is of type object (i.e., a string), whereas PREM_NB in trff_df is int64\n",
    "evs_prems = [str(x) for x in evs_prems]\n",
    "non_prems = [str(x) for x in non_prems]\n",
    "#-----\n",
    "ami_df_evs = ami_df[ami_df['aep_premise_nb'].isin(evs_prems)].copy()\n",
    "ami_df_non = ami_df[ami_df['aep_premise_nb'].isin(non_prems)].copy()\n",
    "#----\n",
    "assert(ami_df.shape[0]==ami_df_evs.shape[0]+ami_df_non.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dd03e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami_df_evs.shape[0] = 2808398\n",
      "ami_df_non.shape[0] = 6591357\n",
      "ami_df_evs.shape[0] = 2808398\n",
      "ami_df_non.shape[0] = 6591357\n"
     ]
    }
   ],
   "source": [
    "print(f'ami_df_evs.shape[0] = {ami_df_evs.shape[0]}')\n",
    "print(f'ami_df_non.shape[0] = {ami_df_non.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a009f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami_df_evs['aep_premise_nb'].nunique() = 492\n",
      "ami_df_evs['aep_premise_nb'].nunique() = 492\n",
      "ami_df_non['aep_premise_nb'].nunique() = 1181\n",
      "ami_df_non['aep_premise_nb'].nunique() = 1181\n"
     ]
    }
   ],
   "source": [
    "print(f\"ami_df_evs['aep_premise_nb'].nunique() = {ami_df_evs['aep_premise_nb'].nunique()}\")\n",
    "print(f\"ami_df_non['aep_premise_nb'].nunique() = {ami_df_non['aep_premise_nb'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ee146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54218922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_df_resamples_evs = {}\n",
    "ami_df_resamples_non = {}\n",
    "for freq_i, dfs_i in ami_df_resamples.items():\n",
    "    df_i = dfs_i['df']\n",
    "    ami_df_evs_i = df_i[df_i['aep_premise_nb'].isin(evs_prems)].copy()\n",
    "    ami_df_non_i = df_i[df_i['aep_premise_nb'].isin(non_prems)].copy()   \n",
    "    #-----\n",
    "    assert(df_i.shape[0]==ami_df_evs_i.shape[0]+ami_df_non_i.shape[0])\n",
    "    assert(freq_i not in ami_df_resamples_evs.keys())\n",
    "    assert(freq_i not in ami_df_resamples_non.keys())\n",
    "    ami_df_resamples_evs[freq_i] = ami_df_evs_i\n",
    "    ami_df_resamples_non[freq_i] = ami_df_non_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a724701",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea781c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32327a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ba1ccc6",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af2da91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    num_classes=2\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=16, kernel_size=25, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=8, kernel_size=10, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv1D(filters=4, kernel_size=10, padding=\"same\")(conv3)\n",
    "    conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = keras.layers.ReLU()(conv4)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv4)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a328d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_df_empty = pd.DataFrame(columns=[\n",
    "    'lag', \n",
    "    'threshold', \n",
    "    'signal_abs_threshold', \n",
    "    'smooth_rolling_window', \n",
    "    #-----\n",
    "    'acc_train_keras', \n",
    "    'prec_train_keras', \n",
    "    'rec_train_keras', \n",
    "    'f1_train_keras', \n",
    "    \n",
    "    'acc_test_keras', \n",
    "    'prec_test_keras', \n",
    "    'rec_test_keras', \n",
    "    'f1_test_keras', \n",
    "    #-----\n",
    "    'acc_train_forest', \n",
    "    'prec_train_forest', \n",
    "    'rec_train_forest', \n",
    "    'f1_train_forest', \n",
    "    \n",
    "    'acc_test_forest', \n",
    "    'prec_test_forest', \n",
    "    'rec_test_forest', \n",
    "    'f1_test_forest', \n",
    "    #-----\n",
    "    'acc_train_svc', \n",
    "    'prec_train_svc', \n",
    "    'rec_train_svc', \n",
    "    'f1_train_svc', \n",
    "    \n",
    "    'acc_test_svc', \n",
    "    'prec_test_svc', \n",
    "    'rec_test_svc', \n",
    "    'f1_test_svc', \n",
    "    #-----\n",
    "    'acc_train_logreg', \n",
    "    'prec_train_logreg', \n",
    "    'rec_train_logreg', \n",
    "    'f1_train_logreg', \n",
    "    \n",
    "    'acc_test_logreg', \n",
    "    'prec_test_logreg', \n",
    "    'rec_test_logreg', \n",
    "    'f1_test_logreg'    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83cf682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_df_evs_fit_OG = ami_df_resamples_evs['H'].copy()\n",
    "ami_df_non_fit_OG = ami_df_resamples_non['H'].copy()\n",
    "#-----\n",
    "value_col = 'mean_TRS value'\n",
    "funky_n_entries=200\n",
    "\n",
    "fit_signal_col_keras='test_final'\n",
    "# fit_signal_col_keras='test_final2'\n",
    "\n",
    "fit_signal_col_peaks = 'test_final'\n",
    "# fit_signal_col_peaks = 'signal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c190b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [24, 36, 48]\n",
    "thresholds = [2, 3, 5, 10]\n",
    "signal_abs_thresholds = [0, 1, 2]\n",
    "smooth_rolling_windows = [24, 36, 48]\n",
    "influence=0\n",
    "\n",
    "# lags = [24, 48]\n",
    "# thresholds = [3]\n",
    "# signal_abs_thresholds = [1]\n",
    "# smooth_rolling_windows = [24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d3417b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lists = [\n",
    "    lags, \n",
    "    thresholds, \n",
    "    signal_abs_thresholds, \n",
    "    smooth_rolling_windows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6763531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "0 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 102: early stopping\n",
      "Epoch 102: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "351.10175704956055\n",
      "\n",
      "1 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "351.10175704956055\n",
      "\n",
      "1 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 93: early stopping\n",
      "Epoch 93: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "255.18495297431946\n",
      "\n",
      "2 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "255.18495297431946\n",
      "\n",
      "2 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 127: early stopping\n",
      "Epoch 127: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "296.61245799064636\n",
      "\n",
      "3 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "296.61245799064636\n",
      "\n",
      "3 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 167: early stopping\n",
      "Epoch 167: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "293.29463601112366\n",
      "\n",
      "4 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "293.29463601112366\n",
      "\n",
      "4 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 101: early stopping\n",
      "Epoch 101: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "269.05496621131897\n",
      "\n",
      "5 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "269.05496621131897\n",
      "\n",
      "5 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 84: early stopping\n",
      "Epoch 84: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "221.38959980010986\n",
      "\n",
      "6 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "221.38959980010986\n",
      "\n",
      "6 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 112: early stopping\n",
      "Epoch 112: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "248.8548355102539\n",
      "\n",
      "7 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "248.8548355102539\n",
      "\n",
      "7 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 147: early stopping\n",
      "Epoch 147: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "286.6389412879944\n",
      "\n",
      "8 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "286.6389412879944\n",
      "\n",
      "8 of 108\n",
      "lag                   = 24\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 79: early stopping\n",
      "Epoch 79: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "223.74205470085144\n",
      "\n",
      "9 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "223.74205470085144\n",
      "\n",
      "9 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 117: early stopping\n",
      "Epoch 117: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "282.91311502456665\n",
      "\n",
      "10 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "282.91311502456665\n",
      "\n",
      "10 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 105: early stopping\n",
      "Epoch 105: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "271.4121038913727\n",
      "\n",
      "11 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "271.4121038913727\n",
      "\n",
      "11 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 112: early stopping\n",
      "Epoch 112: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "275.5525243282318\n",
      "\n",
      "12 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "275.5525243282318\n",
      "\n",
      "12 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 121: early stopping\n",
      "Epoch 121: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "296.2243399620056\n",
      "\n",
      "13 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "296.2243399620056\n",
      "\n",
      "13 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 136: early stopping\n",
      "Epoch 136: early stopping\n",
      "35/35 [==============================] - 0s 9ms/step\n",
      "35/35 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "303.39621329307556\n",
      "\n",
      "14 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "303.39621329307556\n",
      "\n",
      "14 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 114: early stopping\n",
      "Epoch 114: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "260.4627242088318\n",
      "\n",
      "15 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "260.4627242088318\n",
      "\n",
      "15 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 123: early stopping\n",
      "Epoch 123: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "265.5068836212158\n",
      "\n",
      "16 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "265.5068836212158\n",
      "\n",
      "16 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 167: early stopping\n",
      "Epoch 167: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "309.54824781417847\n",
      "\n",
      "17 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "309.54824781417847\n",
      "\n",
      "17 of 108\n",
      "lag                   = 24\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 127: early stopping\n",
      "Epoch 127: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "299.2444291114807\n",
      "\n",
      "18 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "299.2444291114807\n",
      "\n",
      "18 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 223: early stopping\n",
      "Epoch 223: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "401.5233645439148\n",
      "\n",
      "19 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "401.5233645439148\n",
      "\n",
      "19 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 85: early stopping\n",
      "Epoch 85: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "280.339412689209\n",
      "\n",
      "20 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "280.339412689209\n",
      "\n",
      "20 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 103: early stopping\n",
      "Epoch 103: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "276.29256296157837\n",
      "\n",
      "21 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "276.29256296157837\n",
      "\n",
      "21 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 100: early stopping\n",
      "Epoch 100: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "257.08197808265686\n",
      "\n",
      "22 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "257.08197808265686\n",
      "\n",
      "22 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 100: early stopping\n",
      "Epoch 100: early stopping\n",
      "35/35 [==============================] - 1s 9ms/step\n",
      "35/35 [==============================] - 1s 9ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "260.4662663936615\n",
      "\n",
      "23 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.4662663936615\n",
      "\n",
      "23 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 88: early stopping\n",
      "Epoch 88: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "258.0058205127716\n",
      "\n",
      "24 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "258.0058205127716\n",
      "\n",
      "24 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 206: early stopping\n",
      "Epoch 206: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "341.63764929771423\n",
      "\n",
      "25 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "341.63764929771423\n",
      "\n",
      "25 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 85: early stopping\n",
      "Epoch 85: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "217.71619701385498\n",
      "\n",
      "26 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "217.71619701385498\n",
      "\n",
      "26 of 108\n",
      "lag                   = 24\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 159: early stopping\n",
      "Epoch 159: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "307.398149728775\n",
      "\n",
      "27 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "307.398149728775\n",
      "\n",
      "27 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 178: early stopping\n",
      "Epoch 178: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "324.9637212753296\n",
      "\n",
      "28 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "324.9637212753296\n",
      "\n",
      "28 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 147: early stopping\n",
      "Epoch 147: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "285.04979038238525\n",
      "\n",
      "29 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "285.04979038238525\n",
      "\n",
      "29 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 156: early stopping\n",
      "Epoch 156: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "299.52993869781494\n",
      "\n",
      "30 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "299.52993869781494\n",
      "\n",
      "30 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 170: early stopping\n",
      "Epoch 170: early stopping\n",
      "35/35 [==============================] - 0s 9ms/step\n",
      "35/35 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "293.207643032074\n",
      "\n",
      "31 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "293.207643032074\n",
      "\n",
      "31 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 219: early stopping\n",
      "Epoch 219: early stopping\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "18/18 [==============================] - 0s 12ms/step\n",
      "18/18 [==============================] - 0s 12ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "425.53468322753906\n",
      "\n",
      "32 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "425.53468322753906\n",
      "\n",
      "32 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 225: early stopping\n",
      "Epoch 225: early stopping\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "612.6949510574341\n",
      "\n",
      "33 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "612.6949510574341\n",
      "\n",
      "33 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 210: early stopping\n",
      "Epoch 210: early stopping\n",
      "35/35 [==============================] - 1s 13ms/step\n",
      "35/35 [==============================] - 1s 13ms/step\n",
      "18/18 [==============================] - 0s 11ms/step\n",
      "18/18 [==============================] - 0s 11ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "622.4625141620636\n",
      "\n",
      "34 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "622.4625141620636\n",
      "\n",
      "34 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 183: early stopping\n",
      "Epoch 183: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "469.8236403465271\n",
      "\n",
      "35 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "469.8236403465271\n",
      "\n",
      "35 of 108\n",
      "lag                   = 24\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 105: early stopping\n",
      "Epoch 105: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "282.00968623161316\n",
      "\n",
      "36 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "282.00968623161316\n",
      "\n",
      "36 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 120: early stopping\n",
      "Epoch 120: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "326.7371997833252\n",
      "\n",
      "37 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "326.7371997833252\n",
      "\n",
      "37 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 80: early stopping\n",
      "Epoch 80: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "270.54052662849426\n",
      "\n",
      "38 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "270.54052662849426\n",
      "\n",
      "38 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 89: early stopping\n",
      "Epoch 89: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "281.4522023200989\n",
      "\n",
      "39 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "281.4522023200989\n",
      "\n",
      "39 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 85: early stopping\n",
      "Epoch 85: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "224.05341744422913\n",
      "\n",
      "40 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "224.05341744422913\n",
      "\n",
      "40 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 87: early stopping\n",
      "Epoch 87: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "217.8934600353241\n",
      "\n",
      "41 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "217.8934600353241\n",
      "\n",
      "41 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 92: early stopping\n",
      "Epoch 92: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "229.88843274116516\n",
      "\n",
      "42 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "229.88843274116516\n",
      "\n",
      "42 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 109: early stopping\n",
      "Epoch 109: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "226.4343922138214\n",
      "\n",
      "43 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "226.4343922138214\n",
      "\n",
      "43 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 141: early stopping\n",
      "Epoch 141: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "257.3259575366974\n",
      "\n",
      "44 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "257.3259575366974\n",
      "\n",
      "44 of 108\n",
      "lag                   = 36\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 91: early stopping\n",
      "Epoch 91: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "207.42872095108032\n",
      "\n",
      "45 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "207.42872095108032\n",
      "\n",
      "45 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 111: early stopping\n",
      "Epoch 111: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "249.71030449867249\n",
      "\n",
      "46 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "249.71030449867249\n",
      "\n",
      "46 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: early stopping\n",
      "Epoch 90: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "220.2338743209839\n",
      "\n",
      "47 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "220.2338743209839\n",
      "\n",
      "47 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 107: early stopping\n",
      "Epoch 107: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "248.5122983455658\n",
      "\n",
      "48 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "248.5122983455658\n",
      "\n",
      "48 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 105: early stopping\n",
      "Epoch 105: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "218.8936276435852\n",
      "\n",
      "49 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "218.8936276435852\n",
      "\n",
      "49 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 153: early stopping\n",
      "Epoch 153: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "251.3065116405487\n",
      "\n",
      "50 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "251.3065116405487\n",
      "\n",
      "50 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 157: early stopping\n",
      "Epoch 157: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "265.6812024116516\n",
      "\n",
      "51 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "265.6812024116516\n",
      "\n",
      "51 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 90: early stopping\n",
      "Epoch 90: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "207.35332584381104\n",
      "\n",
      "52 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "207.35332584381104\n",
      "\n",
      "52 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 150: early stopping\n",
      "Epoch 150: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "282.9570837020874\n",
      "\n",
      "53 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "282.9570837020874\n",
      "\n",
      "53 of 108\n",
      "lag                   = 36\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 246: early stopping\n",
      "Epoch 246: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "348.9026868343353\n",
      "\n",
      "54 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "348.9026868343353\n",
      "\n",
      "54 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 133: early stopping\n",
      "Epoch 133: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "258.08512473106384\n",
      "\n",
      "55 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "258.08512473106384\n",
      "\n",
      "55 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 87: early stopping\n",
      "Epoch 87: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "205.73649048805237\n",
      "\n",
      "56 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "205.73649048805237\n",
      "\n",
      "56 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 89: early stopping\n",
      "Epoch 89: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "208.78710222244263\n",
      "\n",
      "57 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "208.78710222244263\n",
      "\n",
      "57 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 152: early stopping\n",
      "Epoch 152: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "251.11699390411377\n",
      "\n",
      "58 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "251.11699390411377\n",
      "\n",
      "58 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 97: early stopping\n",
      "Epoch 97: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "209.261004447937\n",
      "\n",
      "59 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "209.261004447937\n",
      "\n",
      "59 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 154: early stopping\n",
      "Epoch 154: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "248.7427270412445\n",
      "\n",
      "60 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "248.7427270412445\n",
      "\n",
      "60 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 241: early stopping\n",
      "Epoch 241: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "315.56504797935486\n",
      "\n",
      "61 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "315.56504797935486\n",
      "\n",
      "61 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 327: early stopping\n",
      "Epoch 327: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "400.8677308559418\n",
      "\n",
      "62 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "400.8677308559418\n",
      "\n",
      "62 of 108\n",
      "lag                   = 36\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 232: early stopping\n",
      "Epoch 232: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "396.64168334007263\n",
      "\n",
      "63 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "396.64168334007263\n",
      "\n",
      "63 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 176: early stopping\n",
      "Epoch 176: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "343.1493458747864\n",
      "\n",
      "64 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "343.1493458747864\n",
      "\n",
      "64 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 193: early stopping\n",
      "Epoch 193: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "376.63970375061035\n",
      "\n",
      "65 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "376.63970375061035\n",
      "\n",
      "65 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 178: early stopping\n",
      "Epoch 178: early stopping\n",
      "35/35 [==============================] - 1s 9ms/step\n",
      "35/35 [==============================] - 1s 9ms/step\n",
      "18/18 [==============================] - 0s 10ms/step\n",
      "18/18 [==============================] - 0s 10ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "408.9955983161926\n",
      "\n",
      "66 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "408.9955983161926\n",
      "\n",
      "66 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 193: early stopping\n",
      "Epoch 193: early stopping\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "329.87101101875305\n",
      "\n",
      "67 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "329.87101101875305\n",
      "\n",
      "67 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 199: early stopping\n",
      "Epoch 199: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "403.9030945301056\n",
      "\n",
      "68 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "403.9030945301056\n",
      "\n",
      "68 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 255: early stopping\n",
      "Epoch 255: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "699.0230596065521\n",
      "\n",
      "69 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "699.0230596065521\n",
      "\n",
      "69 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 215: early stopping\n",
      "Epoch 215: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "453.97717022895813\n",
      "\n",
      "70 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "453.97717022895813\n",
      "\n",
      "70 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 147: early stopping\n",
      "Epoch 147: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "285.6342701911926\n",
      "\n",
      "71 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "285.6342701911926\n",
      "\n",
      "71 of 108\n",
      "lag                   = 36\n",
      "threshold             = 10\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 148: early stopping\n",
      "Epoch 148: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "355.0106153488159\n",
      "\n",
      "72 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "355.0106153488159\n",
      "\n",
      "72 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 89: early stopping\n",
      "Epoch 89: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "379.1808052062988\n",
      "\n",
      "73 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "379.1808052062988\n",
      "\n",
      "73 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 86: early stopping\n",
      "Epoch 86: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 10ms/step\n",
      "18/18 [==============================] - 0s 10ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "271.93889236450195\n",
      "\n",
      "74 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "271.93889236450195\n",
      "\n",
      "74 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 86: early stopping\n",
      "Epoch 86: early stopping\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "258.6908915042877\n",
      "\n",
      "75 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "258.6908915042877\n",
      "\n",
      "75 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 91: early stopping\n",
      "Epoch 91: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "227.34304976463318\n",
      "\n",
      "76 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "227.34304976463318\n",
      "\n",
      "76 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 112: early stopping\n",
      "Epoch 112: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "239.78716492652893\n",
      "\n",
      "77 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "239.78716492652893\n",
      "\n",
      "77 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 82: early stopping\n",
      "Epoch 82: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "215.49306726455688\n",
      "\n",
      "78 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "215.49306726455688\n",
      "\n",
      "78 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 84: early stopping\n",
      "Epoch 84: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "200.71857380867004\n",
      "\n",
      "79 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "200.71857380867004\n",
      "\n",
      "79 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 135: early stopping\n",
      "Epoch 135: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "259.7118790149689\n",
      "\n",
      "80 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "259.7118790149689\n",
      "\n",
      "80 of 108\n",
      "lag                   = 48\n",
      "threshold             = 2\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 94: early stopping\n",
      "Epoch 94: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "266.6828751564026\n",
      "\n",
      "81 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266.6828751564026\n",
      "\n",
      "81 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 102: early stopping\n",
      "Epoch 102: early stopping\n",
      "35/35 [==============================] - 1s 10ms/step\n",
      "35/35 [==============================] - 1s 10ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "369.87444496154785\n",
      "\n",
      "82 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "369.87444496154785\n",
      "\n",
      "82 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 89: early stopping\n",
      "Epoch 89: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "258.5117554664612\n",
      "\n",
      "83 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "258.5117554664612\n",
      "\n",
      "83 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 77: early stopping\n",
      "Epoch 77: early stopping\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "254.1427206993103\n",
      "\n",
      "84 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "254.1427206993103\n",
      "\n",
      "84 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 95: early stopping\n",
      "Epoch 95: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "231.52929997444153\n",
      "\n",
      "85 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "231.52929997444153\n",
      "\n",
      "85 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 158: early stopping\n",
      "Epoch 158: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "290.48583245277405\n",
      "\n",
      "86 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "290.48583245277405\n",
      "\n",
      "86 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 190: early stopping\n",
      "Epoch 190: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "309.5241458415985\n",
      "\n",
      "87 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "309.5241458415985\n",
      "\n",
      "87 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "Epoch 188: early stopping\n",
      "Epoch 188: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "315.7705421447754\n",
      "\n",
      "88 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "315.7705421447754\n",
      "\n",
      "88 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 36\n",
      "Epoch 102: early stopping\n",
      "Epoch 102: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "225.7856845855713\n",
      "\n",
      "89 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "225.7856845855713\n",
      "\n",
      "89 of 108\n",
      "lag                   = 48\n",
      "threshold             = 3\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 48\n",
      "Epoch 111: early stopping\n",
      "Epoch 111: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "236.62190985679626\n",
      "\n",
      "90 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "236.62190985679626\n",
      "\n",
      "90 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 24\n",
      "Epoch 122: early stopping\n",
      "Epoch 122: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "292.7417948246002\n",
      "\n",
      "91 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "292.7417948246002\n",
      "\n",
      "91 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 36\n",
      "Epoch 213: early stopping\n",
      "Epoch 213: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "398.73490810394287\n",
      "\n",
      "92 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "398.73490810394287\n",
      "\n",
      "92 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 0\n",
      "smooth_rolling_window = 48\n",
      "Epoch 179: early stopping\n",
      "Epoch 179: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "391.0564384460449\n",
      "\n",
      "93 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "391.0564384460449\n",
      "\n",
      "93 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 24\n",
      "Epoch 186: early stopping\n",
      "Epoch 186: early stopping\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "35/35 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "360.96975016593933\n",
      "\n",
      "94 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "360.96975016593933\n",
      "\n",
      "94 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 36\n",
      "Epoch 186: early stopping\n",
      "Epoch 186: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "355.65020179748535\n",
      "\n",
      "95 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "355.65020179748535\n",
      "\n",
      "95 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 1\n",
      "smooth_rolling_window = 48\n",
      "Epoch 183: early stopping\n",
      "Epoch 183: early stopping\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "Before inf removal, peak_df.shape[0] = 1672\n",
      "After inf removal, peak_df.shape[0] = 1672\n",
      "374.96442317962646\n",
      "\n",
      "96 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n",
      "374.96442317962646\n",
      "\n",
      "96 of 108\n",
      "lag                   = 48\n",
      "threshold             = 5\n",
      "signal_abs_threshold  = 2\n",
      "smooth_rolling_window = 24\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_32164/3307820283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sparse_categorical_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m---> 99\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (file signature not found)"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_32164/3307820283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sparse_categorical_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m---> 99\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (file signature not found)"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "grid_results_df = grid_results_df_empty.copy()\n",
    "for i, grid_i in enumerate(list(itertools.product(*grid_lists))):\n",
    "    start_i = time.time()\n",
    "    lag                   = grid_i[0]\n",
    "    threshold             = grid_i[1]\n",
    "    signal_abs_threshold  = grid_i[2]\n",
    "    smooth_rolling_window = grid_i[3]\n",
    "    #-------------------------\n",
    "    print(f\"{i} of {len(list(itertools.product(*grid_lists)))}\")\n",
    "    print(f'lag                   = {lag}')\n",
    "    print(f'threshold             = {threshold}')\n",
    "    print(f'signal_abs_threshold  = {signal_abs_threshold}')\n",
    "    print(f'smooth_rolling_window = {smooth_rolling_window}')\n",
    "    #-------------------------\n",
    "    res_i = dict()\n",
    "    res_i['lag']                   = lag\n",
    "    res_i['threshold']             = threshold\n",
    "    res_i['signal_abs_threshold']  = signal_abs_threshold\n",
    "    res_i['smooth_rolling_window'] = smooth_rolling_window\n",
    "    #-------------------------\n",
    "    ami_df_evs_fit = ami_df_evs_fit_OG.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: thresholding_algo_df_i(\n",
    "            df_i=x, \n",
    "            value_col=value_col, \n",
    "            lag=lag, \n",
    "            threshold=threshold, \n",
    "            influence=influence, \n",
    "            signal_abs_threshold=signal_abs_threshold, \n",
    "            smooth_rolling_window=smooth_rolling_window\n",
    "        )\n",
    "    )\n",
    "    ami_df_non_fit = ami_df_non_fit_OG.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: thresholding_algo_df_i(\n",
    "            df_i=x, \n",
    "            value_col=value_col, \n",
    "            lag=lag, \n",
    "            threshold=threshold, \n",
    "            influence=influence, \n",
    "            signal_abs_threshold=signal_abs_threshold, \n",
    "            smooth_rolling_window=smooth_rolling_window\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NEW METHOD KERAS\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    keras_df_evs = ami_df_evs_fit.reset_index(drop=True).groupby(['serialnumber']).apply(\n",
    "        lambda x: make_it_funky(\n",
    "            df_i=x, \n",
    "            n_entries=funky_n_entries, \n",
    "            val_col=fit_signal_col_keras, \n",
    "            SN_col='serialnumber'\n",
    "        )\n",
    "    )\n",
    "    keras_df_non = ami_df_non_fit.reset_index(drop=True).groupby(['serialnumber']).apply(\n",
    "        lambda x: make_it_funky(\n",
    "            df_i=x, \n",
    "            n_entries=funky_n_entries, \n",
    "            val_col=fit_signal_col_keras, \n",
    "            SN_col='serialnumber'\n",
    "        )\n",
    "    )\n",
    "    #-------------------------\n",
    "    keras_df_evs['target']=1\n",
    "    keras_df_non['target']=0\n",
    "    keras_df = pd.concat([keras_df_evs, keras_df_non])\n",
    "    keras_df=keras_df.dropna()\n",
    "    #-------------------------\n",
    "    keras_df_train, keras_df_test = train_test_split(keras_df, test_size=0.33, random_state=42)\n",
    "    #-------------------------\n",
    "    X_train = keras_df_train[[x for x in keras_df_train.columns.tolist() if x != 'target']].values\n",
    "    y_train = keras_df_train['target'].values\n",
    "    X_train=X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    #-----\n",
    "    X_test = keras_df_test[[x for x in keras_df_test.columns.tolist() if x != 'target']].values\n",
    "    y_test = keras_df_test['target'].values\n",
    "    X_test=X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    #-------------------------\n",
    "    model = make_model(input_shape=X_train.shape[1:])\n",
    "    #-------------------------\n",
    "    epochs = 500\n",
    "    batch_size = 32\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "    )\n",
    "    #-------------------------\n",
    "    model = keras.models.load_model(\"best_model.h5\")\n",
    "    #-------------------------\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "    #-----\n",
    "    res_i['acc_train_keras']  = accuracy_score(y_train, y_pred_train)\n",
    "    res_i['prec_train_keras'] = precision_score(y_train, y_pred_train)\n",
    "    res_i['rec_train_keras']  = recall_score(y_train, y_pred_train)\n",
    "    res_i['f1_train_keras']   = f1_score(y_train, y_pred_train)\n",
    "    #-------------------------\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    #-----\n",
    "    res_i['acc_test_keras']  = accuracy_score(y_test, y_pred)\n",
    "    res_i['prec_test_keras'] = precision_score(y_test, y_pred)\n",
    "    res_i['rec_test_keras']  = recall_score(y_test, y_pred)\n",
    "    res_i['f1_test_keras']   = f1_score(y_test, y_pred)\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NEW METHOD PEAKS\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    peak_df_evs = ami_df_evs_fit.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: set_signal_groups_in_df_i(\n",
    "            df_i=x, \n",
    "            SN_col='serialnumber',\n",
    "            signal_col='signal_binary', \n",
    "            return_signal_group_col='signal_grp'        \n",
    "        )\n",
    "    )\n",
    "    #-----\n",
    "    peak_df_non = ami_df_non_fit.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: set_signal_groups_in_df_i(\n",
    "            df_i=x, \n",
    "            SN_col='serialnumber',\n",
    "            signal_col='signal_binary', \n",
    "            return_signal_group_col='signal_grp'        \n",
    "        )\n",
    "    )\n",
    "    #-------------------------\n",
    "    peak_df_evs = peak_df_evs.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: build_peak_features_for_df_i(\n",
    "            df_i=x, \n",
    "            signal_group_col='signal_grp', \n",
    "            value_col=fit_signal_col_peaks,\n",
    "            SN_col='serialnumber', \n",
    "            time_col='starttimeperiod_local',        \n",
    "        )\n",
    "    )\n",
    "    #-----\n",
    "    peak_df_non = peak_df_non.groupby(['serialnumber'], as_index=False, group_keys=False).apply(\n",
    "        lambda x: build_peak_features_for_df_i(\n",
    "            df_i=x, \n",
    "            signal_group_col='signal_grp', \n",
    "            value_col=fit_signal_col_peaks, \n",
    "            SN_col='serialnumber', \n",
    "            time_col='starttimeperiod_local',        \n",
    "        )\n",
    "    )\n",
    "    #-------------------------\n",
    "    peak_df_evs['target']=1\n",
    "    peak_df_non['target']=0\n",
    "    #-------------------------\n",
    "    peak_df=pd.concat([peak_df_evs, peak_df_non])\n",
    "    peak_df=peak_df.sample(frac=1)\n",
    "    #-------------------------\n",
    "    # peak_df_OG = peak_df.copy()\n",
    "    #-------------------------\n",
    "    # peak_df = peak_df_OG.copy()\n",
    "    #-------------------------\n",
    "    peak_df = fill_na_in_peak_df(peak_df)\n",
    "    peak_df = convert_to_seconds_in_peak_df(peak_df)\n",
    "    peak_df = peak_df.drop(columns=['serialnumber'])\n",
    "    #-------------------------\n",
    "    # peak_df = peak_df.drop(columns=[\n",
    "    #     'peak_mean', 'peak_std', \n",
    "    #     'peak_max_std', \n",
    "    #     'peak_width_std', \n",
    "    #     'peak_spacing_std'\n",
    "    # ])\n",
    "    #-------------------------\n",
    "    # Remove inf values\n",
    "    print(f\"Before inf removal, peak_df.shape[0] = {peak_df.shape[0]}\")\n",
    "    peak_df = peak_df.loc[np.isinf(peak_df[[x for x in peak_df.columns if x!='serialnumber']]).sum(axis=1)==0].copy()\n",
    "    print(f\"After inf removal, peak_df.shape[0] = {peak_df.shape[0]}\")\n",
    "    #-------------------------\n",
    "    peak_df_train, peak_df_test = train_test_split(peak_df, test_size=0.33, random_state=42)\n",
    "    #-------------------------\n",
    "    X_train = peak_df_train[[x for x in peak_df_train.columns.tolist() if x!='target']]\n",
    "    y_train = peak_df_train['target']\n",
    "    #-----\n",
    "    X_test = peak_df_test[[x for x in peak_df_test.columns.tolist() if x!='target']]\n",
    "    y_test = peak_df_test['target']\n",
    "    #--------------------------------------------------\n",
    "    # Random Forest\n",
    "    #--------------------------------------------------\n",
    "    forest_clf = RandomForestClassifier(n_estimators = 10, max_depth=None, n_jobs=None)\n",
    "    forest_clf.fit(X_train, y_train)\n",
    "    #-------------------------\n",
    "    y_pred_train = forest_clf.predict(X_train)\n",
    "    res_i['acc_train_forest']  = accuracy_score(y_train, y_pred_train)\n",
    "    res_i['prec_train_forest'] = precision_score(y_train, y_pred_train)\n",
    "    res_i['rec_train_forest']  = recall_score(y_train, y_pred_train)\n",
    "    res_i['f1_train_forest']   = f1_score(y_train, y_pred_train)\n",
    "    #-------------------------\n",
    "    y_pred = forest_clf.predict(X_test)\n",
    "    res_i['acc_test_forest']  = accuracy_score(y_test, y_pred)\n",
    "    res_i['prec_test_forest'] = precision_score(y_test, y_pred)\n",
    "    res_i['rec_test_forest']  = recall_score(y_test, y_pred)\n",
    "    res_i['f1_test_forest']   = f1_score(y_test, y_pred)\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # SVC Forest\n",
    "    #--------------------------------------------------\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    #-------------------------\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #-------------------------\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    res_i['acc_train_svc']  = accuracy_score(y_train, y_pred_train)\n",
    "    res_i['prec_train_svc'] = precision_score(y_train, y_pred_train)\n",
    "    res_i['rec_train_svc']  = recall_score(y_train, y_pred_train)\n",
    "    res_i['f1_train_svc']   = f1_score(y_train, y_pred_train)\n",
    "    #-------------------------\n",
    "    y_pred = clf.predict(X_test)\n",
    "    res_i['acc_test_svc']  = accuracy_score(y_test, y_pred)\n",
    "    res_i['prec_test_svc'] = precision_score(y_test, y_pred)\n",
    "    res_i['rec_test_svc']  = recall_score(y_test, y_pred)\n",
    "    res_i['f1_test_svc']   = f1_score(y_test, y_pred)\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # Logistic Regression\n",
    "    #--------------------------------------------------\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    #-------------------------\n",
    "    y_pred_train = logreg.predict(X_train)\n",
    "    res_i['acc_train_logreg']  = accuracy_score(y_train, y_pred_train)\n",
    "    res_i['prec_train_logreg'] = precision_score(y_train, y_pred_train)\n",
    "    res_i['rec_train_logreg']  = recall_score(y_train, y_pred_train)\n",
    "    res_i['f1_train_logreg']   = f1_score(y_train, y_pred_train)\n",
    "    #-------------------------\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    res_i['acc_test_logreg']  = accuracy_score(y_test, y_pred)\n",
    "    res_i['prec_test_logreg'] = precision_score(y_test, y_pred)\n",
    "    res_i['rec_test_logreg']  = recall_score(y_test, y_pred)\n",
    "    res_i['f1_test_logreg']   = f1_score(y_test, y_pred)\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    grid_results_df = pd.concat([grid_results_df, pd.DataFrame(res_i, index=[grid_results_df.shape[0]])])\n",
    "    print(time.time()-start_i)\n",
    "    print()\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfdfe4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>threshold</th>\n",
       "      <th>signal_abs_threshold</th>\n",
       "      <th>smooth_rolling_window</th>\n",
       "      <th>acc_train_keras</th>\n",
       "      <th>prec_train_keras</th>\n",
       "      <th>rec_train_keras</th>\n",
       "      <th>f1_train_keras</th>\n",
       "      <th>acc_test_keras</th>\n",
       "      <th>prec_test_keras</th>\n",
       "      <th>...</th>\n",
       "      <th>rec_test_svc</th>\n",
       "      <th>f1_test_svc</th>\n",
       "      <th>acc_train_logreg</th>\n",
       "      <th>prec_train_logreg</th>\n",
       "      <th>rec_train_logreg</th>\n",
       "      <th>f1_train_logreg</th>\n",
       "      <th>acc_test_logreg</th>\n",
       "      <th>prec_test_logreg</th>\n",
       "      <th>rec_test_logreg</th>\n",
       "      <th>f1_test_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.881508</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.648318</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.859745</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.646707</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.746575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.874887</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.738230</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.697068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.832470</td>\n",
       "      <td>0.859489</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.687023</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.907540</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.632530</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.886589</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.665615</td>\n",
       "      <td>0.745583</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.726688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.889289</td>\n",
       "      <td>0.963470</td>\n",
       "      <td>0.647239</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.841241</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.718802</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.524540</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.734899</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.678967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.880610</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.754159</td>\n",
       "      <td>0.834244</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>0.747795</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.611429</td>\n",
       "      <td>0.715719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.883888</td>\n",
       "      <td>0.949772</td>\n",
       "      <td>0.638037</td>\n",
       "      <td>0.763303</td>\n",
       "      <td>0.850365</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.683230</td>\n",
       "      <td>0.756014</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.865887</td>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.718336</td>\n",
       "      <td>0.830292</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.733813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag threshold signal_abs_threshold smooth_rolling_window  acc_train_keras  \\\n",
       "0   24         2                    0                    24         0.881508   \n",
       "1   24         2                    0                    36         0.874887   \n",
       "2   24         2                    0                    48         0.912691   \n",
       "3   24         2                    1                    24         0.907540   \n",
       "4   24         2                    1                    36         0.886589   \n",
       "..  ..       ...                  ...                   ...              ...   \n",
       "91  48         5                    0                    36         0.889289   \n",
       "92  48         5                    0                    48         0.850585   \n",
       "93  48         5                    1                    24         0.880610   \n",
       "94  48         5                    1                    36         0.883888   \n",
       "95  48         5                    1                    48         0.865887   \n",
       "\n",
       "    prec_train_keras  rec_train_keras  f1_train_keras  acc_test_keras  \\\n",
       "0           0.925764         0.648318        0.762590        0.859745   \n",
       "1           0.956098         0.601227        0.738230        0.852190   \n",
       "2           0.952569         0.739264        0.832470        0.859489   \n",
       "3           0.995575         0.688073        0.813743        0.843352   \n",
       "4           0.927350         0.665644        0.775000        0.852190   \n",
       "..               ...              ...             ...             ...   \n",
       "91          0.963470         0.647239        0.774312        0.841241   \n",
       "92          0.939560         0.524540        0.673228        0.821168   \n",
       "93          0.953271         0.623853        0.754159        0.834244   \n",
       "94          0.949772         0.638037        0.763303        0.850365   \n",
       "95          0.935961         0.582822        0.718336        0.830292   \n",
       "\n",
       "    prec_test_keras  ...  rec_test_svc  f1_test_svc  acc_train_logreg  \\\n",
       "0          0.931373  ...      0.645570     0.728571          0.857143   \n",
       "1          0.897196  ...      0.632184     0.707395          0.866071   \n",
       "2          0.861789  ...      0.680851     0.757396          0.853571   \n",
       "3          0.883495  ...      0.590361     0.690141          0.878571   \n",
       "4          0.851240  ...      0.634286     0.720779          0.871429   \n",
       "..              ...  ...           ...          ...               ...   \n",
       "91         0.862385  ...      0.640523     0.736842          0.849107   \n",
       "92         0.935897  ...      0.628205     0.717949          0.858929   \n",
       "93         0.911111  ...      0.617143     0.734694          0.872321   \n",
       "94         0.881818  ...      0.664706     0.760943          0.873214   \n",
       "95         0.884211  ...      0.703947     0.775362          0.862500   \n",
       "\n",
       "    prec_train_logreg  rec_train_logreg  f1_train_logreg  acc_test_logreg  \\\n",
       "0            0.837209          0.646707         0.729730         0.865942   \n",
       "1            0.841463          0.650943         0.734043         0.831522   \n",
       "2            0.818182          0.592105         0.687023         0.853261   \n",
       "3            0.868217          0.687117         0.767123         0.847826   \n",
       "4            0.847390          0.665615         0.745583         0.846014   \n",
       "..                ...               ...              ...              ...   \n",
       "91           0.824427          0.637168         0.718802         0.844203   \n",
       "92           0.842308          0.651786         0.734899         0.842391   \n",
       "93           0.848000          0.668770         0.747795         0.846014   \n",
       "94           0.846154          0.683230         0.756014         0.864130   \n",
       "95           0.857692          0.655882         0.743333         0.865942   \n",
       "\n",
       "    prec_test_logreg  rec_test_logreg  f1_test_logreg  \n",
       "0           0.813433         0.689873        0.746575  \n",
       "1           0.804511         0.614943        0.697068  \n",
       "2           0.868966         0.670213        0.756757  \n",
       "3           0.820312         0.632530        0.714286  \n",
       "4           0.830882         0.645714        0.726688  \n",
       "..               ...              ...             ...  \n",
       "91          0.786325         0.601307        0.681481  \n",
       "92          0.800000         0.589744        0.678967  \n",
       "93          0.862903         0.611429        0.715719  \n",
       "94          0.857143         0.670588        0.752475  \n",
       "95          0.809524         0.671053        0.733813  \n",
       "\n",
       "[96 rows x 36 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>threshold</th>\n",
       "      <th>signal_abs_threshold</th>\n",
       "      <th>smooth_rolling_window</th>\n",
       "      <th>acc_train_keras</th>\n",
       "      <th>prec_train_keras</th>\n",
       "      <th>rec_train_keras</th>\n",
       "      <th>f1_train_keras</th>\n",
       "      <th>acc_test_keras</th>\n",
       "      <th>prec_test_keras</th>\n",
       "      <th>...</th>\n",
       "      <th>rec_test_svc</th>\n",
       "      <th>f1_test_svc</th>\n",
       "      <th>acc_train_logreg</th>\n",
       "      <th>prec_train_logreg</th>\n",
       "      <th>rec_train_logreg</th>\n",
       "      <th>f1_train_logreg</th>\n",
       "      <th>acc_test_logreg</th>\n",
       "      <th>prec_test_logreg</th>\n",
       "      <th>rec_test_logreg</th>\n",
       "      <th>f1_test_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.881508</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.648318</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.859745</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.646707</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.746575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.874887</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.738230</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.697068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.832470</td>\n",
       "      <td>0.859489</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.687023</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.907540</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.632530</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.886589</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.665615</td>\n",
       "      <td>0.745583</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.726688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.889289</td>\n",
       "      <td>0.963470</td>\n",
       "      <td>0.647239</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.841241</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.718802</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.524540</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.734899</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.678967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.880610</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.754159</td>\n",
       "      <td>0.834244</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>0.747795</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.611429</td>\n",
       "      <td>0.715719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.883888</td>\n",
       "      <td>0.949772</td>\n",
       "      <td>0.638037</td>\n",
       "      <td>0.763303</td>\n",
       "      <td>0.850365</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.683230</td>\n",
       "      <td>0.756014</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.865887</td>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.718336</td>\n",
       "      <td>0.830292</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.733813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag threshold signal_abs_threshold smooth_rolling_window  acc_train_keras  \\\n",
       "0   24         2                    0                    24         0.881508   \n",
       "1   24         2                    0                    36         0.874887   \n",
       "2   24         2                    0                    48         0.912691   \n",
       "3   24         2                    1                    24         0.907540   \n",
       "4   24         2                    1                    36         0.886589   \n",
       "..  ..       ...                  ...                   ...              ...   \n",
       "91  48         5                    0                    36         0.889289   \n",
       "92  48         5                    0                    48         0.850585   \n",
       "93  48         5                    1                    24         0.880610   \n",
       "94  48         5                    1                    36         0.883888   \n",
       "95  48         5                    1                    48         0.865887   \n",
       "\n",
       "    prec_train_keras  rec_train_keras  f1_train_keras  acc_test_keras  \\\n",
       "0           0.925764         0.648318        0.762590        0.859745   \n",
       "1           0.956098         0.601227        0.738230        0.852190   \n",
       "2           0.952569         0.739264        0.832470        0.859489   \n",
       "3           0.995575         0.688073        0.813743        0.843352   \n",
       "4           0.927350         0.665644        0.775000        0.852190   \n",
       "..               ...              ...             ...             ...   \n",
       "91          0.963470         0.647239        0.774312        0.841241   \n",
       "92          0.939560         0.524540        0.673228        0.821168   \n",
       "93          0.953271         0.623853        0.754159        0.834244   \n",
       "94          0.949772         0.638037        0.763303        0.850365   \n",
       "95          0.935961         0.582822        0.718336        0.830292   \n",
       "\n",
       "    prec_test_keras  ...  rec_test_svc  f1_test_svc  acc_train_logreg  \\\n",
       "0          0.931373  ...      0.645570     0.728571          0.857143   \n",
       "1          0.897196  ...      0.632184     0.707395          0.866071   \n",
       "2          0.861789  ...      0.680851     0.757396          0.853571   \n",
       "3          0.883495  ...      0.590361     0.690141          0.878571   \n",
       "4          0.851240  ...      0.634286     0.720779          0.871429   \n",
       "..              ...  ...           ...          ...               ...   \n",
       "91         0.862385  ...      0.640523     0.736842          0.849107   \n",
       "92         0.935897  ...      0.628205     0.717949          0.858929   \n",
       "93         0.911111  ...      0.617143     0.734694          0.872321   \n",
       "94         0.881818  ...      0.664706     0.760943          0.873214   \n",
       "95         0.884211  ...      0.703947     0.775362          0.862500   \n",
       "\n",
       "    prec_train_logreg  rec_train_logreg  f1_train_logreg  acc_test_logreg  \\\n",
       "0            0.837209          0.646707         0.729730         0.865942   \n",
       "1            0.841463          0.650943         0.734043         0.831522   \n",
       "2            0.818182          0.592105         0.687023         0.853261   \n",
       "3            0.868217          0.687117         0.767123         0.847826   \n",
       "4            0.847390          0.665615         0.745583         0.846014   \n",
       "..                ...               ...              ...              ...   \n",
       "91           0.824427          0.637168         0.718802         0.844203   \n",
       "92           0.842308          0.651786         0.734899         0.842391   \n",
       "93           0.848000          0.668770         0.747795         0.846014   \n",
       "94           0.846154          0.683230         0.756014         0.864130   \n",
       "95           0.857692          0.655882         0.743333         0.865942   \n",
       "\n",
       "    prec_test_logreg  rec_test_logreg  f1_test_logreg  \n",
       "0           0.813433         0.689873        0.746575  \n",
       "1           0.804511         0.614943        0.697068  \n",
       "2           0.868966         0.670213        0.756757  \n",
       "3           0.820312         0.632530        0.714286  \n",
       "4           0.830882         0.645714        0.726688  \n",
       "..               ...              ...             ...  \n",
       "91          0.786325         0.601307        0.681481  \n",
       "92          0.800000         0.589744        0.678967  \n",
       "93          0.862903         0.611429        0.715719  \n",
       "94          0.857143         0.670588        0.752475  \n",
       "95          0.809524         0.671053        0.733813  \n",
       "\n",
       "[96 rows x 36 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac6c8331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>threshold</th>\n",
       "      <th>signal_abs_threshold</th>\n",
       "      <th>smooth_rolling_window</th>\n",
       "      <th>acc_train_keras</th>\n",
       "      <th>prec_train_keras</th>\n",
       "      <th>rec_train_keras</th>\n",
       "      <th>f1_train_keras</th>\n",
       "      <th>acc_test_keras</th>\n",
       "      <th>prec_test_keras</th>\n",
       "      <th>...</th>\n",
       "      <th>rec_test_svc</th>\n",
       "      <th>f1_test_svc</th>\n",
       "      <th>acc_train_logreg</th>\n",
       "      <th>prec_train_logreg</th>\n",
       "      <th>rec_train_logreg</th>\n",
       "      <th>f1_train_logreg</th>\n",
       "      <th>acc_test_logreg</th>\n",
       "      <th>prec_test_logreg</th>\n",
       "      <th>rec_test_logreg</th>\n",
       "      <th>f1_test_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.860862</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>0.708098</td>\n",
       "      <td>0.846995</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.748718</td>\n",
       "      <td>0.867754</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.750853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.856886</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.687623</td>\n",
       "      <td>0.844891</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.884788</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.634969</td>\n",
       "      <td>0.763838</td>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721190</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.829091</td>\n",
       "      <td>0.668622</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.524540</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.734899</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.678967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.844704</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.507645</td>\n",
       "      <td>0.657426</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.774603</td>\n",
       "      <td>0.847321</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.695187</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.714754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.875788</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.631902</td>\n",
       "      <td>0.749091</td>\n",
       "      <td>0.837591</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.822321</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.476608</td>\n",
       "      <td>0.620952</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.522936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.887489</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.776386</td>\n",
       "      <td>0.841241</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.608365</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.690979</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877588</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.659509</td>\n",
       "      <td>0.759717</td>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.798214</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.325077</td>\n",
       "      <td>0.481651</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.436202</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.807971</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.714724</td>\n",
       "      <td>0.824779</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.737589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag threshold signal_abs_threshold smooth_rolling_window  acc_train_keras  \\\n",
       "39  36         2                    1                    24         0.860862   \n",
       "74  48         2                    0                    48         0.856886   \n",
       "79  48         2                    2                    36         0.884788   \n",
       "92  48         5                    0                    48         0.850585   \n",
       "54  36         5                    0                    24         0.844704   \n",
       "..  ..       ...                  ...                   ...              ...   \n",
       "64  36        10                    0                    36         0.875788   \n",
       "31  24        10                    1                    36         0.887489   \n",
       "70  36        10                    2                    36         0.877588   \n",
       "34  24        10                    2                    36         0.851485   \n",
       "86  48         3                    1                    48         0.910891   \n",
       "\n",
       "    prec_train_keras  rec_train_keras  f1_train_keras  acc_test_keras  \\\n",
       "39          0.921569         0.574924        0.708098        0.846995   \n",
       "74          0.956284         0.536810        0.687623        0.844891   \n",
       "79          0.958333         0.634969        0.763838        0.857664   \n",
       "92          0.939560         0.524540        0.673228        0.821168   \n",
       "54          0.932584         0.507645        0.657426        0.821494   \n",
       "..               ...              ...             ...             ...   \n",
       "64          0.919643         0.631902        0.749091        0.837591   \n",
       "31          0.931330         0.665644        0.776386        0.841241   \n",
       "70          0.895833         0.659509        0.759717        0.839416   \n",
       "34          0.930481         0.533742        0.678363        0.806569   \n",
       "86          0.974895         0.714724        0.824779        0.846715   \n",
       "\n",
       "    prec_test_keras  ...  rec_test_svc  f1_test_svc  acc_train_logreg  \\\n",
       "39         0.945055  ...      0.691358     0.764505          0.868750   \n",
       "74         0.945055  ...      0.650000     0.740506          0.853571   \n",
       "79         0.940000  ...      0.642384     0.721190          0.857143   \n",
       "92         0.935897  ...      0.628205     0.717949          0.858929   \n",
       "54         0.935065  ...      0.726190     0.774603          0.847321   \n",
       "..              ...  ...           ...          ...               ...   \n",
       "64         0.834783  ...      0.400000     0.550459          0.822321   \n",
       "31         0.826446  ...      0.479042     0.608365          0.856250   \n",
       "70         0.825000  ...      0.360947     0.523605          0.798214   \n",
       "34         0.806122  ...      0.387097     0.533333          0.818750   \n",
       "86         0.805970  ...      0.675000     0.744828          0.875000   \n",
       "\n",
       "    prec_train_logreg  rec_train_logreg  f1_train_logreg  acc_test_logreg  \\\n",
       "39           0.858824          0.663636         0.748718         0.867754   \n",
       "74           0.818966          0.608974         0.698529         0.836957   \n",
       "79           0.829091          0.668622         0.740260         0.858696   \n",
       "92           0.842308          0.651786         0.734899         0.842391   \n",
       "54           0.822785          0.601852         0.695187         0.842391   \n",
       "..                ...               ...              ...              ...   \n",
       "64           0.890710          0.476608         0.620952         0.811594   \n",
       "31           0.918367          0.553846         0.690979         0.811594   \n",
       "70           0.929204          0.325077         0.481651         0.797101   \n",
       "34           0.918750          0.436202         0.591549         0.807971   \n",
       "86           0.863636          0.686747         0.765101         0.865942   \n",
       "\n",
       "    prec_test_logreg  rec_test_logreg  f1_test_logreg  \n",
       "39          0.839695         0.679012        0.750853  \n",
       "74          0.851562         0.605556        0.707792  \n",
       "79          0.841121         0.596026        0.697674  \n",
       "92          0.800000         0.589744        0.678967  \n",
       "54          0.795620         0.648810        0.714754  \n",
       "..               ...              ...             ...  \n",
       "64          0.838235         0.380000        0.522936  \n",
       "31          0.838710         0.467066        0.600000  \n",
       "70          0.952381         0.355030        0.517241  \n",
       "34          0.855072         0.380645        0.526786  \n",
       "86          0.852459         0.650000        0.737589  \n",
       "\n",
       "[96 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>threshold</th>\n",
       "      <th>signal_abs_threshold</th>\n",
       "      <th>smooth_rolling_window</th>\n",
       "      <th>acc_train_keras</th>\n",
       "      <th>prec_train_keras</th>\n",
       "      <th>rec_train_keras</th>\n",
       "      <th>f1_train_keras</th>\n",
       "      <th>acc_test_keras</th>\n",
       "      <th>prec_test_keras</th>\n",
       "      <th>...</th>\n",
       "      <th>rec_test_svc</th>\n",
       "      <th>f1_test_svc</th>\n",
       "      <th>acc_train_logreg</th>\n",
       "      <th>prec_train_logreg</th>\n",
       "      <th>rec_train_logreg</th>\n",
       "      <th>f1_train_logreg</th>\n",
       "      <th>acc_test_logreg</th>\n",
       "      <th>prec_test_logreg</th>\n",
       "      <th>rec_test_logreg</th>\n",
       "      <th>f1_test_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.860862</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>0.708098</td>\n",
       "      <td>0.846995</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.748718</td>\n",
       "      <td>0.867754</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.750853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.856886</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.687623</td>\n",
       "      <td>0.844891</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.884788</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.634969</td>\n",
       "      <td>0.763838</td>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721190</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.829091</td>\n",
       "      <td>0.668622</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.524540</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.734899</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.678967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.844704</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.507645</td>\n",
       "      <td>0.657426</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.774603</td>\n",
       "      <td>0.847321</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.695187</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.714754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.875788</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.631902</td>\n",
       "      <td>0.749091</td>\n",
       "      <td>0.837591</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.822321</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.476608</td>\n",
       "      <td>0.620952</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.522936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.887489</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.776386</td>\n",
       "      <td>0.841241</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.608365</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.690979</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.877588</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.659509</td>\n",
       "      <td>0.759717</td>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.798214</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.325077</td>\n",
       "      <td>0.481651</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.436202</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.807971</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.714724</td>\n",
       "      <td>0.824779</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.737589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag threshold signal_abs_threshold smooth_rolling_window  acc_train_keras  \\\n",
       "39  36         2                    1                    24         0.860862   \n",
       "74  48         2                    0                    48         0.856886   \n",
       "79  48         2                    2                    36         0.884788   \n",
       "92  48         5                    0                    48         0.850585   \n",
       "54  36         5                    0                    24         0.844704   \n",
       "..  ..       ...                  ...                   ...              ...   \n",
       "64  36        10                    0                    36         0.875788   \n",
       "31  24        10                    1                    36         0.887489   \n",
       "70  36        10                    2                    36         0.877588   \n",
       "34  24        10                    2                    36         0.851485   \n",
       "86  48         3                    1                    48         0.910891   \n",
       "\n",
       "    prec_train_keras  rec_train_keras  f1_train_keras  acc_test_keras  \\\n",
       "39          0.921569         0.574924        0.708098        0.846995   \n",
       "74          0.956284         0.536810        0.687623        0.844891   \n",
       "79          0.958333         0.634969        0.763838        0.857664   \n",
       "92          0.939560         0.524540        0.673228        0.821168   \n",
       "54          0.932584         0.507645        0.657426        0.821494   \n",
       "..               ...              ...             ...             ...   \n",
       "64          0.919643         0.631902        0.749091        0.837591   \n",
       "31          0.931330         0.665644        0.776386        0.841241   \n",
       "70          0.895833         0.659509        0.759717        0.839416   \n",
       "34          0.930481         0.533742        0.678363        0.806569   \n",
       "86          0.974895         0.714724        0.824779        0.846715   \n",
       "\n",
       "    prec_test_keras  ...  rec_test_svc  f1_test_svc  acc_train_logreg  \\\n",
       "39         0.945055  ...      0.691358     0.764505          0.868750   \n",
       "74         0.945055  ...      0.650000     0.740506          0.853571   \n",
       "79         0.940000  ...      0.642384     0.721190          0.857143   \n",
       "92         0.935897  ...      0.628205     0.717949          0.858929   \n",
       "54         0.935065  ...      0.726190     0.774603          0.847321   \n",
       "..              ...  ...           ...          ...               ...   \n",
       "64         0.834783  ...      0.400000     0.550459          0.822321   \n",
       "31         0.826446  ...      0.479042     0.608365          0.856250   \n",
       "70         0.825000  ...      0.360947     0.523605          0.798214   \n",
       "34         0.806122  ...      0.387097     0.533333          0.818750   \n",
       "86         0.805970  ...      0.675000     0.744828          0.875000   \n",
       "\n",
       "    prec_train_logreg  rec_train_logreg  f1_train_logreg  acc_test_logreg  \\\n",
       "39           0.858824          0.663636         0.748718         0.867754   \n",
       "74           0.818966          0.608974         0.698529         0.836957   \n",
       "79           0.829091          0.668622         0.740260         0.858696   \n",
       "92           0.842308          0.651786         0.734899         0.842391   \n",
       "54           0.822785          0.601852         0.695187         0.842391   \n",
       "..                ...               ...              ...              ...   \n",
       "64           0.890710          0.476608         0.620952         0.811594   \n",
       "31           0.918367          0.553846         0.690979         0.811594   \n",
       "70           0.929204          0.325077         0.481651         0.797101   \n",
       "34           0.918750          0.436202         0.591549         0.807971   \n",
       "86           0.863636          0.686747         0.765101         0.865942   \n",
       "\n",
       "    prec_test_logreg  rec_test_logreg  f1_test_logreg  \n",
       "39          0.839695         0.679012        0.750853  \n",
       "74          0.851562         0.605556        0.707792  \n",
       "79          0.841121         0.596026        0.697674  \n",
       "92          0.800000         0.589744        0.678967  \n",
       "54          0.795620         0.648810        0.714754  \n",
       "..               ...              ...             ...  \n",
       "64          0.838235         0.380000        0.522936  \n",
       "31          0.838710         0.467066        0.600000  \n",
       "70          0.952381         0.355030        0.517241  \n",
       "34          0.855072         0.380645        0.526786  \n",
       "86          0.852459         0.650000        0.737589  \n",
       "\n",
       "[96 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_df.sort_values(by=['prec_test_keras'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487961c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28050393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab544762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
