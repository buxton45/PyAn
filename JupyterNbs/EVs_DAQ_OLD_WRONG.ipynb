{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f682a3cd",
   "metadata": {},
   "source": [
    "# MAIN ISSUE HERE:\n",
    "The manner in which TARF_CD==59 was excluded\n",
    "A premise can have multiple tariff codes.  Only removing entries where TARF_CD==59 left the other entries for the premise, which were not EV codes.\n",
    "Therefore, this essentially had the effect of sneaking EV premises into the non-EV sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444718d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "from Utilities_df import DFConstructType\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c07d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "660dd359",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "- TARF_CD==59\n",
    "    - submetered\n",
    "    - the main meter is accounting for the EV meter as well\n",
    "    - Both meters are fed from the same drop. \n",
    "    - If you wanted just the house load, you would need to subtract the EV meter. \n",
    "    - If the tariff says separately metered (donâ€™t think I included any) they are fed off separate drops and the main meter does not account the EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ea885",
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_trff_df = pd.read_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Tariff\\apc_tarf_EV.csv')\n",
    "imp_trff_df = pd.read_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Tariff\\imp_tarf_EV.csv')\n",
    "oh_trff_df = pd.read_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Tariff\\oh_tarf_EV.csv')\n",
    "pso_trff_df = pd.read_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Tariff\\pso_tarf_EV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4caeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apc_trff_df.shape[0])\n",
    "print(imp_trff_df.shape[0])\n",
    "print(oh_trff_df.shape[0])\n",
    "print(pso_trff_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b0c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "opco_trff_dfs = dict(\n",
    "    apc=apc_trff_df, \n",
    "    imp=imp_trff_df, \n",
    "    oh=oh_trff_df, \n",
    "    pso=pso_trff_df, \n",
    ")\n",
    "#-------------------------\n",
    "# Remove any entries where TARF_CD=59\n",
    "# Add 'opco' column\n",
    "# Make sure all PREM_NB values have 9 characters\n",
    "for opco_i in opco_trff_dfs.keys():\n",
    "    trff_df_i = opco_trff_dfs[opco_i]\n",
    "    trff_df_i = trff_df_i[trff_df_i['TARF_CD']!=59].copy()\n",
    "    #-----\n",
    "    trff_df_i['opco'] = opco_i\n",
    "    #-----\n",
    "    trff_df_i['PREM_NB'] = trff_df_i['PREM_NB'].astype(str)\n",
    "    trff_df_i['PREM_NB'] = trff_df_i['PREM_NB'].str.zfill(9)\n",
    "    #-----\n",
    "    opco_trff_dfs[opco_i] = trff_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89032261",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\Data'\n",
    "expand_time = pd.Timedelta('60 days')\n",
    "\n",
    "if not os.path.exists(save_dir_base):\n",
    "    os.makedirs(save_dir_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df643ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trff_dfs = pd.concat(list(opco_trff_dfs.values()))\n",
    "#-----\n",
    "all_trff_dfs_evs = all_trff_dfs[all_trff_dfs['EV']==1].copy()\n",
    "all_trff_dfs_non = all_trff_dfs[all_trff_dfs['EV']==0].copy()\n",
    "assert(all_trff_dfs.shape[0]==(all_trff_dfs_evs.shape[0]+all_trff_dfs_non.shape[0]))\n",
    "#-------------------------\n",
    "assert(all_trff_dfs_evs['PREM_NB'].nunique()==all_trff_dfs_evs['PREM_NB'].shape[0])\n",
    "#-----\n",
    "if all_trff_dfs_non['PREM_NB'].nunique()!=all_trff_dfs_non['PREM_NB'].shape[0]:\n",
    "    all_trff_dfs_non = all_trff_dfs_non.sort_values(by=['TARF_EFCT_TS'], ascending=False).groupby(['PREM_NB'], as_index=False, group_keys=False).first()\n",
    "assert(all_trff_dfs_non['PREM_NB'].nunique()==all_trff_dfs_non['PREM_NB'].shape[0])\n",
    "\n",
    "#--------------------------------------------------\n",
    "all_trff_dfs_evs['t_search_min'] = pd.to_datetime(all_trff_dfs_evs['TARF_EFCT_TS'])\n",
    "all_trff_dfs_evs['t_search_max'] = all_trff_dfs_evs['t_search_min'] + pd.Timedelta(expand_time)\n",
    "#-------------------------\n",
    "# For non-EV entries, collect events from the general time period as EVs\n",
    "# EVS_t_min = pd.to_datetime(all_trff_dfs_evs['TARF_EFCT_TS']).min()\n",
    "# EVS_t_max = pd.to_datetime(all_trff_dfs_evs['TARF_EFCT_TS']).max()\n",
    "# !!!!!!!!!!! Actually, cds_ds_db.ev_ami_final only contains data from 2022-04-01 to 2023-04-01!\n",
    "EVS_t_min = pd.to_datetime('2022-04-01')\n",
    "EVS_t_max = pd.to_datetime('2023-04-01')\n",
    "#-----\n",
    "all_trff_dfs_non[['t_search_min', 't_search_max']] = [\n",
    "    Utilities_dt.get_random_datetime_interval_between(EVS_t_min, EVS_t_max, pd.Timedelta(expand_time)) \n",
    "    for _ in range(all_trff_dfs_non.shape[0])\n",
    "]\n",
    "#--------------------------------------------------\n",
    "all_trff_dfs = pd.concat([all_trff_dfs_evs, all_trff_dfs_non])\n",
    "\n",
    "# So, I guess there are some premises with EV and non-EV tariffs.\n",
    "# If this is the case, keep only the EV tariff\n",
    "if all_trff_dfs['PREM_NB'].nunique()!=all_trff_dfs['PREM_NB'].shape[0]:\n",
    "    all_trff_dfs = all_trff_dfs.sort_values(by=['EV'], ascending=False).groupby(['PREM_NB'], as_index=False, group_keys=False).first()\n",
    "assert(all_trff_dfs['PREM_NB'].nunique()==all_trff_dfs['PREM_NB'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As noted above, cds_ds_db.ev_ami_final only contains data from 2022-04-01 to 2023-04-01!\n",
    "# Therefore, if any search times outside of this, reset them (this should only be the case for EVs)\n",
    "# I still want them to be set as close as possible to original values, so handle those before 2022-04-01\n",
    "#   and those after 2023-04-01 separately (don't want all to be exactly the same, hence the +=2*pd.Timedelta(expand_time))\n",
    "all_trff_dfs=all_trff_dfs.reset_index(drop=True)\n",
    "#-----\n",
    "t_search_min_col_idx = Utilities_df.find_idxs_in_highest_order_of_columns(all_trff_dfs, 't_search_min')\n",
    "t_search_max_col_idx = Utilities_df.find_idxs_in_highest_order_of_columns(all_trff_dfs, 't_search_max')\n",
    "assert(len(t_search_min_col_idx)==len(t_search_max_col_idx)==1)\n",
    "t_search_min_col_idx = t_search_min_col_idx[0]\n",
    "t_search_max_col_idx = t_search_max_col_idx[0]\n",
    "#-----\n",
    "for idx_i in range(all_trff_dfs.shape[0]):\n",
    "    if all_trff_dfs.iloc[idx_i]['t_search_min']<pd.to_datetime('2022-04-01'):\n",
    "        t_min_i, t_max_i = Utilities_dt.get_random_datetime_interval_between(\n",
    "            EVS_t_min, \n",
    "            EVS_t_min+2*pd.Timedelta(expand_time), \n",
    "            pd.Timedelta(expand_time)\n",
    "        ) \n",
    "        all_trff_dfs.iloc[idx_i, [t_search_min_col_idx, t_search_max_col_idx]] = t_min_i, t_max_i\n",
    "    elif all_trff_dfs.iloc[idx_i]['t_search_max']>pd.to_datetime('2023-04-01'):\n",
    "        t_min_i, t_max_i = Utilities_dt.get_random_datetime_interval_between(\n",
    "            EVS_t_max-2*pd.Timedelta(expand_time), \n",
    "            EVS_t_max, \n",
    "            pd.Timedelta(expand_time)\n",
    "        )\n",
    "        all_trff_dfs.iloc[idx_i, [t_search_min_col_idx, t_search_max_col_idx]] = t_min_i, t_max_i\n",
    "    else:\n",
    "        continue\n",
    "#-----\n",
    "assert(\n",
    "    all_trff_dfs[\n",
    "        (all_trff_dfs['t_search_min']<pd.to_datetime('2022-04-01')) | \n",
    "        (all_trff_dfs['t_search_max']>pd.to_datetime('2023-04-01'))\n",
    "    ].shape[0]==0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27551d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a23480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'#PNs:     {all_trff_dfs.shape[0]}')\n",
    "print(f'#EVs:     {all_trff_dfs[\"EV\"].sum()}')\n",
    "print(f'#not EVs: {(all_trff_dfs[\"EV\"]==0).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df59f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trff_dfs.to_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\EVs\\all_trff_dfs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2731f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "n_update=10\n",
    "for i, (idx_i, row_i) in enumerate(all_trff_dfs.iterrows()):\n",
    "    if i%n_update==0:\n",
    "        print(f\"{i}/{all_trff_dfs.shape[0]}\")\n",
    "    ami_i = AMINonVee(\n",
    "        df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "        build_sql_function_kwargs= dict(\n",
    "            cols_of_interest = ['*'], \n",
    "            premise_nbs = row_i['PREM_NB'],  \n",
    "            date_range = [\n",
    "                row_i['t_search_min'], \n",
    "                row_i['t_search_max']\n",
    "            ], \n",
    "            schema_name='cds_ds_db', \n",
    "            table_name='ev_ami_final'\n",
    "        ), \n",
    "        init_df_in_constructor=True\n",
    "    )\n",
    "    df_i = ami_i.df.copy()\n",
    "    df_i['opco'] = row_i['opco']\n",
    "    save_name_i = f\"{row_i['opco']}_{row_i['PREM_NB']}.csv\"\n",
    "    df_i.to_csv(os.path.join(save_dir_base, save_name_i), index=False)\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f455a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
