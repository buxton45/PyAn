{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30553584",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DOVSOutages.ipynb\n",
    "%run AMINonVee.ipynb\n",
    "%run AMINonVeeSQL.ipynb\n",
    "%run AMINonVeeCircuitSQL.ipynb\n",
    "%run MeterPremise.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bda34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6c10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb28dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae24304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d098d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed947977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_get_circuit_info_mp_sql():\n",
    "    # From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    # and ensure all of the listed serial numbers are on the same circuit\n",
    "    mp_sql_where = SQLWhere([dict(field_desc='mfr_devc_ser_nbr', comparison_operator='IN', value='({})', needs_quotes=False), \n",
    "\n",
    "                             dict(field_desc='circuit_nb', comparison_operator='IS NOT', value='NULL', needs_quotes=False), \n",
    "                             dict(field_desc='circuit_nb', comparison_operator='<>', value='', needs_quotes=True), \n",
    "\n",
    "                             dict(field_desc='circuit_nm', comparison_operator='IS NOT', value='NULL', needs_quotes=False), \n",
    "                             dict(field_desc='circuit_nm', comparison_operator='<>', value='', needs_quotes=True), \n",
    "\n",
    "                             dict(field_desc='station_nb', comparison_operator='IS NOT', value='NULL', needs_quotes=False), \n",
    "                             dict(field_desc='station_nb', comparison_operator='<>', value='', needs_quotes=True), \n",
    "\n",
    "                             dict(field_desc='station_nm', comparison_operator='IS NOT', value='NULL', needs_quotes=False), \n",
    "                             dict(field_desc='station_nm', comparison_operator='<>', value='', needs_quotes=True), \n",
    "                            ], \n",
    "                            idxs=None, run_check=True)\n",
    "    # The combine_where_elements have no practical effect, but I have included because\n",
    "    # they make the output string look better\n",
    "    mp_sql_where.combine_where_elements([1,2], 'AND', close_gaps_in_keys=False)\n",
    "    mp_sql_where.combine_where_elements([3,4], 'AND', close_gaps_in_keys=False)\n",
    "    mp_sql_where.combine_where_elements([5,6], 'AND', close_gaps_in_keys=False)\n",
    "    mp_sql_where.combine_where_elements([7,8], 'AND', close_gaps_in_keys=True)\n",
    "    #--------------------\n",
    "    mp_sql = SQLQuery(sql_select = SQLSelect(['DISTINCT circuit_nb,circuit_nm,station_nb,station_nm']), \n",
    "                      sql_from = SQLFrom('default', 'meter_premise'), \n",
    "                      sql_where = mp_sql_where \n",
    "                     )\n",
    "    return mp_sql\n",
    "\n",
    "\n",
    "def get_circuit_info(conn_aws, serial_numbers):\n",
    "    # From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    # and ensure all of the listed serial numbers are on the same circuit\n",
    "    mp_sql = build_get_circuit_info_mp_sql()\n",
    "    mp_sql_stmnt = mp_sql.get_sql_statement(insert_n_tabs_to_each_line=1).format(Utilities_sql.join_list_w_quotes(serial_numbers))\n",
    "    #--------------------\n",
    "    df_mp = pd.read_sql(mp_sql_stmnt, conn_aws)\n",
    "    assert(df_mp.shape[0]==1)\n",
    "    #--------------------\n",
    "    circuit_nb = df_mp.iloc[0]['circuit_nb']\n",
    "    circuit_nm = df_mp.iloc[0]['circuit_nm']\n",
    "    station_nb = df_mp.iloc[0]['station_nb']\n",
    "    station_nm = df_mp.iloc[0]['station_nm']\n",
    "    return dict(circuit_nb=circuit_nb, \n",
    "                circuit_nm=circuit_nm, \n",
    "                station_nb=station_nb, \n",
    "                station_nm=station_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ace3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377efd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26c3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trsf_pole_nbs_on_circuit(conn_aws, circuit_nb, circuit_nm, station_nb, station_nm):\n",
    "    mp_sql = SQLQuery(sql_select = SQLSelect(['DISTINCT trsf_pole_nb']), \n",
    "                      sql_from = SQLFrom('default', 'meter_premise'), \n",
    "                      sql_where = SQLWhere([dict(field_desc='circuit_nb', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                                            dict(field_desc='circuit_nm', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                                            dict(field_desc='station_nb', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                                            dict(field_desc='station_nm', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                                           ], \n",
    "                                           idxs=None, run_check=True) \n",
    "                     )\n",
    "    mp_sql_stmnt = mp_sql.get_sql_statement().format(circuit_nb, circuit_nm, station_nb, station_nm)\n",
    "    #--------------------\n",
    "    df_mp = pd.read_sql(mp_sql_stmnt, conn_aws)\n",
    "    trsf_pole_nbs = df_mp['trsf_pole_nb'].tolist()\n",
    "    return trsf_pole_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee01a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de11ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mp_sql_w_circuit_info_or_trsf_pole_nbs():\n",
    "    mp_sql_where = SQLWhere([dict(field_desc='circuit_nb', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                             dict(field_desc='circuit_nm', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                             dict(field_desc='station_nb', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                             dict(field_desc='station_nm', comparison_operator='=', value='{}', needs_quotes=True), \n",
    "                             dict(field_desc='trsf_pole_nb', comparison_operator='IN', value='({})', needs_quotes=False), \n",
    "                            ], \n",
    "                            idxs=None, run_check=True)\n",
    "    mp_sql_where.combine_where_elements(list(range(0,4)), 'AND', close_gaps_in_keys=False)\n",
    "    mp_sql_where.combine_where_elements([0,4], 'OR', close_gaps_in_keys=True)\n",
    "    #--------------------\n",
    "    mp_sql = SQLQuery(sql_select = SQLSelect(['mfr_devc_ser_nbr', 'trsf_pole_nb']), \n",
    "                      sql_from = SQLFrom('default', 'meter_premise'), \n",
    "                      sql_where = mp_sql_where \n",
    "                     )\n",
    "    return mp_sql\n",
    "\n",
    "def build_mp_sql_statement_w_circuit_info_or_trsf_pole_nbs(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                           trsf_pole_nbs, \n",
    "                                                           insert_n_tabs_to_each_line=1):\n",
    "    mp_sql = build_mp_sql_w_circuit_info_or_trsf_pole_nbs()\n",
    "    mp_sql_statement = mp_sql.get_sql_statement(insert_n_tabs_to_each_line=1).format(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                                                     Utilities_sql.join_list_w_quotes(trsf_pole_nbs))\n",
    "    return mp_sql_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646141cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0a97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a78f748",
   "metadata": {},
   "source": [
    "# FINDING OTHERS ON THE CIRCUIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8f92a",
   "metadata": {},
   "source": [
    "### OLD ORIGINAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcedea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sql_outage_others_on_circuit_1_0(conn_aws, dev_ser_nbrs, date_range, groupby_xfmr=False, verbose=True):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in dev_ser_nbrs, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    mp_where_str_1 = \"mfr_devc_ser_nbr IN ({})\".format(','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    sql_mp_1 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT circuit_nb,circuit_nm,station_nb,station_nm\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    AND circuit_nb IS NOT NULL AND circuit_nb <> ''\n",
    "    AND circuit_nm IS NOT NULL AND circuit_nm <> ''\n",
    "    AND station_nb IS NOT NULL AND station_nb <> ''\n",
    "    AND station_nm IS NOT NULL AND station_nm <> ''\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_1)\n",
    "    #--------------------\n",
    "    df_mp_1 = pd.read_sql(sql_mp_1, conn_aws)\n",
    "    assert(df_mp_1.shape[0]==1)\n",
    "    #--------------------\n",
    "    circuit_nb = df_mp_1.iloc[0]['circuit_nb']\n",
    "    circuit_nm = df_mp_1.iloc[0]['circuit_nm']\n",
    "    station_nb = df_mp_1.iloc[0]['station_nb']\n",
    "    station_nm = df_mp_1.iloc[0]['station_nm']\n",
    "    \n",
    "    # ********************** Step 2 **********************\n",
    "    mp_where_str_2 = (\n",
    "    f\"\"\"\n",
    "    circuit_nb = '{circuit_nb}'\n",
    "    AND circuit_nm = '{circuit_nm}'\n",
    "    AND station_nb = '{station_nb}'\n",
    "    AND station_nm = '{station_nm}'\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    sql_mp_2 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT trsf_pole_nb\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_2)\n",
    "    #--------------------\n",
    "    df_mp_2 = pd.read_sql(sql_mp_2, conn_aws)\n",
    "    trsf_pole_nbs = df_mp_2['trsf_pole_nb'].tolist()\n",
    "    \n",
    "    # ********************** Step 3 **********************\n",
    "    mp_where_str_3 = (\n",
    "    \"\"\"\n",
    "    (circuit_nb = '{}'\n",
    "    AND circuit_nm = '{}'\n",
    "    AND station_nb = '{}'\n",
    "    AND station_nm = '{}')\n",
    "    OR trsf_pole_nb IN ({})\n",
    "    \"\"\"\n",
    "    ).format(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "             ','.join([\"'{}'\".format(x) for x in trsf_pole_nbs]))\n",
    "    #--------------------\n",
    "    if groupby_xfmr:\n",
    "        groupby_xfmr_str = 'MP.trsf_pole_nb, '\n",
    "    else:\n",
    "        groupby_xfmr_str = ''    \n",
    "    #--------------------\n",
    "    sql = (\n",
    "    \"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "        SELECT mfr_devc_ser_nbr, trsf_pole_nb\n",
    "        FROM default.meter_premise\n",
    "        WHERE {0}\n",
    "    ), \n",
    "    U AS (\n",
    "        SELECT serialnumber, starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "               aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt, value\n",
    "        FROM usage_nonvee.reading_ivl_nonvee\n",
    "        WHERE aep_opco = 'oh'\n",
    "        AND aep_usage_dt BETWEEN {1} AND {2}\n",
    "    )\n",
    "\n",
    "    SELECT {3}U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, \n",
    "           U.aep_derived_uom, U.aep_srvc_qlty_idntfr, U.aep_usage_dt, \n",
    "           SUM(U.value) as value_sum, SUM(POWER(U.value, 2)) as value_sq_sum, \n",
    "           AVG(U.value) as value_mean, STDDEV_SAMP(U.value) as value_std, \n",
    "           COUNT(U.value) as counts, COUNT(*) as counts_including_null\n",
    "    FROM MP\n",
    "    INNER JOIN U\n",
    "    ON MP.mfr_devc_ser_nbr = U.serialnumber\n",
    "    WHERE U.serialnumber NOT IN ({4})\n",
    "    GROUP BY {3}U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, U.aep_derived_uom, U.aep_srvc_qlty_idntfr, U.aep_usage_dt\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_3, \n",
    "             f\"'{date_range[0]}'\",  \n",
    "             f\"'{date_range[1]}'\", \n",
    "             groupby_xfmr_str, \n",
    "             ','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print('sql_mp_1:\\n', sql_mp_1, '\\n\\n')\n",
    "        print('df_mp_1:\\n', df_mp_1)\n",
    "        print('sql_mp_2:\\n', sql_mp_2, '\\n\\n')\n",
    "        print('Final SQL Statement:\\n', sql)\n",
    "    #--------------------\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee319e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe this aggregates by transformer first, then aggreages all of those...\n",
    "def build_sql_outage_others_on_circuit_2_0(conn_aws, dev_ser_nbrs, date_range, verbose=True):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in dev_ser_nbrs, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    mp_where_str_1 = \"mfr_devc_ser_nbr IN ({})\".format(','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    sql_mp_1 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT circuit_nb,circuit_nm,station_nb,station_nm\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    AND circuit_nb IS NOT NULL AND circuit_nb <> ''\n",
    "    AND circuit_nm IS NOT NULL AND circuit_nm <> ''\n",
    "    AND station_nb IS NOT NULL AND station_nb <> ''\n",
    "    AND station_nm IS NOT NULL AND station_nm <> ''\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_1)\n",
    "    #--------------------\n",
    "    df_mp_1 = pd.read_sql(sql_mp_1, conn_aws)\n",
    "    assert(df_mp_1.shape[0]==1)\n",
    "    #--------------------\n",
    "    circuit_nb = df_mp_1.iloc[0]['circuit_nb']\n",
    "    circuit_nm = df_mp_1.iloc[0]['circuit_nm']\n",
    "    station_nb = df_mp_1.iloc[0]['station_nb']\n",
    "    station_nm = df_mp_1.iloc[0]['station_nm']\n",
    "\n",
    "    # ********************** Step 2 **********************\n",
    "    mp_where_str_2 = (\n",
    "    f\"\"\"\n",
    "    circuit_nb = '{circuit_nb}'\n",
    "    AND circuit_nm = '{circuit_nm}'\n",
    "    AND station_nb = '{station_nb}'\n",
    "    AND station_nm = '{station_nm}'\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    sql_mp_2 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT trsf_pole_nb\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_2)\n",
    "    #--------------------\n",
    "    df_mp_2 = pd.read_sql(sql_mp_2, conn_aws)\n",
    "    trsf_pole_nbs = df_mp_2['trsf_pole_nb'].tolist()\n",
    "\n",
    "    # ********************** Step 3 **********************\n",
    "    mp_where_str_3 = (\n",
    "    \"\"\"\n",
    "    (circuit_nb = '{}'\n",
    "    AND circuit_nm = '{}'\n",
    "    AND station_nb = '{}'\n",
    "    AND station_nm = '{}')\n",
    "    OR trsf_pole_nb IN ({})\n",
    "    \"\"\"\n",
    "    ).format(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "             ','.join([\"'{}'\".format(x) for x in trsf_pole_nbs]))   \n",
    "    #--------------------  \n",
    "    sql = (\n",
    "    \"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "        SELECT mfr_devc_ser_nbr, trsf_pole_nb\n",
    "        FROM default.meter_premise\n",
    "        WHERE {0}\n",
    "    ), \n",
    "    U AS (\n",
    "        SELECT serialnumber, starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "               aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt, value\n",
    "        FROM usage_nonvee.reading_ivl_nonvee\n",
    "        WHERE aep_opco = 'oh'\n",
    "        AND aep_usage_dt BETWEEN {1} AND {2}\n",
    "    ), \n",
    "    AGG1 AS (\n",
    "        SELECT MP.trsf_pole_nb, U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, \n",
    "               U.aep_derived_uom, U.aep_srvc_qlty_idntfr, U.aep_usage_dt, \n",
    "               SUM(U.value) as value_sum, SUM(POWER(U.value, 2)) as value_sq_sum, \n",
    "               AVG(U.value) as value_mean, STDDEV_SAMP(U.value) as value_std, \n",
    "               COUNT(U.value) as counts, COUNT(*) as counts_including_null\n",
    "        FROM MP\n",
    "        INNER JOIN U\n",
    "        ON MP.mfr_devc_ser_nbr = U.serialnumber\n",
    "        WHERE U.serialnumber NOT IN ({3})\n",
    "        GROUP BY MP.trsf_pole_nb, U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, \n",
    "                 U.aep_derived_uom, U.aep_srvc_qlty_idntfr, U.aep_usage_dt\n",
    "    )\n",
    "    SELECT starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "           aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt, \n",
    "           SUM(value_sum) AS sum_value_sum, AVG(value_sum) as mean_value_sum, \n",
    "           SUM(value_sq_sum) AS sum_value_sq_sum, AVG(value_sq_sum) as mean_value_sq_sum, \n",
    "           SUM(value_mean) AS sum_value_mean, AVG(value_mean) as mean_value_mean, \n",
    "           SUM(value_std) AS sum_value_std, AVG(value_std) as mean_value_std, \n",
    "           SUM(counts) AS sum_counts, AVG(counts) as mean_counts, \n",
    "           SUM(counts_including_null) AS sum_counts_including_null, AVG(counts_including_null) as mean_counts_including_null\n",
    "    FROM AGG1\n",
    "    GROUP BY starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "             aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_3, \n",
    "             f\"'{date_range[0]}'\",  \n",
    "             f\"'{date_range[1]}'\", \n",
    "             ','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print('sql_mp_1:\\n', sql_mp_1, '\\n\\n')\n",
    "        print('df_mp_1:\\n', df_mp_1)\n",
    "        print('sql_mp_2:\\n', sql_mp_2, '\\n\\n')\n",
    "        print('Final SQL Statement:\\n', sql)\n",
    "    #--------------------\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b73a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to build_sql_outage_others_on_circuit_3_0, but TOTAL kWh is calculated by first forming a \n",
    "# signed_value column which is negative when aep_srvc_qlty_idntfr='RECEIVED' and then aggregating\n",
    "# FOR NOW, this is also only for aep_derived_uom = 'KWH'\n",
    "def build_sql_outage_others_on_circuit_3_0(conn_aws, dev_ser_nbrs, date_range, verbose=True):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in dev_ser_nbrs, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from dev_ser_nbrs)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    mp_where_str_1 = \"mfr_devc_ser_nbr IN ({})\".format(','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    sql_mp_1 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT circuit_nb,circuit_nm,station_nb,station_nm\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    AND circuit_nb IS NOT NULL AND circuit_nb <> ''\n",
    "    AND circuit_nm IS NOT NULL AND circuit_nm <> ''\n",
    "    AND station_nb IS NOT NULL AND station_nb <> ''\n",
    "    AND station_nm IS NOT NULL AND station_nm <> ''\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_1)\n",
    "    #--------------------\n",
    "    df_mp_1 = pd.read_sql(sql_mp_1, conn_aws)\n",
    "    assert(df_mp_1.shape[0]==1)\n",
    "    #--------------------\n",
    "    circuit_nb = df_mp_1.iloc[0]['circuit_nb']\n",
    "    circuit_nm = df_mp_1.iloc[0]['circuit_nm']\n",
    "    station_nb = df_mp_1.iloc[0]['station_nb']\n",
    "    station_nm = df_mp_1.iloc[0]['station_nm']\n",
    "\n",
    "    # ********************** Step 2 **********************\n",
    "    mp_where_str_2 = (\n",
    "    f\"\"\"\n",
    "    circuit_nb = '{circuit_nb}'\n",
    "    AND circuit_nm = '{circuit_nm}'\n",
    "    AND station_nb = '{station_nb}'\n",
    "    AND station_nm = '{station_nm}'\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    sql_mp_2 = (\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT trsf_pole_nb\n",
    "    FROM default.meter_premise\n",
    "    WHERE {}\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_2)\n",
    "    #--------------------\n",
    "    df_mp_2 = pd.read_sql(sql_mp_2, conn_aws)\n",
    "    trsf_pole_nbs = df_mp_2['trsf_pole_nb'].tolist()\n",
    "\n",
    "    # ********************** Step 3 **********************\n",
    "    mp_where_str_3 = (\n",
    "    \"\"\"\n",
    "    (circuit_nb = '{}'\n",
    "    AND circuit_nm = '{}'\n",
    "    AND station_nb = '{}'\n",
    "    AND station_nm = '{}')\n",
    "    OR trsf_pole_nb IN ({})\n",
    "    \"\"\"\n",
    "    ).format(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "             ','.join([\"'{}'\".format(x) for x in trsf_pole_nbs]))   \n",
    "    #--------------------  \n",
    "    sql = (\n",
    "    \"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "        SELECT mfr_devc_ser_nbr, trsf_pole_nb\n",
    "        FROM default.meter_premise\n",
    "        WHERE {0}\n",
    "    ), \n",
    "    USG_W_SIGNED_VAL AS (\n",
    "        SELECT serialnumber, starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "               aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt, value, IF(aep_srvc_qlty_idntfr='RECEIVED', -1*value, value) as signed_value\n",
    "        FROM usage_nonvee.reading_ivl_nonvee\n",
    "        WHERE aep_opco = 'oh'\n",
    "        AND aep_derived_uom = 'KWH'\n",
    "        AND aep_usage_dt BETWEEN {1} AND {2}    \n",
    "    ), \n",
    "    U AS (\n",
    "        SELECT serialnumber, starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "               aep_derived_uom, aep_usage_dt, SUM(signed_value) as value\n",
    "        FROM USG_W_SIGNED_VAL\n",
    "        GROUP BY serialnumber, starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "                 aep_derived_uom, aep_usage_dt\n",
    "    ), \n",
    "    AGG1 AS (\n",
    "        SELECT MP.trsf_pole_nb, U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, \n",
    "               U.aep_derived_uom, U.aep_usage_dt, \n",
    "               SUM(U.value) as value_sum, SUM(POWER(U.value, 2)) as value_sq_sum, \n",
    "               AVG(U.value) as value_mean, STDDEV_SAMP(U.value) as value_std, \n",
    "               COUNT(U.value) as counts, COUNT(*) as counts_including_null\n",
    "        FROM MP\n",
    "        INNER JOIN U\n",
    "        ON MP.mfr_devc_ser_nbr = U.serialnumber\n",
    "        WHERE U.serialnumber NOT IN ({3})\n",
    "        GROUP BY MP.trsf_pole_nb, U.starttimeperiod, U.endtimeperiod, U.aep_endtime_utc, U.timezoneoffset, \n",
    "                 U.aep_derived_uom, U.aep_usage_dt\n",
    "    )\n",
    "    SELECT starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "           aep_derived_uom, aep_usage_dt, \n",
    "           SUM(value_sum) AS sum_value_sum, AVG(value_sum) as mean_value_sum, \n",
    "           SUM(value_sq_sum) AS sum_value_sq_sum, AVG(value_sq_sum) as mean_value_sq_sum, \n",
    "           SUM(value_mean) AS sum_value_mean, AVG(value_mean) as mean_value_mean, \n",
    "           SUM(value_std) AS sum_value_std, AVG(value_std) as mean_value_std, \n",
    "           SUM(counts) AS sum_counts, AVG(counts) as mean_counts, \n",
    "           SUM(counts_including_null) AS sum_counts_including_null, AVG(counts_including_null) as mean_counts_including_null\n",
    "    FROM AGG1\n",
    "    GROUP BY starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, \n",
    "             aep_derived_uom, aep_usage_dt\n",
    "    \"\"\"\n",
    "    ).format(mp_where_str_3, \n",
    "             f\"'{date_range[0]}'\",  \n",
    "             f\"'{date_range[1]}'\", \n",
    "             ','.join([\"'{}'\".format(x) for x in dev_ser_nbrs]))\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print('sql_mp_1:\\n', sql_mp_1, '\\n\\n')\n",
    "        print('df_mp_1:\\n', df_mp_1)\n",
    "        print('sql_mp_2:\\n', sql_mp_2, '\\n\\n')\n",
    "        print('Final SQL Statement:\\n', sql)\n",
    "    #--------------------\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "325ea0ae",
   "metadata": {},
   "source": [
    "### NEW FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3576018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#TODO PROBABLY MOVE TO SQLSelect.py\n",
    "#     OR MAYBE Utilities_sql.py\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def refine_agg_cols_and_types(agg_cols_and_types, try_to_split_col_strs=True):\n",
    "    # Change any string keys to SQLElement keys\n",
    "    # This makes it such that all keys in agg_cols_and_types are of type SQLElement.\n",
    "    # The input keys may be of type SQLElement or str (when simple column names).\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #\n",
    "    # NOTE: Cannot alter dict when iterating over dict\n",
    "    #       Therefore, one must iterate over a list of the keys\n",
    "    #         i.e. for col in list(agg_cols_and_types.keys())\n",
    "    #       Even if one defines keys = agg_cols_and_types.keys() beforehand,\n",
    "    #         and tries for col in keys, this will not work!\n",
    "    for col in list(agg_cols_and_types.keys()):\n",
    "        assert(isinstance(col, str) or isinstance(col, SQLElement))\n",
    "        if isinstance(col, str):\n",
    "            if try_to_split_col_strs:\n",
    "                components_dict = SQLElement.split_field_desc(col)\n",
    "                field_desc         = components_dict['field_desc']\n",
    "                table_alias_prefix = components_dict['table_alias_prefix']\n",
    "            else:\n",
    "                field_desc=col\n",
    "                table_alias_prefix=None\n",
    "            sql_el = SQLElement(field_desc=field_desc, \n",
    "                                table_alias_prefix=table_alias_prefix)\n",
    "            assert(sql_el not in agg_cols_and_types)\n",
    "            agg_cols_and_types[sql_el] = agg_cols_and_types[col]\n",
    "            del agg_cols_and_types[col]\n",
    "    return agg_cols_and_types\n",
    "\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#TODO PROBABLY MOVE TO SQLSelect.py\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def add_aggregate_elements_to_sql_select(sql_select, agg_cols_and_types, \n",
    "                                         try_to_split_col_strs=True, \n",
    "                                         include_counts_including_null=True, **kwargs):\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #---------------------\n",
    "    to_SQL_dict = {'sum':'SUM({})', \n",
    "                   'sq_sum':'SUM(POWER({}, 2))', \n",
    "                   'mean':'AVG({})', \n",
    "                   'std':'STDDEV_SAMP({})', \n",
    "                   'count':'COUNT({})'}\n",
    "    #---------------------\n",
    "    # Make all keys in agg_cols_and_types type SQLElement\n",
    "    agg_cols_and_types = refine_agg_cols_and_types(agg_cols_and_types, try_to_split_col_strs)\n",
    "    #---------------------\n",
    "    # If any of the aggregate columns (which, at this point, are all SQLElement objects) are found\n",
    "    # in the sql_select, remove them.\n",
    "    comp_alias = kwargs.get('comp_alias', False)\n",
    "    comp_table_alias_prefix = kwargs.get('comp_table_alias_prefix', True)\n",
    "    for sql_elm in agg_cols_and_types.keys():\n",
    "        found_idx = sql_select.find_idx_of_approx_element_in_collection_dict(sql_elm, \n",
    "                                                                             comp_alias=comp_alias, \n",
    "                                                                             comp_table_alias_prefix=comp_table_alias_prefix)\n",
    "        if found_idx > -1:\n",
    "            sql_select.remove_single_element_from_collection_at_idx(found_idx)\n",
    "    #---------------------\n",
    "    # Get new agg_cols with aliases\n",
    "    agg_sql_elements = [] \n",
    "    for col_el,agg_types in agg_cols_and_types.items():\n",
    "        for agg_type in agg_types:\n",
    "            field_desc_i = to_SQL_dict[agg_type].format(col_el.get_field_desc(include_table_alias_prefix=True))\n",
    "            #alias_i = f\"{col_el.get_field_desc(include_table_alias_prefix=False)}_{agg_type}\"\n",
    "            alias_i = f\"{agg_type}_{col_el.get_field_desc(include_table_alias_prefix=False)}\"\n",
    "            sql_el_i = SQLSelectElement(field_desc=field_desc_i, alias=alias_i, is_agg=True)\n",
    "            assert(sql_el_i not in agg_sql_elements)\n",
    "            agg_sql_elements.append(sql_el_i)\n",
    "    if include_counts_including_null:\n",
    "        agg_sql_elements.append(SQLSelectElement(field_desc='COUNT(*)', alias='counts_including_null', is_agg=True))\n",
    "    #---------------------\n",
    "    # Add new agg_cols with aliases (stored now in SQLSelectElement objects) to sql_select\n",
    "    sql_select.add_select_elements(agg_sql_elements, run_check=True)\n",
    "    #---------------------\n",
    "    return sql_select\n",
    "\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#TODO PROBABLY MOVE TO SQLSelect.py\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def build_aggregate_sql_select(field_descs, agg_cols_and_types, \n",
    "                               try_to_split_col_strs=True, \n",
    "                               global_table_alias_prefix=None, idxs=None, run_check=False, \n",
    "                               include_counts_including_null=True, \n",
    "                               **kwargs):\n",
    "    # field_descs, global_table_alias_prefix, idxs, run_check:\n",
    "    #   These are just as should be input into SQLSelect\n",
    "    #   i.e., field_descs should be a list of column names or a list of dict items, each with \n",
    "    #         possible keys 'field_desc', 'alias', 'table_alias_prefix'\n",
    "    #\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #---------------------\n",
    "    sql_select = SQLSelect(field_descs=field_descs, \n",
    "                           global_table_alias_prefix=global_table_alias_prefix, \n",
    "                           idxs=idxs, run_check=run_check)\n",
    "    sql_select = add_aggregate_elements_to_sql_select(sql_select=sql_select, \n",
    "                                                      agg_cols_and_types=agg_cols_and_types, \n",
    "                                                      try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                                      include_counts_including_null=include_counts_including_null, \n",
    "                                                      **kwargs) \n",
    "    return sql_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ffab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO BETTER NAME\n",
    "# TODO MAYBE RENAME global_table_alias_prefix to e.g. global_usg_table_alias_prefix?\n",
    "# TODO much other work to do as well here\n",
    "def build_agg_1_sql(field_descs, agg_cols_and_types, groupby_cols, groupby_xfmr, \n",
    "                    try_to_split_col_strs=True, global_table_alias_prefix='U', idxs=None, run_check=True, \n",
    "                    include_counts_including_null=True, **kwargs):\n",
    "    kwargs['comp_table_alias_prefix'] = kwargs.get('comp_table_alias_prefix', False)\n",
    "    #--------------------\n",
    "    agg_1_sql_select = build_aggregate_sql_select(field_descs=field_descs, \n",
    "                                                  agg_cols_and_types=agg_cols_and_types, \n",
    "                                                  try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                                  global_table_alias_prefix=global_table_alias_prefix, \n",
    "                                                  idxs=idxs, run_check=run_check, \n",
    "                                                  include_counts_including_null=include_counts_including_null, \n",
    "                                                  **kwargs)\n",
    "    if groupby_xfmr:\n",
    "        agg_1_sql_select.add_select_element(field_desc='trsf_pole_nb', alias=None, table_alias_prefix='MP', \n",
    "                                            idx=0, run_check=True)\n",
    "    #--------------------\n",
    "    agg_1_sql_join = SQLJoin(join_type='INNER', \n",
    "                             join_table='', \n",
    "                             join_table_alias='MP', \n",
    "                             orig_table_alias=global_table_alias_prefix, \n",
    "                             list_of_columns_to_join=[['serialnumber', 'mfr_devc_ser_nbr']])\n",
    "    #--------------------\n",
    "    agg_1_sql_groupby = SQLGroupBy(field_descs=groupby_cols, \n",
    "                                   global_table_alias_prefix=global_table_alias_prefix, \n",
    "                                   idxs=None, run_check=True)\n",
    "    if groupby_xfmr:\n",
    "        agg_1_sql_groupby.add_groupby_statement(field_desc='trsf_pole_nb', table_alias_prefix='MP', idx=0, run_check=True)\n",
    "    #--------------------\n",
    "    agg_1_sql = SQLQuery(sql_select = agg_1_sql_select, \n",
    "                         sql_from = SQLFrom(global_table_alias_prefix), \n",
    "                         sql_where = SQLWhere([dict(field_desc='serialnumber', comparison_operator='NOT IN', \n",
    "                                                    value=f'({Utilities_sql.join_list_w_quotes(serial_numbers)})', \n",
    "                                                    needs_quotes=False, table_alias_prefix=global_table_alias_prefix)]), \n",
    "                         sql_join_coll = agg_1_sql_join, \n",
    "                         sql_groupby=agg_1_sql_groupby)\n",
    "\n",
    "    return agg_1_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c2daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agg_rd2_sql(agg_1_sql, groupby_cols, agg_types_rd2=['sum', 'mean'], agg_1_table_alias='AGG1'):\n",
    "    # Below, I will set some of the table_alias_prefix to None\n",
    "    # So, the maintain the original agg_1_sql, make a deep copy\n",
    "    agg_1_sql_cpy = copy.deepcopy(agg_1_sql)\n",
    "    #-----\n",
    "    # Find aggregate elements (to be aggregated again) and \"normal elements\"\n",
    "    #   which are all elements which are not aggregate and not equal to 'trsf_pole_nb'\n",
    "    #   (which should be equal to groupby_cols)\n",
    "    agg_element_ids = agg_1_sql_cpy.sql_select.get_agg_element_ids()\n",
    "    normal_element_ids = [idx for idx,sql_el in agg_1_sql_cpy.sql_select.collection_dict.items() \n",
    "                          if (idx not in agg_element_ids and sql_el.field_desc != 'trsf_pole_nb')]\n",
    "    #-----\n",
    "    field_descs_normal = [agg_1_sql_cpy.sql_select.collection_dict[idx] \n",
    "                          for idx in normal_element_ids]\n",
    "    for fd in field_descs_normal:\n",
    "        fd.table_alias_prefix = None\n",
    "    #-----\n",
    "    agg_cols_and_types_rd2 = {}\n",
    "    for idx in agg_element_ids:\n",
    "        assert(agg_1_sql_cpy.sql_select.collection_dict[idx].alias not in agg_cols_and_types_rd2)\n",
    "        agg_cols_and_types_rd2[agg_1_sql_cpy.sql_select.collection_dict[idx].alias] = agg_types_rd2\n",
    "    #-----\n",
    "    sql_select_final = build_aggregate_sql_select(field_descs=field_descs_normal, \n",
    "                                                  agg_cols_and_types=agg_cols_and_types_rd2, \n",
    "                                                  include_counts_including_null=False)\n",
    "    sql_groupby_final = SQLGroupBy(field_descs=groupby_cols, global_table_alias_prefix=None, idxs=None, run_check=True)\n",
    "    sql_partial = SQLQuery(sql_select=sql_select_final, \n",
    "                           sql_from = SQLFrom(agg_1_table_alias), \n",
    "                           sql_where = None, \n",
    "                           sql_groupby=sql_groupby_final)    \n",
    "    return sql_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0762cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_usg_w_signed_val_sql(cols_of_interest_usage):\n",
    "    usg_w_signed_val_sql_select = SQLSelect(cols_of_interest_usage)\n",
    "    usg_w_signed_val_sql_select.add_select_element(field_desc=\"IF(aep_srvc_qlty_idntfr='RECEIVED', -1*value, value)\", alias=\"signed_value\")\n",
    "    usg_w_signed_val_sql = SQLQuery(sql_select = usg_w_signed_val_sql_select, \n",
    "                                    sql_from = SQLFrom('usage_nonvee', 'reading_ivl_nonvee'), \n",
    "                                    sql_where = SQLWhere([dict(field_desc='aep_opco', comparison_operator='=', value='oh', needs_quotes=True), \n",
    "                                                          dict(field_desc='aep_derived_uom', comparison_operator='=', value='KWH', needs_quotes=True), \n",
    "                                                          dict(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                               value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "                                                         ], idxs=None, run_check=True)\n",
    "                                   )\n",
    "    return usg_w_signed_val_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b5511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a2ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO cols_of_interest_usage used!!!! BUT NOT AN INPUT TO FUNCTION!!!!!\n",
    "def build_sql_outage_others_on_circuit_1(conn_aws, serial_numbers, date_range, \n",
    "                                       field_descs, agg_cols_and_types, groupby_cols, \n",
    "                                       try_to_split_col_strs=True, \n",
    "                                       groupby_xfmr=False, verbose=True, \n",
    "                                       include_counts_including_null=True, \n",
    "                                       **kwargs):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    # field_descs:\n",
    "    #   This is just as should be input into SQLSelect\n",
    "    #   i.e., field_descs should be a list of column names or a list of dict items, each with \n",
    "    #         possible keys 'field_desc', 'alias', 'table_alias_prefix'\n",
    "    #\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #\n",
    "    # groupby_cols:\n",
    "    #   should be columns from usage_nonvee.reading_ivl_nonvee.\n",
    "    #   SHOULD NOT contain 'trsf_pole_nb', as this will be added where needed.\n",
    "    #     (if 'trsf_pole_nb' in groupby_cols, it will simply be removed)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    circuit_info = get_circuit_info(conn_aws, serial_numbers)\n",
    "    circuit_nb = circuit_info['circuit_nb']\n",
    "    circuit_nm = circuit_info['circuit_nm']\n",
    "    station_nb = circuit_info['station_nb']\n",
    "    station_nm = circuit_info['station_nm']\n",
    "    \n",
    "    # ********************** Step 2 **********************\n",
    "    trsf_pole_nbs = get_trsf_pole_nbs_on_circuit(conn_aws, circuit_nb, circuit_nm, station_nb, station_nm)\n",
    "    \n",
    "    # ********************** Step 3 **********************\n",
    "    mp_sql_stmnt = build_mp_sql_statement_w_circuit_info_or_trsf_pole_nbs(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                                          trsf_pole_nbs, \n",
    "                                                                          insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    cols_of_interest_usage = []\n",
    "    for x in field_descs:\n",
    "        if isinstance(x, str):\n",
    "            cols_of_interest_usage.append(x)\n",
    "        elif isinstance(x, dict):\n",
    "            cols_of_interest_usage.append(x[field_desc])\n",
    "        elif isinstance(x, SQLElement):\n",
    "            cols_of_interest_usage.append(x.field_desc)\n",
    "        else:\n",
    "            assert(0)\n",
    "    assert('serialnumber' not in cols_of_interest_usage)\n",
    "    cols_of_interest_usage= ['serialnumber'] + cols_of_interest_usage\n",
    "    usg_sql = build_sql_usg(cols_of_interest_usage=cols_of_interest_usage, serial_numbers=[], date_range=date_range)\n",
    "    usg_sql.sql_where.find_and_remove_approx_element_in_collection_dict(SQLWhereElement('serialnumber', comparison_operator='', value=''))\n",
    "    usg_sql_stmnt = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    if 'trsf_pole_nb' in groupby_cols:\n",
    "        _ = groupby_cols.pop(groupby_cols.index('trsf_pole_nb'))\n",
    "    agg_1_sql = build_agg_1_sql(field_descs=field_descs, \n",
    "                                agg_cols_and_types=agg_cols_and_types, \n",
    "                                groupby_cols=groupby_cols, \n",
    "                                groupby_xfmr=groupby_xfmr, \n",
    "                                try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                global_table_alias_prefix='U', \n",
    "                                idxs=None, run_check=True, \n",
    "                                include_counts_including_null=include_counts_including_null, \n",
    "                                **kwargs)\n",
    "    agg_1_sql_stmnt = agg_1_sql.get_sql_statement()\n",
    "    #-------------------------------------\n",
    "    sql_full_stmnt = f\"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "    {mp_sql_stmnt}\n",
    "    ), \n",
    "    U AS (\n",
    "    {usg_sql_stmnt}\n",
    "    )\n",
    "\n",
    "    {agg_1_sql_stmnt}\n",
    "    \"\"\"\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print(sql_full_stmnt)\n",
    "    #--------------------\n",
    "    return sql_full_stmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d06572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO cols_of_interest_usage used!!!! BUT NOT AN INPUT TO FUNCTION!!!!!\n",
    "# I believe this aggregates by transformer first, then aggreages all of those...\n",
    "def build_sql_outage_others_on_circuit_2(conn_aws, serial_numbers, date_range, \n",
    "                                         field_descs, agg_cols_and_types, groupby_cols, \n",
    "                                         try_to_split_col_strs=True, \n",
    "                                         verbose=True, \n",
    "                                         include_counts_including_null=True, \n",
    "                                         **kwargs):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    # field_descs:\n",
    "    #   This is just as should be input into SQLSelect\n",
    "    #   i.e., field_descs should be a list of column names or a list of dict items, each with \n",
    "    #         possible keys 'field_desc', 'alias', 'table_alias_prefix'\n",
    "    #\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #\n",
    "    # groupby_cols:\n",
    "    #   should be columns from usage_nonvee.reading_ivl_nonvee.\n",
    "    #   SHOULD NOT contain 'trsf_pole_nb', as this will be added where needed.\n",
    "    #     (if 'trsf_pole_nb' in groupby_cols, it will simply be removed)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    circuit_info = get_circuit_info(conn_aws, serial_numbers)\n",
    "    circuit_nb = circuit_info['circuit_nb']\n",
    "    circuit_nm = circuit_info['circuit_nm']\n",
    "    station_nb = circuit_info['station_nb']\n",
    "    station_nm = circuit_info['station_nm']\n",
    "    \n",
    "    # ********************** Step 2 **********************\n",
    "    trsf_pole_nbs = get_trsf_pole_nbs_on_circuit(conn_aws, circuit_nb, circuit_nm, station_nb, station_nm)\n",
    "    \n",
    "    # ********************** Step 3 **********************\n",
    "    mp_sql_stmnt = build_mp_sql_statement_w_circuit_info_or_trsf_pole_nbs(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                                          trsf_pole_nbs, \n",
    "                                                                          insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    cols_of_interest_usage = []\n",
    "    for x in field_descs:\n",
    "        if isinstance(x, str):\n",
    "            cols_of_interest_usage.append(x)\n",
    "        elif isinstance(x, dict):\n",
    "            cols_of_interest_usage.append(x[field_desc])\n",
    "        elif isinstance(x, SQLElement):\n",
    "            cols_of_interest_usage.append(x.field_desc)\n",
    "        else:\n",
    "            assert(0)\n",
    "    assert('serialnumber' not in cols_of_interest_usage)\n",
    "    cols_of_interest_usage= ['serialnumber'] + cols_of_interest_usage\n",
    "    usg_sql = build_sql_usg(cols_of_interest_usage=cols_of_interest_usage, serial_numbers=[], date_range=date_range)\n",
    "    usg_sql.sql_where.find_and_remove_approx_element_in_collection_dict(SQLWhereElement('serialnumber', comparison_operator='', value=''))\n",
    "    usg_sql_stmnt = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    if 'trsf_pole_nb' in groupby_cols:\n",
    "        _ = groupby_cols.pop(groupby_cols.index('trsf_pole_nb'))\n",
    "    agg_1_sql = build_agg_1_sql(field_descs=field_descs, \n",
    "                                agg_cols_and_types=agg_cols_and_types, \n",
    "                                groupby_cols=groupby_cols, \n",
    "                                groupby_xfmr=True, \n",
    "                                try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                global_table_alias_prefix='U', \n",
    "                                idxs=None, run_check=True, \n",
    "                                include_counts_including_null=include_counts_including_null, \n",
    "                                **kwargs)\n",
    "    agg_1_sql_stmnt = agg_1_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    agg_types_rd2 = ['sum', 'mean']\n",
    "    agg_rd2_sql = build_agg_rd2_sql(agg_1_sql, groupby_cols, agg_types_rd2=agg_types_rd2, agg_1_table_alias='AGG1')\n",
    "    agg_rd2_sql_statement = agg_rd2_sql.get_sql_statement()\n",
    "    #-------------------------------------\n",
    "    sql_full_stmnt = f\"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "    {mp_sql_stmnt}\n",
    "    ), \n",
    "    U AS (\n",
    "    {usg_sql_stmnt}\n",
    "    ), \n",
    "    AGG1 AS (\n",
    "    {agg_1_sql_stmnt}\n",
    "    )\n",
    "\n",
    "    {agg_rd2_sql_statement}\n",
    "    \"\"\"\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print(sql_full_stmnt)\n",
    "    #--------------------\n",
    "    return sql_full_stmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a6d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO cols_of_interest_usage used!!!! BUT NOT AN INPUT TO FUNCTION!!!!!\n",
    "# Similar to build_sql_outage_others_on_circuit_3_0, but TOTAL kWh is calculated by first forming a \n",
    "# signed_value column which is negative when aep_srvc_qlty_idntfr='RECEIVED' and then aggregating\n",
    "# FOR NOW, this is also only for aep_derived_uom = 'KWH'\n",
    "def build_sql_outage_others_on_circuit_3(conn_aws, serial_numbers, date_range, \n",
    "                                         field_descs, agg_cols_and_types, groupby_cols, \n",
    "                                         try_to_split_col_strs=True, \n",
    "                                         verbose=True, \n",
    "                                         include_counts_including_null=True, \n",
    "                                         **kwargs):\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    # field_descs:\n",
    "    #   This is just as should be input into SQLSelect\n",
    "    #   i.e., field_descs should be a list of column names or a list of dict items, each with \n",
    "    #         possible keys 'field_desc', 'alias', 'table_alias_prefix'\n",
    "    #\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #\n",
    "    # groupby_cols:\n",
    "    #   should be columns from usage_nonvee.reading_ivl_nonvee.\n",
    "    #   SHOULD NOT contain 'trsf_pole_nb', as this will be added where needed.\n",
    "    #     (if 'trsf_pole_nb' in groupby_cols, it will simply be removed)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    circuit_info = get_circuit_info(conn_aws, serial_numbers)\n",
    "    circuit_nb = circuit_info['circuit_nb']\n",
    "    circuit_nm = circuit_info['circuit_nm']\n",
    "    station_nb = circuit_info['station_nb']\n",
    "    station_nm = circuit_info['station_nm']\n",
    "    \n",
    "    # ********************** Step 2 **********************\n",
    "    trsf_pole_nbs = get_trsf_pole_nbs_on_circuit(conn_aws, circuit_nb, circuit_nm, station_nb, station_nm)\n",
    "    \n",
    "    # ********************** Step 3 **********************\n",
    "    mp_sql_stmnt = build_mp_sql_statement_w_circuit_info_or_trsf_pole_nbs(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                                          trsf_pole_nbs, \n",
    "                                                                          insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    cols_of_interest_usage = []\n",
    "    for x in field_descs:\n",
    "        if isinstance(x, str):\n",
    "            cols_of_interest_usage.append(x)\n",
    "        elif isinstance(x, dict):\n",
    "            cols_of_interest_usage.append(x[field_desc])\n",
    "        elif isinstance(x, SQLElement):\n",
    "            cols_of_interest_usage.append(x.field_desc)\n",
    "        else:\n",
    "            assert(0)\n",
    "    assert('serialnumber' not in cols_of_interest_usage)\n",
    "    cols_of_interest_usage= ['serialnumber'] + cols_of_interest_usage\n",
    "    #--------------------\n",
    "    usg_w_signed_val_sql=build_usg_w_signed_val_sql(cols_of_interest_usage)\n",
    "    usg_w_signed_val_sql_stmnt = usg_w_signed_val_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    usg_sql_select = SQLSelect(cols_of_interest_usage)\n",
    "    # Instead of value, want SUM(signed_value) AS value\n",
    "    value_idx = usg_sql_select.find_idx_of_approx_element_in_collection_dict(SQLSelectElement('value'))\n",
    "    usg_sql_select.remove_single_element_from_collection_at_idx(value_idx)\n",
    "    usg_sql_select.add_select_element(field_desc='SUM(signed_value)', alias='value')\n",
    "    # Going to sum over aep_srvc_qlty_idntfr, (by excluding from groupby) so don't want it in selection anymore\n",
    "    aep_srvc_qlty_idntfr_idx = usg_sql_select.find_idx_of_approx_element_in_collection_dict(SQLSelectElement('aep_srvc_qlty_idntfr'))\n",
    "    usg_sql_select.remove_single_element_from_collection_at_idx(aep_srvc_qlty_idntfr_idx)\n",
    "    #-----\n",
    "    usg_sql_groupby = SQLGroupBy(field_descs=['serialnumber'] + [x for x in groupby_cols if x != 'aep_srvc_qlty_idntfr'], \n",
    "                                 global_table_alias_prefix=None, idxs=None, run_check=True)\n",
    "    #-----\n",
    "    usg_sql = SQLQuery(sql_select = usg_sql_select, \n",
    "                       sql_from = SQLFrom(table_name='USG_W_SIGNED_VAL'), \n",
    "                       sql_where = SQLWhere([dict(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                  value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "                                            ], idxs=None, run_check=True), \n",
    "                       sql_groupby = usg_sql_groupby\n",
    "                     )\n",
    "    usg_sql_stmnt = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    if 'trsf_pole_nb' in groupby_cols:\n",
    "        _ = groupby_cols.pop(groupby_cols.index('trsf_pole_nb'))\n",
    "    agg_1_sql = build_agg_1_sql(field_descs=field_descs, \n",
    "                                agg_cols_and_types=agg_cols_and_types, \n",
    "                                groupby_cols=groupby_cols, \n",
    "                                groupby_xfmr=True, \n",
    "                                try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                global_table_alias_prefix='U', \n",
    "                                idxs=None, run_check=True, \n",
    "                                include_counts_including_null=include_counts_including_null, \n",
    "                                **kwargs)\n",
    "    # aep_srvc_qlty_idntfr was summed over, so should no longer be included\n",
    "    aep_srvc_qlty_idntfr_idx = agg_1_sql.sql_select.find_idx_of_approx_element_in_collection_dict(SQLSelectElement('aep_srvc_qlty_idntfr'))\n",
    "    if aep_srvc_qlty_idntfr_idx > -1:\n",
    "        agg_1_sql.sql_select.remove_single_element_from_collection_at_idx(aep_srvc_qlty_idntfr_idx)\n",
    "    # aep_srvc_qlty_idntfr was summed over, so should no longer be included\n",
    "    aep_srvc_qlty_idntfr_idx = agg_1_sql.sql_groupby.find_idx_of_approx_element_in_collection_dict(SQLGroupByElement('aep_srvc_qlty_idntfr'))\n",
    "    if aep_srvc_qlty_idntfr_idx > -1:\n",
    "        agg_1_sql.sql_groupby.remove_single_element_from_collection_at_idx(aep_srvc_qlty_idntfr_idx)\n",
    "    agg_1_sql_stmnt = agg_1_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    #--------------------\n",
    "    agg_types_rd2 = ['sum', 'mean']\n",
    "    agg_rd2_sql = build_agg_rd2_sql(agg_1_sql, groupby_cols, agg_types_rd2=agg_types_rd2, agg_1_table_alias='AGG1')\n",
    "    # aep_srvc_qlty_idntfr was summed over, so should no longer be included\n",
    "    aep_srvc_qlty_idntfr_idx = agg_rd2_sql.sql_groupby.find_idx_of_approx_element_in_collection_dict(SQLGroupByElement('aep_srvc_qlty_idntfr'))\n",
    "    if aep_srvc_qlty_idntfr_idx > -1:\n",
    "        agg_rd2_sql.sql_groupby.remove_single_element_from_collection_at_idx(aep_srvc_qlty_idntfr_idx)    \n",
    "    agg_rd2_sql_statement = agg_rd2_sql.get_sql_statement()\n",
    "    #-------------------------------------\n",
    "    sql_full_stmnt = f\"\"\"\n",
    "    WITH MP\n",
    "    AS (\n",
    "    {mp_sql_stmnt}\n",
    "    ), \n",
    "    USG_W_SIGNED_VAL AS (\n",
    "    {usg_w_signed_val_sql_stmnt}\n",
    "    ), \n",
    "    U AS (\n",
    "    {usg_sql_stmnt}\n",
    "    ), \n",
    "    AGG1 AS (\n",
    "    {agg_1_sql_stmnt}\n",
    "    )\n",
    "\n",
    "    {agg_rd2_sql_statement}\n",
    "    \"\"\"\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print(sql_full_stmnt)\n",
    "    #--------------------\n",
    "    return sql_full_stmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7fef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "920bd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_usg_kwh_net_or_total_sql_statementOLD(usg_sql_dict, final_table_alias='USG_KWH', \n",
    "                                                insert_n_tabs_to_each_line=1, prepend_with_to_stmnt=False):\n",
    "    assert('usg_w_signed_val_sql'  in usg_sql_dict)\n",
    "    assert('usg_w_net_value_sql'   in usg_sql_dict)\n",
    "    assert('usg_w_total_value_sql' in usg_sql_dict)\n",
    "    assert('usg_wnv_union_wtv_sql' in usg_sql_dict)\n",
    "    assert('usg_sql'               in usg_sql_dict)\n",
    "    #-----\n",
    "    usg_w_signed_val_sql  = usg_sql_dict['usg_w_signed_val_sql']\n",
    "    usg_w_net_value_sql   = usg_sql_dict['usg_w_net_value_sql']\n",
    "    usg_w_total_value_sql = usg_sql_dict['usg_w_total_value_sql']\n",
    "    usg_wnv_union_wtv_sql = usg_sql_dict['usg_wnv_union_wtv_sql']\n",
    "    usg_sql               = usg_sql_dict['usg_sql']\n",
    "    #-----\n",
    "    usg_w_signed_val_sql_stmnt  = usg_w_signed_val_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    usg_w_net_value_sql_stmnt   = usg_w_net_value_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    usg_w_total_value_sql_stmnt = usg_w_total_value_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    usg_wnv_union_wtv_sql_stmnt = usg_wnv_union_wtv_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    usg_sql_stmnt               = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    #-----\n",
    "    if prepend_with_to_stmnt:\n",
    "        sql_full_stmnt = \"WITH \"\n",
    "    else:\n",
    "        sql_full_stmnt = \"\"\n",
    "    sql_full_stmnt += f\"USG_W_SIGNED_VAL AS (\\n{usg_w_signed_val_sql_stmnt}\\n), \"\\\n",
    "    f\"\\nUSG_W_NET_VAL AS (\\n{usg_w_net_value_sql_stmnt}\\n), \"\\\n",
    "    f\"\\nUSG_W_TOTAL_VAL AS (\\n{usg_w_total_value_sql_stmnt}\\n), \"\\\n",
    "    f\"\\nUSG_W_NET_VAL_UNION_USG_W_TOTAL_VAL AS (\\n{usg_wnv_union_wtv_sql_stmnt}\\n), \"\\\n",
    "    f\"\\n{final_table_alias} AS (\\n{usg_sql_stmnt}\\n)\"\n",
    "    return sql_full_stmnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bae9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_usg_kwh_net_or_totalOLD(cols_of_interest_usage, \n",
    "                               date_range, \n",
    "                               serial_numbers, \n",
    "                               additional_derived_uoms=None, \n",
    "                               run_careful=True, \n",
    "                               value_col='value', \n",
    "                               aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                               serialnumber_col='serialnumber', \n",
    "                               return_statement=True, \n",
    "                               final_table_alias='USG_KWH', \n",
    "                               insert_n_tabs_to_each_line=1, \n",
    "                               prepend_with_to_stmnt=False, \n",
    "                               **kwargs):\n",
    "    r\"\"\"\n",
    "    additional_derived_uoms:\n",
    "      - additional_derived_uoms can take on any form acceptable for the aep_derived_uoms input parameter\n",
    "          in build_sql_usg (reproduced below).\n",
    "      - ADDITIONALLY, additional_derived_uoms may equal the string 'ALL'\n",
    "          If additional_derived_uoms=='ALL', then the net kWh table will be combine with\n",
    "          aep_derived_uoms of all OTHER types (exclduing, of course, 'KWH', as this is handled in\n",
    "          the rest of this function!)\n",
    "    \n",
    "    *** from build_sql_usg ***\n",
    "    aep_derived_uoms should be a list whose elements are of type:\n",
    "      i.   string, equal to a aep_derived_uom \n",
    "               e.g. aep_derived_uoms = ['KVARH', 'KVAH']\n",
    "      ii.  tuple, equal to [aep_derived_uom, aep_srvc_qlty_idntfr] pair, in that order\n",
    "               e.g. aep_derived_uoms = [['VOLT', 'AVG']]\n",
    "      iii. dict with keys equal to aep_derived_uom, aep_srvc_qlty_idntfr\n",
    "               e.g. aep_derived_uoms = [dict(aep_derived_uom='VOLT', aep_srvc_qlty_idntfr='AVG')]\n",
    "      iv.  any combination of the aboe\n",
    "               e.g. aep_derived_uoms = ['KVARH', ['VOLT', 'AVG'], \n",
    "                                        dict(aep_derived_uom='KVAH', aep_srvc_qlty_idntfr='DELIVERED')]\n",
    "    \"\"\"\n",
    "    # See build_sql_usg for information about additional_derived_uoms\n",
    "    # FOR UNION TO WORK, NEED TO BE CAREFUL AND ENSURE COLUMNS ARE EXACTLY THE SAME AS ARE THEIR ORDERS!\n",
    "    usg_w_signed_val_sql=build_usg_w_signed_val_sql(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                                    date_range=date_range, \n",
    "                                                    serial_numbers=serial_numbers)\n",
    "    #------------------------------------------------------------\n",
    "    # WHERE statements already handled in usg_w_signed_val_sql\n",
    "    # Therefore, not needed here in usg_w_net_value_sql\n",
    "    usg_w_net_value_sql = build_usg_w_net_value_sql(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                                    date_range=None, \n",
    "                                                    serial_numbers=None, \n",
    "                                                    value_col=value_col, \n",
    "                                                    aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                                    serialnumber_col=serialnumber_col, \n",
    "                                                    usg_w_signed_val_table_name='USG_W_SIGNED_VAL', \n",
    "                                                    sum_signed_val_col='signed_value', \n",
    "                                                    sum_signed_val_alias=None, \n",
    "                                                    new_const_aep_srvc_qlty_idntfr_val='DEL_MINUS_REC')\n",
    "    #------------------------------------------------------------\n",
    "    usg_w_total_value_sql = build_usg_w_total_val_sql(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                                      serial_numbers=serial_numbers)\n",
    "    #------------------------------------------------------------\n",
    "    # Create union of usg_w_net_value_sql and usg_w_total_value_sql\n",
    "    # This will be aggregated to calculate the final net values\n",
    "    #   - Remember, from what I have seen so far, entries either have\n",
    "    #      'RECEIVED' and 'DELIVERED' OR 'RECEIVED' and 'TOTAL'\n",
    "    #   - usg_w_net_value_sql combined any entries with 'RECEIVED' and 'DELIVERED'\n",
    "    #   - usg_w_total_value_sql kept only 'TOTAL' entries (while discarding 'RECEIVED' for these pairs)\n",
    "    # So, the procedure here allows for the case where the sample contains entires of both types\n",
    "    #   'RECEIVED'/'DELIVERED' and 'RECEIVED'/'TOTAL'\n",
    "    #\n",
    "    # NOTE: easier to do SELECT *, but better to do it this way\n",
    "    #       because it is important columns are exactly the same in unions.\n",
    "    #       Especially important if including any additional unions here\n",
    "    sub_query_usg_wnv = SQLQuery(sql_select = SQLSelect(cols_of_interest_usage), \n",
    "                                 sql_from = SQLFrom(table_name='USG_W_NET_VAL'), \n",
    "                                 sql_where = None)\n",
    "\n",
    "    sub_query_usg_wtv = SQLQuery(sql_select = SQLSelect(cols_of_interest_usage), \n",
    "                                 sql_from = SQLFrom(table_name='USG_W_TOTAL_VAL'), \n",
    "                                 sql_where = None)\n",
    "    #-------------------------\n",
    "    sub_query_stmnt = f\"(\\n{sub_query_usg_wnv.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)}\\n)\" \\\n",
    "                      f\"\\nUNION\\n\" \\\n",
    "                      f\"(\\n{sub_query_usg_wtv.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)}\\n)\"\n",
    "    #-------------------------\n",
    "    if additional_derived_uoms == 'ALL':\n",
    "        additional_sql = build_sql_usg(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                       serial_numbers=serial_numbers, \n",
    "                                       date_range=date_range, \n",
    "                                       aep_derived_uoms=None, \n",
    "                                       kwh_and_vlt_only=False, \n",
    "                                       aep_opco=kwargs.get('aep_opco', None), \n",
    "                                       schema_name=kwargs.get('schema_name', 'usage_nonvee'), \n",
    "                                       table_name=kwargs.get('table_name', 'reading_ivl_nonvee'), \n",
    "                                       serialnumber_col=serialnumber_col, \n",
    "                                       aep_derived_uom_col=kwargs.get('aep_derived_uom_col', 'aep_derived_uom'), \n",
    "                                       aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col)\n",
    "        additional_sql.sql_where.add_where_statement(field_desc='aep_derived_uom', \n",
    "                                                     comparison_operator='<>', value='KWH', needs_quotes=True)        \n",
    "        \n",
    "    elif additional_derived_uoms is not None and len(additional_derived_uoms)>0:\n",
    "        additional_sql = build_sql_usg(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                       serial_numbers=serial_numbers, \n",
    "                                       date_range=date_range, \n",
    "                                       aep_derived_uoms=additional_derived_uoms, \n",
    "                                       kwh_and_vlt_only=False, \n",
    "                                       aep_opco=kwargs.get('aep_opco', None), \n",
    "                                       schema_name=kwargs.get('schema_name', 'usage_nonvee'), \n",
    "                                       table_name=kwargs.get('table_name', 'reading_ivl_nonvee'), \n",
    "                                       serialnumber_col=serialnumber_col, \n",
    "                                       aep_derived_uom_col=kwargs.get('aep_derived_uom_col', 'aep_derived_uom'), \n",
    "                                       aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col)\n",
    "    else:\n",
    "        additional_sql = None\n",
    "    #-------------------------\n",
    "    if additional_sql is not None:\n",
    "        sub_query_stmnt +=  f\"\\nUNION\\n\" \\\n",
    "                            f\"(\\n{additional_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)}\\n)\"\n",
    "    #-------------------------\n",
    "    usg_wnv_union_wtv_sql = SQLQueryGeneric(sub_query_stmnt)\n",
    "    #------------------------------------------------------------\n",
    "    # Now, aggregate table from usg_wnv_union_wtv_sql (similar to usg_w_net_value_sql) to get the final net\n",
    "    # value, which is the ..\n",
    "    # FUCK TODO\n",
    "    # Now that I am writing this out and thinking about it, I don't think all of this is necessary.\n",
    "    # At this point, everything is still being done at the serial number level\n",
    "    # Therefore, should not come across a case where all 'DELIVERED', 'RECEIVED' and 'TOTAL' are present.\n",
    "    # IF such an instance exists, then TOTAL better equal DELIVERED-RECEIVED!\n",
    "    # I'll finish out this effort anyway, but intend to go back to working with non-aggregate data when\n",
    "    # developing this functionality instead of trying to skip ahead with agg\n",
    "    if run_careful:\n",
    "        # This \"aggregates\" again, but enforces COUNT({value_col})=1\n",
    "        # Which essentially means make sure there is only one value per group.\n",
    "        # The reason for this is as follows:\n",
    "        #   A serial should either have 'DELIVERED'/'RECEIVED' OR 'TOTAL'/'RECEIVED'\n",
    "        #   Therefore, all entries for a given serial number should be in usg_w_net_value_sql OR usg_w_total_value_sql\n",
    "        #     but not both.  The code below essentially enforces this.\n",
    "        usg_sql = build_usg_w_net_value_sql(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                            date_range=date_range, \n",
    "                                            serial_numbers=serial_numbers, \n",
    "                                            value_col=value_col, \n",
    "                                            aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                            serialnumber_col=serialnumber_col, \n",
    "                                            usg_w_signed_val_table_name='USG_W_NET_VAL_UNION_USG_W_TOTAL_VAL_0', \n",
    "                                            sum_signed_val_col=value_col, \n",
    "                                            sum_signed_val_alias=None, \n",
    "                                            new_const_aep_srvc_qlty_idntfr_val='CALCULATED_NET', \n",
    "                                            **kwargs)\n",
    "        usg_sql.sql_where=SQLWhere()\n",
    "        usg_sql.sql_having = SQLHaving([dict(field_desc=f'COUNT({value_col})', comparison_operator='=', \n",
    "                                             value='1', needs_quotes=False)\n",
    "                                       ], idxs=None, run_check=True)\n",
    "    else:\n",
    "        usg_sql = SQLQuery(sql_select = SQLSelect(['*']), \n",
    "                           sql_from = SQLFrom('USG_W_NET_VAL_UNION_USG_W_TOTAL_VAL_0'), \n",
    "                           sql_where=None)\n",
    "\n",
    "    \n",
    "    usg_sql_dict = {'usg_w_signed_val_sql':usg_w_signed_val_sql, \n",
    "                    'usg_w_net_value_sql':usg_w_net_value_sql, \n",
    "                    'usg_w_total_value_sql':usg_w_total_value_sql, \n",
    "                    'usg_wnv_union_wtv_sql':usg_wnv_union_wtv_sql, \n",
    "                    'usg_sql':usg_sql}\n",
    "    if return_statement:\n",
    "        return assemble_usg_kwh_net_or_total_sql_statementOLD(usg_sql_dict=usg_sql_dict, \n",
    "                                                           final_table_alias=final_table_alias, \n",
    "                                                           insert_n_tabs_to_each_line=insert_n_tabs_to_each_line, \n",
    "                                                           prepend_with_to_stmnt=prepend_with_to_stmnt)\n",
    "    else:\n",
    "        return usg_sql_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8540d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3213a435",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dc4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced by build_sql_kwh_usg_delrec_w_signed_val\n",
    "def build_usg_w_signed_val_sqlOLD(cols_of_interest_usage, \n",
    "                               date_range, \n",
    "                               serial_numbers, \n",
    "                               serialnumber_col='serialnumber'):\n",
    "    usg_w_signed_val_sql_select = SQLSelect(cols_of_interest_usage)\n",
    "    usg_w_signed_val_sql_select.add_select_element(field_desc=\"IF(aep_srvc_qlty_idntfr='RECEIVED', -1*value, value)\", alias=\"signed_value\")\n",
    "    #-----\n",
    "    usg_w_signed_val_sql_where = SQLWhere([dict(field_desc='aep_opco', comparison_operator='=', value='oh', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_derived_uom', comparison_operator='=', value='KWH', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_srvc_qlty_idntfr', comparison_operator='=', value='RECEIVED', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_srvc_qlty_idntfr', comparison_operator='=', value='DELIVERED', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "                                          ], idxs=None, run_check=True)\n",
    "    usg_w_signed_val_sql_where.combine_where_elements([2,3], 'OR', close_gaps_in_keys=True)\n",
    "    if serial_numbers is not None:\n",
    "        usg_w_signed_val_sql_where.add_where_statement(field_desc=serialnumber_col, comparison_operator='IN', \n",
    "                                                      value=f'({Utilities_sql.join_list_w_quotes(serial_numbers)})', needs_quotes=False)\n",
    "    #-----\n",
    "    usg_w_signed_val_sql = SQLQuery(sql_select = usg_w_signed_val_sql_select, \n",
    "                                    sql_from = SQLFrom('usage_nonvee', 'reading_ivl_nonvee'), \n",
    "                                    sql_where = usg_w_signed_val_sql_where\n",
    "                                   )\n",
    "    return usg_w_signed_val_sql\n",
    "\n",
    "# Replaced by build_sql_kwh_usg_total_only\n",
    "def build_usg_w_total_val_sqlOLD(cols_of_interest_usage, date_range, serial_numbers, serialnumber_col='serialnumber'):\n",
    "    usg_w_total_val_sql_select = SQLSelect(cols_of_interest_usage)\n",
    "    #-----\n",
    "    usg_w_total_val_sql_where = SQLWhere([dict(field_desc='aep_opco', comparison_operator='=', value='oh', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_derived_uom', comparison_operator='=', value='KWH', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_srvc_qlty_idntfr', comparison_operator='=', value='TOTAL', needs_quotes=True), \n",
    "                                           dict(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "                                          ], idxs=None, run_check=True)\n",
    "    if serial_numbers is not None:\n",
    "        usg_w_total_val_sql_where.add_where_statement(field_desc=serialnumber_col, comparison_operator='IN', \n",
    "                                                      value=f'({Utilities_sql.join_list_w_quotes(serial_numbers)})', needs_quotes=False)\n",
    "    #-----\n",
    "    usg_w_total_val_sql = SQLQuery(sql_select = usg_w_total_val_sql_select, \n",
    "                                    sql_from = SQLFrom('usage_nonvee', 'reading_ivl_nonvee'), \n",
    "                                    sql_where = usg_w_total_val_sql_where\n",
    "                                   )\n",
    "    return usg_w_total_val_sql\n",
    "\n",
    "\n",
    "#Updated version called build_sql_usg_agg_by_srvc_qlty_idntfr\n",
    "def build_sql_usg_w_net_valueOLD(cols_of_interest_usage, \n",
    "                              date_range, \n",
    "                              serial_numbers, \n",
    "                              value_col='value', \n",
    "                              aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                              serialnumber_col='serialnumber', \n",
    "                              usg_w_signed_val_table_name='KWH_USG_DELREC_W_SIGNED_VAL', \n",
    "                              **kwargs):\n",
    "    r\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # TODO IN FUTURE will allow for groupby_cols input argument, which will default to \n",
    "    # cols_of_interest_usage - value_col - aep_srvc_qlty_idntfr_col if non input\n",
    "    # Leaving out for now because I want a failure if groupby_cols is included, to ensure everything is working\n",
    "    # TODO also in the future maybe(?) make serial_numbers = None by default, but again want to fail if not for now\n",
    "    # TODO also, maybe want aep_opco etc in different dict than kwargs...\n",
    "    #-------------------------\n",
    "    assert(value_col                in cols_of_interest_usage)\n",
    "    assert(aep_srvc_qlty_idntfr_col in cols_of_interest_usage)\n",
    "    assert(serialnumber_col         in cols_of_interest_usage)\n",
    "    #-------------------------\n",
    "    sum_signed_val_col                 = kwargs.get('sum_signed_val_col', 'signed_value')\n",
    "    sum_signed_val_alias               = kwargs.get('sum_signed_val_alias', None)\n",
    "    new_const_aep_srvc_qlty_idntfr_val = kwargs.get('new_const_aep_srvc_qlty_idntfr_val', 'CALCULATED_NET')\n",
    "    #-------------------------\n",
    "    sql_select_usg_w_net_value = SQLSelect(cols_of_interest_usage)\n",
    "    #-----\n",
    "    # Instead of value, want SUM(signed_value) AS value\n",
    "    sql_select_usg_w_net_value = AMINonVeeSQL.adjust_value_to_sum_signed_val_in_sql_select(sql_select_usg_w_net_value, \n",
    "                                                                              value_col=value_col, \n",
    "                                                                              sum_signed_val=f'SUM({sum_signed_val_col})', \n",
    "                                                                              sum_signed_val_alias=sum_signed_val_alias)\n",
    "    #-----\n",
    "    # Going to sum over aep_srvc_qlty_idntfr, (by excluding from groupby) so don't want it in selection anymore\n",
    "    # But, add in generic aep_srvc_qlty_idntfr with value equal to 'CALCULATED_NET'\n",
    "    sql_select_usg_w_net_value = AMINonVeeSQL.adjust_aep_srvc_qlty_idntfr_to_const_in_sql_select(sql_select_usg_w_net_value, \n",
    "                                                                                    aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                                                                    new_const_val=new_const_aep_srvc_qlty_idntfr_val)\n",
    "    #-------------------------\n",
    "    sql_where_usg_w_net_value = SQLWhere()\n",
    "    if date_range is not None:\n",
    "        sql_where_usg_w_net_value.add_where_statement(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                      value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "    aep_opco = kwargs.get('aep_opco', None)\n",
    "    if aep_opco is not None:\n",
    "        sql_where_usg_w_net_value.add_where_statement(field_desc='aep_opco', comparison_operator='=', value=f'{aep_opco}', \n",
    "                                                      needs_quotes=True, idx=0)\n",
    "    if serial_numbers is not None:\n",
    "        sql_where_usg_w_net_value.add_where_statement(field_desc=serialnumber_col, comparison_operator='IN', \n",
    "                                                      value=f'({Utilities_sql.join_list_w_quotes(serial_numbers)})', needs_quotes=False)\n",
    "    #-------------------------\n",
    "    groupby_cols = Utilities.include_at_front_and_exclude_from_list(cols_of_interest_usage, \n",
    "                                                                    exclude_from_list=[aep_srvc_qlty_idntfr_col, value_col], \n",
    "                                                                    inplace=False)\n",
    "    sql_groupby_usg_w_net_value = SQLGroupBy(field_descs=groupby_cols, \n",
    "                                             global_table_alias_prefix=None, idxs=None, run_check=True)\n",
    "    #-------------------------\n",
    "    sql_usg_w_net_value = SQLQuery(sql_select = sql_select_usg_w_net_value, \n",
    "                                   sql_from = SQLFrom(table_name=usg_w_signed_val_table_name), \n",
    "                                   sql_where = sql_where_usg_w_net_value, \n",
    "                                   sql_groupby = sql_groupby_usg_w_net_value, \n",
    "                                   sql_having = SQLHaving([dict(field_desc=f'COUNT({sum_signed_val_col})', comparison_operator='=', \n",
    "                                                                value='2', needs_quotes=False)\n",
    "                                                          ], idxs=None, run_check=True)\n",
    "                     )\n",
    "    return sql_usg_w_net_value\n",
    "\n",
    "\n",
    "# Previously assemble_usg_kwh_net_or_total_sql_statement\n",
    "def assemble_net_kwh_usage_sql_statementOLD(usg_sql_dict, final_table_alias='USG_KWH', \n",
    "                                         insert_n_tabs_to_each_line=1, prepend_with_to_stmnt=False):\n",
    "    assert('sql_kwh_usg_delrec_w_signed_val'      in usg_sql_dict)\n",
    "    assert('sql_kwh_usg_delrec_net'               in usg_sql_dict)\n",
    "    assert('sql_kwh_usg_total_only'               in usg_sql_dict)\n",
    "    assert('sql_kwh_usg_delrec_net_union_total_0' in usg_sql_dict)\n",
    "    assert('sql_kwh_usg_delrec_net_union_total'   in usg_sql_dict)\n",
    "    assert('additional_sql'                       in usg_sql_dict)\n",
    "    #-----\n",
    "    sql_kwh_usg_delrec_w_signed_val      = usg_sql_dict['sql_kwh_usg_delrec_w_signed_val']\n",
    "    sql_kwh_usg_delrec_net               = usg_sql_dict['sql_kwh_usg_delrec_net']\n",
    "    sql_kwh_usg_total_only               = usg_sql_dict['sql_kwh_usg_total_only']\n",
    "    sql_kwh_usg_delrec_net_union_total_0 = usg_sql_dict['sql_kwh_usg_delrec_net_union_total_0']\n",
    "    sql_kwh_usg_delrec_net_union_total   = usg_sql_dict['sql_kwh_usg_delrec_net_union_total']\n",
    "    additional_sql                       = usg_sql_dict['additional_sql']\n",
    "    #-----\n",
    "    sql_kwh_usg_delrec_w_signed_val_stmnt      = sql_kwh_usg_delrec_w_signed_val.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    sql_kwh_usg_delrec_net_stmnt               = sql_kwh_usg_delrec_net.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    sql_kwh_usg_total_only_stmnt               = sql_kwh_usg_total_only.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    sql_kwh_usg_delrec_net_union_total_0_stmnt = sql_kwh_usg_delrec_net_union_total_0.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    sql_kwh_usg_delrec_net_union_total_stmnt   = sql_kwh_usg_delrec_net_union_total.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line)\n",
    "    #-----\n",
    "    if prepend_with_to_stmnt:\n",
    "        sql_full_stmnt = \"WITH \"\n",
    "    else:\n",
    "        sql_full_stmnt = \"\"\n",
    "    sql_full_stmnt += f\"KWH_USG_DELREC_W_SIGNED_VAL AS (\\n{sql_kwh_usg_delrec_w_signed_val_stmnt}\\n), \"\\\n",
    "    f\"\\nKWH_USG_DELREC_NET AS (\\n{sql_kwh_usg_delrec_net_stmnt}\\n), \"\\\n",
    "    f\"\\nKWH_USG_TOTAL_VAL AS (\\n{sql_kwh_usg_total_only_stmnt}\\n), \"\\\n",
    "    f\"\\nKWH_USG_DELREC_NET_UNION_TOTAL_0 AS (\\n{sql_kwh_usg_delrec_net_union_total_0_stmnt}\\n), \"\n",
    "    if additional_sql is None:\n",
    "        sql_full_stmnt += f\"\\n{final_table_alias} AS (\\n{sql_kwh_usg_delrec_net_union_total_stmnt}\\n)\"\n",
    "    else:\n",
    "        sql_full_stmnt += f\"\\nKWH_USG_DELREC_NET_UNION_TOTAL AS (\\n{sql_kwh_usg_delrec_net_union_total_stmnt}\\n), \"\n",
    "        usage_union_sql = SQLQuery(sql_select = SQLSelect(['*']), \n",
    "                                   sql_from = SQLFrom(table_name='KWH_USG_DELREC_NET_UNION_TOTAL'), \n",
    "                                   sql_where = None)        \n",
    "        sql_full_stmnt += f\"\\n{final_table_alias} AS (\\n\" \\\n",
    "                          f\"\\t(\\n\\t{usage_union_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line+1)}\\n\\t)\" \\\n",
    "                          f\"\\n\\tUNION\\n\" \\\n",
    "                          f\"\\t(\\n\\t{additional_sql.get_sql_statement(insert_n_tabs_to_each_line=insert_n_tabs_to_each_line+1)}\\n\\t)\" \\\n",
    "                          f\"\\n)\"\n",
    "        \n",
    "    return sql_full_stmnt\n",
    "\n",
    "\n",
    "#TODO cols_of_interest_usage used!!!! BUT NOT AN INPUT TO FUNCTION!!!!!\n",
    "# Similar to build_sql_outage_others_on_circuit_3_0, but TOTAL kWh is calculated by first forming a \n",
    "# signed_value column which is negative when aep_srvc_qlty_idntfr='RECEIVED' and then aggregating\n",
    "# FOR NOW, this is also only for aep_derived_uom = 'KWH'\n",
    "# TODO: calculate_net_kwh is not really correct.  This combines the negative \"RECEIVED\" value with whatever else is there\n",
    "#       So, for case where RECIEVED is accompanied by DELIEVERED, this is correct\n",
    "#       BUT, when RECEIVED is accompanied by TOTAL, this in incorrect, as net should just be total\n",
    "# TODO Would I ever want groupby_xfmr = False and stop_after_agg_1 = False?\n",
    "# Write out what all combos mean in description\n",
    "def build_sql_outage_others_on_circuit_OLD(conn_aws, serial_numbers, date_range, \n",
    "                                       field_descs, agg_cols_and_types, groupby_cols, \n",
    "                                       calculate_net_kwh, \n",
    "                                       groupby_xfmr=True, stop_after_agg_1=False, \n",
    "                                       try_to_split_col_strs=True, \n",
    "                                       verbose=True, \n",
    "                                       include_counts_including_null=True, \n",
    "                                       **kwargs):\n",
    "    # TODO I don't think I'd ever want groupby_xfmr = False and stop_after_agg_1 = False? Correct?\n",
    "    assert(groupby_xfmr+stop_after_agg_1>0)\n",
    "    # Return SQL statement to build aggregate of all OTHER meters on the circuit (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    # field_descs:\n",
    "    #   This is just as should be input into SQLSelect\n",
    "    #   i.e., field_descs should be a list of column names or a list of dict items, each with \n",
    "    #         possible keys 'field_desc', 'alias', 'table_alias_prefix'\n",
    "    #\n",
    "    # agg_cols_and_types_dict:\n",
    "    #  keys:\n",
    "    #      equal to column names OR SQLElement objects (representing column names) to be aggregated\n",
    "    #  values:\n",
    "    #      each value should be equal to a list of aggregations to perform on column\n",
    "    #      At this time, the available aggregate functions are:\n",
    "    #        'sum', 'sq_sum', 'mean', 'std', 'count'\n",
    "    #      NOTE: If more aggregate functions are added, to_SQL_dict must be updated appropriately\n",
    "    #\n",
    "    # try_to_split_col_strs:\n",
    "    #   when True and a key in agg_cols_and_types_dict of type str is found, this will attempt to split\n",
    "    #   the column name into field_desc and table_alias_prefix components,\n",
    "    #   which will then be used when creating the SQLElement replacement key\n",
    "    #   e.g. 'U.value' --> field_desc='value' and table_alias_prefix='U'\n",
    "    #\n",
    "    # groupby_cols:\n",
    "    #   should be columns from usage_nonvee.reading_ivl_nonvee.\n",
    "    #   SHOULD NOT contain 'trsf_pole_nb', as this will be added where needed.\n",
    "    #     (if 'trsf_pole_nb' in groupby_cols, it will simply be removed)\n",
    "    # ****************************************************\n",
    "    # Step 1: From the serial numbers given in serial_numbers, first find the circuit information\n",
    "    #         and ensure all of the listed serial numbers are on the same circuit\n",
    "    # Step 2: Given the circuit information, find all transformers on the circuit.\n",
    "    #         This information is needed because not all meters contain circuit data, and without the transformer\n",
    "    #           numbers on the circuit these meters would be left out.\n",
    "    #         In the final query, meters on the circuit will be found which either have the correct circuit\n",
    "    #           information OR the correct transformer number.\n",
    "    #           NOTE: To be 100% correct, it should probably be meters which have the correct circuit information\n",
    "    #                 OR no circuit infomration AND the correct transformer number.\n",
    "    # Step 3: Put it all together.  Return SQL statement to build aggregate of all OTHER meters on the circuit \n",
    "    #           (i.e., excluding those from serial_numbers)\n",
    "    # ****************************************************\n",
    "    \n",
    "    # ********************** Step 1 **********************\n",
    "    circuit_info = AMINonVeeCircuitSQL.get_circuit_info(conn_aws, \n",
    "                                                        build_mp_kwargs=dict(mfr_devc_ser_nbrs=serial_numbers))\n",
    "    circuit_nb = circuit_info['circuit_nb']\n",
    "    circuit_nm = circuit_info['circuit_nm']\n",
    "    station_nb = circuit_info['station_nb']\n",
    "    station_nm = circuit_info['station_nm']\n",
    "    \n",
    "    # ********************** Step 2 **********************\n",
    "    trsf_pole_nbs = AMINonVeeCircuitSQL.get_trsf_pole_nbs_on_circuit(conn_aws, \n",
    "                                                                     circuit_nb, circuit_nm, \n",
    "                                                                     station_nb, station_nm)\n",
    "    \n",
    "    # ********************** Step 3 **********************\n",
    "    mp_sql_stmnt = AMINonVeeCircuitSQL.build_mp_sql_w_circuit_info_or_trsf_pole_nbs(circuit_nb, circuit_nm, station_nb, station_nm, \n",
    "                                                                                    trsf_pole_nbs, \n",
    "                                                                                    return_args = dict(return_statement=True, \n",
    "                                                                                                       insert_n_tabs_to_each_line=1))\n",
    "    #--------------------\n",
    "    cols_of_interest_usage = []\n",
    "    for x in field_descs:\n",
    "        if isinstance(x, str):\n",
    "            cols_of_interest_usage.append(x)\n",
    "        elif isinstance(x, dict):\n",
    "            cols_of_interest_usage.append(x[field_desc])\n",
    "        elif isinstance(x, SQLElement):\n",
    "            cols_of_interest_usage.append(x.field_desc)\n",
    "        else:\n",
    "            assert(0)\n",
    "    assert('serialnumber' not in cols_of_interest_usage)\n",
    "    cols_of_interest_usage= ['serialnumber'] + cols_of_interest_usage\n",
    "    #--------------------\n",
    "    if calculate_net_kwh:\n",
    "        sql_kwh_usg_delrec_w_signed_val = AMINonVeeSQL.build_sql_kwh_usg_delrec_w_signed_val(cols_of_interest_usage=cols_of_interest_usage, \n",
    "                                                                                date_range=date_range, \n",
    "                                                                                serial_numbers=None, \n",
    "                                                                                aep_opco=kwargs.get('aep_opco', None), \n",
    "                                                                                alias='KWH_USG_DELREC_W_SIGNED_VAL')\n",
    "        #sql_kwh_usg_delrec_w_signed_val.sql_where.remove_single_element_from_collection_at_idx(2) #Old version did not force 'RECEIVED' or 'DELIVERED here'\n",
    "        sql_kwh_usg_delrec_w_signed_val_stmnt = sql_kwh_usg_delrec_w_signed_val.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "        #--------------------\n",
    "        usg_sql_select = SQLSelect(cols_of_interest_usage)\n",
    "        # Instead of value, want SUM(signed_value) AS value\n",
    "        value_idx = usg_sql_select.find_idx_of_approx_element_in_collection_dict(SQLSelectElement('value'))\n",
    "        usg_sql_select.remove_single_element_from_collection_at_idx(value_idx)\n",
    "        usg_sql_select.add_select_element(field_desc='SUM(signed_value)', alias='value')\n",
    "        # Going to sum over aep_srvc_qlty_idntfr, (by excluding from groupby) so don't want it in selection anymore\n",
    "        aep_srvc_qlty_idntfr_idx = usg_sql_select.find_idx_of_approx_element_in_collection_dict(SQLSelectElement('aep_srvc_qlty_idntfr'))\n",
    "        usg_sql_select.remove_single_element_from_collection_at_idx(aep_srvc_qlty_idntfr_idx)\n",
    "        # But, add in generic aep_srvc_qlty_idntfr with value equal to 'CALCULATED_NET'\n",
    "        usg_sql_select.add_select_element(field_desc=\"'CALCULATED_NET'\", alias='aep_srvc_qlty_idntfr')\n",
    "        #-----\n",
    "        usg_sql_groupby = SQLGroupBy(field_descs=['serialnumber'] + [x for x in groupby_cols if x != 'aep_srvc_qlty_idntfr'], \n",
    "                                     global_table_alias_prefix=None, idxs=None, run_check=True)\n",
    "        #-----\n",
    "        usg_sql = SQLQuery(sql_select = usg_sql_select, \n",
    "                           sql_from = SQLFrom(table_name='KWH_USG_DELREC_W_SIGNED_VAL'), \n",
    "                           sql_where = SQLWhere([dict(field_desc='aep_usage_dt', comparison_operator='BETWEEN', \n",
    "                                                      value=[f'{date_range[0]}',f'{date_range[1]}'], needs_quotes=True)\n",
    "                                                ], idxs=None, run_check=True), \n",
    "                           sql_groupby = usg_sql_groupby\n",
    "                         )\n",
    "        usg_sql_stmnt = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    else:\n",
    "        usg_sql = AMINonVeeSQL.build_sql_usg(cols_of_interest_usage=cols_of_interest_usage, serial_numbers=[], date_range=date_range)\n",
    "        usg_sql.sql_where.find_and_remove_approx_element_in_collection_dict(SQLWhereElement('serialnumber', comparison_operator='', value=''))\n",
    "        usg_sql_stmnt = usg_sql.get_sql_statement(insert_n_tabs_to_each_line=1)        \n",
    "    #--------------------\n",
    "    if 'trsf_pole_nb' in groupby_cols:\n",
    "        _ = groupby_cols.pop(groupby_cols.index('trsf_pole_nb'))\n",
    "    agg_1_sql = AMINonVeeCircuitSQL.build_agg_1_sql(field_descs=field_descs, \n",
    "                                                    agg_cols_and_types=agg_cols_and_types, \n",
    "                                                    groupby_cols=groupby_cols, \n",
    "                                                    groupby_xfmr=groupby_xfmr, \n",
    "                                                    try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                                    usg_alias='U', \n",
    "                                                    idxs=None, run_check=True, \n",
    "                                                    include_counts_including_null=include_counts_including_null, \n",
    "                                                    **kwargs)\n",
    "    agg_1_sql_stmnt = agg_1_sql.get_sql_statement(insert_n_tabs_to_each_line=1)\n",
    "    if stop_after_agg_1:\n",
    "        sql_full_stmnt = f\"WITH MP AS (\\n{mp_sql_stmnt}\\n),  \\nU AS (\\n{usg_sql_stmnt}\\n) \\n\\n{agg_1_sql_stmnt}\"\n",
    "        if verbose:\n",
    "            print(sql_full_stmnt)\n",
    "        #--------------------\n",
    "        return sql_full_stmnt\n",
    "    #--------------------\n",
    "    agg_types_rd2 = ['sum', 'mean']\n",
    "    agg_rd2_sql = AMINonVeeCircuitSQL.build_agg_rd2_sql(agg_1_sql, groupby_cols, \n",
    "                                                        agg_types_rd2=agg_types_rd2, agg_1_table_alias='AGG1')  \n",
    "    agg_rd2_sql_statement = agg_rd2_sql.get_sql_statement()\n",
    "    #-------------------------------------\n",
    "    sql_full_stmnt = f\"WITH MP AS (\\n{mp_sql_stmnt}),  \" \n",
    "    if calculate_net_kwh:\n",
    "        sql_full_stmnt += f\"\\nKWH_USG_DELREC_W_SIGNED_VAL AS (\\n{sql_kwh_usg_delrec_w_signed_val_stmnt}\\n),  \"\n",
    "    sql_full_stmnt += f\"\\nU AS (\\n{usg_sql_stmnt}\\n),  \"\\\n",
    "                      f\"\\nAGG1 AS (\\n{agg_1_sql_stmnt}\\n) \"\\\n",
    "                      f\"\\n\\n{agg_rd2_sql_statement}\"\n",
    "    # ********************** Return **********************\n",
    "    if verbose:\n",
    "        print(sql_full_stmnt)\n",
    "    #--------------------\n",
    "    return sql_full_stmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4458fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "474fedbe",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# NORMAL TESTING FROM ORIGINAL DEVELOPMENT\n",
    "test_df_3_0/test_df_3 are investigated more in the next section (Looking into the difference...) below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae05c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee259805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a50fa5f",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf50598",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "    groupby_xfmr=True\n",
    "    test_sql_stmnt_gpd_0 = build_sql_outage_others_on_circuit_1_0(conn_aws, serial_numbers, date_range, groupby_xfmr, verbose=False)\n",
    "    test_sql_stmnt_gpd = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "        conn_aws, \n",
    "        serial_numbers, date_range, \n",
    "        field_descs, agg_cols_and_types, groupby_cols, \n",
    "        aep_derived_uoms_and_idntfrs=None, \n",
    "        calculate_net_kwh=False, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "        stop_after_agg_1=True, groupby_xfmr_in_agg_1=groupby_xfmr, \n",
    "        include_counts_including_null=True, \n",
    "        addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs), \n",
    "        verbose=False\n",
    "    )\n",
    "    #--------------\n",
    "    test_df_gpd_0 = pd.read_sql(test_sql_stmnt_gpd_0, conn_aws)\n",
    "    test_df_gpd = pd.read_sql(test_sql_stmnt_gpd, conn_aws)\n",
    "    #---------------\n",
    "    test_df_gpd_0 = Utilities_df.remove_table_aliases(test_df_gpd_0)\n",
    "    test_df_gpd = Utilities_df.remove_table_aliases(test_df_gpd)\n",
    "    #---------------\n",
    "    old_to_new_cols = {\n",
    "        'value_mean':'mean_value', \n",
    "        'value_std':'std_value', \n",
    "        'value_sq_sum':'sq_sum_value', \n",
    "        'value_sum':'sum_value', \n",
    "        'counts':'count_value'\n",
    "    }\n",
    "    test_df_gpd_0 = test_df_gpd_0.rename(columns=old_to_new_cols)\n",
    "    #---------------        \n",
    "    print(f\"test_df_gpd_0.shape = {test_df_gpd_0.shape}\")\n",
    "    print(f\"test_df_gpd.shape   = {test_df_gpd.shape}\")\n",
    "    print(f\"test_df_gpd_0.shape==test_df_gpd.shape?: {test_df_gpd_0.shape==test_df_gpd.shape}\")\n",
    "    #-----\n",
    "    overlap_cols = list(set(test_df_gpd_0.columns).intersection(set(test_df_gpd.columns)))\n",
    "    #-----\n",
    "    numeric_cols_1 = Utilities_df.get_numeric_columns(test_df_gpd_0)\n",
    "    numeric_cols_2 = Utilities_df.get_numeric_columns(test_df_gpd)\n",
    "    cols_compared = list(set(numeric_cols_1).intersection(set(numeric_cols_2)))\n",
    "    cols_not_compared = [x for x in overlap_cols if x not in cols_compared]\n",
    "    #-----\n",
    "    in_gpd_0_not_gpd = list(set(test_df_gpd_0.columns).difference(set(test_df_gpd.columns)))\n",
    "    in_gpd_not_gpd_0 = list(set(test_df_gpd.columns).difference(set(test_df_gpd_0.columns)))\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are shared numeric columns equal?')\n",
    "    approx_dfs = Utilities_df.get_dfs_diff_approx_ok(test_df_gpd, test_df_gpd_0, \n",
    "                                                     sort_by=['aep_endtime_utc'])\n",
    "    if approx_dfs.shape[0]==0:\n",
    "        print('True')\n",
    "    else:\n",
    "        print('False')\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are other shared columns equal?')\n",
    "    print(test_df_gpd.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared].equals(\n",
    "        test_df_gpd_0.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared])\n",
    "         )\n",
    "    #-----\n",
    "    print()\n",
    "    print('Columns not compared?')\n",
    "    print(f\"in_gpd_0_not_gpd: {in_gpd_0_not_gpd}\")\n",
    "    print(f\"in_gpd_not_gpd_0: {in_gpd_not_gpd_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "    groupby_xfmr=False\n",
    "    test_sql_stmnt_0 = build_sql_outage_others_on_circuit_1_0(conn_aws, serial_numbers, date_range, groupby_xfmr, verbose=False)\n",
    "    test_sql_stmnt = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "        conn_aws, \n",
    "        serial_numbers, date_range, \n",
    "        field_descs, agg_cols_and_types, groupby_cols, \n",
    "        aep_derived_uoms_and_idntfrs=None, \n",
    "        calculate_net_kwh=False, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "        stop_after_agg_1=True, groupby_xfmr_in_agg_1=groupby_xfmr,  \n",
    "        include_counts_including_null=True, \n",
    "        addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs),  \n",
    "        verbose=False\n",
    "    )\n",
    "    #--------------\n",
    "    test_df_0 = pd.read_sql(test_sql_stmnt_0, conn_aws)\n",
    "    test_df = pd.read_sql(test_sql_stmnt, conn_aws)\n",
    "    #---------------\n",
    "    test_df_0 = Utilities_df.remove_table_aliases(test_df_0)\n",
    "    test_df = Utilities_df.remove_table_aliases(test_df)\n",
    "    #---------------\n",
    "    old_to_new_cols = {\n",
    "        'value_mean':'mean_value', \n",
    "        'value_std':'std_value', \n",
    "        'value_sq_sum':'sq_sum_value', \n",
    "        'value_sum':'sum_value', \n",
    "        'counts':'count_value'\n",
    "    }\n",
    "    test_df_0 = test_df_0.rename(columns=old_to_new_cols)\n",
    "    #---------------        \n",
    "    print(f\"test_df_0.shape = {test_df_0.shape}\")\n",
    "    print(f\"test_df.shape   = {test_df.shape}\")\n",
    "    print(f\"test_df_0.shape==test_df.shape?: {test_df_0.shape==test_df.shape}\")\n",
    "    #-----\n",
    "    overlap_cols = list(set(test_df_0.columns).intersection(set(test_df.columns)))\n",
    "    #-----\n",
    "    numeric_cols_1 = Utilities_df.get_numeric_columns(test_df_0)\n",
    "    numeric_cols_2 = Utilities_df.get_numeric_columns(test_df)\n",
    "    cols_compared = list(set(numeric_cols_1).intersection(set(numeric_cols_2)))\n",
    "    cols_not_compared = [x for x in overlap_cols if x not in cols_compared]\n",
    "    #-----\n",
    "    in_0_not_ = list(set(test_df_0.columns).difference(set(test_df.columns)))\n",
    "    in_not_0 = list(set(test_df.columns).difference(set(test_df_0.columns)))\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are shared numeric columns equal?')\n",
    "    approx_dfs = Utilities_df.get_dfs_diff_approx_ok(test_df, test_df_0, \n",
    "                                                     sort_by=['aep_endtime_utc'])\n",
    "    if approx_dfs.shape[0]==0:\n",
    "        print('True')\n",
    "    else:\n",
    "        print('False')\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are other shared columns equal?')\n",
    "    print(test_df.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared].equals(\n",
    "        test_df_0.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared])\n",
    "         )\n",
    "    #-----\n",
    "    print()\n",
    "    print('Columns not compared?')\n",
    "    print(f\"in_0_not_: {in_0_not_}\")\n",
    "    print(f\"in_not_0: {in_not_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "    test_sql_stmnt_2_0 = build_sql_outage_others_on_circuit_2_0(conn_aws, serial_numbers, date_range, verbose=False)\n",
    "    test_sql_stmnt_2 = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "        conn_aws, \n",
    "        serial_numbers, date_range, \n",
    "        field_descs, agg_cols_and_types, groupby_cols, \n",
    "        aep_derived_uoms_and_idntfrs=None, \n",
    "        calculate_net_kwh=False, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "        stop_after_agg_1=False, groupby_xfmr_in_agg_1=True,  \n",
    "        include_counts_including_null=True, \n",
    "        addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs),  \n",
    "        verbose=False\n",
    "    )\n",
    "    #--------------\n",
    "    test_df_2_0 = pd.read_sql(test_sql_stmnt_2_0, conn_aws)\n",
    "    test_df_2 = pd.read_sql(test_sql_stmnt_2, conn_aws)\n",
    "    #---------------\n",
    "    test_df_2_0 = Utilities_df.remove_table_aliases(test_df_2_0)\n",
    "    test_df_2 = Utilities_df.remove_table_aliases(test_df_2)\n",
    "    #---------------\n",
    "    old_to_new_cols = {\n",
    "        'sum_value_sum':'sum_sum_value', \n",
    "        'mean_value_sum':'mean_sum_value', \n",
    "        'sum_value_sq_sum':'sum_sq_sum_value',\n",
    "        'mean_value_sq_sum':'mean_sq_sum_value', \n",
    "        'sum_value_mean':'sum_mean_value', \n",
    "        'mean_value_mean':'mean_mean_value',\n",
    "        'sum_value_std':'sum_std_value', \n",
    "        'mean_value_std':'mean_std_value', \n",
    "        'sum_counts':'sum_count_value', \n",
    "        'mean_counts':'mean_count_value',\n",
    "        'sum_counts_including_null':'sum_counts_including_null', \n",
    "        'mean_counts_including_null':'mean_counts_including_null'\n",
    "    }\n",
    "    test_df_2_0 = test_df_2_0.rename(columns=old_to_new_cols)\n",
    "    #---------------        \n",
    "    print(f\"test_df_2_0.shape = {test_df_2_0.shape}\")\n",
    "    print(f\"test_df_2.shape   = {test_df_2.shape}\")\n",
    "    print(f\"test_df_2_0.shape==test_df_2.shape?: {test_df_2_0.shape==test_df_2.shape}\")\n",
    "    #-----\n",
    "    overlap_cols = list(set(test_df_2_0.columns).intersection(set(test_df_2.columns)))\n",
    "    #-----\n",
    "    numeric_cols_1 = Utilities_df.get_numeric_columns(test_df_2_0)\n",
    "    numeric_cols_2 = Utilities_df.get_numeric_columns(test_df_2)\n",
    "    cols_compared = list(set(numeric_cols_1).intersection(set(numeric_cols_2)))\n",
    "    cols_not_compared = [x for x in overlap_cols if x not in cols_compared]\n",
    "    #-----\n",
    "    in_2_0_not_2 = list(set(test_df_2_0.columns).difference(set(test_df_2.columns)))\n",
    "    in_2_not_2_0 = list(set(test_df_2.columns).difference(set(test_df_2_0.columns)))\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are shared numeric columns equal?')\n",
    "    approx_dfs = Utilities_df.get_dfs_diff_approx_ok(test_df_2, test_df_2_0, \n",
    "                                                     sort_by=['aep_endtime_utc'])\n",
    "    if approx_dfs.shape[0]==0:\n",
    "        print('True')\n",
    "    else:\n",
    "        print('False')\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are other shared columns equal?')\n",
    "    print(test_df_2.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared].equals(\n",
    "        test_df_2_0.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared])\n",
    "         )\n",
    "    #-----\n",
    "    print()\n",
    "    print('Columns not compared?')\n",
    "    print(f\"in_2_0_not_2: {in_2_0_not_2}\")\n",
    "    print(f\"in_2_not_2_0: {in_2_not_2_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Old version did not combine net kwh correctly, so expect some small differences here\n",
    "run_test = True\n",
    "if run_test:\n",
    "    cols_of_interest_usage_agg = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                                  'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'value', 'aep_usage_dt']\n",
    "\n",
    "    serial_numbers = dev_ser_nbrs\n",
    "    date_range = ['2021-01-01', '2021-01-02']\n",
    "    field_descs=cols_of_interest_usage_agg\n",
    "    agg_cols_and_types = {'U.value':['sum', 'sq_sum', 'mean', 'std', 'count']}\n",
    "    groupby_cols = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                    'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'aep_usage_dt']\n",
    "    try_to_split_col_strs = True\n",
    "    \n",
    "    \n",
    "    test_sql_stmnt_3_0 = build_sql_outage_others_on_circuit_3_0(conn_aws, serial_numbers, date_range, verbose=False)\n",
    "    test_sql_stmnt_3 = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "        conn_aws, \n",
    "        serial_numbers, date_range, \n",
    "        field_descs, agg_cols_and_types, groupby_cols, \n",
    "        aep_derived_uoms_and_idntfrs=['KWH'], \n",
    "        calculate_net_kwh=True, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "        stop_after_agg_1=False, groupby_xfmr_in_agg_1=True,  \n",
    "        include_counts_including_null=True, \n",
    "        addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs),  \n",
    "        verbose=False\n",
    "    )\n",
    "    #--------------\n",
    "    test_df_3_0 = pd.read_sql(test_sql_stmnt_3_0, conn_aws)\n",
    "    test_df_3 = pd.read_sql(test_sql_stmnt_3, conn_aws)\n",
    "    #---------------\n",
    "    test_df_3_0 = Utilities_df.remove_table_aliases(test_df_3_0)\n",
    "    test_df_3 = Utilities_df.remove_table_aliases(test_df_3)\n",
    "    #---------------\n",
    "    old_to_new_cols = {\n",
    "        'sum_value_sum':'sum_sum_value', \n",
    "        'mean_value_sum':'mean_sum_value', \n",
    "        'sum_value_sq_sum':'sum_sq_sum_value',\n",
    "        'mean_value_sq_sum':'mean_sq_sum_value', \n",
    "        'sum_value_mean':'sum_mean_value', \n",
    "        'mean_value_mean':'mean_mean_value',\n",
    "        'sum_value_std':'sum_std_value', \n",
    "        'mean_value_std':'mean_std_value', \n",
    "        'sum_counts':'sum_count_value', \n",
    "        'mean_counts':'mean_count_value',\n",
    "        'sum_counts_including_null':'sum_counts_including_null', \n",
    "        'mean_counts_including_null':'mean_counts_including_null'\n",
    "    }\n",
    "    test_df_3_0 = test_df_3_0.rename(columns=old_to_new_cols)\n",
    "    #---------------        \n",
    "    print(f\"test_df_3_0.shape = {test_df_3_0.shape}\")\n",
    "    print(f\"test_df_3.shape   = {test_df_3.shape}\")\n",
    "    print(f\"test_df_3_0.shape==test_df_3.shape?: {test_df_3_0.shape==test_df_3.shape}\")\n",
    "    #-----\n",
    "    overlap_cols = list(set(test_df_3_0.columns).intersection(set(test_df_3.columns)))\n",
    "    #-----\n",
    "    numeric_cols_1 = Utilities_df.get_numeric_columns(test_df_3_0)\n",
    "    numeric_cols_2 = Utilities_df.get_numeric_columns(test_df_3)\n",
    "    cols_compared = list(set(numeric_cols_1).intersection(set(numeric_cols_2)))\n",
    "    cols_not_compared = [x for x in overlap_cols if x not in cols_compared]\n",
    "    #-----\n",
    "    in_3_0_not_3 = list(set(test_df_3_0.columns).difference(set(test_df_3.columns)))\n",
    "    in_3_not_3_0 = list(set(test_df_3.columns).difference(set(test_df_3_0.columns)))\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are shared numeric columns equal?')\n",
    "    approx_dfs = Utilities_df.get_dfs_diff_approx_ok(test_df_3, test_df_3_0, \n",
    "                                                     sort_by=['aep_endtime_utc'])\n",
    "    if approx_dfs.shape[0]==0:\n",
    "        print('True')\n",
    "    else:\n",
    "        print('False')\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are other shared columns equal?')\n",
    "    print(test_df_3.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared].equals(\n",
    "        test_df_3_0.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared])\n",
    "         )\n",
    "    #-----\n",
    "    print()\n",
    "    print('Columns not compared?')\n",
    "    print(f\"in_3_0_not_3: {in_3_0_not_3}\")\n",
    "    print(f\"in_3_not_3_0: {in_3_not_3_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff153306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfa404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0458136b",
   "metadata": {},
   "source": [
    "# Looking into the difference between old (wrong) net method and new\n",
    "NOT TERRIBLY IMPORTANT, BUT WOULD BE GOOD TO LOOK AT IF POSSIBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95237f",
   "metadata": {},
   "source": [
    "# Investigation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Old version did not combine net kwh correctly, so expect some small differences here\n",
    "run_test = True\n",
    "if run_test:\n",
    "    conn_aws = Utilities.get_athena_prod_aws_connection()\n",
    "    cols_of_interest_usage_agg = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                                  'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'value', 'aep_usage_dt']\n",
    "\n",
    "    serial_numbers = [884390632, 880682782, 880320285, 880076534, 880320207, 889926007, 884390655, 880076535]\n",
    "    date_range = ['2021-01-01', '2021-01-02']\n",
    "    field_descs=cols_of_interest_usage_agg\n",
    "    agg_cols_and_types = {'U.value':['sum', 'sq_sum', 'mean', 'std', 'count']}\n",
    "    groupby_cols = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                    'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'aep_usage_dt']\n",
    "    try_to_split_col_strs = True\n",
    "    \n",
    "    \n",
    "    test_sql_stmnt_3_0 = build_sql_outage_others_on_circuit_3_0(conn_aws, serial_numbers, date_range, verbose=False)\n",
    "    test_sql_stmnt_3 = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "        conn_aws, \n",
    "        serial_numbers, date_range, \n",
    "        field_descs, agg_cols_and_types, groupby_cols, \n",
    "        aep_derived_uoms_and_idntfrs=['KWH'], \n",
    "        calculate_net_kwh=True, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "        stop_after_agg_1=False, groupby_xfmr_in_agg_1=True,  \n",
    "        include_counts_including_null=True, \n",
    "        addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs),  \n",
    "        verbose=False\n",
    "    )\n",
    "    #--------------\n",
    "    test_df_3_0 = pd.read_sql(test_sql_stmnt_3_0, conn_aws)\n",
    "    test_df_3 = pd.read_sql(test_sql_stmnt_3, conn_aws)\n",
    "    #---------------\n",
    "    test_df_3_0 = Utilities_df.remove_table_aliases(test_df_3_0)\n",
    "    test_df_3 = Utilities_df.remove_table_aliases(test_df_3)\n",
    "    #---------------\n",
    "    old_to_new_cols = {\n",
    "        'sum_value_sum':'sum_sum_value', \n",
    "        'mean_value_sum':'mean_sum_value', \n",
    "        'sum_value_sq_sum':'sum_sq_sum_value',\n",
    "        'mean_value_sq_sum':'mean_sq_sum_value', \n",
    "        'sum_value_mean':'sum_mean_value', \n",
    "        'mean_value_mean':'mean_mean_value',\n",
    "        'sum_value_std':'sum_std_value', \n",
    "        'mean_value_std':'mean_std_value', \n",
    "        'sum_counts':'sum_count_value', \n",
    "        'mean_counts':'mean_count_value',\n",
    "        'sum_counts_including_null':'sum_counts_including_null', \n",
    "        'mean_counts_including_null':'mean_counts_including_null'\n",
    "    }\n",
    "    test_df_3_0 = test_df_3_0.rename(columns=old_to_new_cols)\n",
    "    #---------------        \n",
    "    print(f\"test_df_3_0.shape = {test_df_3_0.shape}\")\n",
    "    print(f\"test_df_3.shape   = {test_df_3.shape}\")\n",
    "    print(f\"test_df_3_0.shape==test_df_3.shape?: {test_df_3_0.shape==test_df_3.shape}\")\n",
    "    #-----\n",
    "    overlap_cols = list(set(test_df_3_0.columns).intersection(set(test_df_3.columns)))\n",
    "    #-----\n",
    "    numeric_cols_1 = Utilities_df.get_numeric_columns(test_df_3_0)\n",
    "    numeric_cols_2 = Utilities_df.get_numeric_columns(test_df_3)\n",
    "    cols_compared = list(set(numeric_cols_1).intersection(set(numeric_cols_2)))\n",
    "    cols_not_compared = [x for x in overlap_cols if x not in cols_compared]\n",
    "    #-----\n",
    "    in_3_0_not_3 = list(set(test_df_3_0.columns).difference(set(test_df_3.columns)))\n",
    "    in_3_not_3_0 = list(set(test_df_3.columns).difference(set(test_df_3_0.columns)))\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are shared numeric columns equal?')\n",
    "    approx_dfs = Utilities_df.get_dfs_diff_approx_ok(test_df_3, test_df_3_0, \n",
    "                                                     sort_by=['aep_endtime_utc'])\n",
    "    if approx_dfs.shape[0]==0:\n",
    "        print('True')\n",
    "    else:\n",
    "        print('False')\n",
    "    #-----\n",
    "    print()\n",
    "    print('Are other shared columns equal?')\n",
    "    print(test_df_3.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared].equals(\n",
    "        test_df_3_0.sort_values(by=['aep_endtime_utc'], ignore_index=True)[cols_not_compared])\n",
    "         )\n",
    "    #-----\n",
    "    print()\n",
    "    print('Columns not compared?')\n",
    "    print(f\"in_3_0_not_3: {in_3_0_not_3}\")\n",
    "    print(f\"in_3_not_3_0: {in_3_not_3_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9056be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dfs2 = Utilities_df.get_dfs_diff_approx_ok(test_df_3, test_df_3_0, \n",
    "                                                 sort_by=['aep_endtime_utc'], precision=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dfs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad167d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_sql_stmnt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3beaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dfs[approx_dfs['df1_values']<approx_dfs['df2_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dfs2[approx_dfs2['df1_values']<approx_dfs2['df2_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61160dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78702ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_all_meters_sql = (\"\"\"\n",
    "WITH MP AS (\n",
    "\tSELECT\n",
    "\t\tmfr_devc_ser_nbr,\n",
    "\t\ttrsf_pole_nb\n",
    "\tFROM default.meter_premise\n",
    "\tWHERE ((circuit_nb = '06' AND circuit_nm = 'F-8906' AND station_nb = '0089' AND station_nm = 'SHANNON') OR trsf_pole_nb IN ('1893161692563','1893355692345','1893751692088','1893772692757','1893899692721','1893951691949','1894151692642','1894214691507','1894621689717','1894659692098','1894664692742','1894678692290','1894768691393','1894943690495','1895049690979','1895178691337','1895190688028','1895221691730','1895235691963','1895246688635','1895255692207','1895272691100','1895277692451','1895297692694','1895370693033','1895419689332','1895538690860','1895591688085','1895653691427','1895669689010','1895673688667','1895705692098','1895765692797','1895787693054','1895802691061','1895967692502','1895973688498','1896012692779','1896047688699','1896061691034','1896071691608','1896142689907','1896309691590','1896315692166','1896334691869','1896447691298','1896518692741','1896666693007','1896729691561','1896762692722','1896787690973','1896900691263','1896951692709','1897157690938','1897169691673','1897408691211','1897446691568','1897490692052','1897699691192','1897720691449','1897741691677','1897865690874','1898038691760','1898058691998','1898320691619','1898348691146','1898361692107','1898448692512','1898542690818','1898602691388','1898660692325','1898754690937','1898929691480','1898946692563','1898957691780','1898973692077','1899011693413','1899106690894','1899182691250','1899186691373','1899251692330','1899262692739','1899306686450','1899330690530','1899371693192','1899546687512','1899603693174','1899614693453','1899649692288','1899871692788','1899904694088','1900092693415','1900189693043','1900446693384','1900478693062','1900535686424','1900618686345','1900748686223','1900748694060','1900817693669','1900894686082','1902544684474','1902790683950','1903623679856','1903780683051','1904182681045','1904650682157','1905083680959','1905578681621','1905640682612','1905661682903','1905687683306','1905736683825','1905757684156','1905864684957','1905982685611','1893219692283','1893264692222','1893536692216','1894149691809','1894280692399','1894403692776','1894449691795','1894481692273','1894560691535','1894742692493','1894906690009','1894969691261','1895207688217','1895226688429','1895304688796','1895333688974','1895360690468','1895581688258','1895635688596','1895638690270','1895648689269','1895663691073','1895680691825','1895722692307','1895755692661','1895767688084','1895864690116','1895886691337','1895899688297','1896050692190','1896074689159','1896105691885','1896194693045','1896209691318','1896220692485','1896263692761','1896274689106','1896306691018','1896429693028','1896437689065','1896452689696','1896539691575','1896556692151','1896563691854','1896594692451','1896682691279','1896700692441','1896755691839','1896806691269','1896893692988','1896896691832','1896918692102','1896933692339','1896967689336','1897146691437','1897178691797','1897186691908','1897227692256','1897279690927','1897317692840','1897328692949','1897466691810','1897624690894','1897762691919','1897796692230','1897854692791','1898025691521','1898058692601','1898077692251','1898120691163','1898340691865','1898434690828','1898619691638','1898629691745','1898649691985','1898906691247','1898955692686','1898963692341','1898975692923','1898990693157','1899245691812','1899246692505','1899276692972','1899367693469','1899471686652','1899526692602','1899566692886','1899637687248','1899833693161','1900175686768','1900213687659','1900318693697','1900512684131','1900539693369','1900609693369','1900833684107','1901141684086','1901816683611','1901933681296','1902975679875','1903015683914','1903015684150','1903140683755','1903272683613','1903445683433','1903718680905','1904750680226','1904973685590','1905424683819','1905632682406','1905741684371','1905774683523','1905785684538','1905800685208','1905835685763','1905912686911','1905954684979','1905956685108','1906067685050'))\n",
    "),  \n",
    "KWH_USG_DELREC_W_SIGNED_VAL AS (\n",
    "\tSELECT\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\taep_srvc_qlty_idntfr,\n",
    "\t\tvalue,\n",
    "\t\taep_usage_dt,\n",
    "\t\tIF(aep_srvc_qlty_idntfr='RECEIVED', -1*value, value) AS signed_value\n",
    "\tFROM usage_nonvee.reading_ivl_nonvee\n",
    "\tWHERE aep_usage_dt BETWEEN '2021-01-01' AND '2021-01-02'\n",
    "\tAND   ((aep_derived_uom = 'KWH' AND aep_srvc_qlty_idntfr = 'RECEIVED') OR (aep_derived_uom = 'KWH' AND aep_srvc_qlty_idntfr = 'DELIVERED'))\n",
    "), \n",
    "\n",
    "KWH_USG_DELREC_NET AS (\n",
    "\tSELECT\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\t'DEL_MINUS_REC' AS aep_srvc_qlty_idntfr,\n",
    "\t\tSUM(signed_value) AS value,\n",
    "\t\taep_usage_dt\n",
    "\tFROM KWH_USG_DELREC_W_SIGNED_VAL\n",
    "\tGROUP BY\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\taep_usage_dt\n",
    "\tHAVING COUNT(signed_value) = 2\n",
    "), \n",
    "\n",
    "KWH_USG_TOTAL_VAL AS (\n",
    "\tSELECT\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\taep_srvc_qlty_idntfr,\n",
    "\t\tvalue,\n",
    "\t\taep_usage_dt\n",
    "\tFROM usage_nonvee.reading_ivl_nonvee\n",
    "\tWHERE aep_usage_dt BETWEEN '2021-01-01' AND '2021-01-02'\n",
    "\tAND   ((aep_derived_uom = 'KWH' AND aep_srvc_qlty_idntfr = 'TOTAL'))\n",
    "), \n",
    "\n",
    "KWH_USG_DELREC_NET_UNION_TOTAL_0 AS (\n",
    "\t(\n",
    "\tSELECT\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\taep_srvc_qlty_idntfr,\n",
    "\t\tvalue,\n",
    "\t\taep_usage_dt\n",
    "\tFROM KWH_USG_DELREC_NET\n",
    "\t)\n",
    "\tUNION\n",
    "\t(\n",
    "\tSELECT\n",
    "\t\tserialnumber,\n",
    "\t\tstarttimeperiod,\n",
    "\t\tendtimeperiod,\n",
    "\t\taep_endtime_utc,\n",
    "\t\ttimezoneoffset,\n",
    "\t\taep_derived_uom,\n",
    "\t\taep_srvc_qlty_idntfr,\n",
    "\t\tvalue,\n",
    "\t\taep_usage_dt\n",
    "\tFROM KWH_USG_TOTAL_VAL\n",
    "\t)\n",
    "), \n",
    "\n",
    "U AS (\n",
    "SELECT\n",
    "\tserialnumber,\n",
    "\tstarttimeperiod,\n",
    "\tendtimeperiod,\n",
    "\taep_endtime_utc,\n",
    "\ttimezoneoffset,\n",
    "\taep_derived_uom,\n",
    "\t'CALCULATED_NET' AS aep_srvc_qlty_idntfr,\n",
    "\tvalue,\n",
    "\taep_usage_dt\n",
    "FROM KWH_USG_DELREC_NET_UNION_TOTAL_0\n",
    "), \n",
    "AGG1 AS (\n",
    "\tSELECT\n",
    "\t\tMP.trsf_pole_nb,\n",
    "        U.serialnumber, \n",
    "\t\tU.starttimeperiod,\n",
    "\t\tU.endtimeperiod,\n",
    "\t\tU.aep_endtime_utc,\n",
    "\t\tU.timezoneoffset,\n",
    "\t\tU.aep_derived_uom,\n",
    "\t\tU.aep_srvc_qlty_idntfr,\n",
    "        value, \n",
    "\t\tU.aep_usage_dt\n",
    "\tFROM U\n",
    "\t\tINNER JOIN MP ON U.serialnumber=MP.mfr_devc_ser_nbr\n",
    "\tWHERE U.serialnumber NOT IN ('884390632','880682782','880320285','880076534','880320207','889926007','884390655','880076535')\n",
    ") \n",
    "\n",
    "SELECT * FROM AGG1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_all_meters_df = pd.read_sql(test_3_all_meters_sql, conn_aws)\n",
    "test_3_all_meters_df = Utilities_df.remove_prepend_from_columns_in_df(test_3_all_meters_df)\n",
    "test_3_all_meters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_by_cols_1 = ['trsf_pole_nb', 'starttimeperiod', 'endtimeperiod',\n",
    "                'aep_endtime_utc', 'timezoneoffset', 'aep_derived_uom',\n",
    "                'aep_srvc_qlty_idntfr', 'aep_usage_dt']\n",
    "gp_by_cols_2 = ['starttimeperiod', 'endtimeperiod',\n",
    "                'aep_endtime_utc', 'timezoneoffset', 'aep_derived_uom',\n",
    "                'aep_srvc_qlty_idntfr', 'aep_usage_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_1 = test_3_all_meters_df.groupby(gp_by_cols_1).agg({'value':['sum', 'mean', 'count']})\n",
    "gpd_1 = Utilities_df.flatten_multiindex_index(gpd_1)\n",
    "gpd_1 = gpd_1.reset_index()\n",
    "gpd_1 = Utilities_df.flatten_multiindex_columns(gpd_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a56a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_1.sort_values(by='aep_endtime_utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_2 = gpd_1.groupby(gp_by_cols_2).agg({'sum value':['sum', 'mean', 'count'], \n",
    "                                         'mean value':['sum', 'mean', 'count'], \n",
    "                                         'count value':['sum', 'mean', 'count']})\n",
    "gpd_2 = Utilities_df.flatten_multiindex_index(gpd_2)\n",
    "gpd_2 = gpd_2.sort_values(by='aep_endtime_utc')\n",
    "gpd_2 = Utilities_df.flatten_multiindex_index(gpd_2)\n",
    "gpd_2 = gpd_2.reset_index()\n",
    "gpd_2 = Utilities_df.flatten_multiindex_columns(gpd_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170992ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5148f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpd_1.shape)\n",
    "print(gpd_2.shape)\n",
    "print(test_df_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_3.sort_values(by='aep_endtime_utc')['sum_sum_value']!=gpd_2['sum sum value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42988c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25624f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_3.sort_values(by='aep_endtime_utc').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33103e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86aca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01217f64",
   "metadata": {},
   "source": [
    "# Investigation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b312fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_aws = Utilities.get_athena_prod_aws_connection()\n",
    "cols_of_interest_usage_agg = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                              'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'value', 'aep_usage_dt']\n",
    "\n",
    "serial_numbers = [884390632, 880682782, 880320285, 880076534, 880320207, 889926007, 884390655, 880076535]\n",
    "date_range = ['2021-01-01', '2021-01-02']\n",
    "field_descs=cols_of_interest_usage_agg\n",
    "agg_cols_and_types = {'U.value':['sum', 'sq_sum', 'mean', 'std', 'count']}\n",
    "groupby_cols = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset', \n",
    "                'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'aep_usage_dt']\n",
    "try_to_split_col_strs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d102da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sql_stmnt_3OLD = build_sql_outage_others_on_circuit_OLD(conn_aws, \n",
    "                                                             serial_numbers, date_range, \n",
    "                                                             field_descs, agg_cols_and_types, groupby_cols, \n",
    "                                                             calculate_net_kwh=True, \n",
    "                                                             groupby_xfmr=True, stop_after_agg_1=False,  \n",
    "                                                             try_to_split_col_strs=try_to_split_col_strs, \n",
    "                                                             verbose=False, \n",
    "                                                             include_counts_including_null=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3aeb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sql_stmnt_3NEW = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "    conn_aws, \n",
    "    serial_numbers, date_range, \n",
    "    field_descs, agg_cols_and_types, groupby_cols, \n",
    "    aep_derived_uoms_and_idntfrs=['KWH'], \n",
    "    calculate_net_kwh=True, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "    stop_after_agg_1=False, groupby_xfmr_in_agg_1=True,  \n",
    "    include_counts_including_null=True, \n",
    "    addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs), \n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f5ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sql_stmnt_3ALL = AMINonVeeCircuitSQL.build_sql_outage_others_on_circuit(\n",
    "    conn_aws, \n",
    "    serial_numbers, date_range, \n",
    "    field_descs, agg_cols_and_types, groupby_cols, \n",
    "    aep_derived_uoms_and_idntfrs=None, \n",
    "    calculate_net_kwh=True, addtnl_build_net_kwh_kwargs = dict(run_careful=False), \n",
    "    stop_after_agg_1=False, groupby_xfmr_in_agg_1=True, \n",
    "    include_counts_including_null=True, \n",
    "    addtnl_build_agg_1_sql_kwargs=dict(try_to_split_col_strs=try_to_split_col_strs), \n",
    "    verbose=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927fa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd39b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_sql(test_sql_stmnt_3OLD, conn_aws)\n",
    "df_old = Utilities_df.remove_table_aliases(df_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5338c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod</th>\n",
       "      <th>endtimeperiod</th>\n",
       "      <th>aep_endtime_utc</th>\n",
       "      <th>timezoneoffset</th>\n",
       "      <th>aep_derived_uom</th>\n",
       "      <th>aep_srvc_qlty_idntfr</th>\n",
       "      <th>aep_usage_dt</th>\n",
       "      <th>sum_sum_value</th>\n",
       "      <th>mean_sum_value</th>\n",
       "      <th>sum_sq_sum_value</th>\n",
       "      <th>mean_sq_sum_value</th>\n",
       "      <th>sum_mean_value</th>\n",
       "      <th>mean_mean_value</th>\n",
       "      <th>sum_std_value</th>\n",
       "      <th>mean_std_value</th>\n",
       "      <th>sum_count_value</th>\n",
       "      <th>mean_count_value</th>\n",
       "      <th>sum_counts_including_null</th>\n",
       "      <th>mean_counts_including_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01T00:00:00-05:00</td>\n",
       "      <td>2021-01-01T00:15:00-05:00</td>\n",
       "      <td>1609478100</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>463.613398</td>\n",
       "      <td>2.024513</td>\n",
       "      <td>2384.408151</td>\n",
       "      <td>10.412263</td>\n",
       "      <td>172.160459</td>\n",
       "      <td>0.751792</td>\n",
       "      <td>46.190085</td>\n",
       "      <td>0.228664</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01T00:15:00-05:00</td>\n",
       "      <td>2021-01-01T00:30:00-05:00</td>\n",
       "      <td>1609479000</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>456.909598</td>\n",
       "      <td>1.995238</td>\n",
       "      <td>2250.712478</td>\n",
       "      <td>9.828439</td>\n",
       "      <td>169.752305</td>\n",
       "      <td>0.741276</td>\n",
       "      <td>44.888048</td>\n",
       "      <td>0.222218</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01T00:30:00-05:00</td>\n",
       "      <td>2021-01-01T00:45:00-05:00</td>\n",
       "      <td>1609479900</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>471.755002</td>\n",
       "      <td>2.060066</td>\n",
       "      <td>3083.941783</td>\n",
       "      <td>13.466995</td>\n",
       "      <td>188.032186</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>44.812879</td>\n",
       "      <td>0.221846</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01T00:45:00-05:00</td>\n",
       "      <td>2021-01-01T01:00:00-05:00</td>\n",
       "      <td>1609480800</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>469.834198</td>\n",
       "      <td>2.051678</td>\n",
       "      <td>3513.580693</td>\n",
       "      <td>15.343147</td>\n",
       "      <td>197.367526</td>\n",
       "      <td>0.861867</td>\n",
       "      <td>41.015583</td>\n",
       "      <td>0.203047</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01T01:00:00-05:00</td>\n",
       "      <td>2021-01-01T01:15:00-05:00</td>\n",
       "      <td>1609481700</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>470.665401</td>\n",
       "      <td>2.055307</td>\n",
       "      <td>3834.462165</td>\n",
       "      <td>16.744376</td>\n",
       "      <td>200.611510</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>41.073059</td>\n",
       "      <td>0.203332</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             starttimeperiod              endtimeperiod aep_endtime_utc  \\\n",
       "0  2021-01-01T00:00:00-05:00  2021-01-01T00:15:00-05:00      1609478100   \n",
       "1  2021-01-01T00:15:00-05:00  2021-01-01T00:30:00-05:00      1609479000   \n",
       "2  2021-01-01T00:30:00-05:00  2021-01-01T00:45:00-05:00      1609479900   \n",
       "3  2021-01-01T00:45:00-05:00  2021-01-01T01:00:00-05:00      1609480800   \n",
       "4  2021-01-01T01:00:00-05:00  2021-01-01T01:15:00-05:00      1609481700   \n",
       "\n",
       "  timezoneoffset aep_derived_uom aep_srvc_qlty_idntfr aep_usage_dt  \\\n",
       "0         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "1         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "2         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "3         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "4         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "\n",
       "   sum_sum_value  mean_sum_value  sum_sq_sum_value  mean_sq_sum_value  \\\n",
       "0     463.613398        2.024513       2384.408151          10.412263   \n",
       "1     456.909598        1.995238       2250.712478           9.828439   \n",
       "2     471.755002        2.060066       3083.941783          13.466995   \n",
       "3     469.834198        2.051678       3513.580693          15.343147   \n",
       "4     470.665401        2.055307       3834.462165          16.744376   \n",
       "\n",
       "   sum_mean_value  mean_mean_value  sum_std_value  mean_std_value  \\\n",
       "0      172.160459         0.751792      46.190085        0.228664   \n",
       "1      169.752305         0.741276      44.888048        0.222218   \n",
       "2      188.032186         0.821101      44.812879        0.221846   \n",
       "3      197.367526         0.861867      41.015583        0.203047   \n",
       "4      200.611510         0.876033      41.073059        0.203332   \n",
       "\n",
       "   sum_count_value  mean_count_value  sum_counts_including_null  \\\n",
       "0             1362          5.947598                       1377   \n",
       "1             1362          5.947598                       1377   \n",
       "2             1362          5.947598                       1377   \n",
       "3             1362          5.947598                       1377   \n",
       "4             1362          5.947598                       1377   \n",
       "\n",
       "   mean_counts_including_null  \n",
       "0                      6.0131  \n",
       "1                      6.0131  \n",
       "2                      6.0131  \n",
       "3                      6.0131  \n",
       "4                      6.0131  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_sql(test_sql_stmnt_3NEW, conn_aws)\n",
    "df_new = Utilities_df.remove_table_aliases(df_new)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3f7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_sql(test_sql_stmnt_3ALL, conn_aws)\n",
    "df_all = Utilities_df.remove_table_aliases(df_all)\n",
    "df_all_sub=df_all[df_all['aep_derived_uom']=='KWH'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4070af6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 19)\n",
      "(192, 19)\n",
      "(1920, 19)\n",
      "(192, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df_old.shape)\n",
    "print(df_new.shape)\n",
    "print(df_all.shape)\n",
    "print(df_all_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e811b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e53122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod</th>\n",
       "      <th>endtimeperiod</th>\n",
       "      <th>aep_endtime_utc</th>\n",
       "      <th>timezoneoffset</th>\n",
       "      <th>aep_derived_uom</th>\n",
       "      <th>aep_srvc_qlty_idntfr</th>\n",
       "      <th>aep_usage_dt</th>\n",
       "      <th>sum_sum_value</th>\n",
       "      <th>mean_sum_value</th>\n",
       "      <th>sum_sq_sum_value</th>\n",
       "      <th>mean_sq_sum_value</th>\n",
       "      <th>sum_mean_value</th>\n",
       "      <th>mean_mean_value</th>\n",
       "      <th>sum_std_value</th>\n",
       "      <th>mean_std_value</th>\n",
       "      <th>sum_count_value</th>\n",
       "      <th>mean_count_value</th>\n",
       "      <th>sum_counts_including_null</th>\n",
       "      <th>mean_counts_including_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [starttimeperiod, endtimeperiod, aep_endtime_utc, timezoneoffset, aep_derived_uom, aep_srvc_qlty_idntfr, aep_usage_dt, sum_sum_value, mean_sum_value, sum_sq_sum_value, mean_sq_sum_value, sum_mean_value, mean_mean_value, sum_std_value, mean_std_value, sum_count_value, mean_count_value, sum_counts_including_null, mean_counts_including_null]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sub[(df_all_sub['aep_srvc_qlty_idntfr']=='RECEIVED') & (df_all_sub['sum_sum_value']>0)].sort_values(by=['aep_endtime_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ed30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1daeff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_time = '1609478100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9d1474f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod</th>\n",
       "      <th>endtimeperiod</th>\n",
       "      <th>aep_endtime_utc</th>\n",
       "      <th>timezoneoffset</th>\n",
       "      <th>aep_derived_uom</th>\n",
       "      <th>aep_srvc_qlty_idntfr</th>\n",
       "      <th>aep_usage_dt</th>\n",
       "      <th>sum_sum_value</th>\n",
       "      <th>mean_sum_value</th>\n",
       "      <th>sum_sq_sum_value</th>\n",
       "      <th>mean_sq_sum_value</th>\n",
       "      <th>sum_mean_value</th>\n",
       "      <th>mean_mean_value</th>\n",
       "      <th>sum_std_value</th>\n",
       "      <th>mean_std_value</th>\n",
       "      <th>sum_count_value</th>\n",
       "      <th>mean_count_value</th>\n",
       "      <th>sum_counts_including_null</th>\n",
       "      <th>mean_counts_including_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01T00:00:00-05:00</td>\n",
       "      <td>2021-01-01T00:15:00-05:00</td>\n",
       "      <td>1609478100</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>112.230398</td>\n",
       "      <td>0.490089</td>\n",
       "      <td>2190.807903</td>\n",
       "      <td>9.566847</td>\n",
       "      <td>106.327982</td>\n",
       "      <td>0.464314</td>\n",
       "      <td>3.31023</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.87069</td>\n",
       "      <td>1383</td>\n",
       "      <td>5.961207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             starttimeperiod              endtimeperiod aep_endtime_utc  \\\n",
       "0  2021-01-01T00:00:00-05:00  2021-01-01T00:15:00-05:00      1609478100   \n",
       "\n",
       "  timezoneoffset aep_derived_uom aep_srvc_qlty_idntfr aep_usage_dt  \\\n",
       "0         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "\n",
       "   sum_sum_value  mean_sum_value  sum_sq_sum_value  mean_sq_sum_value  \\\n",
       "0     112.230398        0.490089       2190.807903           9.566847   \n",
       "\n",
       "   sum_mean_value  mean_mean_value  sum_std_value  mean_std_value  \\\n",
       "0      106.327982         0.464314        3.31023        0.016387   \n",
       "\n",
       "   sum_count_value  mean_count_value  sum_counts_including_null  \\\n",
       "0             1362           5.87069                       1383   \n",
       "\n",
       "   mean_counts_including_null  \n",
       "0                    5.961207  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old[df_old['aep_endtime_utc']==utc_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f1d7c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod</th>\n",
       "      <th>endtimeperiod</th>\n",
       "      <th>aep_endtime_utc</th>\n",
       "      <th>timezoneoffset</th>\n",
       "      <th>aep_derived_uom</th>\n",
       "      <th>aep_srvc_qlty_idntfr</th>\n",
       "      <th>aep_usage_dt</th>\n",
       "      <th>sum_sum_value</th>\n",
       "      <th>mean_sum_value</th>\n",
       "      <th>sum_sq_sum_value</th>\n",
       "      <th>mean_sq_sum_value</th>\n",
       "      <th>sum_mean_value</th>\n",
       "      <th>mean_mean_value</th>\n",
       "      <th>sum_std_value</th>\n",
       "      <th>mean_std_value</th>\n",
       "      <th>sum_count_value</th>\n",
       "      <th>mean_count_value</th>\n",
       "      <th>sum_counts_including_null</th>\n",
       "      <th>mean_counts_including_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01T00:00:00-05:00</td>\n",
       "      <td>2021-01-01T00:15:00-05:00</td>\n",
       "      <td>1609478100</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>463.613398</td>\n",
       "      <td>2.024513</td>\n",
       "      <td>2384.408151</td>\n",
       "      <td>10.412263</td>\n",
       "      <td>172.160459</td>\n",
       "      <td>0.751792</td>\n",
       "      <td>46.190085</td>\n",
       "      <td>0.228664</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             starttimeperiod              endtimeperiod aep_endtime_utc  \\\n",
       "0  2021-01-01T00:00:00-05:00  2021-01-01T00:15:00-05:00      1609478100   \n",
       "\n",
       "  timezoneoffset aep_derived_uom aep_srvc_qlty_idntfr aep_usage_dt  \\\n",
       "0         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "\n",
       "   sum_sum_value  mean_sum_value  sum_sq_sum_value  mean_sq_sum_value  \\\n",
       "0     463.613398        2.024513       2384.408151          10.412263   \n",
       "\n",
       "   sum_mean_value  mean_mean_value  sum_std_value  mean_std_value  \\\n",
       "0      172.160459         0.751792      46.190085        0.228664   \n",
       "\n",
       "   sum_count_value  mean_count_value  sum_counts_including_null  \\\n",
       "0             1362          5.947598                       1377   \n",
       "\n",
       "   mean_counts_including_null  \n",
       "0                      6.0131  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new['aep_endtime_utc']==utc_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "394e12e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttimeperiod</th>\n",
       "      <th>endtimeperiod</th>\n",
       "      <th>aep_endtime_utc</th>\n",
       "      <th>timezoneoffset</th>\n",
       "      <th>aep_derived_uom</th>\n",
       "      <th>aep_srvc_qlty_idntfr</th>\n",
       "      <th>aep_usage_dt</th>\n",
       "      <th>sum_sum_value</th>\n",
       "      <th>mean_sum_value</th>\n",
       "      <th>sum_sq_sum_value</th>\n",
       "      <th>mean_sq_sum_value</th>\n",
       "      <th>sum_mean_value</th>\n",
       "      <th>mean_mean_value</th>\n",
       "      <th>sum_std_value</th>\n",
       "      <th>mean_std_value</th>\n",
       "      <th>sum_count_value</th>\n",
       "      <th>mean_count_value</th>\n",
       "      <th>sum_counts_including_null</th>\n",
       "      <th>mean_counts_including_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01T00:00:00-05:00</td>\n",
       "      <td>2021-01-01T00:15:00-05:00</td>\n",
       "      <td>1609478100</td>\n",
       "      <td>-05:00</td>\n",
       "      <td>KWH</td>\n",
       "      <td>CALCULATED_NET</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>463.613398</td>\n",
       "      <td>2.024513</td>\n",
       "      <td>2384.408151</td>\n",
       "      <td>10.412263</td>\n",
       "      <td>172.160459</td>\n",
       "      <td>0.751792</td>\n",
       "      <td>46.190085</td>\n",
       "      <td>0.228664</td>\n",
       "      <td>1362</td>\n",
       "      <td>5.947598</td>\n",
       "      <td>1377</td>\n",
       "      <td>6.0131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             starttimeperiod              endtimeperiod aep_endtime_utc  \\\n",
       "2  2021-01-01T00:00:00-05:00  2021-01-01T00:15:00-05:00      1609478100   \n",
       "\n",
       "  timezoneoffset aep_derived_uom aep_srvc_qlty_idntfr aep_usage_dt  \\\n",
       "2         -05:00             KWH       CALCULATED_NET   2021-01-01   \n",
       "\n",
       "   sum_sum_value  mean_sum_value  sum_sq_sum_value  mean_sq_sum_value  \\\n",
       "2     463.613398        2.024513       2384.408151          10.412263   \n",
       "\n",
       "   sum_mean_value  mean_mean_value  sum_std_value  mean_std_value  \\\n",
       "2      172.160459         0.751792      46.190085        0.228664   \n",
       "\n",
       "   sum_count_value  mean_count_value  sum_counts_including_null  \\\n",
       "2             1362          5.947598                       1377   \n",
       "\n",
       "   mean_counts_including_null  \n",
       "2                      6.0131  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sub[df_all_sub['aep_endtime_utc']==utc_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7c5e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.23039838299155\n",
      "463.6133982941974\n",
      "463.6133982941974\n"
     ]
    }
   ],
   "source": [
    "print(df_old[df_old['aep_endtime_utc']==utc_time]['sum_sum_value'].sum())\n",
    "print(df_new[df_new['aep_endtime_utc']==utc_time]['sum_sum_value'].sum())\n",
    "print(df_all_sub[df_all_sub['aep_endtime_utc']==utc_time]['sum_sum_value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7483fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520c863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114dd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1eca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
