{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import string\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL, DfToSqlMap\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from OutageDAQ import OutageDAQ, OutageDAQOutg, OutageDAQOtBL, OutageDAQPrBL\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSingleSlicer as DFSingleSlicer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b435877-05a6-46fb-a20a-49a9d5da8af1",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!! IMPORTANT (?) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61447789-1847-48a8-aa6a-4061bed27186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In MeterPremise, can I create a function which will build mp_df_hist given mp_df_curr?\n",
    "In DOVSOutages I need to build new build_mp_for_outg (and update its use throughout)\n",
    "    APPARENTLY I already have this, build_active_MP_for_outages or one of other similar functions\n",
    "    \n",
    "I need to basically replace everything in DOVSOutages which uses build_mp_for_outg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60281d-723a-4c45-b66e-ffd26b1b99d6",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01df82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e943a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# VARIABLES TO BE SET BY USER!\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "save_dfs_to_file   = True\n",
    "read_dfs_from_file = False\n",
    "save_end_events    = True\n",
    "\n",
    "#-------------------------\n",
    "# run_date is used to collect all results from a given acquisiton run together.\n",
    "# As such, run_date should be set to the first date of the acquisition run, and\n",
    "#   SHOULD NOT be changed for each individual date in a run (which typically lasts\n",
    "#   over the course of days/weeks)\n",
    "run_date = '20240906'\n",
    "\n",
    "#-------------------------\n",
    "date_0 = '2023-04-01' # Lower limit for end events\n",
    "date_1 = '2024-08-31' # Upper limit for end events\n",
    "search_time_half_window = datetime.timedelta(days=31)\n",
    "\n",
    "#--------------------------------------------------\n",
    "# NOTE: below, states and opcos should be consistent!\n",
    "#       i.e., e.g., if states='OH', then opcos should be 'oh' (or None, I suppose)\n",
    "#-------------------------\n",
    "# states used to \n",
    "#   (1) find transformers which suffered at least one outage from DOVS\n",
    "#   (2) find all transformers from MeterPremise\n",
    "# states can be:\n",
    "#   - a single string, e.g. 'OH'\n",
    "#   - a list of strings, e.g., ['OH', 'WV']\n",
    "#   - None\n",
    "# NOTE: states tend to be upper-case!\n",
    "states=['OH']\n",
    "\n",
    "#-------------------------\n",
    "# opcos used with AMIEndEvents to\n",
    "#  (1) find the premise numbers which recorded an event between date_0 and date_1.\n",
    "#  (2) selection/acquisiton of end_device_events\n",
    "# opcos can be:\n",
    "#   - a single string, e.g. 'oh'\n",
    "#   - a list of strings, e.g., ['oh', 'tx']\n",
    "#   - None\n",
    "# NOTE: opcos tend to be lower-case!\n",
    "# NOTE: Acceptable opcos appear to be: ['ap', 'im', 'oh', 'pso', 'swp', 'tx']\n",
    "opcos='oh'\n",
    "\n",
    "#-------------------------\n",
    "# cities = None\n",
    "cities = ['COLUMBUS']\n",
    "\n",
    "\n",
    "# TODO!!!!!!!!!!!!!!!!!!\n",
    "single_zip_xfmrs_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e2d3a-c7c8-4501-9d05-da3b945f7988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1212755-6d9f-463b-9f91-287fe3c13040",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### NEW\n",
    "outg_daq = OutageDAQOutg(\n",
    "    run_date                = run_date, \n",
    "    date_0                  = date_0, \n",
    "    date_1                  = date_1, \n",
    "    collect_evs_sum_vw      = False,  \n",
    "    save_sub_dir            = 'Outgs_Full', \n",
    "    search_time_half_window = search_time_half_window, \n",
    "    states                  = states, \n",
    "    opcos                   = opcos, \n",
    "    cities                  = cities, \n",
    "    single_zip_xfmrs_only   = single_zip_xfmrs_only, \n",
    "    save_end_events         = save_end_events, \n",
    "    save_dfs_to_file        = save_dfs_to_file, \n",
    "    read_dfs_from_file      = read_dfs_from_file, \n",
    "    base_dir                = os.path.join(\n",
    "        Utilities.get_local_data_dir(), \n",
    "        r'dovs_and_end_events_data'\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204894a-5848-40ec-be4b-b73359b841a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# OUTAGES\n",
    "#--------------------------------------------------\n",
    "outg_daq.build_or_load_df_outage_OG(verbose=True)\n",
    "outg_daq.build_or_load_df_mp_outg(verbose=True)\n",
    "outg_daq.build_or_load_df_outage_slim()\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Build zip code information for transformers, \n",
    "# and possibly restrict data to single zipcode transformers only\n",
    "#--------------------------------------------------\n",
    "outg_daq.build_or_load_trsf_pole_zips_info(verbose=True)\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Collect Events\n",
    "#--------------------------------------------------\n",
    "outg_daq.collect_events(\n",
    "    batch_size         = None, \n",
    "    verbose            = True, \n",
    "    n_update           = 1, \n",
    "    delete_all_others  = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb4870-cbe2-4532-883f-cce5c4bfee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b2e2d-b98c-4358-900a-70cddf45b62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641848be-29d3-454c-9860-d105ccb5fb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e3544d9-a9dd-4d21-9a58-920a5fef4909",
   "metadata": {},
   "source": [
    "# OLD DEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f72aa1-b3b9-4b3f-bcd9-57b07d657671",
   "metadata": {},
   "source": [
    "### OutageDAQOutg constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b18fb-573d-4494-a025-1678b903712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde35de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# DFs will be saved in save_dir_base\n",
    "# Collection of end events files will be saved in os.path.join(save_dir_base, 'EndEvents')\n",
    "save_dir_base = os.path.join(\n",
    "    Utilities.get_local_data_dir(), \n",
    "    r'dovs_and_end_events_data', \n",
    "    run_date, \n",
    "    f\"{date_0.replace('-','')}_{date_1.replace('-','')}\", \n",
    "    'Outgs_Full_OLD'\n",
    ")\n",
    "#-------------------------\n",
    "end_events_save_args = dict(\n",
    "    save_to_file = save_end_events, \n",
    "    save_dir     = os.path.join(save_dir_base, 'EndEvents'), \n",
    "    save_name    = r'end_events.csv', \n",
    "    index        = True\n",
    ")\n",
    "#-------------------------\n",
    "print(f\"save_dir_base = {save_dir_base}\")\n",
    "print('end_events_save_args')\n",
    "for k,v in end_events_save_args.items():\n",
    "    print(f\"\\t{k} : {v}\")\n",
    "#-------------------------\n",
    "if save_dfs_to_file or save_end_events:\n",
    "    if not os.path.exists(save_dir_base):\n",
    "        os.makedirs(save_dir_base)\n",
    "    #-----\n",
    "    if save_end_events and not os.path.exists(end_events_save_args['save_dir']):\n",
    "        os.makedirs(end_events_save_args['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "assert(save_dfs_to_file+read_dfs_from_file <=1) # Should never both read and write!\n",
    "assert(pd.to_datetime(date_1)-pd.to_datetime(date_0) > 2*search_time_half_window)\n",
    "#--------------------------------------------------\n",
    "if not read_dfs_from_file:\n",
    "    conn_outages = Utilities.get_utldb01p_oracle_connection()\n",
    "    conn_aws     = Utilities.get_athena_prod_aws_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7a6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "697ad41a",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------\n",
    "# OUTAGES\n",
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfa004-9e8d-45ac-b8cf-dc59f69d87aa",
   "metadata": {},
   "source": [
    "### build_or_load_df_outage_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fecfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Find outages between date_0 and date_1 for states\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "start=time.time()\n",
    "print('-----'*20+f'\\nFinding outages between {date_0} and {date_1} for states={states}\\n'+'-----'*10)\n",
    "if read_dfs_from_file:\n",
    "    print(f\"Reading df_outage_OG from file: {os.path.join(save_dir_base, 'df_outage_OG.pkl')}\")\n",
    "    df_outage_OG = pd.read_pickle(os.path.join(save_dir_base, 'df_outage_OG.pkl'))\n",
    "else:\n",
    "    sql_outage_full = DOVSOutages_SQL.build_sql_std_outage(\n",
    "        mjr_mnr_cause   = None, \n",
    "        include_premise = True, \n",
    "        date_range      = [date_0, date_1], \n",
    "        states          = states, \n",
    "        opcos           = opcos, \n",
    "        cities          = cities\n",
    "    ).get_sql_statement()\n",
    "    #-----\n",
    "    print(f'sql_outage_full:\\n{sql_outage_full}\\n\\n')\n",
    "    #-----\n",
    "    df_outage_OG = pd.read_sql_query(\n",
    "        sql_outage_full, \n",
    "        conn_outages, \n",
    "        dtype = {\n",
    "            'CI_NB':np.int32, \n",
    "            'CMI_NB':np.float64, \n",
    "            'OUTG_REC_NB':np.int32\n",
    "        }\n",
    "    )\n",
    "    if save_dfs_to_file:\n",
    "        df_outage_OG.to_pickle(os.path.join(save_dir_base, 'df_outage_OG.pkl'))\n",
    "#-----\n",
    "print(f\"df_outage_OG.shape = {df_outage_OG.shape}\")\n",
    "print(f\"# OUTG_REC_NBs     = {df_outage_OG['OUTG_REC_NB'].nunique()}\")\n",
    "print(f'\\ntime = {time.time()-start}\\n'+'-----'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf57fc0-3e33-4e79-bd05-70448a2986d8",
   "metadata": {},
   "source": [
    "### build_or_load_df_mp_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_dfs_from_file:\n",
    "    # No real reason to read in df_mp_outg_OG, as it's not used after df_mp_outg is built\n",
    "    # df_mp_outg_OG = pd.read_pickle(os.path.join(save_dir_base, 'df_mp_outg_b4_dupl_rmvl.pkl'))\n",
    "    df_mp_outg = pd.read_pickle(os.path.join(save_dir_base, 'df_mp_outg_full.pkl'))\n",
    "else:\n",
    "    df_mp_outg_OG = OutageDAQOutg.build_active_MP_for_outages_df(\n",
    "        df_outage            = df_outage_OG, \n",
    "        prem_nb_col          = 'PREMISE_NB', \n",
    "        is_slim              = False, \n",
    "        assert_all_PNs_found = False\n",
    "    )\n",
    "    #-----\n",
    "    df_mp_outg_OG['inst_ts'] = pd.to_datetime(df_mp_outg_OG['inst_ts'])\n",
    "    df_mp_outg_OG['rmvl_ts'] = pd.to_datetime(df_mp_outg_OG['rmvl_ts'])\n",
    "    #-----\n",
    "    if save_dfs_to_file:\n",
    "        df_mp_outg_OG.to_pickle(os.path.join(save_dir_base, 'df_mp_outg_b4_dupl_rmvl.pkl'))\n",
    "    #-------------------------\n",
    "    df_mp_outg = MeterPremise.drop_approx_mp_duplicates(\n",
    "        mp_df                 = df_mp_outg_OG.copy(), \n",
    "        fuzziness             = pd.Timedelta('1 hour'), \n",
    "        assert_single_overlap = True, \n",
    "        addtnl_groupby_cols   = ['OUTG_REC_NB'], \n",
    "        gpby_dropna           = False\n",
    "    )\n",
    "    #-----\n",
    "    if save_dfs_to_file:\n",
    "        df_mp_outg.to_pickle(os.path.join(save_dir_base, 'df_mp_outg_full.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447d24d-4b5a-4aa5-9eed-9cee2f07aef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69883087-68f7-4f42-8a6f-530f28c467b4",
   "metadata": {},
   "source": [
    "### build_or_load_df_outage_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060e104-149d-45e4-926b-88dc3426cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_dfs_from_file:\n",
    "    df_outage      = pd.read_pickle(os.path.join(save_dir_base, 'df_outage.pkl'))\n",
    "    df_outage_slim = pd.read_pickle(os.path.join(save_dir_base, 'df_outage_slim.pkl'))\n",
    "else:\n",
    "    df_outage = DOVSOutages.merge_df_outage_with_mp(\n",
    "        df_outage          = df_outage_OG.copy(), \n",
    "        df_mp              = df_mp_outg, \n",
    "        merge_on_outg      = ['OUTG_REC_NB', 'PREMISE_NB'], \n",
    "        merge_on_mp        = ['OUTG_REC_NB', 'prem_nb'], \n",
    "        cols_to_include_mp = None, \n",
    "        drop_cols          = None, \n",
    "        rename_cols        = None, \n",
    "        inplace            = True\n",
    "    )\n",
    "    #-------------------------\n",
    "    #df_outage_slim_OLD = DOVSOutages.consolidate_df_outage_OLD(df_outage)\n",
    "    df_outage_slim     = DOVSOutages.consolidate_df_outage(\n",
    "        df_outage, \n",
    "        addtnl_grpby_cols        = ['trsf_pole_nb'], \n",
    "        set_outg_rec_nb_as_index = False\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    df_outage_slim = DOVSOutages.set_search_time_in_outage_df(\n",
    "        df_outage               = df_outage_slim, \n",
    "        search_time_half_window = search_time_half_window\n",
    "    )\n",
    "    \n",
    "    #-------------------------\n",
    "    if save_dfs_to_file:\n",
    "        df_outage.to_pickle(os.path.join(save_dir_base, 'df_outage.pkl'))\n",
    "        df_outage_slim.to_pickle(os.path.join(save_dir_base, 'df_outage_slim.pkl'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771b625",
   "metadata": {},
   "source": [
    "# Build zip code information for transformers, and possibly restrict data to single zipcode transformers only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413fd8a-5053-4aff-ac97-1ec335e0ac8f",
   "metadata": {},
   "source": [
    "### build_or_load_trsf_pole_zips_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29a045-8ac2-4ef7-b897-192d13315bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6147b-7187-474b-8279-2c0e0ead6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_dfs_from_file:\n",
    "    mp_for_zips_df    = pd.read_pickle(os.path.join(save_dir_base, 'mp_for_zips_df.pkl'))\n",
    "    trsf_pole_df_full = pd.read_pickle(os.path.join(save_dir_base, 'trsf_location_info_df.pkl'))\n",
    "    trsf_pole_zips_df = pd.read_pickle(os.path.join(save_dir_base, 'trsf_pole_zips_df.pkl'))\n",
    "else:\n",
    "    zips_dict = OutageDAQ.build_trsf_pole_zips_df(\n",
    "        field_to_split_and_val = ('premise_nbs', df_mp_outg['prem_nb'].unique().tolist()), \n",
    "        states                 = states, \n",
    "        opcos                  = opcos, \n",
    "        cities                 = cities\n",
    "    )\n",
    "    #----------\n",
    "    trsf_pole_zips_df = zips_dict['trsf_pole_zips_df']\n",
    "    trsf_pole_df_full = zips_dict['trsf_pole_df_full']\n",
    "    mp_for_zips_df    = zips_dict['mp_for_zips_df']\n",
    "    #--------------------------------------------------\n",
    "    if save_dfs_to_file:\n",
    "        mp_for_zips_df.to_pickle(   os.path.join(save_dir_base, 'mp_for_zips_df.pkl'))\n",
    "        trsf_pole_df_full.to_pickle(os.path.join(save_dir_base, 'trsf_location_info_df.pkl'))\n",
    "        trsf_pole_zips_df.to_pickle(os.path.join(save_dir_base, 'trsf_pole_zips_df.pkl'))\n",
    "#--------------------------------------------------\n",
    "if single_zip_xfmrs_only:\n",
    "    trsf_pole_nzips   = trsf_pole_zips_df.drop(columns=['zip+4']).drop_duplicates()['trsf_pole_nb'].value_counts()\n",
    "    single_zip_poles  = trsf_pole_nzips[trsf_pole_nzips==1].index.tolist()\n",
    "    #-----\n",
    "    trsf_pole_zips_df = trsf_pole_zips_df[trsf_pole_zips_df['trsf_pole_nb'].isin(single_zip_poles)]\n",
    "    #-----\n",
    "    df_outage      = df_outage[df_outage['trsf_pole_nb'].isin(single_zip_poles)].copy()\n",
    "    df_outage_slim = df_outage_slim[df_outage_slim['trsf_pole_nb'].isin(single_zip_poles)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455eddf-6b62-4f48-8606-504f486384ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf94899-9c16-48a8-a0c7-6f9a392fa43f",
   "metadata": {},
   "source": [
    "### collect_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d465100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_outage_slim['OUTG_REC_NB'].nunique())\n",
    "print(len(DOVSOutages.get_prem_nbs_from_consolidated_df_outage(df_outage_slim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del df_outage_OG\n",
    "    del df_outage\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22392a-d12d-4767-ae84-5ad196fec034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "df_construct_type              = DFConstructType.kRunSqlQuery\n",
    "contstruct_df_args_end_events  = None\n",
    "addtnl_groupby_cols            = ['OUTG_REC_NB', 'trsf_pole_nb']\n",
    "\n",
    "cols_of_interest_end_dev_event = TableInfos.AMIEndEvents_TI.std_columns_of_interest\n",
    "# batch_size = 10\n",
    "batch_size = 30\n",
    "verbose    = True\n",
    "n_update   = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb262a7-b7c3-4361-9e0b-df8636b7fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_events_sql_function_kwargs = dict(\n",
    "    cols_of_interest                  = cols_of_interest_end_dev_event, \n",
    "    df_outage                         = df_outage_slim, \n",
    "    build_sql_function                = AMIEndEvents_SQL.build_sql_end_events, \n",
    "    build_sql_function_kwargs         = dict(\n",
    "        states = states, \n",
    "        opcos  = opcos, \n",
    "        cities = cities\n",
    "    ), \n",
    "    join_mp_args                      = False, \n",
    "    df_args                           = dict(\n",
    "        addtnl_groupby_cols = addtnl_groupby_cols, \n",
    "        mapping_to_ami      = DfToSqlMap(df_col='PREMISE_NBS', kwarg='premise_nbs', sql_col='aep_premise_nb'), \n",
    "        is_df_consolidated  = True\n",
    "    ), \n",
    "    # GenAn - keys_to_pop in GenAn.build_sql_general\n",
    "    field_to_split                    = 'df_outage', \n",
    "    field_to_split_location_in_kwargs = ['df_outage'], \n",
    "    save_and_dump                     = True, \n",
    "    sort_coll_to_split                = True,\n",
    "    batch_size                        = batch_size, \n",
    "    verbose                           = verbose, \n",
    "    n_update                          = n_update\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b19fd-7460-491b-80f7-5e3abf319472",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "exit_status = Utilities.run_tryexceptwhile_process(\n",
    "    func                = AMIEndEvents,\n",
    "    func_args_dict      = dict(\n",
    "        df_construct_type         = df_construct_type, \n",
    "        contstruct_df_args        = contstruct_df_args_end_events, \n",
    "        build_sql_function        = AMIEndEvents_SQL.build_sql_end_events_for_outages, \n",
    "        build_sql_function_kwargs = end_events_sql_function_kwargs, \n",
    "        init_df_in_constructor    = True, \n",
    "        save_args                 = end_events_save_args\n",
    "    ), \n",
    "    max_calls_per_min   = 1, \n",
    "    lookback_period_min = 15, \n",
    "    max_calls_absolute  = 1000, \n",
    "    verbose             = True\n",
    ")\n",
    "print(f'exit_status = {exit_status}')\n",
    "\n",
    "build_time = time.time()-start\n",
    "print(build_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d233b9-9779-4988-bb10-5b591d848fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71de5a-4c64-48d6-a945-8362e98ccb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
