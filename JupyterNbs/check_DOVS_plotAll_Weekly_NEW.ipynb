{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabbf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./check_DOVS_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import adjustText\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from DOVSAudit import DOVSAudit\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSingleSlicer as DFSingleSlicer\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65d6fd",
   "metadata": {},
   "source": [
    "# Analyze collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074daca",
   "metadata": {},
   "source": [
    "## AMI NonVee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_0 = '2024-02-04'\n",
    "date_1 = '2024-02-10'\n",
    "#-------------------------\n",
    "save_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check'\n",
    "save_subdir = f\"{date_0.replace('-','')}_{date_1.replace('-','')}\"\n",
    "#-----\n",
    "base_dir     = os.path.join(save_dir_base, save_subdir)\n",
    "base_dir_ami = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\AMINonVee')\n",
    "base_dir_ede = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\EndEvents')\n",
    "save_dir     = os.path.join(save_dir_base, save_subdir, r'AllOPCOs\\Results')\n",
    "#-----\n",
    "assert(os.path.exists(base_dir_ami))\n",
    "assert(os.path.exists(base_dir_ede))\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_to_files_dict = DOVSAudit.get_outg_rec_nb_to_files_dict_ami(\n",
    "    base_dir_dict   = base_dir,\n",
    "    base_dir_data   = base_dir_ami, \n",
    "    rebuild         = False, \n",
    "    save_dict       = True\n",
    ")\n",
    "all_outg_rec_nbs = list(outg_rec_nb_to_files_dict.keys())\n",
    "#-------------------------\n",
    "outg_rec_nb_to_files_ede_dict = DOVSAudit.get_outg_rec_nb_to_files_dict_ede(\n",
    "    base_dir_dict   = base_dir,\n",
    "    base_dir_data   = base_dir_ede, \n",
    "    rebuild         = False, \n",
    "    save_dict       = True\n",
    ")\n",
    "all_outg_rec_nbs_ede = list(outg_rec_nb_to_files_ede_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_suboutg_endpt_plots=True\n",
    "\n",
    "calculate_by_PN = True\n",
    "# combine_by_PN_likeness_thresh = pd.Timedelta('1 minutes')\n",
    "combine_by_PN_likeness_thresh = pd.Timedelta('15 minutes')\n",
    "\n",
    "expand_outg_search_time_tight = pd.Timedelta('1 hours')\n",
    "expand_outg_search_time_loose = pd.Timedelta('12 hours')\n",
    "use_est_outg_times=False\n",
    "# use_est_outg_times=True\n",
    "use_full_ede_outgs=False\n",
    "run_outg_inclusion_assessment=True\n",
    "max_pct_PNs_missing_allowed=0\n",
    "# max_pct_PNs_missing_allowed=20\n",
    "#-----\n",
    "expand_outg_est_search_time = expand_outg_search_time_loose\n",
    "if use_est_outg_times:\n",
    "    expand_outg_search_time = expand_outg_search_time_tight\n",
    "else:\n",
    "    expand_outg_search_time = expand_outg_search_time_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(save_dir, r'Results.pdf')\n",
    "pdf = PdfPages(pdf_path)\n",
    "#-------------------------\n",
    "pdf_path_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_dovs_beg = PdfPages(pdf_path_dovs_beg)\n",
    "#-------------------------\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_path_2 = Utilities.append_to_path(\n",
    "        pdf_path, \n",
    "        '_w_suboutg_endpt_plots', \n",
    "        ext_to_find='.pdf', \n",
    "        append_to_end_if_ext_no_found=False\n",
    "    )\n",
    "    pdf_2 = PdfPages(pdf_path_2)\n",
    "#-------------------------\n",
    "pdf_path_n_w_power = os.path.join(save_dir, r'n_w_power_v_time.pdf')\n",
    "pdf_n_w_power = PdfPages(pdf_path_n_w_power)\n",
    "#-----\n",
    "pdf_path_n_w_power_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path_n_w_power, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_n_w_power_dovs_beg = PdfPages(pdf_path_n_w_power_dovs_beg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_PNs_w_power_threshold = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11b7ff-9187-48ff-bc96-33fd9e49ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d73bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "all_detailed_summary_dfs=[]\n",
    "all_detailed_summary_dfs_dovs_beg=[]\n",
    "ci_cmi_summary_df = pd.DataFrame(columns=[\n",
    "    'outg_rec_nb', \n",
    "    'ci_dovs',  'ci_ami', 'ci_ami_dovs_beg', \n",
    "    'cmi_dovs', 'cmi_ami', 'cmi_ami_dovs_beg'\n",
    "])\n",
    "warnings_text = ''\n",
    "\n",
    "#-------------------------\n",
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=all_outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "\n",
    "#-------------------------\n",
    "# Now, iterate through all outages\n",
    "for i_outg, outg_rec_nb in enumerate(all_outg_rec_nbs):\n",
    "    print(f'\\n\\ti_outg: {i_outg+1}/{len(all_outg_rec_nbs)}')\n",
    "    print(f'\\toutg_rec_nb = {outg_rec_nb}')\n",
    "    if outg_rec_nb == '13723021':\n",
    "        continue\n",
    "    if outg_rec_nb == '13749993':\n",
    "        continue\n",
    "    if outg_rec_nb == '13759308' or outg_rec_nb == '13761444':\n",
    "        continue\n",
    "    if outg_rec_nb == '13759308':\n",
    "        continue\n",
    "    if outg_rec_nb == '13739166':\n",
    "        continue\n",
    "    #--------------------------------------------------\n",
    "    audit_i = DOVSAudit(\n",
    "        outg_rec_nb=outg_rec_nb\n",
    "    )\n",
    "    audit_i.load_ami_from_csvs(\n",
    "        paths                          = outg_rec_nb_to_files_dict[outg_rec_nb], \n",
    "        slicers                        = None, \n",
    "        ami_df_info_dict               = None, \n",
    "        run_std_init                   = True, \n",
    "        cols_and_types_to_convert_dict = None, \n",
    "        to_numeric_errors              = 'coerce', \n",
    "        drop_na_rows_when_exception    = True, \n",
    "        drop_unnamed0_col              = True, \n",
    "        pd_read_csv_kwargs             = None, \n",
    "        make_all_columns_lowercase     = False, \n",
    "        assert_all_cols_equal          = True, \n",
    "        min_fsize_MB                   = None\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.ami_df_i.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    #-------------------------\n",
    "    # Need to load dovs before running self assessment below\n",
    "    audit_i.load_dovs(\n",
    "        dovs_df           = dovs_df, \n",
    "        dovs_df_info_dict = None\n",
    "    )\n",
    "    \n",
    "    if run_outg_inclusion_assessment:\n",
    "        to_include_i = audit_i.self_assess_outage_inclusion_requirements(max_pct_PNs_missing_allowed, None)\n",
    "        if not to_include_i:\n",
    "            print(f'outg_rec_nb={outg_rec_nb} did not pass inclusion requirements, skipping!!!!!')\n",
    "            continue\n",
    "    #-------------------------    \n",
    "    n_SNs  = audit_i.ami_df_i['serialnumber'].nunique()\n",
    "    n_PNs  = audit_i.ami_df_i['aep_premise_nb'].nunique()\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NOTE: Can save time by grabbing ede_df_i then performing tz conversion and adding DOVS\n",
    "    if outg_rec_nb not in outg_rec_nb_to_files_ede_dict.keys():\n",
    "        ede_df_i=None\n",
    "    else:\n",
    "        audit_i.load_ede_from_csvs(\n",
    "            paths                          = outg_rec_nb_to_files_ede_dict[outg_rec_nb], \n",
    "            slicers                        = None, \n",
    "            ede_df_info_dict               = None, \n",
    "            run_std_init                   = True, \n",
    "            cols_and_types_to_convert_dict = None, \n",
    "            to_numeric_errors              = 'coerce', \n",
    "            drop_na_rows_when_exception    = True, \n",
    "            drop_unnamed0_col              = True, \n",
    "            pd_read_csv_kwargs             = None, \n",
    "            make_all_columns_lowercase     = False, \n",
    "            assert_all_cols_equal          = True, \n",
    "            min_fsize_MB                   = None\n",
    "        )\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    audit_i.build_best_ests_df()\n",
    "    #-------------------------\n",
    "    # Get the outage time from DOVS\n",
    "    dovs_outg_t_beg_end              = audit_i.dovs_outg_t_beg_end\n",
    "    dovs_outg_t_beg, dovs_outg_t_end = dovs_outg_t_beg_end\n",
    "    #-------------------------\n",
    "    # Get the CI and CMI from DOVS\n",
    "    ci_cmi_dovs       = audit_i.ci_cmi_dovs\n",
    "    ci_dovs, cmi_dovs = ci_cmi_dovs\n",
    "    #-------------------------\n",
    "    # Get the number of premises from DOVS\n",
    "    n_PNs_dovs = audit_i.n_PNs_dovs\n",
    "    #-------------------------\n",
    "    # Get the outage number from DOVS\n",
    "    outage_nb = audit_i.outage_nb\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    # cnsrvtv_out_t_beg/_end are used for placing bounds on the plots generated\n",
    "    # If audit_i.best_ests_df has non-zero size (meaning the algorithm found outages), use to set plotting time.\n",
    "    # Otherwise, use dovs_outg_t_beg/_end\n",
    "    # NOTE: If one did not want to show any data which was thrown out due to overlapping, one would want to\n",
    "    #         update cnsrvtv_out_t_beg/_end after the identify_dovs_overlaps_from_best_ests procedure below \n",
    "    #         (and subsequent trimming of audit_i.best_ests_df)\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        cnsrvtv_out_t_beg = np.min([audit_i.best_ests_df['conservative_min'].min(), dovs_outg_t_beg])\n",
    "        cnsrvtv_out_t_end = np.max([audit_i.best_ests_df['conservative_max'].max(), dovs_outg_t_end])\n",
    "    else:\n",
    "        cnsrvtv_out_t_beg = dovs_outg_t_beg\n",
    "        cnsrvtv_out_t_end = dovs_outg_t_end\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        # Identify and handle any overlaps with other DOVS events\n",
    "        #-------------------------\n",
    "        # dovs_sql_fcn=DOVSOutages_SQL.build_sql_std_outage\n",
    "        dovs_sql_fcn=DOVSOutages_SQL.build_sql_outage\n",
    "        audit_i.identify_overlaps(overlaps_dovs_sql_fcn = dovs_sql_fcn)\n",
    "        #-------------------------\n",
    "        # If any PN has one or more overlapping DOVS events, output info to file\n",
    "        n_PNs_w_overlap = (audit_i.overlap_outgs_for_PNs_df['n_overlap']>0).sum()\n",
    "        if n_PNs_w_overlap>0:\n",
    "            print(f'Need to output to new file\\n\\tn_PNs_w_overlap={n_PNs_w_overlap}')\n",
    "        #-------------------------\n",
    "        # If any PN which lost power has one or more overlapping DOVS events, stop analysis\n",
    "        n_out_PNs_w_overlap = audit_i.overlap_outgs_for_PNs_df[audit_i.overlap_outgs_for_PNs_df['lost_power']==True]['overlap_outg_rec_nbs'].apply(lambda x: len(x)>0).sum()\n",
    "        if n_out_PNs_w_overlap>0:\n",
    "            print('STOP analysis')\n",
    "            continue\n",
    "        #-------------------------\n",
    "        audit_i.resolve_overlapping_audits()\n",
    "        #-----\n",
    "        ci_ami  = audit_i.ci\n",
    "        cmi_ami = audit_i.cmi            \n",
    "        #-------------------------\n",
    "        ami_df_i = audit_i.ami_df_i.copy()\n",
    "        # In ami_df_i, mark any entries which were essentially removed via the identify_dovs_overlaps_from_best_ests\n",
    "        #   and removal procedure above\n",
    "        ami_df_i = DOVSAudit.set_removed_due_to_overlap_in_ami_df_i(\n",
    "            ami_df_i                   = ami_df_i, \n",
    "            best_ests_df               = audit_i.best_ests_df_w_keep_info.copy(), \n",
    "            PN_col                     = 'aep_premise_nb', \n",
    "            time_idfr                  = 'starttimeperiod_local', \n",
    "            PN_col_be                  = 'PN', \n",
    "            keep_col_be                = 'keep', \n",
    "            overlap_times_col_be       = 'overlap_times', \n",
    "            removed_due_to_overlap_col = 'removed_due_to_overlap'\n",
    "        )\n",
    "    else:\n",
    "        ci_ami  = 0\n",
    "        cmi_ami = 0\n",
    "        ami_df_i = audit_i.ami_df_i.copy()\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        best_ests_df_dovs_beg = DOVSAudit.alter_best_ests_df_using_dovs_outg_t_beg(\n",
    "            best_ests_df = audit_i.best_ests_df,\n",
    "            dovs_df      = dovs_df, \n",
    "            outg_rec_nb  = outg_rec_nb\n",
    "        )\n",
    "        if calculate_by_PN:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['PN'].nunique()\n",
    "        else:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['SN'].nunique()\n",
    "        cmi_ami_dovs_beg = (best_ests_df_dovs_beg['winner_max']-best_ests_df_dovs_beg['winner_min']).sum().total_seconds()/60\n",
    "    else:\n",
    "        best_ests_df_dovs_beg = audit_i.best_ests_df.copy()\n",
    "        ci_ami_dovs_beg  = ci_ami\n",
    "        cmi_ami_dovs_beg = cmi_ami        \n",
    "    #--------------------------------------------------\n",
    "    dovs_df_i = DOVSOutages.retrieve_outage_from_dovs_df(\n",
    "        dovs_df                  = dovs_df, \n",
    "        outg_rec_nb              = audit_i.outg_rec_nb, \n",
    "        outg_rec_nb_idfr         = 'index', \n",
    "        assert_outg_rec_nb_found = True\n",
    "    )    \n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        means_df, best_ests_df_w_db_lbl = DOVSAudit.get_mean_times_w_dbscan(\n",
    "            best_ests_df                  = audit_i.best_ests_df, \n",
    "            eps_min                       = 5, \n",
    "            min_samples                   = 2, \n",
    "            ests_to_include_in_clustering = ['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output     = [\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df  = True\n",
    "        )\n",
    "        #-------------------------\n",
    "        n_PNs_w_power_srs = DOVSAudit.build_n_PNs_w_power_srs(\n",
    "            best_ests_df  = audit_i.best_ests_df, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )        \n",
    "        #-------------------------\n",
    "        detailed_summary_df_i = DOVSAudit.build_detailed_summary_df(\n",
    "            means_df              = means_df, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_w_db_lbl,\n",
    "            CI_tot                = ci_ami, \n",
    "            CMI_tot               = cmi_ami, \n",
    "            n_PNs_ami             = n_PNs,\n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            dovs_df_i             = dovs_df_i, \n",
    "            warnings_flag         = audit_i.warnings_flag, \n",
    "            db_label_col          = 'db_label', \n",
    "            winner_min_col        = 'winner_min', \n",
    "            winner_max_col        = 'winner_max', \n",
    "            PN_col                = 'PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col            = 'i_outg'\n",
    "        )\n",
    "        #----------\n",
    "        detailed_summary_df_i[f'first_above_thresh ({n_PNs_w_power_threshold})'] = None\n",
    "        detailed_summary_df_i[f'last_above_thresh ({n_PNs_w_power_threshold})']  = None\n",
    "        frst_abv, last_abv = get_first_last_above_threshold(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs, \n",
    "            threshold         = n_PNs_w_power_threshold\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'first_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = frst_abv\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'last_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = last_abv        \n",
    "        #-------------------------\n",
    "        all_detailed_summary_dfs.append(detailed_summary_df_i)\n",
    "        \n",
    "        #-------------------------\n",
    "        warnings_text += audit_i.generate_warnings_text()\n",
    "    else:\n",
    "        means_df, best_ests_df_w_db_lbl = None, None\n",
    "        n_PNs_w_power_srs = None\n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = DOVSAudit.get_mean_times_w_dbscan(\n",
    "            best_ests_df                  = best_ests_df_dovs_beg, \n",
    "            eps_min                       = 5, \n",
    "            min_samples                   = 2, \n",
    "            ests_to_include_in_clustering = ['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output     = [\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df  = True\n",
    "        )\n",
    "        #-------------------------\n",
    "        n_PNs_w_power_srs_dovs_beg = DOVSAudit.build_n_PNs_w_power_srs(\n",
    "            best_ests_df  = best_ests_df_dovs_beg, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )        \n",
    "        #-------------------------\n",
    "        detailed_summary_df_dovs_beg_i = DOVSAudit.build_detailed_summary_df(\n",
    "            means_df              = means_df_dovs_beg, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_dovs_beg_w_db_lbl,\n",
    "            CI_tot                = ci_ami_dovs_beg, \n",
    "            CMI_tot               = cmi_ami_dovs_beg, \n",
    "            n_PNs_ami             = n_PNs,\n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            dovs_df_i             = dovs_df_i, \n",
    "            warnings_flag         = audit_i.warnings_flag, \n",
    "            db_label_col          = 'db_label', \n",
    "            winner_min_col        = 'winner_min', \n",
    "            winner_max_col        = 'winner_max', \n",
    "            PN_col                = 'PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col            = 'i_outg'\n",
    "        )\n",
    "        #----------\n",
    "        detailed_summary_df_dovs_beg_i[f'first_above_thresh ({n_PNs_w_power_threshold})'] = None\n",
    "        detailed_summary_df_dovs_beg_i[f'last_above_thresh ({n_PNs_w_power_threshold})']  = None\n",
    "        frst_abv, last_abv = get_first_last_above_threshold(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs_dovs_beg, \n",
    "            threshold         = n_PNs_w_power_threshold\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_dovs_beg_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_dovs_beg_i.columns.tolist().index(f'first_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = frst_abv\n",
    "        #-----\n",
    "        detailed_summary_df_dovs_beg_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_dovs_beg_i.columns.tolist().index(f'last_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = last_abv        \n",
    "        #-------------------------\n",
    "        all_detailed_summary_dfs_dovs_beg.append(detailed_summary_df_dovs_beg_i)\n",
    "    else:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = None, None\n",
    "    #-------------------------\n",
    "    ci_cmi_summary_df = pd.concat([\n",
    "        ci_cmi_summary_df, \n",
    "        pd.DataFrame(\n",
    "            dict(\n",
    "                outg_rec_nb=outg_rec_nb, \n",
    "                ci_dovs=ci_dovs,   ci_ami=ci_ami, ci_ami_dovs_beg=ci_ami_dovs_beg, \n",
    "                cmi_dovs=cmi_dovs, cmi_ami=cmi_ami, cmi_ami_dovs_beg=cmi_ami_dovs_beg\n",
    "            ), \n",
    "            index=[ci_cmi_summary_df.shape[0]]\n",
    "        )\n",
    "    ])\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # ######################### PLOTTING #########################\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    # Instead of using get_full_part_not_outage_subset_dfs, simply grab the PNs which suffered\n",
    "    #   outages from best_ests_df\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        outg_SNs = audit_i.best_ests_df['PN'].unique().tolist()\n",
    "        removed_due_to_overlap_col = 'removed_due_to_overlap'\n",
    "    else:\n",
    "        outg_SNs = []\n",
    "        removed_due_to_overlap_col = None\n",
    "    #-----\n",
    "    ami_df_i_out      = ami_df_i[ami_df_i['aep_premise_nb'].isin(outg_SNs)]\n",
    "    ami_df_i_not_out  = ami_df_i[~ami_df_i['aep_premise_nb'].isin(outg_SNs)]  \n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df_w_keep_info is not None and audit_i.best_ests_df_w_keep_info.shape[0]>0:\n",
    "        ptntl_ovrlp_outg_rec_nbs = list(set(audit_i.best_ests_df_w_keep_info['overlap_DOVS'].sum()))\n",
    "        if len(ptntl_ovrlp_outg_rec_nbs)>0:\n",
    "            ovrlp_dovs = DOVSOutages(\n",
    "                df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "                contstruct_df_args=None, \n",
    "                init_df_in_constructor=True,\n",
    "                build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "                build_sql_function_kwargs=dict(\n",
    "                    outg_rec_nbs=ptntl_ovrlp_outg_rec_nbs, \n",
    "                    include_premise=True\n",
    "                ), \n",
    "                build_consolidated=True\n",
    "            )\n",
    "            other_dovs_events_df = ovrlp_dovs.df.reset_index().copy()\n",
    "        else:\n",
    "            other_dovs_events_df = None\n",
    "    else:\n",
    "        other_dovs_events_df = None\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    fig, axs = plot_all_out_not_NEW(\n",
    "        fig_num                    = fig_num, \n",
    "        ami_df_i                   = ami_df_i, \n",
    "        ami_df_i_out               = ami_df_i_out, \n",
    "        ami_df_i_not_out           = ami_df_i_not_out, \n",
    "        dovs_outg_t_beg            = dovs_outg_t_beg, \n",
    "        dovs_outg_t_end            = dovs_outg_t_end, \n",
    "        cnsrvtv_out_t_beg          = cnsrvtv_out_t_beg, \n",
    "        cnsrvtv_out_t_end          = cnsrvtv_out_t_end, \n",
    "        means_df                   = means_df, \n",
    "        outg_rec_nb                = outg_rec_nb, \n",
    "        outage_nb                  = outage_nb, \n",
    "        n_PNs_dovs                 = n_PNs_dovs, \n",
    "        ci_dovs                    = ci_dovs, \n",
    "        cmi_dovs                   = cmi_dovs, \n",
    "        ci_ami                     = ci_ami, \n",
    "        cmi_ami                    = cmi_ami, \n",
    "        name                       = 'AMI', \n",
    "        results_2_dict             = dict(\n",
    "            ci_ami   = ci_ami_dovs_beg, \n",
    "            cmi_ami  = cmi_ami_dovs_beg, \n",
    "            means_df = means_df_dovs_beg, \n",
    "            name = 'AMI w/ DOVS t_beg'\n",
    "        ), \n",
    "        expand_time                = pd.Timedelta('1 hour'), \n",
    "        removed_due_to_overlap_col = removed_due_to_overlap_col, \n",
    "        mean_keys_to_include       = ['winner', 'conservative', 'zero_times'], \n",
    "        default_subplots_args      = dict(n_x=2, n_y=2, row_major=True, sharex=True), \n",
    "        other_dovs_events_df       = other_dovs_events_df, \n",
    "        leg_i_plot                 = 1, \n",
    "        leg_kwargs                 = dict(ncols=1, fontsize=15, bbox_to_anchor=(1, 1.2)), \n",
    "        ci_info_fontsize           = 16, \n",
    "        left_text_x                = 0.915  \n",
    "    )\n",
    "\n",
    "    if n_PNs_w_power_srs is not None:\n",
    "        fig, axs[3] = DOVSAudit.plot_n_PNs_w_power_srs(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs, \n",
    "            simp_freq         = '1T', \n",
    "            threshold         = n_PNs_w_power_threshold, \n",
    "            fig_num           = fig_num, \n",
    "            fig_ax            = (fig, axs[3]), \n",
    "            threshold_color   = 'magenta'\n",
    "        )\n",
    "        \n",
    "    for ax_i in axs:\n",
    "        ax_i.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    fig_num += 1\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    if include_suboutg_endpt_plots:\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df_dovs_beg is not None:\n",
    "        fig, axs = plot_all_out_not_NEW(\n",
    "            fig_num              = fig_num, \n",
    "            ami_df_i             = ami_df_i, \n",
    "            ami_df_i_out         = ami_df_i_out, \n",
    "            ami_df_i_not_out     = ami_df_i_not_out, \n",
    "            dovs_outg_t_beg      = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end      = dovs_outg_t_end, \n",
    "            cnsrvtv_out_t_beg    = cnsrvtv_out_t_beg, \n",
    "            cnsrvtv_out_t_end    = cnsrvtv_out_t_end, \n",
    "            means_df             = means_df_dovs_beg, \n",
    "            outg_rec_nb          = outg_rec_nb, \n",
    "            outage_nb            = outage_nb, \n",
    "            n_PNs_dovs           = n_PNs_dovs, \n",
    "            ci_dovs              = ci_dovs, \n",
    "            cmi_dovs             = cmi_dovs, \n",
    "            ci_ami               = ci_ami_dovs_beg, \n",
    "            cmi_ami              = cmi_ami_dovs_beg, \n",
    "            name                 = 'AMI w/ DOVS t_beg', \n",
    "            results_2_dict       = dict(\n",
    "                ci_ami   = ci_ami, \n",
    "                cmi_ami  = cmi_ami, \n",
    "                means_df = means_df, \n",
    "                name = 'AMI'\n",
    "            ), \n",
    "            expand_time          = pd.Timedelta('1 hour'), \n",
    "            removed_due_to_overlap_col = removed_due_to_overlap_col, \n",
    "            mean_keys_to_include = ['winner', 'conservative', 'zero_times'], \n",
    "            default_subplots_args      = dict(n_x=2, n_y=2, row_major=True, sharex=True), \n",
    "            other_dovs_events_df       = other_dovs_events_df, \n",
    "            leg_i_plot                 = 1, \n",
    "            leg_kwargs                 = dict(ncols=1, fontsize=15, bbox_to_anchor=(1, 1.2)), \n",
    "            ci_info_fontsize           = 16, \n",
    "            left_text_x                = 0.915  \n",
    "        )\n",
    "        \n",
    "        if n_PNs_w_power_srs_dovs_beg is not None:\n",
    "            fig, axs[3] = DOVSAudit.plot_n_PNs_w_power_srs(\n",
    "                n_PNs_w_power_srs = n_PNs_w_power_srs_dovs_beg, \n",
    "                simp_freq         = '1T', \n",
    "                threshold         = n_PNs_w_power_threshold, \n",
    "                fig_num           = fig_num, \n",
    "                fig_ax            = (fig, axs[3]), \n",
    "                threshold_color   = 'magenta'\n",
    "            )\n",
    "\n",
    "        for ax_i in axs:\n",
    "            ax_i.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "        fig_num += 1\n",
    "        pdf_dovs_beg.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df is not None and include_suboutg_endpt_plots:\n",
    "        fig, axs = plot_suboutg_endpts(\n",
    "            fig_num               = fig_num, \n",
    "            ami_df_i              = ami_df_i, \n",
    "            means_df              = means_df, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_w_db_lbl, \n",
    "            dovs_outg_t_beg       = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end       = dovs_outg_t_end, \n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            expand_time           = pd.Timedelta('15 minutes'), \n",
    "            mean_keys_to_include  = ['winner', 'conservative', 'zero_times']\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        _, fig, ax = DOVSAudit.build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df  = audit_i.best_ests_df, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            simp_freq     = '1T', \n",
    "            threshold     = n_PNs_w_power_threshold, \n",
    "            fig_num       = fig_num, \n",
    "            title         = f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        _, fig, ax = DOVSAudit.build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df  = best_ests_df_dovs_beg, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            simp_freq     = '1T', \n",
    "            threshold     = n_PNs_w_power_threshold, \n",
    "            fig_num       = fig_num, \n",
    "            title         = f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power_dovs_beg.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "detailed_summary_df          = pd.concat(all_detailed_summary_dfs)\n",
    "detailed_summary_df_dovs_beg = pd.concat(all_detailed_summary_dfs_dovs_beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23be694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()\n",
    "pdf_dovs_beg.close()\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_2.close()\n",
    "pdf_n_w_power.close()\n",
    "pdf_n_w_power_dovs_beg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cmi_summary_df['ci_dovs']         = ci_cmi_summary_df['ci_dovs'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami']          = ci_cmi_summary_df['ci_ami'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami_dovs_beg'] = ci_cmi_summary_df['ci_ami_dovs_beg'].astype(float)\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami']\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami_dovs_beg']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami_dovs_beg']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami_dovs_beg'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami_dovs_beg']\n",
    "#-----\n",
    "# For plotting purposes, make a outg_rec_in column which is simply 0 to delta_df.shape[0]-1\n",
    "ci_cmi_summary_df['outg_rec_int'] = range(ci_cmi_summary_df.shape[0])\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_summary_df.to_pickle(os.path.join(save_dir, r'detailed_summary.pkl'))\n",
    "detailed_summary_df_dovs_beg.to_pickle(os.path.join(save_dir, r'detailed_summary_dovs_beg.pkl'))\n",
    "ci_cmi_summary_df.to_pickle(os.path.join(save_dir, r'ci_cmi_summary.pkl'))\n",
    "#-----\n",
    "detailed_summary_df.to_csv(os.path.join(save_dir, r'detailed_summary.csv'))\n",
    "detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, r'detailed_summary_dovs_beg.csv'))\n",
    "ci_cmi_summary_df.to_csv(os.path.join(save_dir, r'ci_cmi_summary.csv'))\n",
    "#-----\n",
    "# For Mico and Amanda\n",
    "detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, f'detailed_summary_dovs_beg_{save_subdir}.csv'))\n",
    "#-----\n",
    "with open(os.path.join(save_dir, r'warnings.txt'), 'w') as f:\n",
    "    f.write(warnings_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57ce29",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997d5eb-f6cf-4063-a8d9-06306de71a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
