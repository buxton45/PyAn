{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17087ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "import itertools\n",
    "from dateutil.parser import parse\n",
    "from operator import itemgetter\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acovf, acf, pacf, pacf_yw, pacf_ols\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.graphics.tsaplots import month_plot, quarter_plot, seasonal_plot\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA, ARMAResults, ARIMAResults\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from arch import arch_model\n",
    "\n",
    "from scipy.stats.mstats import trim\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "# import constants for the days of the week\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest\n",
    "import DickeyFullerTest as dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed602ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7e9c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d4d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e3bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65b16ed8",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20d57c",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_level(index_name, df):\n",
    "    index_names = list(df.index.names)\n",
    "    index_level=None\n",
    "    for i,idx_name_i in enumerate(index_names):\n",
    "        if idx_name_i==index_name:\n",
    "            assert(index_level is None)\n",
    "            index_level = i\n",
    "    assert(index_level is not None)\n",
    "    return index_level\n",
    "\n",
    "def find_datetime_idx(df):\n",
    "    # NOTE: For now, this will fail if more than one datetime index is found\n",
    "    # This is enforced through the line: assert(datetime_idx is None)\n",
    "    datetime_idx = None\n",
    "    grouped_cols = list(df.index.names)\n",
    "    if len(grouped_cols)==1:\n",
    "        if isinstance(df.index[0], datetime.datetime):\n",
    "            datetime_idx = {'idx_level':0, 'idx_name':grouped_cols[0]}\n",
    "    else:\n",
    "        assert(len(grouped_cols)==len(df.index[0]))\n",
    "        for i in range(len(grouped_cols)):\n",
    "            if isinstance(df.index[0][i], datetime.datetime):\n",
    "                assert(datetime_idx is None)\n",
    "                datetime_idx = {'idx_level':i, 'idx_name':grouped_cols[i]}\n",
    "    return datetime_idx\n",
    "\n",
    "def find_in_df_columns_or_indices(df, names):\n",
    "    # Determine where names are located in df (special case if name found in index and is datetime)\n",
    "    # Returns dict {'names_in_cols':names_in_cols, 'names_in_idxs':names_in_idxs}\n",
    "    #     names_in_cols is a list of all names found in the columns of df\n",
    "    #     names_in_idxs is a dictionary with:\n",
    "    #         'datetime_idx' = None or {'idx_level':idx_level, 'idx_name':idx_name} if found to be datetime\n",
    "    #         'regular_idxs' = list of non-datetime indices, where eadch element\n",
    "    #                          is a dict of the form {'idx_level':idx_level, 'idx_name':idx_name}\n",
    "    #\n",
    "    # NOTE: For now, this will fail if more than one datetime index is found\n",
    "    # This is enforced through the line: assert(datetime_idx is None)\n",
    "    #-------------------------\n",
    "    names_in_idxs = {'datetime_idx':None, 'regular_idxs':[]}\n",
    "    names_in_cols = []\n",
    "    #-------------------------\n",
    "    col_names = df.columns.tolist()\n",
    "    idx_names = list(df.index.names)\n",
    "    sample_idx = df.index[0] # Used for determining if datetime element exists\n",
    "    #-------------------------\n",
    "    for name in names:\n",
    "        if name in col_names:\n",
    "            names_in_cols.append(name)\n",
    "        elif name in idx_names:\n",
    "            if len(idx_names)==1:\n",
    "                if isinstance(sample_idx, datetime.datetime):\n",
    "                    assert(names_in_idxs['datetime_idx'] is None)\n",
    "                    names_in_idxs['datetime_idx'] = {'idx_level':0, 'idx_name':name}\n",
    "            else:\n",
    "                idx_level = idx_names.index(name)\n",
    "                if isinstance(sample_idx[idx_level], datetime.datetime):\n",
    "                    assert(names_in_idxs['datetime_idx'] is None)\n",
    "                    names_in_idxs['datetime_idx'] = {'idx_level':idx_level, 'idx_name':name}\n",
    "                else:\n",
    "                    regular_idx = {'idx_level':idx_level, 'idx_name':name}\n",
    "                    names_in_idxs['regular_idxs'].append(regular_idx)\n",
    "        else:\n",
    "            print(f'Name: {name} NOT FOUND in df columns or indices')\n",
    "            assert(0)\n",
    "    names_in_cols_and_idxs_dict = {'names_in_cols':names_in_cols, 'names_in_idxs':names_in_idxs}\n",
    "    return names_in_cols_and_idxs_dict\n",
    "\n",
    "def get_list_of_idx_level_name_value_dicts(list_of_idx_level_name_dicts, names_vals_dict):\n",
    "    # names_vals_dict = {'idx_name_1':idx_val_1, 'idx_name_2':idx_val_2, ... , 'idx_name_n':idx_val_n}\n",
    "    # list_of_idx_level_name_dicts = [{'idx_level':idx_level_a, 'idx_name': idx_name_a}, \n",
    "    #                                 {'idx_level':idx_level_b, 'idx_name': idx_name_b}, \n",
    "    #                                                    ...\n",
    "    #                                 {'idx_level':idx_level_m, 'idx_name': idx_name_m}]\n",
    "    # \n",
    "    # return_list_dicts = [{'idx_level':idx_level_a, 'idx_name': idx_name_a, 'idx_value':idx_val_a}, \n",
    "    #                      {'idx_level':idx_level_b, 'idx_name': idx_name_b, 'idx_value':idx_val_b}, \n",
    "    #                                         ...\n",
    "    #                      {'idx_level':idx_level_m, 'idx_name': idx_name_m, 'idx_value':idx_val_m}]    \n",
    "    \n",
    "    # Only the members included in list_of_idx_level_name_dicts will be in the returned list.\n",
    "    # This implies each 'idx_name' value in list_of_idx_level_name_dicts must be a key in names_vals_dict.\n",
    "    # -----> names_vals_dict must include at least all members in list_of_idx_level_name_dicts, \n",
    "    #        but can also include more without effect.\n",
    "    # -----------------------------------------------------------------------\n",
    "    return_list_dicts = []\n",
    "    for level_name_dict in list_of_idx_level_name_dicts:\n",
    "        assert(level_name_dict['idx_name'] in names_vals_dict)\n",
    "        return_list_dicts.append({**level_name_dict, \n",
    "                                  **{'idx_value':names_vals_dict[level_name_dict['idx_name']]}\n",
    "                                 })\n",
    "    return return_list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_idx_select_arg_list(list_of_idx_level_name_value_dicts, df_idx_names):\n",
    "    # list_of_idx_level_name_value_dicts can include entries for all levels in df, but does not have to.\n",
    "    # Any missing level will be assigned a value of slice(None), which is equivalent for no slicing on that level\n",
    "    #\n",
    "    # list_of_idx_level_name_value_dicts = [{'idx_level':0, 'idx_name':'time_idx', 'idx_value':pd.to_datetime('2018-10-04 12:00:00')}, \n",
    "    #                                       {'idx_level':2, 'idx_name': 'prem_nb', 'idx_value':109826791}]\n",
    "    # idx_select_arg_list = (pd.to_datetime('2018-10-04 12:00:00'), slice(None), 109826791)\n",
    "    # ----------------------------------------------------------------\n",
    "    n_idx_levels_in_df = len(df_idx_names)\n",
    "    assert(len(list_of_idx_level_name_value_dicts) <= n_idx_levels_in_df)\n",
    "    assert(all(x['idx_name'] in df_idx_names for x in list_of_idx_level_name_value_dicts))\n",
    "    #-------------------------\n",
    "    if len(list_of_idx_level_name_value_dicts) < n_idx_levels_in_df:\n",
    "        for level,df_idx_name in enumerate(df_idx_names):\n",
    "            if df_idx_name not in [x['idx_name'] for x in list_of_idx_level_name_value_dicts]:\n",
    "                list_of_idx_level_name_value_dicts.append({'idx_level':level, 'idx_name': df_idx_name, 'idx_value':slice(None)})\n",
    "    \n",
    "    # Make sure each level has a value\n",
    "    assert(all(x['idx_name'] in df_idx_names for x in list_of_idx_level_name_value_dicts))\n",
    "    assert(all(x['idx_level'] in list(range(len(df_idx_names))) for x in list_of_idx_level_name_value_dicts))\n",
    "\n",
    "    # Get a list of the index values on which to select\n",
    "    # sorted by the index level\n",
    "    list_of_idx_level_value_dicts = {x['idx_level']:x['idx_value'] for x in list_of_idx_level_name_value_dicts}\n",
    "    idx_select_arg_list = []\n",
    "    for level in range(len(df_idx_names)):\n",
    "        idx_select_arg_list.append(list_of_idx_level_value_dicts[level])\n",
    "    # Convert idx_select_arg_list to usable form\n",
    "    idx_select_arg_list = tuple(x if x is not None else slice(None) for x in idx_select_arg_list)\n",
    "    return idx_select_arg_list\n",
    "\n",
    "\n",
    "def replace_cols_in_gpd_df_with_values_from_df_singlegroup(gpd_vals_dict, gpd_df, df, resample_freq, cols_to_replace):\n",
    "    # TODO!!!!!!!!!!!!!!\n",
    "    # if datetime index included, resample_freq MUST match the frequency used for gpd_df\n",
    "    #\n",
    "    # gpd_vals_dict should be a dictionary containing keys which are indice names from gpd_vals_dict\n",
    "    #   and values are corresponding values to group\n",
    "    # If all indices from gpd_vals_dict are included, this is the same thing as replacing the column\n",
    "    #   values row by row.  This can be very time consuming\n",
    "    # In most cases (indeed in the case for which this was designed) the time index can be excluded\n",
    "    #\n",
    "    # cols_to_replace should be columns in gpd_df, not indices\n",
    "    # Enforce this\n",
    "    tmp_dict = find_in_df_columns_or_indices(gpd_df, cols_to_replace)\n",
    "    assert(tmp_dict['names_in_idxs']['datetime_idx'] is None)\n",
    "    assert(len(tmp_dict['names_in_idxs']['regular_idxs'])==0)\n",
    "\n",
    "    # All keys in gpd_vals_dict should be indices in gpd_df\n",
    "    # Assert this\n",
    "    # At the same time, find if any datetime indices supplied in gpd_vals_dict\n",
    "    gpd_df_idx_names = list(gpd_df.index.names)\n",
    "    gpd_datetime_idx=None\n",
    "    for key in gpd_vals_dict:\n",
    "        assert(key in gpd_df_idx_names)\n",
    "        if isinstance(gpd_vals_dict[key], datetime.datetime):\n",
    "            gpd_datetime_idx = {'idx_level': gpd_df_idx_names.index(key), 'idx_name': key}\n",
    "\n",
    "    # Determine where in df the gpd_vals_dict.keys() are located\n",
    "    names_in_cols_and_idxs_dict = find_in_df_columns_or_indices(df, gpd_vals_dict.keys())\n",
    "    gpd_cols_in_df_cols = names_in_cols_and_idxs_dict['names_in_cols']\n",
    "    gpd_cols_in_df_idxs = names_in_cols_and_idxs_dict['names_in_idxs']\n",
    "\n",
    "    # If datetime index found in gpd_df, one should also be found in df\n",
    "    # More generally, gpd_datetime_idx should equal gpd_cols_in_df_idxs['datetime_idx'], \n",
    "    #   whether they equal a datetime idx, or both equal None\n",
    "    assert(gpd_cols_in_df_idxs['datetime_idx']==gpd_datetime_idx)\n",
    "    #------------------------------------------------------------------\n",
    "    # First, apply selection via indices, then columns\n",
    "    # If datetime index, apply first\n",
    "    if gpd_datetime_idx is not None:\n",
    "        # The methodology here also only will work of the time index is the first index\n",
    "        # TODO THIS COULD BE CHANGED USING THE 'idx_level' info!\n",
    "        assert(gpd_cols_in_df_idxs['datetime_idx']['idx_level']==0)\n",
    "        t_slice_beg = gpd_vals_dict[gpd_datetime_idx['idx_name']]\n",
    "        t_slice_end = t_slice_beg + pd.to_timedelta(resample_freq if resample_freq[0].isnumeric() else '1'+resample_freq)\n",
    "        df = df.loc[t_slice_beg:t_slice_end]\n",
    "    # Now, other indices\n",
    "    regular_idxs = gpd_cols_in_df_idxs['regular_idxs']\n",
    "    if len(regular_idxs)>0:\n",
    "        # Make sure entries in regular_idxs are in correct order\n",
    "        regular_idxs = sorted(regular_idxs, key=lambda x: x['idx_level'])\n",
    "        # Get values for indices\n",
    "        regular_idx_vals = [gpd_vals_dict[x['idx_name']] for x in regular_idxs]\n",
    "        regular_list_of_idx_level_name_value_dicts = get_list_of_idx_level_name_value_dicts(regular_idxs, gpd_vals_dict)\n",
    "        regular_idx_select_arg_list = build_idx_select_arg_list(regular_list_of_idx_level_name_value_dicts, list(df.index.names))\n",
    "                \n",
    "        df = df.loc(axis=0)[pd.IndexSlice[regular_idx_select_arg_list]]\n",
    "    # ------------------------------------------------------------\n",
    "    # Now, apply selection via columns\n",
    "    col_bool_mask = [True]*df.shape[0]\n",
    "    for col in gpd_cols_in_df_cols:\n",
    "        col_bool_mask = (col_bool_mask) & (df[col]==gpd_vals_dict[col])\n",
    "    df = df.loc[col_bool_mask]\n",
    "    # ------------------------------------------------------------\n",
    "    # Now, df is reduced down to only the elements of interest\n",
    "    # Need to grab the values for all columns in cols_to_replace\n",
    "    # There should only be one unique value for each, let's enforce this with asset\n",
    "    replace_dict = {}\n",
    "    for col in cols_to_replace:\n",
    "        value_counts = df[col].value_counts()\n",
    "        n_unique = len(value_counts)\n",
    "        # n_unique should be 1, with the only exception being\n",
    "        # when a column is full of NaNs, in which case n_unique will be 0\n",
    "        assert(n_unique==1 or n_unique==0)\n",
    "        if n_unique==0:\n",
    "            # All values should be NaNs\n",
    "            assert(all(df[col].isna()))\n",
    "            value = np.nan\n",
    "        else:\n",
    "            value = value_counts.index[0]\n",
    "        assert(col not in replace_dict)\n",
    "        replace_dict[col] = value\n",
    "    # ------------------------------------------------------------\n",
    "    # Finally, replace the value(s) in gpd_df with replace_dict\n",
    "    list_of_idx_level_name_dicts_to_include = [{'idx_level': get_index_level(x, gpd_df), 'idx_name': x} for x in gpd_vals_dict]\n",
    "    list_of_idx_level_name_value_dicts = get_list_of_idx_level_name_value_dicts(list_of_idx_level_name_dicts_to_include, gpd_vals_dict)\n",
    "    idx_select_arg_list = build_idx_select_arg_list(list_of_idx_level_name_value_dicts, list(gpd_df.index.names))\n",
    "    gpd_df.loc[pd.IndexSlice[idx_select_arg_list], cols_to_replace] = itemgetter(*tuple(cols_to_replace))(replace_dict)\n",
    "    \n",
    "    # Could also return df is wanted for debugging/answer checking\n",
    "    return gpd_df\n",
    "\n",
    "\n",
    "# For each entry in gpd_df, I need to grab the values of the variables used for grouping.\n",
    "# Then, I need to get that group from df_kwh_15T to find the values of all other columns to be set.\n",
    "#\n",
    "# Typically (but not always): \n",
    "#     the time_idx grouped will be the index of df_kwh_15T\n",
    "#     any other grouping variables are columns in df_kwh_15T\n",
    "# However, it may occur that df_kwh_15T has a multi-index, in which the grouping\n",
    "# variable are contained.  Any of these cases should work\n",
    "\n",
    "def replace_cols_in_gpd_df_with_values_from_df(gpd_df, df, resample_freq, cols_to_replace, exclude_time_idx=True):\n",
    "    # Not recommended to set exclude_time_idx=False unless dfs are small\n",
    "    #   as this will perform the replacement row-by-row.\n",
    "    # exclude_time_idx=True is far more efficient \n",
    "    #TODO build in option to allow user to input the names of indices to be included\n",
    "    #    Right now, all indices in gpd_df are included, except possibly the time index\n",
    "    gpd_datetime_idx = find_datetime_idx(gpd_df)\n",
    "    n_idxs = len(gpd_df.index[0])\n",
    "    level = []\n",
    "    for i in range(n_idxs):\n",
    "        if (exclude_time_idx and \n",
    "            gpd_datetime_idx is not None and \n",
    "            gpd_datetime_idx['idx_level']==i):\n",
    "            continue\n",
    "        level.append(i)\n",
    "    #-------------------------\n",
    "    all_groups = list(gpd_df.groupby(level=level).groups.keys())\n",
    "    idx_names_to_include = [list(gpd_df.index.names)[lvl] for lvl in level]\n",
    "    assert(len(all_groups[0])==len(idx_names_to_include))\n",
    "    gpd_vals_dicts = [dict(zip(idx_names_to_include, grp)) for grp in all_groups]    \n",
    "    #-------------------------\n",
    "    for gpd_vals_dict in gpd_vals_dicts:\n",
    "        gpd_df = replace_cols_in_gpd_df_with_values_from_df_singlegroup(gpd_vals_dict=gpd_vals_dict, \n",
    "                                                                        gpd_df=gpd_df, \n",
    "                                                                        df=df, \n",
    "                                                                        resample_freq=resample_freq, \n",
    "                                                                        cols_to_replace=cols_to_replace)\n",
    "    return gpd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02af3d",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d474c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd3435b",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7855d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0f44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ba04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf915765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be32d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_df = pd.read_csv(os.path.join(Utilities.get_local_data_dir(), r'sample_outages\\outg_rec_nb_11751094\\outg_rec_nb_11751094_2019_q4.csv'))\n",
    "# read_df = read_df[read_df['serialnumber']==880687439]\n",
    "# read_df = read_df[(read_df['aep_derived_uom']=='KWH') & (read_df['aep_srvc_qlty_idntfr']=='TOTAL')]\n",
    "# read_df = read_df[['endtimeperiod', 'endtimeperiod','aep_endtime_utc', 'timezoneoffset']]\n",
    "# read_df = read_df.sort_values(by='aep_endtime_utc', ignore_index=True)\n",
    "# read_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
