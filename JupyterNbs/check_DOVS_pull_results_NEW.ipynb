{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./check_DOVS_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import adjustText\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#-----\n",
    "from DOVSAudit import DOVSAudit\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "from Utilities_df import DFConstructType\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65d6fd",
   "metadata": {},
   "source": [
    "# Analyze collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074daca",
   "metadata": {},
   "source": [
    "## AMI NonVee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\Mico2\\NEWAF3'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs = [\n",
    "    r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\Mico2\\AllOPCOs'\n",
    "]\n",
    "assert(all([os.path.exists(dir_i) for dir_i in base_dirs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f05b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_to_files_dicts = []\n",
    "outg_rec_nb_to_files_ede_dicts = []\n",
    "for base_dir in base_dirs:\n",
    "    print(base_dir)\n",
    "    base_dir_ami = os.path.join(base_dir, r'AMINonVee')\n",
    "    base_dir_ede = os.path.join(base_dir, r'EndEvents')\n",
    "    assert(os.path.exists(base_dir_ami))\n",
    "    assert(os.path.exists(base_dir_ede))\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    if os.path.exists(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl')):\n",
    "        with open(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl'), 'rb') as handle:\n",
    "            outg_rec_nb_to_files_dict = pickle.load(handle)\n",
    "    else:\n",
    "        #-------------------------\n",
    "        paths = Utilities.find_all_paths(\n",
    "            base_dir=base_dir_ami, \n",
    "            glob_pattern=r'ami_nonvee_[0-9]*.csv', \n",
    "            regex_pattern=None\n",
    "        )\n",
    "        paths=natsorted(paths)\n",
    "        #-------------------------\n",
    "        outg_rec_nbs_in_files = dict()\n",
    "        for path in paths:\n",
    "            assert(path not in outg_rec_nbs_in_files.keys())\n",
    "            df = GenAn.read_df_from_csv(path)\n",
    "            outg_rec_nbs_in_files[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "        outg_rec_nb_to_files_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files)\n",
    "        #-------------------------\n",
    "        with open(os.path.join(base_dir, 'outg_rec_nb_to_files_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(outg_rec_nb_to_files_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #-------------------------\n",
    "    outg_rec_nb_to_files_dicts.append(outg_rec_nb_to_files_dict)\n",
    "    #--------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    if os.path.exists(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl')):\n",
    "        with open(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl'), 'rb') as handle:\n",
    "            outg_rec_nb_to_files_ede_dict = pickle.load(handle)\n",
    "    else:\n",
    "        #-------------------------\n",
    "        paths_ede = Utilities.find_all_paths(\n",
    "            base_dir=base_dir_ede, \n",
    "            glob_pattern=r'end_events_[0-9]*.csv', \n",
    "            regex_pattern=None\n",
    "        )\n",
    "        paths_ede=natsorted(paths_ede)\n",
    "        #-------------------------\n",
    "        outg_rec_nbs_in_files_ede = dict()\n",
    "        for path in paths_ede:\n",
    "            assert(path not in outg_rec_nbs_in_files_ede.keys())\n",
    "            df = GenAn.read_df_from_csv(path)\n",
    "            outg_rec_nbs_in_files_ede[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "        outg_rec_nb_to_files_ede_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files_ede)\n",
    "        #-------------------------\n",
    "        with open(os.path.join(base_dir, 'outg_rec_nb_to_files_ede_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(outg_rec_nb_to_files_ede_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #-------------------------\n",
    "    outg_rec_nb_to_files_ede_dicts.append(outg_rec_nb_to_files_ede_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abd9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There really shouldn't be any overlap in the outg_rec_nbs from each base_dir\n",
    "# In the rare case this isn't desired, simply comment out\n",
    "all_outg_rec_nbs = []\n",
    "for dct_i in outg_rec_nb_to_files_dicts:\n",
    "    for outg_rec_nb_i, files_i in dct_i.items():\n",
    "        assert(outg_rec_nb_i not in all_outg_rec_nbs)\n",
    "        all_outg_rec_nbs.append(outg_rec_nb_i)\n",
    "#-------------------------\n",
    "# Since there are no repeats, it is safe to simply combine all dicts\n",
    "outg_rec_nb_to_files_dict = dict()\n",
    "for dct_i in outg_rec_nb_to_files_dicts:\n",
    "    outg_rec_nb_to_files_dict = outg_rec_nb_to_files_dict|dct_i\n",
    "#-------------------------\n",
    "assert(set(outg_rec_nb_to_files_dict.keys()).symmetric_difference(set(all_outg_rec_nbs))==set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88251c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There really shouldn't be any overlap in the outg_rec_nbs from each base_dir\n",
    "# In the rare case this isn't desired, simply comment out\n",
    "all_outg_rec_nbs_ede = []\n",
    "for dct_i in outg_rec_nb_to_files_ede_dicts:\n",
    "    for outg_rec_nb_i, files_i in dct_i.items():\n",
    "        assert(outg_rec_nb_i not in all_outg_rec_nbs_ede)\n",
    "        all_outg_rec_nbs_ede.append(outg_rec_nb_i)\n",
    "#-------------------------\n",
    "# Since there are no repeats, it is safe to simply combine all dicts\n",
    "outg_rec_nb_to_files_ede_dict = dict()\n",
    "for dct_i in outg_rec_nb_to_files_ede_dicts:\n",
    "    outg_rec_nb_to_files_ede_dict = outg_rec_nb_to_files_ede_dict|dct_i\n",
    "#-------------------------\n",
    "assert(set(outg_rec_nb_to_files_ede_dict.keys()).symmetric_difference(set(all_outg_rec_nbs_ede))==set())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b307e",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67487073",
   "metadata": {},
   "outputs": [],
   "source": [
    "mico2_df = pd.read_excel(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\Mico2\\Mico2_redOnly.xlsx', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fccdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mico2_df=mico2_df.rename(columns={\n",
    "    'Unnamed: 0':'outage_nb', \n",
    "    'Unnamed: 1':'dt_on_ts'\n",
    "})\n",
    "mico2_df=mico2_df[['outage_nb', 'dt_on_ts']]\n",
    "mico2_df['dt_on_ts'] = pd.to_datetime(mico2_df['dt_on_ts'])\n",
    "outage_nbs=mico2_df['outage_nb'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5286a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get outg_rec_nbs\n",
    "tmp_dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outage_nbs=outage_nbs, \n",
    "        field_to_split='outage_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "tmp_dovs_df = tmp_dovs.df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outage numbers are re-used, which is annoying\n",
    "assert(mico2_df['outage_nb'].nunique()==mico2_df.shape[0])\n",
    "# tmp_dovs_df=tmp_dovs_df.groupby('OUTAGE_NB', as_index=False, group_keys=False).apply(\n",
    "#     lambda x: x[x['DT_ON_TS']==mico2_df[mico2_df['outage_nb']==x.name]['dt_on_ts'].unique().tolist()[0]]\n",
    "# )\n",
    "tmp_dovs_df=tmp_dovs_df.groupby('OUTAGE_NB', as_index=False, group_keys=False).apply(\n",
    "    lambda x: x[np.abs(x['DT_ON_TS']-mico2_df[mico2_df['outage_nb']==x.name]['dt_on_ts'].unique().tolist()[0])<pd.Timedelta('12H')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dovs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb64802",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nbs = tmp_dovs_df.index.get_level_values(0).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(outg_rec_nbs).difference(set(all_outg_rec_nbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# Missing = {len(set(outg_rec_nbs).difference(set(all_outg_rec_nbs)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f47264",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nbs = [x for x in outg_rec_nbs if x in all_outg_rec_nbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'#outg_rec_nbs = {len(outg_rec_nbs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b746c",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_suboutg_endpt_plots=True\n",
    "\n",
    "calculate_by_PN = True\n",
    "# combine_by_PN_likeness_thresh = pd.Timedelta('1 minutes')\n",
    "combine_by_PN_likeness_thresh = pd.Timedelta('15 minutes')\n",
    "\n",
    "expand_outg_search_time_tight = pd.Timedelta('1 hours')\n",
    "expand_outg_search_time_loose = pd.Timedelta('12 hours')\n",
    "use_est_outg_times=False\n",
    "# use_est_outg_times=True\n",
    "use_full_ede_outgs=False\n",
    "run_outg_inclusion_assessment=True\n",
    "max_pct_PNs_missing_allowed=0\n",
    "# max_pct_PNs_missing_allowed=20\n",
    "#-----\n",
    "expand_outg_est_search_time = expand_outg_search_time_loose\n",
    "if use_est_outg_times:\n",
    "    expand_outg_search_time = expand_outg_search_time_tight\n",
    "else:\n",
    "    expand_outg_search_time = expand_outg_search_time_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec41ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(save_dir, r'Results.pdf')\n",
    "pdf = PdfPages(pdf_path)\n",
    "#-------------------------\n",
    "pdf_path_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_dovs_beg = PdfPages(pdf_path_dovs_beg)\n",
    "#-------------------------\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_path_2 = Utilities.append_to_path(\n",
    "        pdf_path, \n",
    "        '_w_suboutg_endpt_plots', \n",
    "        ext_to_find='.pdf', \n",
    "        append_to_end_if_ext_no_found=False\n",
    "    )\n",
    "    pdf_2 = PdfPages(pdf_path_2)\n",
    "#-------------------------\n",
    "pdf_path_n_w_power = os.path.join(save_dir, r'n_w_power_v_time.pdf')\n",
    "pdf_n_w_power = PdfPages(pdf_path_n_w_power)\n",
    "#-----\n",
    "pdf_path_n_w_power_dovs_beg = Utilities.append_to_path(\n",
    "    pdf_path_n_w_power, \n",
    "    '_dovs_beg', \n",
    "    ext_to_find='.pdf', \n",
    "    append_to_end_if_ext_no_found=False\n",
    ")\n",
    "pdf_n_w_power_dovs_beg = PdfPages(pdf_path_n_w_power_dovs_beg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_PNs_w_power_threshold = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d73bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "all_detailed_summary_dfs=[]\n",
    "all_detailed_summary_dfs_dovs_beg=[]\n",
    "ci_cmi_summary_df = pd.DataFrame(columns=[\n",
    "    'outg_rec_nb', \n",
    "    'ci_dovs',  'ci_ami', 'ci_ami_dovs_beg', \n",
    "    'cmi_dovs', 'cmi_ami', 'cmi_ami_dovs_beg'\n",
    "])\n",
    "warnings_text = ''\n",
    "\n",
    "#-------------------------\n",
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type         = DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args        = None, \n",
    "    init_df_in_constructor    = True,\n",
    "    build_sql_function        = DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs = dict(\n",
    "        outg_rec_nbs=outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated        = True\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "\n",
    "#-------------------------\n",
    "# Now, iterate through all outages\n",
    "for i_outg, outg_rec_nb in enumerate(outg_rec_nbs):\n",
    "    print(f'\\n\\ti_outg: {i_outg+1}/{len(outg_rec_nbs)}')\n",
    "    print(f'\\toutg_rec_nb = {outg_rec_nb}')\n",
    "    #--------------------------------------------------\n",
    "    audit_i = DOVSAudit(\n",
    "        outg_rec_nb=outg_rec_nb\n",
    "    )\n",
    "    audit_i.load_ami_from_csvs(\n",
    "        paths                          = outg_rec_nb_to_files_dict[outg_rec_nb], \n",
    "        slicers                        = None, \n",
    "        ami_df_info_dict               = None, \n",
    "        run_std_init                   = True, \n",
    "        cols_and_types_to_convert_dict = None, \n",
    "        to_numeric_errors              = 'coerce', \n",
    "        drop_na_rows_when_exception    = True, \n",
    "        drop_unnamed0_col              = True, \n",
    "        pd_read_csv_kwargs             = None, \n",
    "        make_all_columns_lowercase     = False, \n",
    "        assert_all_cols_equal          = True, \n",
    "        min_fsize_MB                   = None\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.ami_df_i.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    #-------------------------\n",
    "    # Need to load dovs before running self assessment below\n",
    "    audit_i.load_dovs(\n",
    "        dovs_df           = dovs_df, \n",
    "        dovs_df_info_dict = None\n",
    "    )\n",
    "    \n",
    "    if run_outg_inclusion_assessment:\n",
    "        to_include_i = audit_i.self_assess_outage_inclusion_requirements(max_pct_PNs_missing_allowed, None)\n",
    "        if not to_include_i:\n",
    "            print(f'outg_rec_nb={outg_rec_nb} did not pass inclusion requirements, skipping!!!!!')\n",
    "            continue\n",
    "    #-------------------------    \n",
    "    n_SNs  = audit_i.ami_df_i['serialnumber'].nunique()\n",
    "    n_PNs  = audit_i.ami_df_i['aep_premise_nb'].nunique()\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NOTE: Can save time by grabbing ede_df_i then performing tz conversion and adding DOVS\n",
    "    if outg_rec_nb not in outg_rec_nb_to_files_ede_dict.keys():\n",
    "        ede_df_i=None\n",
    "    else:\n",
    "        audit_i.load_ede_from_csvs(\n",
    "            paths                          = outg_rec_nb_to_files_ede_dict[outg_rec_nb], \n",
    "            slicers                        = None, \n",
    "            ede_df_info_dict               = None, \n",
    "            run_std_init                   = True, \n",
    "            cols_and_types_to_convert_dict = None, \n",
    "            to_numeric_errors              = 'coerce', \n",
    "            drop_na_rows_when_exception    = True, \n",
    "            drop_unnamed0_col              = True, \n",
    "            pd_read_csv_kwargs             = None, \n",
    "            make_all_columns_lowercase     = False, \n",
    "            assert_all_cols_equal          = True, \n",
    "            min_fsize_MB                   = None\n",
    "        )\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    audit_i.build_best_ests_df()\n",
    "    #-------------------------\n",
    "    # Get the outage time from DOVS\n",
    "    dovs_outg_t_beg_end              = audit_i.dovs_outg_t_beg_end\n",
    "    dovs_outg_t_beg, dovs_outg_t_end = dovs_outg_t_beg_end\n",
    "    #-------------------------\n",
    "    # Get the CI and CMI from DOVS\n",
    "    ci_cmi_dovs       = audit_i.ci_cmi_dovs\n",
    "    ci_dovs, cmi_dovs = ci_cmi_dovs\n",
    "    #-------------------------\n",
    "    # Get the number of premises from DOVS\n",
    "    n_PNs_dovs = audit_i.n_PNs_dovs\n",
    "    #-------------------------\n",
    "    # Get the outage number from DOVS\n",
    "    outage_nb = audit_i.outage_nb\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    # cnsrvtv_out_t_beg/_end are used for placing bounds on the plots generated\n",
    "    # If audit_i.best_ests_df has non-zero size (meaning the algorithm found outages), use to set plotting time.\n",
    "    # Otherwise, use dovs_outg_t_beg/_end\n",
    "    # NOTE: If one did not want to show any data which was thrown out due to overlapping, one would want to\n",
    "    #         update cnsrvtv_out_t_beg/_end after the identify_dovs_overlaps_from_best_ests procedure below \n",
    "    #         (and subsequent trimming of audit_i.best_ests_df)\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        cnsrvtv_out_t_beg = np.min([audit_i.best_ests_df['conservative_min'].min(), dovs_outg_t_beg])\n",
    "        cnsrvtv_out_t_end = np.max([audit_i.best_ests_df['conservative_max'].max(), dovs_outg_t_end])\n",
    "    else:\n",
    "        cnsrvtv_out_t_beg = dovs_outg_t_beg\n",
    "        cnsrvtv_out_t_end = dovs_outg_t_end\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        # Identify and handle any overlaps with other DOVS events\n",
    "        #-------------------------\n",
    "        # dovs_sql_fcn=DOVSOutages_SQL.build_sql_std_outage\n",
    "        dovs_sql_fcn=DOVSOutages_SQL.build_sql_outage\n",
    "        audit_i.identify_overlaps(overlaps_dovs_sql_fcn = dovs_sql_fcn)\n",
    "        #-------------------------\n",
    "        # If any PN has one or more overlapping DOVS events, output info to file\n",
    "        n_PNs_w_overlap = (audit_i.overlap_outgs_for_PNs_df['n_overlap']>0).sum()\n",
    "        if n_PNs_w_overlap>0:\n",
    "            print(f'Need to output to new file\\n\\tn_PNs_w_overlap={n_PNs_w_overlap}')\n",
    "        #-------------------------\n",
    "        # If any PN which lost power has one or more overlapping DOVS events, stop analysis\n",
    "        n_out_PNs_w_overlap = audit_i.overlap_outgs_for_PNs_df[audit_i.overlap_outgs_for_PNs_df['lost_power']==True]['overlap_outg_rec_nbs'].apply(lambda x: len(x)>0).sum()\n",
    "        if n_out_PNs_w_overlap>0:\n",
    "            print('STOP analysis')\n",
    "            continue\n",
    "        #-------------------------\n",
    "        audit_i.resolve_overlapping_audits()\n",
    "        #-----\n",
    "        ci_ami  = audit_i.ci\n",
    "        cmi_ami = audit_i.cmi            \n",
    "        #-------------------------\n",
    "        ami_df_i = audit_i.ami_df_i.copy()\n",
    "        # In ami_df_i, mark any entries which were essentially removed via the identify_dovs_overlaps_from_best_ests\n",
    "        #   and removal procedure above\n",
    "        ami_df_i = DOVSAudit.set_removed_due_to_overlap_in_ami_df_i(\n",
    "            ami_df_i                   = ami_df_i, \n",
    "            best_ests_df               = audit_i.best_ests_df_w_keep_info.copy(), \n",
    "            PN_col                     = 'aep_premise_nb', \n",
    "            time_idfr                  = 'starttimeperiod_local', \n",
    "            PN_col_be                  = 'PN', \n",
    "            keep_col_be                = 'keep', \n",
    "            overlap_times_col_be       = 'overlap_times', \n",
    "            removed_due_to_overlap_col = 'removed_due_to_overlap'\n",
    "        )\n",
    "    else:\n",
    "        ci_ami  = 0\n",
    "        cmi_ami = 0\n",
    "        ami_df_i = audit_i.ami_df_i.copy()\n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        best_ests_df_dovs_beg = DOVSAudit.alter_best_ests_df_using_dovs_outg_t_beg(\n",
    "            best_ests_df = audit_i.best_ests_df,\n",
    "            dovs_df      = dovs_df, \n",
    "            outg_rec_nb  = outg_rec_nb\n",
    "        )\n",
    "        if calculate_by_PN:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['PN'].nunique()\n",
    "        else:\n",
    "            ci_ami_dovs_beg  = best_ests_df_dovs_beg['SN'].nunique()\n",
    "        cmi_ami_dovs_beg = (best_ests_df_dovs_beg['winner_max']-best_ests_df_dovs_beg['winner_min']).sum().total_seconds()/60\n",
    "    else:\n",
    "        best_ests_df_dovs_beg = audit_i.best_ests_df.copy()\n",
    "        ci_ami_dovs_beg  = ci_ami\n",
    "        cmi_ami_dovs_beg = cmi_ami        \n",
    "    #--------------------------------------------------\n",
    "    dovs_df_i = DOVSOutages.retrieve_outage_from_dovs_df(\n",
    "        dovs_df                  = dovs_df, \n",
    "        outg_rec_nb              = audit_i.outg_rec_nb, \n",
    "        outg_rec_nb_idfr         = 'index', \n",
    "        assert_outg_rec_nb_found = True\n",
    "    )    \n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        means_df, best_ests_df_w_db_lbl = DOVSAudit.get_mean_times_w_dbscan(\n",
    "            best_ests_df                  = audit_i.best_ests_df, \n",
    "            eps_min                       = 5, \n",
    "            min_samples                   = 2, \n",
    "            ests_to_include_in_clustering = ['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output     = [\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df  = True\n",
    "        )\n",
    "        #-------------------------\n",
    "        n_PNs_w_power_srs = DOVSAudit.build_n_PNs_w_power_srs(\n",
    "            best_ests_df  = audit_i.best_ests_df, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )        \n",
    "        #-------------------------\n",
    "        detailed_summary_df_i = DOVSAudit.build_detailed_summary_df(\n",
    "            means_df              = means_df, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_w_db_lbl,\n",
    "            CI_tot                = ci_ami, \n",
    "            CMI_tot               = cmi_ami, \n",
    "            n_PNs_ami             = n_PNs,\n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            dovs_df_i             = dovs_df_i, \n",
    "            warnings_flag         = audit_i.warnings_flag, \n",
    "            db_label_col          = 'db_label', \n",
    "            winner_min_col        = 'winner_min', \n",
    "            winner_max_col        = 'winner_max', \n",
    "            PN_col                = 'PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col            = 'i_outg'\n",
    "        )\n",
    "        #----------\n",
    "        detailed_summary_df_i[f'first_above_thresh ({n_PNs_w_power_threshold})'] = None\n",
    "        detailed_summary_df_i[f'last_above_thresh ({n_PNs_w_power_threshold})']  = None\n",
    "        frst_abv, last_abv = get_first_last_above_threshold(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs, \n",
    "            threshold         = n_PNs_w_power_threshold\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'first_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = frst_abv\n",
    "        #-----\n",
    "        detailed_summary_df_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_i.columns.tolist().index(f'last_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = last_abv        \n",
    "        #-------------------------\n",
    "        all_detailed_summary_dfs.append(detailed_summary_df_i)\n",
    "        \n",
    "        #-------------------------\n",
    "        warnings_text += audit_i.generate_warnings_text()\n",
    "    else:\n",
    "        means_df, best_ests_df_w_db_lbl = None, None\n",
    "        n_PNs_w_power_srs = None\n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = DOVSAudit.get_mean_times_w_dbscan(\n",
    "            best_ests_df                  = best_ests_df_dovs_beg, \n",
    "            eps_min                       = 5, \n",
    "            min_samples                   = 2, \n",
    "            ests_to_include_in_clustering = ['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output     = [\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df  = True\n",
    "        )\n",
    "        #-------------------------\n",
    "        n_PNs_w_power_srs_dovs_beg = DOVSAudit.build_n_PNs_w_power_srs(\n",
    "            best_ests_df  = best_ests_df_dovs_beg, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )        \n",
    "        #-------------------------\n",
    "        detailed_summary_df_dovs_beg_i = DOVSAudit.build_detailed_summary_df(\n",
    "            means_df              = means_df_dovs_beg, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_dovs_beg_w_db_lbl,\n",
    "            CI_tot                = ci_ami_dovs_beg, \n",
    "            CMI_tot               = cmi_ami_dovs_beg, \n",
    "            n_PNs_ami             = n_PNs,\n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            dovs_df_i             = dovs_df_i, \n",
    "            warnings_flag         = audit_i.warnings_flag, \n",
    "            db_label_col          = 'db_label', \n",
    "            winner_min_col        = 'winner_min', \n",
    "            winner_max_col        = 'winner_max', \n",
    "            PN_col                = 'PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col            = 'i_outg'\n",
    "        )\n",
    "        #----------\n",
    "        detailed_summary_df_dovs_beg_i[f'first_above_thresh ({n_PNs_w_power_threshold})'] = None\n",
    "        detailed_summary_df_dovs_beg_i[f'last_above_thresh ({n_PNs_w_power_threshold})']  = None\n",
    "        frst_abv, last_abv = get_first_last_above_threshold(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs_dovs_beg, \n",
    "            threshold         = n_PNs_w_power_threshold\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_dovs_beg_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_dovs_beg_i.columns.tolist().index(f'first_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = frst_abv\n",
    "        #-----\n",
    "        detailed_summary_df_dovs_beg_i.iloc[\n",
    "            0, \n",
    "            detailed_summary_df_dovs_beg_i.columns.tolist().index(f'last_above_thresh ({n_PNs_w_power_threshold})')\n",
    "        ] = last_abv        \n",
    "        #-------------------------\n",
    "        all_detailed_summary_dfs_dovs_beg.append(detailed_summary_df_dovs_beg_i)\n",
    "    else:\n",
    "        means_df_dovs_beg, best_ests_df_dovs_beg_w_db_lbl = None, None\n",
    "    #-------------------------\n",
    "    ci_cmi_summary_df = pd.concat([\n",
    "        ci_cmi_summary_df, \n",
    "        pd.DataFrame(\n",
    "            dict(\n",
    "                outg_rec_nb=outg_rec_nb, \n",
    "                ci_dovs=ci_dovs,   ci_ami=ci_ami, ci_ami_dovs_beg=ci_ami_dovs_beg, \n",
    "                cmi_dovs=cmi_dovs, cmi_ami=cmi_ami, cmi_ami_dovs_beg=cmi_ami_dovs_beg\n",
    "            ), \n",
    "            index=[ci_cmi_summary_df.shape[0]]\n",
    "        )\n",
    "    ])\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # ######################### PLOTTING #########################\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #--------------------------------------------------\n",
    "    # Instead of using get_full_part_not_outage_subset_dfs, simply grab the PNs which suffered\n",
    "    #   outages from best_ests_df\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        outg_SNs = audit_i.best_ests_df['PN'].unique().tolist()\n",
    "        removed_due_to_overlap_col = 'removed_due_to_overlap'\n",
    "    else:\n",
    "        outg_SNs = []\n",
    "        removed_due_to_overlap_col = None\n",
    "    #-----\n",
    "    ami_df_i_out      = ami_df_i[ami_df_i['aep_premise_nb'].isin(outg_SNs)]\n",
    "    ami_df_i_not_out  = ami_df_i[~ami_df_i['aep_premise_nb'].isin(outg_SNs)]  \n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    if audit_i.best_ests_df_w_keep_info is not None and audit_i.best_ests_df_w_keep_info.shape[0]>0:\n",
    "        ptntl_ovrlp_outg_rec_nbs = list(set(audit_i.best_ests_df_w_keep_info['overlap_DOVS'].sum()))\n",
    "        if len(ptntl_ovrlp_outg_rec_nbs)>0:\n",
    "            ovrlp_dovs = DOVSOutages(\n",
    "                df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "                contstruct_df_args=None, \n",
    "                init_df_in_constructor=True,\n",
    "                build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "                build_sql_function_kwargs=dict(\n",
    "                    outg_rec_nbs=ptntl_ovrlp_outg_rec_nbs, \n",
    "                    include_premise=True\n",
    "                ), \n",
    "                build_consolidated=True\n",
    "            )\n",
    "            other_dovs_events_df = ovrlp_dovs.df.reset_index().copy()\n",
    "        else:\n",
    "            other_dovs_events_df = None\n",
    "    else:\n",
    "        other_dovs_events_df = None\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    fig, axs = plot_all_out_not_NEW(\n",
    "        fig_num                    = fig_num, \n",
    "        ami_df_i                   = ami_df_i, \n",
    "        ami_df_i_out               = ami_df_i_out, \n",
    "        ami_df_i_not_out           = ami_df_i_not_out, \n",
    "        dovs_outg_t_beg            = dovs_outg_t_beg, \n",
    "        dovs_outg_t_end            = dovs_outg_t_end, \n",
    "        cnsrvtv_out_t_beg          = cnsrvtv_out_t_beg, \n",
    "        cnsrvtv_out_t_end          = cnsrvtv_out_t_end, \n",
    "        means_df                   = means_df, \n",
    "        outg_rec_nb                = outg_rec_nb, \n",
    "        outage_nb                  = outage_nb, \n",
    "        n_PNs_dovs                 = n_PNs_dovs, \n",
    "        ci_dovs                    = ci_dovs, \n",
    "        cmi_dovs                   = cmi_dovs, \n",
    "        ci_ami                     = ci_ami, \n",
    "        cmi_ami                    = cmi_ami, \n",
    "        name                       = 'AMI', \n",
    "        results_2_dict             = dict(\n",
    "            ci_ami   = ci_ami_dovs_beg, \n",
    "            cmi_ami  = cmi_ami_dovs_beg, \n",
    "            means_df = means_df_dovs_beg, \n",
    "            name = 'AMI w/ DOVS t_beg'\n",
    "        ), \n",
    "        expand_time                = pd.Timedelta('1 hour'), \n",
    "        removed_due_to_overlap_col = removed_due_to_overlap_col, \n",
    "        mean_keys_to_include       = ['winner', 'conservative', 'zero_times'], \n",
    "        default_subplots_args      = dict(n_x=2, n_y=2, row_major=True, sharex=True), \n",
    "        other_dovs_events_df       = other_dovs_events_df, \n",
    "        leg_i_plot                 = 1, \n",
    "        leg_kwargs                 = dict(ncols=1, fontsize=15, bbox_to_anchor=(1, 1.2)), \n",
    "        ci_info_fontsize           = 16, \n",
    "        left_text_x                = 0.915  \n",
    "    )\n",
    "\n",
    "    if n_PNs_w_power_srs is not None:\n",
    "        fig, axs[3] = DOVSAudit.plot_n_PNs_w_power_srs(\n",
    "            n_PNs_w_power_srs = n_PNs_w_power_srs, \n",
    "            simp_freq         = '1T', \n",
    "            threshold         = n_PNs_w_power_threshold, \n",
    "            fig_num           = fig_num, \n",
    "            fig_ax            = (fig, axs[3]), \n",
    "            threshold_color   = 'magenta'\n",
    "        )\n",
    "        \n",
    "    for ax_i in axs:\n",
    "        ax_i.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    fig_num += 1\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    if include_suboutg_endpt_plots:\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df_dovs_beg is not None:\n",
    "        fig, axs = plot_all_out_not_NEW(\n",
    "            fig_num              = fig_num, \n",
    "            ami_df_i             = ami_df_i, \n",
    "            ami_df_i_out         = ami_df_i_out, \n",
    "            ami_df_i_not_out     = ami_df_i_not_out, \n",
    "            dovs_outg_t_beg      = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end      = dovs_outg_t_end, \n",
    "            cnsrvtv_out_t_beg    = cnsrvtv_out_t_beg, \n",
    "            cnsrvtv_out_t_end    = cnsrvtv_out_t_end, \n",
    "            means_df             = means_df_dovs_beg, \n",
    "            outg_rec_nb          = outg_rec_nb, \n",
    "            outage_nb            = outage_nb, \n",
    "            n_PNs_dovs           = n_PNs_dovs, \n",
    "            ci_dovs              = ci_dovs, \n",
    "            cmi_dovs             = cmi_dovs, \n",
    "            ci_ami               = ci_ami_dovs_beg, \n",
    "            cmi_ami              = cmi_ami_dovs_beg, \n",
    "            name                 = 'AMI w/ DOVS t_beg', \n",
    "            results_2_dict       = dict(\n",
    "                ci_ami   = ci_ami, \n",
    "                cmi_ami  = cmi_ami, \n",
    "                means_df = means_df, \n",
    "                name = 'AMI'\n",
    "            ), \n",
    "            expand_time          = pd.Timedelta('1 hour'), \n",
    "            removed_due_to_overlap_col = removed_due_to_overlap_col, \n",
    "            mean_keys_to_include = ['winner', 'conservative', 'zero_times'], \n",
    "            default_subplots_args      = dict(n_x=2, n_y=2, row_major=True, sharex=True), \n",
    "            other_dovs_events_df       = other_dovs_events_df, \n",
    "            leg_i_plot                 = 1, \n",
    "            leg_kwargs                 = dict(ncols=1, fontsize=15, bbox_to_anchor=(1, 1.2)), \n",
    "            ci_info_fontsize           = 16, \n",
    "            left_text_x                = 0.915  \n",
    "        )\n",
    "        \n",
    "        if n_PNs_w_power_srs_dovs_beg is not None:\n",
    "            fig, axs[3] = DOVSAudit.plot_n_PNs_w_power_srs(\n",
    "                n_PNs_w_power_srs = n_PNs_w_power_srs_dovs_beg, \n",
    "                simp_freq         = '1T', \n",
    "                threshold         = n_PNs_w_power_threshold, \n",
    "                fig_num           = fig_num, \n",
    "                fig_ax            = (fig, axs[3]), \n",
    "                threshold_color   = 'magenta'\n",
    "            )\n",
    "\n",
    "        for ax_i in axs:\n",
    "            ax_i.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "        fig_num += 1\n",
    "        pdf_dovs_beg.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df is not None and include_suboutg_endpt_plots:\n",
    "        fig, axs = plot_suboutg_endpts(\n",
    "            fig_num               = fig_num, \n",
    "            ami_df_i              = ami_df_i, \n",
    "            means_df              = means_df, \n",
    "            best_ests_df_w_db_lbl = best_ests_df_w_db_lbl, \n",
    "            dovs_outg_t_beg       = dovs_outg_t_beg, \n",
    "            dovs_outg_t_end       = dovs_outg_t_end, \n",
    "            outg_rec_nb           = outg_rec_nb, \n",
    "            expand_time           = pd.Timedelta('15 minutes'), \n",
    "            mean_keys_to_include  = ['winner', 'conservative', 'zero_times']\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_2.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if audit_i.best_ests_df.shape[0]>0:\n",
    "        _, fig, ax = DOVSAudit.build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df  = audit_i.best_ests_df, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            simp_freq     = '1T', \n",
    "            threshold     = n_PNs_w_power_threshold, \n",
    "            fig_num       = fig_num, \n",
    "            title         = f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if best_ests_df_dovs_beg.shape[0]>0:\n",
    "        _, fig, ax = DOVSAudit.build_n_PNs_w_power_srs_and_plot(\n",
    "            best_ests_df  = best_ests_df_dovs_beg, \n",
    "            ami_df_i      = ami_df_i, \n",
    "            return_pct    = True, \n",
    "            simp_freq     = '1T', \n",
    "            threshold     = n_PNs_w_power_threshold, \n",
    "            fig_num       = fig_num, \n",
    "            title         = f\"OUTG_REC_NB = {outg_rec_nb}\", \n",
    "            PN_col        = 'PN', \n",
    "            t_min_col     = 'winner_min', \n",
    "            t_max_col     = 'winner_max', \n",
    "            i_outg_col    = 'i_outg', \n",
    "            PN_col_ami_df = 'aep_premise_nb'\n",
    "        )\n",
    "        #-------------------------\n",
    "        fig_num += 1\n",
    "        pdf_n_w_power_dovs_beg.savefig(fig, bbox_inches='tight')     \n",
    "        plt.close(fig)\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "detailed_summary_df          = pd.concat(all_detailed_summary_dfs)\n",
    "detailed_summary_df_dovs_beg = pd.concat(all_detailed_summary_dfs_dovs_beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4be243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23be694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()\n",
    "pdf_dovs_beg.close()\n",
    "if include_suboutg_endpt_plots:\n",
    "    pdf_2.close()\n",
    "pdf_n_w_power.close()\n",
    "pdf_n_w_power_dovs_beg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60363f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cmi_summary_df['ci_dovs']         = ci_cmi_summary_df['ci_dovs'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami']          = ci_cmi_summary_df['ci_ami'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami_dovs_beg'] = ci_cmi_summary_df['ci_ami_dovs_beg'].astype(float)\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami']\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami_dovs_beg']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami_dovs_beg']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami_dovs_beg'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami_dovs_beg']\n",
    "#-----\n",
    "# For plotting purposes, make a outg_rec_in column which is simply 0 to delta_df.shape[0]-1\n",
    "ci_cmi_summary_df['outg_rec_int'] = range(ci_cmi_summary_df.shape[0])\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_summary_df.to_pickle(os.path.join(save_dir, r'detailed_summary.pkl'))\n",
    "detailed_summary_df_dovs_beg.to_pickle(os.path.join(save_dir, r'detailed_summary_dovs_beg.pkl'))\n",
    "ci_cmi_summary_df.to_pickle(os.path.join(save_dir, r'ci_cmi_summary.pkl'))\n",
    "#-----\n",
    "detailed_summary_df.to_csv(os.path.join(save_dir, r'detailed_summary.csv'))\n",
    "detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, r'detailed_summary_dovs_beg.csv'))\n",
    "ci_cmi_summary_df.to_csv(os.path.join(save_dir, r'ci_cmi_summary.csv'))\n",
    "#-----\n",
    "with open(os.path.join(save_dir, r'warnings.txt'), 'w') as f:\n",
    "    f.write(warnings_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57ce29",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc328ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa74c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_DOVS_PREMISE_DIM=True, \n",
    "        include_DOVS_MASTER_GEO_DIM=True, \n",
    "        include_DOVS_OUTAGE_ATTRIBUTES_DIM=True, \n",
    "        include_DOVS_CLEARING_DEVICE_DIM=True, \n",
    "        include_DOVS_EQUIPMENT_TYPES_DIM=True, \n",
    "        include_DOVS_OUTAGE_CAUSE_TYPES_DIM=True\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_df_0 = dovs.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1acaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_DOVS_PREMISE_DIM=True, \n",
    "        include_DOVS_MASTER_GEO_DIM=True, \n",
    "        include_DOVS_OUTAGE_ATTRIBUTES_DIM=True, \n",
    "        include_DOVS_CLEARING_DEVICE_DIM=True, \n",
    "        include_DOVS_EQUIPMENT_TYPES_DIM=True, \n",
    "        include_DOVS_OUTAGE_CAUSE_TYPES_DIM=True\n",
    "    ), \n",
    "    build_consolidated=False\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "dovs_df = dovs_df.set_index('OUTG_REC_NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_info_dict = dict(\n",
    "    is_consolidated  = True,\n",
    "    outg_rec_nb_idfr = 'index', \n",
    "    PN_col           = 'PREMISE_NB', \n",
    "    PNs_col          = 'premise_nbs', \n",
    "    outg_t_beg_col   = 'DT_OFF_TS_FULL', \n",
    "    outg_t_end_col   = 'DT_ON_TS'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc711e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bef44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_idfr_loc = Utilities_df.get_idfr_loc(\n",
    "    df = dovs_df, \n",
    "    idfr = dovs_df_info_dict['outg_rec_nb_idfr']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f86877",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nb_idfr_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34153ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the outg_rec_nbs are in the index, then reset_index must be called for\n",
    "#   consolidate_df_outage to run properly\n",
    "if outg_rec_nb_idfr_loc[1]:\n",
    "    outg_rec_nb_idx_lvl = outg_rec_nb_idfr_loc[0]\n",
    "    #-----\n",
    "    if dovs_df.index.names[outg_rec_nb_idx_lvl]:\n",
    "        outg_rec_nb_col = dovs_df.index.names[outg_rec_nb_idx_lvl]\n",
    "    else:\n",
    "        outg_rec_nb_col = 'OUTG_REC_NB_'+Utilities.generate_random_string(str_len=4)\n",
    "        assert(outg_rec_nb_col not in dovs_df.columns.tolist())\n",
    "        assert(outg_rec_nb_col not in list(dovs_df.index.names))\n",
    "        dovs_df.index = dovs_df.index.set_names(outg_rec_nb_col, level=outg_rec_nb_idx_lvl)\n",
    "    #-----\n",
    "    # Set the outg_rec_nb_col and drop index\n",
    "    dovs_df[outg_rec_nb_col] = dovs_df.index.get_level_values(outg_rec_nb_idx_lvl)\n",
    "    if dovs_df.index.nlevels==1:\n",
    "        # NOTE: Values already placed in outg_rec_nb_col above, hence why drop=True below\n",
    "        dovs_df = dovs_df.reset_index(drop=True)\n",
    "    else:\n",
    "        dovs_df = dovs_df.droplevel(outg_rec_nb_idx_lvl, axis=0)\n",
    "    #-----\n",
    "    assert(outg_rec_nb_col in dovs_df.columns.tolist())\n",
    "else:\n",
    "    outg_rec_nb_col = outg_rec_nb_idfr_loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2497422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFF_TM and REST_TM are premise specific, and should not be included\n",
    "cols_to_drop = ['OFF_TM', 'REST_TM']\n",
    "cols_to_drop = list(set(cols_to_drop).intersection(set(dovs_df.columns.tolist())))\n",
    "#-----\n",
    "# PN_col must be in dovs_df\n",
    "assert(dovs_df_info_dict['PN_col'] in dovs_df.columns.tolist())\n",
    "#-----\n",
    "# All columns exepct premise numbers (and cols_to_drop) should be shared by groups\n",
    "cols_shared_by_group = [x for x in dovs_df.columns.tolist() \n",
    "                        if x not in [outg_rec_nb_col, dovs_df_info_dict['PN_col']]+cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df = DOVSOutages.consolidate_df_outage(\n",
    "    df_outage                    = dovs_df, \n",
    "    outg_rec_nb_col              = outg_rec_nb_col, \n",
    "    addtnl_grpby_cols            = None, \n",
    "    cols_shared_by_group         = cols_shared_by_group, \n",
    "    cols_to_collect_in_lists     = [dovs_df_info_dict['PN_col']], \n",
    "    allow_duplicates_in_lists    = False, \n",
    "    allow_NaNs_in_lists          = False, \n",
    "    recover_uniqueness_violators = True, \n",
    "    gpby_dropna                  = False, \n",
    "    rename_cols                  = None,     \n",
    "    premise_nb_col               = dovs_df_info_dict['PN_col'], \n",
    "    premise_nbs_col              = dovs_df_info_dict['PNs_col'], \n",
    "    cols_to_drop                 = cols_to_drop, \n",
    "    sort_PNs                     = True, \n",
    "    drop_null_premise_nbs        = True, \n",
    "    set_outg_rec_nb_as_index     = True,\n",
    "    drop_outg_rec_nb_if_index    = True, \n",
    "    verbose                      = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_df_0.sort_index().equals(dovs_df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59145ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793ae1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ae0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15003d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_include_i = assess_outage_inclusion_requirements(\n",
    "    ami_df_i=ami_df_i, \n",
    "    outg_rec_nb=outg_rec_nb, \n",
    "    dovs_df=dovs_df, \n",
    "    max_pct_PNs_missing_allowed=max_pct_PNs_missing_allowed, \n",
    "    ami_df_i_info_dict=None, \n",
    "    dovs_df_info_dict=None, \n",
    "    check_found_ami_for_all_SNs_kwargs=None\n",
    "\n",
    ")\n",
    "print(f\"to_include_i==audit_i?: {to_include_i==audit_i.self_assess_outage_inclusion_requirements(max_pct_PNs_missing_allowed, None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e5063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f082a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19e73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
