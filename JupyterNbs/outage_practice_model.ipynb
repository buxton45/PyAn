{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "import itertools\n",
    "from dateutil.parser import parse\n",
    "from operator import itemgetter\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acovf, acf, pacf, pacf_yw, pacf_ols\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.graphics.tsaplots import month_plot, quarter_plot, seasonal_plot\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA, ARMAResults, ARIMAResults\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from arch import arch_model\n",
    "\n",
    "from scipy.stats.mstats import trim\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "# import constants for the days of the week\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "#---------------------------------------------------------------------\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "from AMINonVee import AMINonVee\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest\n",
    "import DickeyFullerTest as dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98065514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf061bd",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca07bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d48e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63275412",
   "metadata": {},
   "source": [
    "## Trying to combine total, received, and delivered for circuit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_circuit_non_vals(df, non_val_cols, \n",
    "                           aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                           aep_srvc_qlty_idntfr_vals={'rec':'RECEIVED', 'del':'DELIVERED', 'tot':'TOTAL'}):\n",
    "    # Typically, df_rec, df_del, and df_tot will not all contain to entire set of\n",
    "    # dates.  To simplify the merge, first grab the total set of non_vals_df.\n",
    "    # This is achieved using the combine_first method, which will keep the first non-null\n",
    "    # element between the two datasets.\n",
    "    # Then, merges can be done using just the value_cols and time_idx.\n",
    "    # The non_vals_df will be combined with the vals_df in the end\n",
    "    #------------------------\n",
    "    df_rec = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['rec']]\n",
    "    df_del = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['del']]\n",
    "    df_tot = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['tot']]\n",
    "    #------------------------\n",
    "    non_vals_df = df_del[non_val_cols].combine_first(df_rec[non_val_cols])\n",
    "    non_vals_df = non_vals_df.combine_first(df_tot[non_val_cols])\n",
    "    assert(non_vals_df.isna().sum().sum()==0) #TODO should this assert remain?\n",
    "    return non_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6767114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circuit_total_vals_for_time_idx(gp1):\n",
    "    # gp1 should be a DataFrame from a grouped call on time index\n",
    "    assert(gp1.index.nunique()==1)\n",
    "    \n",
    "    # Should only be 'RECEIVED', 'DELIVERED', and 'TOTAL' as possible\n",
    "    # values for aep_srvc_qlty_idntfr below\n",
    "    aep_srvc_qlty_idntfrs = gp1['aep_srvc_qlty_idntfr'].tolist()\n",
    "    assert(len(aep_srvc_qlty_idntfrs)<=3)\n",
    "    \n",
    "    if 'RECEIVED' in aep_srvc_qlty_idntfrs:\n",
    "        received = gp1[gp1['aep_srvc_qlty_idntfr']=='RECEIVED']\n",
    "        assert(received.shape[0]==1)\n",
    "        received = received.iloc[0][['value_sum_cir', 'counts_cir']].to_dict()\n",
    "    else:\n",
    "        received = {'value_sum_cir':0, 'counts_cir':0}\n",
    "    #-----\n",
    "    if 'DELIVERED' in aep_srvc_qlty_idntfrs:\n",
    "        delivered = gp1[gp1['aep_srvc_qlty_idntfr']=='DELIVERED']\n",
    "        assert(delivered.shape[0]==1)\n",
    "        delivered = delivered.iloc[0][['value_sum_cir', 'counts_cir']].to_dict()\n",
    "    else:\n",
    "        delivered = {'value_sum_cir':0, 'counts_cir':0}\n",
    "    #-----\n",
    "    if 'TOTAL' in aep_srvc_qlty_idntfrs:\n",
    "        total = gp1[gp1['aep_srvc_qlty_idntfr']=='TOTAL']\n",
    "        assert(total.shape[0]==1)\n",
    "        total = total.iloc[0][['value_sum_cir', 'counts_cir']].to_dict()\n",
    "    else:\n",
    "        total = {'value_sum_cir':0, 'counts_cir':0}\n",
    "    #----------------------------------------------\n",
    "    net_sum = total['value_sum_cir']+delivered['value_sum_cir']-received['value_sum_cir']\n",
    "    net_counts = max(received['counts_cir'], total['counts_cir']+delivered['counts_cir'])\n",
    "    net_mean = net_sum/net_counts\n",
    "    \n",
    "    return {'value_sum_cir':net_sum, \n",
    "            'counts_cir':net_counts, \n",
    "            'value_mean_cir':net_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciruit_total_vals_method1(df, non_val_cols, \n",
    "                                  aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                                  aep_srvc_qlty_idntfr_vals={'rec':'RECEIVED', 'del':'DELIVERED', 'tot':'TOTAL'}):\n",
    "    results_series = df.groupby(level=0).apply(get_circuit_total_vals_for_time_idx)\n",
    "    results_df = pd.DataFrame.from_dict(results_series.to_dict(), orient='index')\n",
    "\n",
    "    non_vals_df = build_circuit_non_vals(df, non_val_cols, \n",
    "                                         aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                         aep_srvc_qlty_idntfr_vals=aep_srvc_qlty_idntfr_vals)\n",
    "    assert(non_vals_df.shape[0]==results_df.shape[0])\n",
    "    results_df = results_df.merge(non_vals_df, how='inner', left_index=True, right_index=True)\n",
    "    results_df[aep_srvc_qlty_idntfr_col] = 'TOTAL'\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09419d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciruit_total_vals_method2(df, non_val_cols, \n",
    "                                  value_cols_dict = {'value_sum_cir_col':'value_sum_cir', \n",
    "                                                     'counts_cir_col':'counts_cir', \n",
    "                                                     'value_mean_cir_col':'value_mean_cir'}, \n",
    "                                  remove_intermediate_cols=True, \n",
    "                                  aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                                  aep_srvc_qlty_idntfr_vals={'rec':'RECEIVED', 'del':'DELIVERED', 'tot':'TOTAL'}, \n",
    "                                  maintain_original_col_order=True):\n",
    "    # TODO How to enforce assert(len(aep_srvc_qlty_idntfrs)<=3)\n",
    "    #---------------------------------------------------\n",
    "    expected_keys = ['counts_cir_col', 'value_mean_cir_col', 'value_sum_cir_col']\n",
    "    assert(len(set(value_cols_dict.keys()).intersection(set(expected_keys)))==3)    \n",
    "    value_cols = list(value_cols_dict.values())\n",
    "    #---------------------------------------------------\n",
    "    df_rec = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['rec']]\n",
    "    df_del = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['del']]\n",
    "    df_tot = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['tot']]\n",
    "    #---------------------------------------------------    \n",
    "    # This essentially enforces assert(len(aep_srvc_qlty_idntfrs)<=3)\n",
    "    assert(df_rec.shape[0]==df_rec.index.nunique())\n",
    "    assert(df_del.shape[0]==df_del.index.nunique())\n",
    "    assert(df_tot.shape[0]==df_tot.index.nunique())\n",
    "    #---------------------------------------------------\n",
    "    return_df = df_del[value_cols].merge(df_rec[value_cols], \n",
    "                                         left_index=True, right_index=True, \n",
    "                                         how='outer', suffixes=('_del', '_rec')) \n",
    "    # Note: Suffix argument will do nothing here, as df_tot contains value_cols, whereas\n",
    "    #       return_df currently contains [f'x_{del}' for x in value_cols] and [f'x_{rec}' for x in value_cols]\n",
    "    #       Therefore, there are no overlapping column names.  As such, we must rename using .rename\n",
    "    return_df = return_df.merge(df_tot[value_cols], left_index=True, right_index=True, how='outer')\n",
    "    return_df = return_df.rename(columns = {x:f'{x}_tot' for x in value_cols})\n",
    "    # I used an outer merge so there will always been an entry for delivered, received, and total in return_df\n",
    "    # However, if one of these did not exist in the original, the outer merge will leave a NaN value in the cell\n",
    "    # Therefore, I call return_df.fillna(0) to replace any of these NaNs with 0\n",
    "    return_df = return_df.fillna(0)\n",
    "    #---------------------------------------------------\n",
    "    value_sum_cir_col = value_cols_dict['value_sum_cir_col']\n",
    "    counts_cir_col = value_cols_dict['counts_cir_col']\n",
    "    value_mean_cir_col = value_cols_dict['value_mean_cir_col']\n",
    "    #---------------------------------------------------\n",
    "    # Made a list of newly created columns, which will be need if remove_intermediate_cols==True\n",
    "    new_col_tags = ['_del', '_rec', '_tot']\n",
    "    new_cols = [value_col+tag for value_col in value_cols for tag in new_col_tags]\n",
    "    new_cols.append(f\"{counts_cir_col}_del_plus_tot\")\n",
    "    #---------------------------------------------------\n",
    "    return_df[f\"{counts_cir_col}_del_plus_tot\"] = (return_df[f\"{counts_cir_col}_del\"] +\n",
    "                                                   return_df[f\"{counts_cir_col}_tot\"])\n",
    "    return_df[counts_cir_col] = return_df[[f\"{counts_cir_col}_rec\", \n",
    "                                           f\"{counts_cir_col}_del_plus_tot\"]].max(axis=1)\n",
    "    return_df[value_sum_cir_col] = (return_df[f\"{value_sum_cir_col}_tot\"] +\n",
    "                                    return_df[f\"{value_sum_cir_col}_del\"] -\n",
    "                                    return_df[f\"{value_sum_cir_col}_rec\"])\n",
    "    return_df[value_mean_cir_col] = return_df[value_sum_cir_col]/return_df[value_cols_dict['counts_cir_col']]\n",
    "    return_df[counts_cir_col]=return_df[counts_cir_col].astype('int64')\n",
    "    #---------------------------------------------------\n",
    "    if remove_intermediate_cols:\n",
    "        return_df = return_df.drop(columns=new_cols)\n",
    "    #---------------------------------------------------\n",
    "    non_vals_df = build_circuit_non_vals(df, non_val_cols, \n",
    "                                         aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                         aep_srvc_qlty_idntfr_vals=aep_srvc_qlty_idntfr_vals)\n",
    "    assert(non_vals_df.shape[0]==return_df.shape[0])\n",
    "    return_df = return_df.merge(non_vals_df, how='inner', left_index=True, right_index=True)\n",
    "    return_df[aep_srvc_qlty_idntfr_col] = 'TOTAL'\n",
    "    if maintain_original_col_order:\n",
    "        cols_from_og = [x for x in df.columns if x in return_df.columns]\n",
    "        return_df = Utilities_df.move_cols_to_front(return_df, cols_from_og)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e3a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516638be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cbe00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eeda15",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6a330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129210bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e715ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = [\n",
    "    'serialnumber',\n",
    "    'prem_nb', \n",
    "    'srvc_pole_nb', \n",
    "    'trsf_pole_nb',\n",
    "    'annual_kwh',\n",
    "    'station_nb',\n",
    "    'xfmr_nb', \n",
    "    'starttimeperiod', \n",
    "    'endtimeperiod', \n",
    "    'aep_endtime_utc', \n",
    "    'timezoneoffset', \n",
    "    'aep_derived_uom',\n",
    "    'aep_srvc_qlty_idntfr', \n",
    "    'value', \n",
    "    'aep_usage_dt'\n",
    "]\n",
    "\n",
    "cols_of_interest_cir = [\n",
    "    'starttimeperiod', \n",
    "    'endtimeperiod', \n",
    "    'aep_endtime_utc', \n",
    "    'timezoneoffset',\n",
    "    'aep_derived_uom', \n",
    "    'aep_srvc_qlty_idntfr', \n",
    "    'aep_usage_dt', \n",
    "    'value_sum',\n",
    "    'counts', \n",
    "    'value_mean'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeee089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outage_dir = os.path.join(Utilities.get_local_data_dir(), r'sample_outages\\outg_rec_nb_11751094')\n",
    "df_circuit_dir = os.path.join(Utilities.get_local_data_dir(), r'sample_circuits\\NewMethod\\outg_rec_nb_11751094')\n",
    "df_xfmr_circuit_dir = os.path.join(Utilities.get_local_data_dir(), r'sample_circuits\\NewMethod\\GroupByXfmr_v2\\outg_rec_nb_11751094')\n",
    "\n",
    "out_t_beg_local = pd.to_datetime('2020-06-21 10:52:00')\n",
    "out_t_end_local = pd.to_datetime('2020-06-21 12:50:00')\n",
    "no_outage_center_local = pd.to_datetime('2020-08-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de407e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs=['H', '4H', 'D', 'MS']\n",
    "time_col_for_agg='endtimeperiod_utc'\n",
    "other_grouper_cols=['serialnumber']\n",
    "build_agg_dfs=True\n",
    "other_cols_to_keep = ['prem_nb', 'srvc_pole_nb', 'trsf_pole_nb', 'station_nb', \n",
    "                      'xfmr_nb', 'aep_derived_uom', 'aep_srvc_qlty_idntfr']\n",
    "other_cols_to_keep_agg = ['aep_derived_uom', 'aep_srvc_qlty_idntfr']\n",
    "agg_cols=['value', 'annual_kwh']\n",
    "agg_types=['mean']\n",
    "mix_agg_functions=False\n",
    "\n",
    "# Should not be any overlap between other_cols_to_keep and agg_cols\n",
    "assert(len(set(other_cols_to_keep).intersection(set(agg_cols)))==0)\n",
    "assert(len(set(other_cols_to_keep_agg).intersection(set(agg_cols)))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key = 'df'\n",
    "df_agg_key = 'df_agg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b82b04",
   "metadata": {},
   "source": [
    "# Load Outage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ba209",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwh_vlt_dfs_dict = AMINonVee.assemble_kwh_vlt_dfs_from_saved_csvs(file_dir=df_outage_dir, glob_pattern=r'outg_rec_nb_*.csv', \n",
    "                                                        cols_of_interest=cols_of_interest, \n",
    "                                                        verbose=True)\n",
    "df_kwh_15T = kwh_vlt_dfs_dict['kwh']\n",
    "df_vlt_15T = kwh_vlt_dfs_dict['vlt']\n",
    "# #-------------------------------------------------------------------------------------------------\n",
    "dfs_kwh_dict = AMINonVee.build_time_resampled_dfs(df_kwh_15T, base_freq='15T', freqs=freqs, \n",
    "                                 other_grouper_cols=other_grouper_cols, other_cols_to_keep=other_cols_to_keep, \n",
    "                                 build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, \n",
    "                                 agg_cols=agg_cols, agg_types=agg_types, \n",
    "                                 other_cols_to_keep_agg=other_cols_to_keep_agg, mix_agg_functions=mix_agg_functions, \n",
    "                                 df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_kwh_15T.equals(dfs_kwh_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "dfs_vlt_dict = AMINonVee.build_time_resampled_dfs(df_vlt_15T, base_freq='15T', freqs=freqs, \n",
    "                                 other_grouper_cols=other_grouper_cols, other_cols_to_keep=other_cols_to_keep, \n",
    "                                 build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, \n",
    "                                 agg_cols=agg_cols, agg_types=agg_types, \n",
    "                                 other_cols_to_keep_agg=other_cols_to_keep_agg, mix_agg_functions=mix_agg_functions, \n",
    "                                 df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_vlt_15T.equals(dfs_vlt_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_kwh_dict['H']['df_agg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae8d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd37744",
   "metadata": {},
   "source": [
    "# Load Circuit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed88ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "# There seems to be inconsistency in the database\n",
    "# For some, each has a 'RECEIVED' and 'DELIVERED'\n",
    "# For others, each has a 'RECEIVED' and 'TOTAL'\n",
    "# I have not found a case yet with all three ('RECEIVED', 'DELIVERED', and 'TOTAL')\n",
    "# It seems that the 'RECEIVED' counts is typically correct\n",
    "# However, may want to simply take the max of n_TOTAL+n_DELIVERED and n_RECEIVED\n",
    "\n",
    "kwh_vlt_dfs_cir_dict = AMINonVee.assemble_kwh_vlt_dfs_from_saved_csvs(file_dir=df_circuit_dir, glob_pattern=r'outg_rec_nb_*q[0-9].csv', \n",
    "                                                            value_cols=['value_sum', 'counts', 'value_mean'], \n",
    "                                                            cols_of_interest=cols_of_interest_cir, \n",
    "                                                            combine_kwh_delivered_and_received=False, \n",
    "                                                            merge_and_groupby_cols=['aep_endtime_utc'], \n",
    "                                                            verbose=True)\n",
    "df_cir_kwh_15T = kwh_vlt_dfs_cir_dict['kwh']\n",
    "df_cir_vlt_15T = kwh_vlt_dfs_cir_dict['vlt']\n",
    "\n",
    "##TODO Currently, counts includes Null values as well.  The code below changes it back\n",
    "df_cir_kwh_15T = df_cir_kwh_15T[df_cir_kwh_15T['value_sum'].notna()]\n",
    "df_cir_kwh_15T.loc[df_cir_kwh_15T['value_sum']!=0,'counts']=round(df_cir_kwh_15T[df_cir_kwh_15T['value_sum']!=0]['value_sum']/df_cir_kwh_15T[df_cir_kwh_15T['value_sum']!=0]['value_mean'])\n",
    "df_cir_kwh_15T['counts'] = df_cir_kwh_15T['counts'].astype(int)\n",
    "\n",
    "df_cir_vlt_15T = df_cir_vlt_15T[df_cir_vlt_15T['value_sum'].notna()]\n",
    "df_cir_vlt_15T.loc[df_cir_vlt_15T['value_sum']!=0,'counts']=round(df_cir_vlt_15T[df_cir_vlt_15T['value_sum']!=0]['value_sum']/df_cir_vlt_15T[df_cir_vlt_15T['value_sum']!=0]['value_mean'])\n",
    "df_cir_vlt_15T['counts'] = df_cir_vlt_15T['counts'].astype(int)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "rename_agg_cols_cir={'value_sum':'value_sum_cir', 'counts':'counts_cir', 'value_mean':'value_mean_cir'}\n",
    "df_cir_kwh_15T = df_cir_kwh_15T.rename(columns=rename_agg_cols_cir)\n",
    "df_cir_vlt_15T = df_cir_vlt_15T.rename(columns=rename_agg_cols_cir)\n",
    "agg_cols_cir=list(rename_agg_cols_cir.values())\n",
    "\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "# Need to handle how delivered, received, total will be combined before re-indexing!\n",
    "# For now, let's simply use 'TOTAL' from kwh\n",
    "df_cir_kwh_15T_FULL = df_cir_kwh_15T.copy()\n",
    "#df_cir_kwh_15T = df_cir_kwh_15T[df_cir_kwh_15T['aep_srvc_qlty_idntfr']=='TOTAL'].copy()\n",
    "\n",
    "# TODO!!!!!!!!!!!!!!!!!!!!!\n",
    "# How to handle different aep_srvc_qlty_idntfr for vlt?\n",
    "# ['INSTVA1', 'INSTVC1', 'INSTVB1', 'AVG']\n",
    "# For now, 'AVG' from vlt\n",
    "df_cir_vlt_15T_FULL = df_cir_vlt_15T.copy()\n",
    "df_cir_vlt_15T = df_cir_vlt_15T[df_cir_vlt_15T['aep_srvc_qlty_idntfr']=='AVG'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ad7a6",
   "metadata": {},
   "source": [
    "### Use combine method on full dataset and then resample/aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd070c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_val_cols = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset',\n",
    "                'aep_derived_uom', 'aep_usage_dt', 'aep_endtime_utc_from_timestamp', \n",
    "                'starttimeperiod_utc', 'endtimeperiod_utc']\n",
    "value_cols_dict = {'value_sum_cir_col':'value_sum_cir', \n",
    "                   'counts_cir_col':'counts_cir', \n",
    "                   'value_mean_cir_col':'value_mean_cir'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cir_kwh_15T = get_ciruit_total_vals_method2(df_cir_kwh_15T, non_val_cols, \n",
    "                                               value_cols_dict=value_cols_dict, remove_intermediate_cols=True)\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# TODO!!!!!!!!!!!!!!!!!\n",
    "# Also, would expect e.g. dfs_cir_kwh_dict['H'][df_key]==dfs_cir_kwh_dict['H'][df_agg_key]\n",
    "# However, this is close but not exactly true\n",
    "# It appears there are some times with duplicate entries\n",
    "# Compare the size of df_cir_kwh_15T[df_cir_kwh_15T['aep_srvc_qlty_idntfr']=='TOTAL']\n",
    "# to the number of unique indices\n",
    "#\n",
    "#\n",
    "\n",
    "dfs_cir_kwh_dict = AMINonVee.build_time_resampled_dfs(df_cir_kwh_15T, freqs=freqs, other_grouper_cols=[], \n",
    "                                     build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, \n",
    "                                     agg_cols=agg_cols_cir, agg_types=['mean', 'sum'], \n",
    "                                     df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_cir_kwh_15T.equals(dfs_cir_kwh_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "dfs_cir_vlt_dict = AMINonVee.build_time_resampled_dfs(df_cir_vlt_15T, freqs=freqs, other_grouper_cols=[], \n",
    "                                     build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, agg_cols=agg_cols_cir, \n",
    "                                     df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_cir_vlt_15T.equals(dfs_cir_vlt_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking endtimeperiod_utc against aep_endtime_utc_from_timestamp')\n",
    "print('df_kwh_15T:     ', all(df_kwh_15T['endtimeperiod_utc']==df_kwh_15T['aep_endtime_utc_from_timestamp']))\n",
    "print('df_vlt_15T:     ', all(df_vlt_15T['endtimeperiod_utc']==df_vlt_15T['aep_endtime_utc_from_timestamp']))\n",
    "#-----\n",
    "print('df_cir_kwh_15T: ', all(df_cir_kwh_15T['endtimeperiod_utc']==df_cir_kwh_15T['aep_endtime_utc_from_timestamp']))\n",
    "print('df_cir_vlt_15T: ', all(df_cir_vlt_15T['endtimeperiod_utc']==df_cir_vlt_15T['aep_endtime_utc_from_timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kwh_15T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca3813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1488bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bac4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deda6d8b",
   "metadata": {},
   "source": [
    "# Load Xfmr Circuit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09650f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mean_from_sum_and_counts(df, sum_x_col, n_counts_col, placement_col):\n",
    "    df[placement_col] = df[sum_x_col]/df[n_counts_col]\n",
    "    return df\n",
    "\n",
    "def build_std_from_mossom(df, sum_x_col, sum_x2_col, n_counts_col, placement_col, sample_std=True):\n",
    "    # mossom = Mean Of Sqaures minus Square Of Means\n",
    "    #   variance = std**2 ~ bar{x**2}-(bar{x})**2\n",
    "    # However, here I will actually be using sum(x**2) and sum(x) instead\n",
    "    #   ==> std**2 ~ (1/n)*sum(x**2) - (1/n**2)*sum(x)\n",
    "    # Default to sample std (std_s w/ n-1 in denominator), \n",
    "    #    not population std (std_p w/ n in denominator)\n",
    "    # \n",
    "    # std_p**2 = bar{x**2}-(bar{x})**2\n",
    "    #          = (1/n)*sum(x**2) - (1/n**2)*sum(x)\n",
    "    # std_s**2 = (n/(n-1))*std_p**2 = (n/(n-1))*(bar{x**2}-(bar{x})**2)\n",
    "    #          = (n/(n-1))*((1/n)*sum(x**2) - (1/n**2)*sum(x))\n",
    "    df[placement_col] = np.sqrt(\n",
    "        (df[sum_x2_col]/df[n_counts_col] - df[sum_x_col]*df[sum_x_col]/(df[n_counts_col]*df[n_counts_col]))\n",
    "    )\n",
    "    if sample_std:\n",
    "        df[placement_col] = df[placement_col]*np.sqrt((df[n_counts_col]/(df[n_counts_col]-1)))\n",
    "    return df\n",
    "\n",
    "def build_mean_and_std_from_sum_x_x2_and_counts(df, sum_x_col, sum_x2_col, n_counts_col, \n",
    "                                                placement_col_mean, placement_col_std, \n",
    "                                                sample_std=True):\n",
    "    df = build_mean_from_sum_and_counts(df, sum_x_col, n_counts_col, placement_col_mean)\n",
    "    df = build_std_from_mossom(df, sum_x_col, sum_x2_col, n_counts_col, placement_col_std)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c69fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_counts_for_del_rec_tot(merged_df, col_name_base, \n",
    "           col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "           remove_intermediate_cols=True):\n",
    "    col_rec = col_name_base+col_tags['rec']\n",
    "    col_del = col_name_base+col_tags['del']\n",
    "    col_tot = col_name_base+col_tags['tot']\n",
    "    #---------------------------------------------------    \n",
    "    merged_df[f\"{col_name_base}_del_plus_tot\"] = merged_df[col_del] + merged_df[col_tot]\n",
    "    merged_df[col_name_base] = merged_df[[col_rec, f\"{col_name_base}_del_plus_tot\"]].max(axis=1)\n",
    "    merged_df[col_name_base]=merged_df[col_name_base].astype('int64')\n",
    "    #---------------------------------------------------\n",
    "    if remove_intermediate_cols:\n",
    "        merged_df = merged_df.drop(columns=[col_rec, col_del, col_tot, f\"{col_name_base}_del_plus_tot\"])\n",
    "    return merged_df\n",
    "\n",
    "def build_net_value_for_del_rec_tot(merged_df, col_name_base, \n",
    "                                    col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "                                    remove_intermediate_cols=True):\n",
    "    col_rec = col_name_base+col_tags['rec']\n",
    "    col_del = col_name_base+col_tags['del']\n",
    "    col_tot = col_name_base+col_tags['tot']\n",
    "    #--------------------------------------------------- \n",
    "    merged_df[col_name_base] = (merged_df[col_tot] +\n",
    "                                merged_df[col_del] -\n",
    "                                merged_df[col_rec])\n",
    "    #--------------------------------------------------- \n",
    "    if remove_intermediate_cols:\n",
    "        merged_df = merged_df.drop(columns=[col_rec, col_del, col_tot])\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ciruit_total_vals(df, non_val_cols, \n",
    "                          value_cols_dict_list = [\n",
    "                              {'value_col':'sum_value_sum', 'counts_col':'sum_counts', 'mean_col':'mean_value_sum'}, \n",
    "                              {'value_col':'sum_value_sq_sum', 'counts_col':'sum_counts', 'mean_col':'mean_value_sq_sum'}, \n",
    "                              {'value_col':'sum_value_mean', 'counts_col':'sum_counts', 'mean_col':'mean_value_mean'},\n",
    "                              {'value_col':'sum_value_std', 'counts_col':'sum_counts', 'mean_col':'mean_value_std'}\n",
    "                          ], \n",
    "                          remove_intermediate_cols=True, \n",
    "                          aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "                          aep_srvc_qlty_idntfr_vals={'rec':'RECEIVED', 'del':'DELIVERED', 'tot':'TOTAL'}, \n",
    "                          maintain_original_col_order=True):\n",
    "    #--------------------------------------------------- \n",
    "    value_cols = [x['value_col'] for x in value_cols_dict_list]\n",
    "    counts_cols = list(set(x['counts_col'] for x in value_cols_dict_list))\n",
    "    merge_cols = value_cols + counts_cols\n",
    "    #---------------------------------------------------\n",
    "    df_rec = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['rec']]\n",
    "    df_del = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['del']]\n",
    "    df_tot = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['tot']]\n",
    "    #---------------------------------------------------    \n",
    "    # This essentially enforces assert(len(aep_srvc_qlty_idntfrs)<=3)\n",
    "    # -- each line ensures that every date in df has exactly one entry\n",
    "    assert(df_rec.shape[0]==df_rec.index.nunique())\n",
    "    assert(df_del.shape[0]==df_del.index.nunique())\n",
    "    assert(df_tot.shape[0]==df_tot.index.nunique())\n",
    "    #---------------------------------------------------\n",
    "    return_df = df_del[merge_cols].merge(df_rec[merge_cols], \n",
    "                                         left_index=True, right_index=True, \n",
    "                                         how='outer', suffixes=('_del', '_rec')) \n",
    "    # Note: Suffix argument will do nothing here, as df_tot contains merge_cols, whereas\n",
    "    #       return_df currently contains [f'x_{del}' for x in merge_cols] and [f'x_{rec}' for x in merge_cols]\n",
    "    #       Therefore, there are no overlapping column names.  As such, we must rename using .rename\n",
    "    return_df = return_df.merge(df_tot[merge_cols], left_index=True, right_index=True, how='outer')\n",
    "    return_df = return_df.rename(columns = {x:f'{x}_tot' for x in merge_cols})\n",
    "    # I used an outer merge so there will always been an entry for delivered, received, and total in return_df\n",
    "    # However, if one of these did not exist in the original, the outer merge will leave a NaN value in the cell\n",
    "    # Therefore, I call return_df.fillna(0) to replace any of these NaNs with 0\n",
    "    return_df = return_df.fillna(0)\n",
    "    #---------------------------------------------------\n",
    "    for counts_col in counts_cols:\n",
    "        return_df = build_net_counts_for_del_rec_tot(return_df, col_name_base=counts_col, \n",
    "                                                     col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "                                                     remove_intermediate_cols=remove_intermediate_cols)\n",
    "    for value_col in value_cols:\n",
    "        return_df = build_net_value_for_del_rec_tot(return_df, col_name_base=value_col, \n",
    "                                                    col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "                                                    remove_intermediate_cols=remove_intermediate_cols)\n",
    "    for cols_dict in value_cols_dict_list:\n",
    "        if (cols_dict.get('mean_col', None) is None or \n",
    "            cols_dict.get('counts_col', None) is None):\n",
    "            continue\n",
    "        return_df = build_mean_from_sum_and_counts(return_df, cols_dict['value_col'], cols_dict['counts_col'], cols_dict['mean_col'])\n",
    "    #---------------------------------------------------\n",
    "    non_vals_df = build_circuit_non_vals(df, non_val_cols, \n",
    "                                         aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "                                         aep_srvc_qlty_idntfr_vals=aep_srvc_qlty_idntfr_vals)\n",
    "    assert(non_vals_df.shape[0]==return_df.shape[0])\n",
    "    return_df = return_df.merge(non_vals_df, how='inner', left_index=True, right_index=True)\n",
    "    return_df[aep_srvc_qlty_idntfr_col] = 'TOTAL'\n",
    "    if maintain_original_col_order:\n",
    "        cols_from_og = [x for x in df.columns if x in return_df.columns]\n",
    "        return_df = Utilities_df.move_cols_to_front(return_df, cols_from_og)\n",
    "    return return_df\n",
    "\n",
    "\n",
    "# def get_ciruit_total_vals(df, non_val_cols, value_cols, counts_cols, \n",
    "#                           mean_cols_dict_list=None, \n",
    "#                           remove_intermediate_cols=True, \n",
    "#                           aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "#                           aep_srvc_qlty_idntfr_vals={'rec':'RECEIVED', 'del':'DELIVERED', 'tot':'TOTAL'}, \n",
    "#                           maintain_original_col_order=True):\n",
    "#     # Note: If new mean columns need to be calculated, use value_cols_dict_list\n",
    "#     #       Each entry should be a dict with keys: 'value_col', 'counts_col', 'mean_col' \n",
    "#     #--------------------------------------------------- \n",
    "#     merge_cols = value_cols + counts_cols\n",
    "#     #---------------------------------------------------\n",
    "#     df_rec = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['rec']]\n",
    "#     df_del = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['del']]\n",
    "#     df_tot = df[df[aep_srvc_qlty_idntfr_col]==aep_srvc_qlty_idntfr_vals['tot']]\n",
    "#     #---------------------------------------------------    \n",
    "#     # This essentially enforces assert(len(aep_srvc_qlty_idntfrs)<=3)\n",
    "#     # -- each line ensures that every date in df has exactly one entry\n",
    "#     assert(df_rec.shape[0]==df_rec.index.nunique())\n",
    "#     assert(df_del.shape[0]==df_del.index.nunique())\n",
    "#     assert(df_tot.shape[0]==df_tot.index.nunique())\n",
    "#     #---------------------------------------------------\n",
    "#     return_df = df_del[merge_cols].merge(df_rec[merge_cols], \n",
    "#                                          left_index=True, right_index=True, \n",
    "#                                          how='outer', suffixes=('_del', '_rec')) \n",
    "#     # Note: Suffix argument will do nothing here, as df_tot contains merge_cols, whereas\n",
    "#     #       return_df currently contains [f'x_{del}' for x in merge_cols] and [f'x_{rec}' for x in merge_cols]\n",
    "#     #       Therefore, there are no overlapping column names.  As such, we must rename using .rename\n",
    "#     return_df = return_df.merge(df_tot[merge_cols], left_index=True, right_index=True, how='outer')\n",
    "#     return_df = return_df.rename(columns = {x:f'{x}_tot' for x in merge_cols})\n",
    "#     # I used an outer merge so there will always been an entry for delivered, received, and total in return_df\n",
    "#     # However, if one of these did not exist in the original, the outer merge will leave a NaN value in the cell\n",
    "#     # Therefore, I call return_df.fillna(0) to replace any of these NaNs with 0\n",
    "#     return_df = return_df.fillna(0)\n",
    "#     #---------------------------------------------------\n",
    "#     for counts_col in counts_cols:\n",
    "#         return_df = build_net_counts_for_del_rec_tot(return_df, col_name_base=counts_col, \n",
    "#                                                      col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "#                                                      remove_intermediate_cols=remove_intermediate_cols)\n",
    "#     for value_col in value_cols:\n",
    "#         return_df = build_net_value_for_del_rec_tot(return_df, col_name_base=value_col, \n",
    "#                                                     col_tags = {'rec':'_rec', 'del':'_del', 'tot':'_tot'}, \n",
    "#                                                     remove_intermediate_cols=remove_intermediate_cols)\n",
    "#     if mean_cols_dict_list:\n",
    "#         for mean_cols_dict in mean_cols_dict_list:\n",
    "#             return_df = build_mean_from_sum_and_counts(return_df, mean_cols_dict['value_col'], mean_cols_dict['counts_col'], mean_cols_dict['mean_col'])\n",
    "#     #---------------------------------------------------\n",
    "#     non_vals_df = build_circuit_non_vals(df, non_val_cols, \n",
    "#                                          aep_srvc_qlty_idntfr_col=aep_srvc_qlty_idntfr_col, \n",
    "#                                          aep_srvc_qlty_idntfr_vals=aep_srvc_qlty_idntfr_vals)\n",
    "#     assert(non_vals_df.shape[0]==return_df.shape[0])\n",
    "#     return_df = return_df.merge(non_vals_df, how='inner', left_index=True, right_index=True)\n",
    "#     return_df[aep_srvc_qlty_idntfr_col] = 'TOTAL'\n",
    "#     if maintain_original_col_order:\n",
    "#         cols_from_og = [x for x in df.columns if x in return_df.columns]\n",
    "#         return_df = Utilities_df.move_cols_to_front(return_df, cols_from_og)\n",
    "#     return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_pattern=r'outg_rec_nb_*q[0-9].csv'\n",
    "value_cols_xfmr_cir = ['sum_value_sum', 'mean_value_sum', 'sum_value_sq_sum',\n",
    "                       'mean_value_sq_sum', 'sum_value_mean', 'mean_value_mean',\n",
    "                       'sum_value_std', 'mean_value_std', 'sum_counts', 'mean_counts',\n",
    "                       'sum_counts_including_null', 'mean_counts_including_null']\n",
    "agg_cols_xfmr_cir=value_cols_xfmr_cir\n",
    "agg_types_xfmr_cir = ['mean', 'sum', 'count']\n",
    "cols_of_interest_xfmr_cir = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset',\n",
    "                             'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'aep_usage_dt',\n",
    "                             'sum_value_sum', 'mean_value_sum', 'sum_value_sq_sum',\n",
    "                             'mean_value_sq_sum', 'sum_value_mean', 'mean_value_mean',\n",
    "                             'sum_value_std', 'mean_value_std', 'sum_counts', 'mean_counts',\n",
    "                             'sum_counts_including_null', 'mean_counts_including_null']\n",
    "combine_kwh_delivered_and_received=False\n",
    "merge_and_groupby_cols=['aep_endtime_utc']\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbee024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob_pattern=r'outg_rec_nb_*q[0-9].csv'\n",
    "# value_cols_xfmr_cir = ['sum_value_sum', 'sum_value_sq_sum', 'mean_value_mean', 'mean_value_std', \n",
    "#                        'sum_counts', 'sum_counts_including_null']\n",
    "# agg_cols_xfmr_cir=value_cols_xfmr_cir\n",
    "# agg_types_xfmr_cir = ['mean', 'sum', 'count']\n",
    "# cols_of_interest_xfmr_cir = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset',\n",
    "#                              'aep_derived_uom', 'aep_srvc_qlty_idntfr', 'aep_usage_dt',\n",
    "#                              'sum_value_sum', 'sum_value_sq_sum', 'mean_value_mean', 'mean_value_std', \n",
    "#                              'sum_counts', 'sum_counts_including_null']\n",
    "# combine_kwh_delivered_and_received=False\n",
    "# merge_and_groupby_cols=['aep_endtime_utc']\n",
    "# verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwh_vlt_dfs_xfmr_cir_dict = AMINonVee.assemble_kwh_vlt_dfs_from_saved_csvs(file_dir=df_xfmr_circuit_dir, glob_pattern=glob_pattern, \n",
    "                                                                 value_cols=value_cols_xfmr_cir, \n",
    "                                                                 cols_of_interest=cols_of_interest_xfmr_cir, \n",
    "                                                                 combine_kwh_delivered_and_received=combine_kwh_delivered_and_received, \n",
    "                                                                 merge_and_groupby_cols=merge_and_groupby_cols, \n",
    "                                                                 verbose=verbose)\n",
    "df_xfmr_cir_kwh_15T = kwh_vlt_dfs_xfmr_cir_dict['kwh']\n",
    "df_xfmr_cir_vlt_15T = kwh_vlt_dfs_xfmr_cir_dict['vlt']\n",
    "\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "#TODO!!!!!!!!!!!!!!!!!!\n",
    "# Need to handle how delivered, received, total will be combined before re-indexing!\n",
    "# For now, let's simply use 'TOTAL' from kwh\n",
    "df_xfmr_cir_kwh_15T_FULL = df_xfmr_cir_kwh_15T.copy()\n",
    "#df_cir_kwh_15T = df_cir_kwh_15T[df_cir_kwh_15T['aep_srvc_qlty_idntfr']=='TOTAL'].copy()\n",
    "\n",
    "# TODO!!!!!!!!!!!!!!!!!!!!!\n",
    "# How to handle different aep_srvc_qlty_idntfr for vlt?\n",
    "# ['INSTVA1', 'INSTVC1', 'INSTVB1', 'AVG']\n",
    "# For now, 'AVG' from vlt\n",
    "df_xfmr_cir_vlt_15T_FULL = df_xfmr_cir_vlt_15T.copy()\n",
    "df_xfmr_cir_vlt_15T = df_xfmr_cir_vlt_15T[df_xfmr_cir_vlt_15T['aep_srvc_qlty_idntfr']=='AVG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5931835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xfmr_cir_vlt_15T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xfmr_circuit_dir_NEW = os.path.join(Utilities.get_local_data_dir(), r'sample_circuits\\NewMethod\\GroupByXfmr_v3_NET\\outg_rec_nb_11751094')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ff239",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = Utilities.find_all_paths(base_dir=df_xfmr_circuit_dir_NEW, glob_pattern=glob_pattern)\n",
    "\n",
    "start_time_col = 'starttimeperiod'\n",
    "end_time_col = 'endtimeperiod'\n",
    "aep_endtime_utc_col = 'aep_endtime_utc'\n",
    "timezoneoffset_col = 'timezoneoffset'\n",
    "\n",
    "dfs_full = []\n",
    "for csv in csvs:\n",
    "    if verbose:\n",
    "        print('Reading file: ', csv)\n",
    "    df = pd.read_csv(csv)\n",
    "    df = Utilities_df.remove_prepend_from_columns_in_df(df)\n",
    "    #df = df[cols_of_interest]\n",
    "    if df.shape[0]==0:\n",
    "        continue\n",
    "    dfs_full.append(df)\n",
    "df_xfmr_cir_kwh_15T = pd.concat(dfs_full)\n",
    "df_xfmr_cir_kwh_15T = Utilities_dt.convert_timestamp_to_utc_in_df(df_xfmr_cir_kwh_15T, timestamp_col=aep_endtime_utc_col)\n",
    "df_xfmr_cir_kwh_15T = Utilities_dt.build_utc_time_column(df_xfmr_cir_kwh_15T, time_col=[start_time_col, end_time_col])\n",
    "df_xfmr_cir_kwh_15T = Utilities_dt.convert_timezoneoffset_col_to_timedelta(df_xfmr_cir_kwh_15T, timezoneoffset_col=timezoneoffset_col)\n",
    "\n",
    "df_xfmr_cir_kwh_15T = df_xfmr_cir_kwh_15T.set_index(f'{aep_endtime_utc_col}_from_timestamp', drop=False).sort_index()\n",
    "df_xfmr_cir_kwh_15T.index.name='time_idx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615319b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xfmr_cir_kwh_15T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ece6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_x2_col = 'sum_value_sq_sum'\n",
    "sum_x_col = 'sum_value_sum'\n",
    "n_counts_col = 'sum_counts'\n",
    "placement_col_mean = 'value_mean_pool'\n",
    "placement_col_std = 'value_std_pool'\n",
    "\n",
    "df_xfmr_cir_kwh_15T = build_mean_and_std_from_sum_x_x2_and_counts(df_xfmr_cir_kwh_15T, sum_x_col, sum_x2_col, n_counts_col, \n",
    "                                                                  placement_col_mean, placement_col_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e32cf0",
   "metadata": {},
   "source": [
    "### Use combine method on full dataset and then resample/aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_val_cols = ['starttimeperiod', 'endtimeperiod', 'aep_endtime_utc', 'timezoneoffset',\n",
    "#                 'aep_derived_uom', 'aep_usage_dt', 'aep_endtime_utc_from_timestamp', \n",
    "#                 'starttimeperiod_utc', 'endtimeperiod_utc']\n",
    "# value_cols_dict_list = [\n",
    "#     {'value_col':'sum_value_sum', 'counts_col':'sum_counts', 'mean_col':'mean_value_sum'}, \n",
    "#     {'value_col':'sum_value_sq_sum', 'counts_col':'sum_counts', 'mean_col':'mean_value_sq_sum'}, \n",
    "#     {'value_col':'sum_value_mean', 'counts_col':'sum_counts', 'mean_col':'mean_value_mean'}\n",
    "# ]\n",
    "\n",
    "# remaining_vals = []\n",
    "# for value_cols_dict in value_cols_dict_list:\n",
    "#     remaining_vals.extend(value_cols_dict.values())\n",
    "# remaining_vals = list(set(remaining_vals))\n",
    "\n",
    "# df_xfmr_cir_kwh_15T = get_ciruit_total_vals(df_xfmr_cir_kwh_15T, non_val_cols, \n",
    "#                                             value_cols_dict_list=value_cols_dict_list, \n",
    "#                                             remove_intermediate_cols=True)\n",
    "# # df_xfmr_cir_kwh_15T = df_xfmr_cir_kwh_15T[df_xfmr_cir_kwh_15T['aep_srvc_qlty_idntfr']=='TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cfba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_xfmr_cir_kwh_15T = build_mean_and_std_from_sum_x_x2_and_counts(df_xfmr_cir_kwh_15T, sum_x_col, sum_x2_col, n_counts_col, \n",
    "                                                                  placement_col_mean, placement_col_std)\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# TODO!!!!!!!!!!!!!!!!!\n",
    "# Also, would expect e.g. dfs_cir_kwh_dict['H'][df_key]==dfs_cir_kwh_dict['H'][df_agg_key]\n",
    "# However, this is close but not exactly true\n",
    "# It appears there are some times with duplicate entries\n",
    "# Compare the size of df_cir_kwh_15T[df_cir_kwh_15T['aep_srvc_qlty_idntfr']=='TOTAL']\n",
    "# to the number of unique indices\n",
    "#\n",
    "#\n",
    "\n",
    "dfs_xfmr_cir_kwh_dict = AMINonVee.build_time_resampled_dfs(df_xfmr_cir_kwh_15T, freqs=freqs, other_grouper_cols=[], \n",
    "                                     build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, \n",
    "                                     agg_cols=value_cols_xfmr_cir, agg_types=agg_types_xfmr_cir, \n",
    "                                     df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_xfmr_cir_kwh_15T.equals(dfs_xfmr_cir_kwh_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "dfs_xfmr_cir_vlt_dict = AMINonVee.build_time_resampled_dfs(df_xfmr_cir_vlt_15T, freqs=freqs, other_grouper_cols=[], \n",
    "                                     build_agg_dfs=build_agg_dfs, time_col_for_agg=time_col_for_agg, \n",
    "                                     agg_cols=value_cols_xfmr_cir, agg_types=agg_types_xfmr_cir, \n",
    "                                     df_key=df_key, df_agg_key=df_agg_key)\n",
    "#-----\n",
    "assert(df_xfmr_cir_vlt_15T.equals(dfs_xfmr_cir_vlt_dict['15T'][df_key]))\n",
    "#-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5310dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking endtimeperiod_utc against aep_endtime_utc_from_timestamp')\n",
    "print('df_kwh_15T:     ', all(df_kwh_15T['endtimeperiod_utc']==df_kwh_15T['aep_endtime_utc_from_timestamp']))\n",
    "print('df_vlt_15T:     ', all(df_vlt_15T['endtimeperiod_utc']==df_vlt_15T['aep_endtime_utc_from_timestamp']))\n",
    "#-----\n",
    "print('df_cir_kwh_15T: ', all(df_cir_kwh_15T['endtimeperiod_utc']==df_cir_kwh_15T['aep_endtime_utc_from_timestamp']))\n",
    "print('df_cir_vlt_15T: ', all(df_cir_vlt_15T['endtimeperiod_utc']==df_cir_vlt_15T['aep_endtime_utc_from_timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482537db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cab94be",
   "metadata": {},
   "source": [
    "# Convert out_t_beg_local and out_t_end_local to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[out_t_beg, out_t_end, no_outage_center] = Utilities_dt.determine_timezone_and_convert_local_to_utc_time([out_t_beg_local, out_t_end_local, no_outage_center_local], \n",
    "                                                                                            pd.to_timedelta(df_kwh_15T['timezoneoffset'].unique()).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40145c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1822a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020502e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_time = datetime.timedelta(days=3)\n",
    "ax=df_cir_kwh_15T_FULL[df_cir_kwh_15T_FULL['aep_srvc_qlty_idntfr']=='TOTAL'][out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(figsize=(20,10), label='TOTAL', color='red')\n",
    "ax=df_cir_kwh_15T_FULL[df_cir_kwh_15T_FULL['aep_srvc_qlty_idntfr']=='DELIVERED'][out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(label='DELIVERED')\n",
    "ax=df_cir_kwh_15T[out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(label='AVG/NET', color='purple')\n",
    "ax.axvline(out_t_beg, color='red')\n",
    "ax.axvline(out_t_end, color='lawngreen')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc887064",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "expand_time = datetime.timedelta(days=3)\n",
    "fig, ax = plt.subplots(1, 1, num=fig_num, figsize=[14, 6])\n",
    "subplots_adjust_args = {'left':0.075, 'right':0.975, \n",
    "                        'bottom':0.10, 'top':0.95, \n",
    "                        'wspace':0.2, 'hspace':0.35}\n",
    "plt.subplots_adjust(**subplots_adjust_args)\n",
    "df_cir_kwh_15T_FULL[df_cir_kwh_15T_FULL['aep_srvc_qlty_idntfr']=='TOTAL'][out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(ax=ax, figsize=(20,10), label='TOTAL', color='red')\n",
    "df_cir_kwh_15T_FULL[df_cir_kwh_15T_FULL['aep_srvc_qlty_idntfr']=='DELIVERED'][out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(ax=ax, label='DELIVERED')\n",
    "df_cir_kwh_15T[out_t_beg-expand_time:out_t_end+expand_time]['value_mean_cir'].plot(ax=ax, label='AVG/NET', color='purple')\n",
    "ax.axvline(out_t_beg, color='red')\n",
    "ax.axvline(out_t_end, color='lawngreen')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title(label='15T Circuit Average Consumption', fontsize=25)\n",
    "ax.set_xlabel(xlabel='Datetime', fontsize=20, x=0.9, y=0.0, ha='right', va='top')\n",
    "ax.tick_params(axis='both', labelsize=15)\n",
    "#----------------------------------------\n",
    "if save_figs:\n",
    "    save_dir = r'C:\\Users\\s346557\\Documents\\Presentations\\GroupMeetings\\20220120\\Figures\\SampleUsage'\n",
    "    save_name = 'totalreceived_vs_deliveredreceived.png'\n",
    "    fig.savefig(os.path.join(save_dir, save_name))\n",
    "#----------------------------------------    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa2e51",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_coeff(df_1, col_1, df_2, col_2):    \n",
    "    common_idxs_kwh = set(df_1.index).intersection(set(df_2.index))\n",
    "    df_1_to_corr = df_1.loc[common_idxs_kwh]\n",
    "    df_2_to_corr = df_2.loc[common_idxs_kwh]\n",
    "    #-----\n",
    "    corr = df_1_to_corr[col_1].corr(df_2_to_corr[col_2])\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f251d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xfmr_cir_vlt_15T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(df_xfmr_cir_kwh_15T['value_mean_pool']==df_cir_kwh_15T['value_mean_cir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbec0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False\n",
    "expand_time = datetime.timedelta(days=3)\n",
    "fig, (ax0,ax1) = plt.subplots(2, 1, num=fig_num, figsize=[14, 12])\n",
    "subplots_adjust_args = {'left':0.075, 'right':0.80, \n",
    "                        'bottom':0.10, 'top':0.95, \n",
    "                        'wspace':0.2, 'hspace':0.35}\n",
    "plt.subplots_adjust(**subplots_adjust_args)\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=dfs_kwh_dict['15T'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'15T Average Consumption (kWh)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='kWh', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='', fontsize=0, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='D')\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=df_cir_kwh_15T, \n",
    "                                  x='endtimeperiod_utc', y='value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "# fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=df_xfmr_cir_kwh_15T, \n",
    "#                                   x='endtimeperiod_utc', y='value_mean_pool', hue=None, \n",
    "#                                   out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean(2)')\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=df_xfmr_cir_kwh_15T, \n",
    "                                  x='endtimeperiod_utc', y='mean_value_mean', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Xfmr Mean')\n",
    "\n",
    "kwh_corr = get_correlation_coeff(dfs_kwh_dict['15T'][df_agg_key], 'mean_mtrs value', \n",
    "                                 df_cir_kwh_15T, 'value_mean_cir')\n",
    "plt.text(0.825, 1.075, f'Corr. 1-2 = {kwh_corr}', transform=ax0.transAxes, fontsize=15)\n",
    "kwh_corr = get_correlation_coeff(dfs_kwh_dict['15T'][df_agg_key], 'mean_mtrs value', \n",
    "                                 df_xfmr_cir_kwh_15T, 'mean_value_mean')\n",
    "plt.text(0.825, 1.025, f'Corr. 1-3 = {kwh_corr}', transform=ax0.transAxes, fontsize=15)\n",
    "\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=dfs_vlt_dict['15T'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'15T Average Voltage (V)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='Voltage (V)', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='Usage Start Time', fontsize=20, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='D')\n",
    "ax1.set_ylim([225,250])\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=df_cir_vlt_15T, \n",
    "                                  x='endtimeperiod_utc', y='value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=df_xfmr_cir_vlt_15T, \n",
    "                                  x='endtimeperiod_utc', y='mean_value_mean', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Xfmr Mean')\n",
    "\n",
    "vlt_corr = get_correlation_coeff(dfs_vlt_dict['15T'][df_agg_key], 'mean_mtrs value', \n",
    "                                 df_cir_vlt_15T, 'value_mean_cir')\n",
    "plt.text(0.825, 1.075, f'Corr. 1-2 = {vlt_corr}', transform=ax1.transAxes, fontsize=15)\n",
    "vlt_corr = get_correlation_coeff(dfs_vlt_dict['15T'][df_agg_key], 'mean_mtrs value', \n",
    "                                 df_xfmr_cir_vlt_15T, 'mean_value_mean')\n",
    "plt.text(0.825, 1.025, f'Corr. 1-3 = {vlt_corr}', transform=ax1.transAxes, fontsize=15)\n",
    "#----------------------------------------\n",
    "if save_figs:\n",
    "    save_dir = r'C:\\Users\\s346557\\Documents\\Presentations\\GroupMeetings\\20220120\\Figures\\SampleUsage'\n",
    "    save_name = '15T_outage_consumption_vs_circuit.png'\n",
    "    fig.savefig(os.path.join(save_dir, save_name))\n",
    "#----------------------------------------   \n",
    "fig_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_xfmr_cir_kwh_dict['H'][df_key].columns\n",
    "# 'mean_TRS mean_value_mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_time = datetime.timedelta(days=3)\n",
    "fig, (ax0,ax1) = plt.subplots(2, 1, num=fig_num, figsize=[14, 12])\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=dfs_kwh_dict['H'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_TRS mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'Hourly Average Consumption (kWh)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='kWh', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='', fontsize=0, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='D')\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=dfs_cir_kwh_dict['H'][df_key], \n",
    "                                  x='date', y='mean_TRS value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, dfs_xfmr_cir_kwh_dict['H'][df_key], \n",
    "                                  x='date', y='mean_TRS mean_value_mean', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean (2)')\n",
    "\n",
    "kwh_corr = get_correlation_coeff(dfs_kwh_dict['H'][df_agg_key], 'mean_TRS mean_mtrs value', \n",
    "                                 dfs_cir_kwh_dict['H'][df_key], 'mean_TRS value_mean_cir')\n",
    "plt.text(1.01, 1.01, f'Corr = {kwh_corr}', transform=ax0.transAxes, fontsize=15)\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=dfs_vlt_dict['H'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_TRS mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'Hourly Average Voltage (V)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='Voltage (V)', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='Usage Start Time', fontsize=20, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='D')\n",
    "ax1.set_ylim([225,250])\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=dfs_cir_vlt_dict['H'][df_key], \n",
    "                                  x='date', y='mean_TRS value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "vlt_corr = get_correlation_coeff(dfs_vlt_dict['H'][df_agg_key], 'mean_TRS mean_mtrs value', \n",
    "                                 dfs_cir_vlt_dict['H'][df_key], 'mean_TRS value_mean_cir')\n",
    "plt.text(1.01, 1.01, f'Corr = {vlt_corr}', transform=ax1.transAxes, fontsize=15)\n",
    "\n",
    "fig_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52901c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_time = datetime.timedelta(days=31)\n",
    "fig, (ax0,ax1) = plt.subplots(2, 1, num=fig_num, figsize=[14, 12])\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=dfs_kwh_dict['D'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_TRS mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'Daily Average Consumption (kWh)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='kWh', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='', fontsize=0, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='7D')\n",
    "\n",
    "fig,ax0 = AMINonVee.plot_usage_around_outage(fig, ax0, data=dfs_cir_kwh_dict['D'][df_key], \n",
    "                                  x='date', y='mean_TRS value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "kwh_corr = get_correlation_coeff(dfs_kwh_dict['D'][df_agg_key], 'mean_TRS mean_mtrs value', \n",
    "                                 dfs_cir_kwh_dict['D'][df_key], 'mean_TRS value_mean_cir')\n",
    "plt.text(1.01, 1.01, f'Corr = {kwh_corr}', transform=ax0.transAxes, fontsize=15)\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=dfs_vlt_dict['D'][df_agg_key], \n",
    "                                  x='endtimeperiod_utc', y='mean_TRS mean_mtrs value', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Outage Mean', \n",
    "                                  title_args=dict(label=f'Daily Average Voltage (V)', fontsize=25), \n",
    "                                  draw_outage_limits=True, \n",
    "                                  ylabel_args = dict(ylabel='Voltage (V)', fontsize=20, x=0.0, y=0.8, ha='left', va='bottom'), \n",
    "                                  xlabel_args = dict(xlabel='Usage Start Time', fontsize=20, x=0.9, y=0.0, ha='right', va='top'), \n",
    "                                   seg_line_freq='7D')\n",
    "ax1.set_ylim([225,250])\n",
    "\n",
    "fig,ax1 = AMINonVee.plot_usage_around_outage(fig, ax1, data=dfs_cir_vlt_dict['D'][df_key], \n",
    "                                  x='date', y='mean_TRS value_mean_cir', hue=None, \n",
    "                                  out_t_beg=out_t_beg, out_t_end=out_t_end, expand_time=expand_time, data_label='Circuit Mean')\n",
    "\n",
    "vlt_corr = get_correlation_coeff(dfs_vlt_dict['D'][df_agg_key], 'mean_TRS mean_mtrs value', \n",
    "                                 dfs_cir_vlt_dict['D'][df_key], 'mean_TRS value_mean_cir')\n",
    "plt.text(1.01, 1.01, f'Corr = {vlt_corr}', transform=ax1.transAxes, fontsize=15)\n",
    "\n",
    "fig_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e9f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf675a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
