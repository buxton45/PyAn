{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5755605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7b1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c94829",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_testing_data=True\n",
    "fig_num=0\n",
    "\n",
    "dovs_and_end_events_data_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data'\n",
    "if run_testing_data:\n",
    "    dovs_and_end_events_data_dir = os.path.join(dovs_and_end_events_data_dir, r'TESTING_DATASETS')\n",
    "\n",
    "files_dir_outg             = os.path.join(dovs_and_end_events_data_dir, r'EndEvents')\n",
    "files_dir_outg_prim_strict = os.path.join(dovs_and_end_events_data_dir, r'EndEvents_prim_strict')\n",
    "files_dir_no_outg = os.path.join(dovs_and_end_events_data_dir, r'EndEvents_NoOutg')\n",
    "\n",
    "file_path_glob = r'end_events_[0-9]*.csv'\n",
    "file_path_regex = None\n",
    "\n",
    "\n",
    "assert_all_cols_equal=True\n",
    "include_normalize_by_nSNs=True\n",
    "inclue_zero_counts=True\n",
    "return_multiindex_outg_reason=False\n",
    "return_normalized_separately=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248987d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_to_replace=[\n",
    "    r'\\:?\\s*([0-9a-zA-Z]{1,2})(\\:[0-9a-zA-Z]{1,2})+', \n",
    "   (\n",
    "       (\n",
    "           r'(Under Voltage)\\s*'\\\n",
    "           r'([0-9a-zA-Z]*)?\\s*'\\\n",
    "           r'(\\([0-9a-zA-Z\\s]*\\))\\s*'\\\n",
    "           r'([0-9a-zA-Z]*)?\\s?'\\\n",
    "           r'(for meter\\:?\\s*)'\\\n",
    "           r'(?:(?:[0-9a-zA-Z]{1,2})(?:\\:[0-9a-zA-Z]{1,2})+)?[\\s:,.]*'\\\n",
    "           r'(?:Phase\\s{1,2}[ABC](?:(?:\\s*and\\s*[ABC])|(?:,\\s*[ABC])*))?\\s*'\\\n",
    "           r'(Voltage out of tolerance)?'\n",
    "       ), \n",
    "       'AMIEndEvents.under_voltage_match_func'\n",
    "   ), \n",
    "   (\n",
    "       (\n",
    "           r'(Last Gasp\\s*-\\s*[0-9a-zA-Z\\s]*)[\\s\\:,.]*'\\\n",
    "           r'.*'\\\n",
    "           r'(Fail Reason: .*)$'\n",
    "       ), \n",
    "       'AMIEndEvents.last_gasp_reduce_func'\n",
    "   ), \n",
    "    (r'(Angle out of tolerance) \\[.*\\]', r'\\1'), \n",
    "    (r'(NIC Power Restore Trap Received from device).*', r'\\1'), #TODO This has much info, like last gasp\n",
    "    (\n",
    "        (\n",
    "            r'(Requested operation .* could not be applied to the given device type and firmware version.) '\\\n",
    "            r'Device, DeviceType: .*, Firmware Version: .*$'\n",
    "        ), \n",
    "        r'\\1'\n",
    "    ), \n",
    "    ('meterN/A', 'meter'),\n",
    "    (r'(Meter needs explicit time sync.) Drift: -?\\d* s, (Encountered Problems:\\s*.*), Meter_Time', r'\\1 \\2'), \n",
    "    (r'(Meter Program Seal mismatch for Device) \\[Device ID, MAC Id\\] = .*', r'\\1'), \n",
    "    (r'Device Time: .* Failed Device Reason: (.*) Reboot Counter: .* Refresh Counter: .*', r'\\1'), \n",
    "    (r'(Ignoring (?:Interval|Register) Read data for device as it has time in the future) .*', r'\\1'), \n",
    "    (r'(Secure association operation failed consecutively for 1 times for [0-9a-zA-Z]{4}.) .*', r'\\1'), \n",
    "    (r'Device, (Last Gasp State: .*), (Detector State: .*), Reboot Count: \\d*', r'\\1, \\2'), \n",
    "    (r'(Detected end of voltage sag on meter).*', r'\\1'), \n",
    "    (r'(Detected end of voltage swell on meter).*', r'\\1'), \n",
    "    r'N/A', \n",
    "    (r'\\s{2,}', ' ')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c56aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f959cc98",
   "metadata": {},
   "source": [
    "# NEW DEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b24d1",
   "metadata": {},
   "source": [
    "### OLD FUNCTIONS TO BE UPDATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_SNs_for_xfmrs_OLD(\n",
    "    trsf_pole_nbs, \n",
    "    df_mp_curr, \n",
    "    df_mp_hist,\n",
    "    no_outg_time_infos_df=None, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    files_dir_no_outg=r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\EndEvents_NoOutg', \n",
    "    file_path_glob_no_outg = r'end_events_[0-9]*.csv', \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Difficulty is that default.meter_premise_hist does not have trsf_pole_nb field.\n",
    "    Therefore, one must use default.meter_premise to find the premise numbers for xfrms in trsf_pole_nbs,\n",
    "      then use those PNs to select the correct entries from default.meter_premise_hist.\n",
    "    \n",
    "    If df_mp_curr OR df_mp_hist is not supplied, both will be built!\n",
    "    \n",
    "    addtnl_mp_df_curr_cols/addtnl_mp_df_hist_cols:\n",
    "      Only used when df_mp_curr/df_mp_hist not supplied and therefore need to be built\n",
    "      \n",
    "    If no_outg_time_infos_df is not supplied, it will be built.\n",
    "      files_dir_no_outg and file_path_glob_no_outg are only used when no_outg_time_infos_df needs built\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    necessary_mp_cols = [df_mp_serial_number_col, df_mp_prem_nb_col, df_mp_install_time_col, df_mp_removal_time_col]\n",
    "    #-------------------------\n",
    "    if df_mp_curr is None or df_mp_hist is None:\n",
    "        mp_df_curr_hist = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "            trsf_pole_nbs, \n",
    "            join_curr_hist=False, \n",
    "            addtnl_mp_df_curr_cols=addtnl_mp_df_curr_cols, \n",
    "            addtnl_mp_df_hist_cols=addtnl_mp_df_hist_cols, \n",
    "            df_mp_serial_number_col=df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col=df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col=df_mp_install_time_col, \n",
    "            df_mp_removal_time_col=df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col=df_mp_trsf_pole_nb_col\n",
    "        )\n",
    "        df_mp_curr = mp_df_curr_hist['mp_df_curr']\n",
    "        df_mp_hist = mp_df_curr_hist['mp_df_hist']\n",
    "    #-------------------------\n",
    "    # At a bare minimum, df_mp_curr and df_mp_hist must both have the following columns:\n",
    "    #   necessary_mp_cols = ['mfr_devc_ser_nbr', 'prem_nb', 'inst_ts', 'rmvl_ts']\n",
    "    assert(all([x in df_mp_curr.columns for x in necessary_mp_cols+[df_mp_trsf_pole_nb_col]]))\n",
    "    assert(all([x in df_mp_hist.columns for x in necessary_mp_cols]))\n",
    "    #-------------------------\n",
    "    # PNs_for_xfmrs is a DF with trsf_pole_nbs indices and elements which are lists of PNs for each xfmr\n",
    "    PNs_for_xfmrs = MeterPremise.get_SNs_andor_PNs_for_xfmrs(\n",
    "        trsf_pole_nbs=trsf_pole_nbs, \n",
    "        include_SNs=False,\n",
    "        include_PNs=True,\n",
    "        trsf_pole_nb_col=df_mp_trsf_pole_nb_col, \n",
    "        serial_number_col=df_mp_serial_number_col, \n",
    "        prem_nb_col=df_mp_prem_nb_col, \n",
    "        return_SNs_col=None, #Not grabbing SNs\n",
    "        return_PNs_col=return_prem_nbs_col, \n",
    "        assert_all_trsf_pole_nbs_found=assert_all_trsf_pole_nbs_found, \n",
    "        mp_df=df_mp_curr, \n",
    "        return_mp_df_also=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Instead of a DF with trsf_pole_nb index and prem_nb column, we want opposite\n",
    "    xfmr_for_PNs_df = PNs_for_xfmrs.explode(return_prem_nbs_col)\n",
    "    xfmr_for_PNs_df[xfmr_for_PNs_df.index.name] = xfmr_for_PNs_df.index\n",
    "    xfmr_for_PNs_df = xfmr_for_PNs_df.set_index(return_prem_nbs_col)  \n",
    "    #-------------------------\n",
    "    # If no_outg_time_infos_df is None, build it.  \n",
    "    #   no_outg_time_infos_df has prem_nbs indices and t_min, t_max columns\n",
    "    #   This is where the time information for each premise number comes from\n",
    "    if no_outg_time_infos_df is None:\n",
    "        paths_no_outg = Utilities.find_all_paths(base_dir=files_dir_no_outg, glob_pattern=file_path_glob_no_outg)\n",
    "        no_outg_time_infos_df = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "            summary_paths=[AMIEndEvents.find_summary_file_from_csv(x) for x in paths_no_outg], \n",
    "            output_prem_nbs_col=return_prem_nbs_col, \n",
    "            output_t_min_col=t_min_col, \n",
    "            output_t_max_col=t_max_col, \n",
    "            make_prem_nbs_idx=True, \n",
    "            include_summary_paths=False\n",
    "        )    \n",
    "    #-------------------------\n",
    "    # Merge xfmr_for_PNs_df with no_outg_time_infos_df to append the time data to the former\n",
    "    # NOTE: It is possible for t_min/t_max to be NaT (NaN) for some entries after the merge, meaning that the \n",
    "    #       premise numbers were not found in no_outg_time_infos_df\n",
    "    #       This happens because these premise numbers must not have had any meter events, and thus were not included \n",
    "    #         in the SQL query (as it takes a long time to find empty results, so I weed these out before running the \n",
    "    #         query), and therefore the premise numbers were not found in the summary files/no_outg_time_infos_df.    \n",
    "    xfmr_for_PNs_df = pd.merge(xfmr_for_PNs_df, no_outg_time_infos_df, how='left', left_index=True, right_index=True)\n",
    "    #-------------------------\n",
    "    # Want to consolidate xfmr_for_PNs_df, grouping by trsf_pole_nb and collecting t_min,t_max, and a list\n",
    "    # of the premise numbers.  Therefore, first the index must be reset to make a PNs columns\n",
    "    xfmr_for_PNs_df=xfmr_for_PNs_df.reset_index()\n",
    "    #-----\n",
    "    # Consolidate xfmr_for_PNs_df\n",
    "    # NOTE: If t_min/t_max is NaT (NaN) for all premise numbers in a given trsf_pole_nb (see NOTE above before merge\n",
    "    #       with no_outg_time_infos_df), then Utilities_df.consolidate_df will return an empty list (technically, an\n",
    "    #       empty np.ndarray) for that trsf_pole_nb\n",
    "    xfmr_for_PNs_df=Utilities_df.consolidate_df_OLD(\n",
    "        df=xfmr_for_PNs_df, \n",
    "        groupby_col=df_mp_trsf_pole_nb_col, \n",
    "        cols_shared_by_group=[t_min_col, t_max_col], \n",
    "        cols_to_collect_in_lists=[return_prem_nbs_col]\n",
    "    )    \n",
    "    #--------------------------------------------------\n",
    "    # Only reason for making dict is to ensure trsf_pole_nbs are not repeated \n",
    "    active_SNs_in_xfmrs_dfs_dict = {}\n",
    "\n",
    "    for trsf_pole_nb_i, row_i in xfmr_for_PNs_df.iterrows():\n",
    "        # active_SNs_df_i will have indices equal to premise numbers and value equal to lists\n",
    "        #   of active SNs for each PN\n",
    "        PNs_i=row_i[return_prem_nbs_col]\n",
    "        dt_0_i=row_i[t_min_col]\n",
    "        dt_1_i=row_i[t_max_col]\n",
    "        # See NOTEs above regarding t_min/t_max being empty\n",
    "        # In such a case, it is simply impossibe (with the summary files currently generated) to access\n",
    "        #   the date over which the data would have been run, if any events existed.\n",
    "        #   In future versions, this information will be included in the summary files!\n",
    "        # I don't want to completely exclude these (by e.g., setting dt_0_i=pd.Timestamp.min and \n",
    "        #   dt_1_i=pd.Timestamp.max), so I will simply include the meters which are active TODAY.\n",
    "        # This obviously is not correct, but this occurrence is rare (only happening when every single meter\n",
    "        #   on a transformer had no events during the time period) and this crude approximation will be fine.\n",
    "        if Utilities.is_object_one_of_types(dt_0_i, [list, np.ndarray]):\n",
    "            assert(len(dt_0_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            assert(Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]) and len(dt_1_i)==0)\n",
    "            dt_0_i=pd.Timestamp.today()\n",
    "        if Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]):\n",
    "            assert(len(dt_1_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            # But, dt_0_i changed already above, so much check row_i[t_min_col] instead!\n",
    "            assert(Utilities.is_object_one_of_types(row_i[t_min_col], [list, np.ndarray]) and len(row_i[t_min_col])==0)\n",
    "            dt_1_i=pd.Timestamp.today()\n",
    "        active_SNs_df_i = MeterPremise.get_active_SNs_for_PNs_at_datetime_interval(\n",
    "            PNs=PNs_i,\n",
    "            df_mp_curr=df_mp_curr, \n",
    "            df_mp_hist=df_mp_hist, \n",
    "            dt_0=dt_0_i,\n",
    "            dt_1=dt_1_i,\n",
    "            output_index=None,\n",
    "            output_groupby=[df_mp_prem_nb_col], \n",
    "            include_prems_wo_active_SNs_when_groupby=True, \n",
    "            assert_all_PNs_found=False\n",
    "        )\n",
    "        active_SNs_df_i=active_SNs_df_i.reset_index()\n",
    "        if active_SNs_df_i.shape[0]==0:\n",
    "            active_SNs_df_i[df_mp_prem_nb_col] = np.nan\n",
    "            active_SNs_df_i[df_mp_serial_number_col] = [[]] \n",
    "        active_SNs_df_i[df_mp_trsf_pole_nb_col] = trsf_pole_nb_i\n",
    "        active_SNs_df_i = active_SNs_df_i.explode(df_mp_serial_number_col)\n",
    "        assert(trsf_pole_nb_i not in active_SNs_in_xfmrs_dfs_dict)\n",
    "        active_SNs_in_xfmrs_dfs_dict[trsf_pole_nb_i] = active_SNs_df_i\n",
    "    #-------------------------\n",
    "    active_SNs_df = pd.concat(list(active_SNs_in_xfmrs_dfs_dict.values()))\n",
    "    #-------------------------\n",
    "    active_SNs_df = Utilities_df.consolidate_df_OLD(\n",
    "        df=active_SNs_df, \n",
    "        groupby_col=df_mp_trsf_pole_nb_col, \n",
    "        cols_shared_by_group=None, \n",
    "        cols_to_collect_in_lists=[df_mp_serial_number_col, df_mp_prem_nb_col], \n",
    "        include_groupby_col_in_output_cols=False, \n",
    "        allow_duplicates_in_lists=False, \n",
    "        recover_uniqueness_violators=True, \n",
    "        rename_cols=None, \n",
    "        verbose=False\n",
    "    )\n",
    "    #-----\n",
    "    # Change [nan] entries to []\n",
    "    active_SNs_df.loc[active_SNs_df[df_mp_serial_number_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0, df_mp_serial_number_col] = [[]]\n",
    "    active_SNs_df.loc[active_SNs_df[df_mp_prem_nb_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0, df_mp_prem_nb_col] = [[]]\n",
    "    #-------------------------\n",
    "    active_SNs_df = active_SNs_df.rename(columns={\n",
    "        df_mp_prem_nb_col:return_prem_nbs_col, \n",
    "        df_mp_serial_number_col:return_SNs_col\n",
    "    })\n",
    "    #-------------------------\n",
    "    return active_SNs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xfmr_active_SNs_to_rcpo_df_OLD(\n",
    "    rcpo_df, \n",
    "    set_xfmr_nSNs=True, \n",
    "    include_active_xfmr_PNs=False, #Should be equal to the PNs already in rcpo_df!\n",
    "    df_mp_curr=None,\n",
    "    df_mp_hist=None, \n",
    "    no_outg_time_infos_df=None, \n",
    "    addtnl_get_active_SNs_for_xfmrs_kwargs=None, \n",
    "    xfmr_SNs_col='_xfmr_SNs', \n",
    "    xfmr_nSNs_col='_xfmr_nSNs', \n",
    "    xfmr_PNs_col='_xfmr_PNs', \n",
    "    xfmr_nPNs_col='_xfmr_nPNs', \n",
    "):\n",
    "    r\"\"\"\n",
    "    NOTE: If include_active_xfmr_PNs is True, this column (named xfmr_PNs_col='_xfmr_SNs') should be \n",
    "          equal to the PNs already in rcpo_df!\n",
    "    NOTE: xfmr_SNs_col, xfmr_nSNs_col, xfmr_PNs_col, and xfmr_nPNs_col should all be strings, not tuples.\n",
    "          If column is multiindex, the level_0 value will be handled below.\n",
    "          \n",
    "    NOTE: If any of xfmr_SNs_col, xfmr_nSNs_col, xfmr_PNs_col, and xfmr_nPNs_col are already contained in \n",
    "          rcpo_df, they will be replaced.  This is needed so that the merge operation does not come back with _x and _y\n",
    "          values.  So, one should make sure this function call is truly needed, as grabbing the serial numbers for the\n",
    "          outages typically takes a couple/few minutes.\n",
    "          \n",
    "    NOTE: To make things run faster, the user can supply df_mp_curr and df_mp_hist.  These will be included in \n",
    "          get_active_SNs_for_xfmrs_kwargs.\n",
    "          NOTE: If df_mp_curr/df_mp_hist is also supplied in addtnl_get_active_SNs_for_xfmrs_kwargs,\n",
    "                that/those in addtnl_get_active_SNs_for_xfmrs_kwargs will ultimately be used (not the\n",
    "                explicity df_mp_hist/curr in the function arguments!)\n",
    "          CAREFUL: If one does supple df_mp_curr/hist, one must be certain these DFs contain all necessary elements!\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    get_active_SNs_for_xfmrs_kwargs = dict(\n",
    "        trsf_pole_nbs=rcpo_df.index.unique().tolist(), \n",
    "        df_mp_curr=df_mp_curr, \n",
    "        df_mp_hist=df_mp_hist, \n",
    "        no_outg_time_infos_df=no_outg_time_infos_df, \n",
    "        return_prem_nbs_col=xfmr_PNs_col, \n",
    "        return_SNs_col=xfmr_SNs_col\n",
    "    )\n",
    "    if addtnl_get_active_SNs_for_xfmrs_kwargs is not None:\n",
    "        get_active_SNs_for_xfmrs_kwargs = {**get_active_SNs_for_xfmrs_kwargs, \n",
    "                                           **addtnl_get_active_SNs_for_xfmrs_kwargs}\n",
    "    active_SNs_df = get_active_SNs_for_xfmrs_OLD(**get_active_SNs_for_xfmrs_kwargs)\n",
    "    assert(isinstance(active_SNs_df, pd.DataFrame))\n",
    "    #-------------------------\n",
    "    # Assert below might be too strong here...\n",
    "    assert(sorted(rcpo_df.index.unique().tolist())==sorted(active_SNs_df.index.unique().tolist()))\n",
    "    assert(rcpo_df.columns.nlevels<=2)\n",
    "    if rcpo_df.columns.nlevels==1:\n",
    "        #----------\n",
    "        # See note above about columns being replaced/dropped\n",
    "        cols_to_drop = [x for x in rcpo_df.columns if x in active_SNs_df.columns]\n",
    "        if len(cols_to_drop)>0:\n",
    "            rcpo_df = rcpo_df.drop(columns=cols_to_drop)\n",
    "        #----------\n",
    "        rcpo_df = rcpo_df.merge(active_SNs_df, left_index=True, right_index=True)\n",
    "        #----------\n",
    "        if set_xfmr_nSNs:\n",
    "            rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, xfmr_SNs_col, xfmr_nSNs_col)\n",
    "            if include_active_xfmr_PNs:\n",
    "                rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, xfmr_PNs_col, xfmr_nPNs_col)\n",
    "    else:\n",
    "        # Currently, only expecting raw and/or norm.  No problem to allow more, but for now keep this to alert \n",
    "        # of anything unexpected\n",
    "        assert(rcpo_df.columns.get_level_values(0).nunique()<=2)\n",
    "        for i,level_0_val in enumerate(rcpo_df.columns.get_level_values(0).unique()):\n",
    "            if i==0:\n",
    "                active_SNs_df.columns = pd.MultiIndex.from_product([[level_0_val], active_SNs_df.columns])\n",
    "            else:\n",
    "                active_SNs_df.columns = active_SNs_df.columns.set_levels([level_0_val], level=0)\n",
    "            #----------\n",
    "            # See note above about columns being replaced/dropped\n",
    "            cols_to_drop = [x for x in rcpo_df.columns if x in active_SNs_df.columns]\n",
    "            if len(cols_to_drop)>0:\n",
    "                rcpo_df = rcpo_df.drop(columns=cols_to_drop)\n",
    "            #----------\n",
    "            rcpo_df = rcpo_df.merge(active_SNs_df, left_index=True, right_index=True)\n",
    "            #----------\n",
    "            if set_xfmr_nSNs:\n",
    "                rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, (level_0_val, xfmr_SNs_col), (level_0_val, xfmr_nSNs_col))\n",
    "                if include_active_xfmr_PNs:\n",
    "                    rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, (level_0_val, xfmr_PNs_col), (level_0_val, xfmr_nPNs_col))\n",
    "    #-------------------------\n",
    "    rcpo_df = rcpo_df.sort_index(axis=1,level=0)\n",
    "    #-------------------------\n",
    "    return rcpo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rcpo_df_norm_by_xfmr_active_nSNs_OLD(\n",
    "    rcpo_df_raw, \n",
    "    xfmr_nSNs_col='_xfmr_nSNs', \n",
    "    xfmr_SNs_col='_xfmr_SNs', \n",
    "    other_SNs_col_tags_to_ignore=['_SNs', '_nSNs', '_prem_nbs', '_nprem_nbs', '_xfmr_PNs', '_xfmr_nPNs'], \n",
    "    drop_xfmr_nSNs_eq_0=True, \n",
    "    new_level_0_val='counts_norm_by_xfmr_nSNs', \n",
    "    remove_SNs_cols=False, \n",
    "    df_mp_curr=None,\n",
    "    df_mp_hist=None, \n",
    "    no_outg_time_infos_df=None, \n",
    "    addtnl_get_active_SNs_for_xfmrs_kwargs=None\n",
    "):\n",
    "    r\"\"\"\n",
    "    Build rcpo_df normalized by the number of serial numbers in each outage\n",
    "\n",
    "    drop_xfmr_nSNs_eq_0:\n",
    "      It is possible for the number of serial numbers in an outage to be zero!\n",
    "      Premise numbers are always found, but the meter_premise database does not always \n",
    "        contain the premise numbers.\n",
    "      Dividing by zero will make all counts for such an entry equal to NaN or inf.\n",
    "      When drop_xfmr_nSNs_eq_0 is True, such entries will be removed.\n",
    "\n",
    "    NOTE: xfmr_SNs_col and xfmr_nSNs_col should both be strings, not tuples.\n",
    "          If column is MultiIndex, the level_0 value will be handled below.\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    n_counts_col = xfmr_nSNs_col\n",
    "    list_col = xfmr_SNs_col\n",
    "    #-------------------------\n",
    "    # NOTE: MECPODf.add_outage_SNs_to_rcpo_df expects xfmr_SNs_col and xfmr_nSNs_col to be strings, not tuples\n",
    "    #       as it handles the level 0 values if they exist.  So, if tuples, use only highest level values (i.e., level 1)\n",
    "    assert(Utilities.is_object_one_of_types(list_col, [str, tuple]))\n",
    "    assert(Utilities.is_object_one_of_types(n_counts_col, [str, tuple]))\n",
    "    #-----\n",
    "    add_list_col_to_rcpo_df_func = add_xfmr_active_SNs_to_rcpo_df_OLD\n",
    "    add_list_col_to_rcpo_df_kwargs = dict(\n",
    "        set_xfmr_nSNs=True, \n",
    "        include_active_xfmr_PNs=True, \n",
    "        df_mp_curr=df_mp_curr,\n",
    "        df_mp_hist=df_mp_hist, \n",
    "        no_outg_time_infos_df=no_outg_time_infos_df, \n",
    "        addtnl_get_active_SNs_for_xfmrs_kwargs=addtnl_get_active_SNs_for_xfmrs_kwargs, \n",
    "        xfmr_SNs_col='_xfmr_SNs', \n",
    "        xfmr_nSNs_col='_xfmr_nSNs', \n",
    "        xfmr_PNs_col='_xfmr_PNs', \n",
    "        xfmr_nPNs_col='_xfmr_nPNs', \n",
    "    )\n",
    "    #-------------------------\n",
    "    other_col_tags_to_ignore = other_SNs_col_tags_to_ignore\n",
    "    drop_n_counts_eq_0 = drop_xfmr_nSNs_eq_0\n",
    "    new_level_0_val = new_level_0_val\n",
    "    remove_ignored_cols = remove_SNs_cols\n",
    "    #-------------------------\n",
    "    return MECPODf.build_rcpo_df_norm_by_list_counts(\n",
    "        rcpo_df_raw=rcpo_df_raw, \n",
    "        n_counts_col=n_counts_col, \n",
    "        list_col=list_col, \n",
    "        add_list_col_to_rcpo_df_func=add_list_col_to_rcpo_df_func, \n",
    "        add_list_col_to_rcpo_df_kwargs=add_list_col_to_rcpo_df_kwargs, \n",
    "        other_col_tags_to_ignore=other_col_tags_to_ignore, \n",
    "        drop_n_counts_eq_0=drop_n_counts_eq_0, \n",
    "        new_level_0_val=new_level_0_val, \n",
    "        remove_ignored_cols=remove_ignored_cols\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc285805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09a58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cca69f6",
   "metadata": {},
   "source": [
    "### NEW FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index_and_identify_cols_to_merge(\n",
    "    df, \n",
    "    merge_on, \n",
    "    tag_for_idx_names=None\n",
    "):\n",
    "    r\"\"\"\n",
    "    Designed to work with merge_rcpo_and_df (but should definitely be useful elsewhere), which \n",
    "    allows the user to join the DFs by columns, specific index levels or any mixture of the two.\n",
    "    \n",
    "    In order to achieve this type of general merging, it is easiest to call reset_index, making everything\n",
    "      to be merged on a column.\n",
    "    HOWEVER, in order to keep track of the original indices, which likely will be restored after the merge,\n",
    "      it is important for all index levels to have a name.\n",
    "      \n",
    "    merge_on:\n",
    "        This is a list that directs the columns/indices to be used in the join.\n",
    "        Column identifiers:\n",
    "            Single strings for normal DF, lists/tuples for MultiIndex columns\n",
    "        Index identifiers:\n",
    "            f'index_{idx_level}' to specify index level by number\n",
    "            ('index', idx_level_name) to specify index level by name\n",
    "            \n",
    "    RETURNS:\n",
    "        A dict object with keys = ['df', 'df_idx_names_OG', 'df_idx_names', 'reset_merge_on']\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    df=df.copy()\n",
    "    #-------------------------\n",
    "    assert(Utilities.is_object_one_of_types(merge_on, [list, tuple]))\n",
    "    #-------------------------\n",
    "    # Make sure all index levels have names!\n",
    "    # If the level has a name, the code below will leave it unchanged in df_idx_names\n",
    "    # If it does not have a name, it will be names f'index_{idx_level}', where idx_level \n",
    "    #   is the index level number\n",
    "    df_idx_names_OG = list(df.index.names)\n",
    "    df_idx_names = [x if x is not None else f'index_{i}' \n",
    "                    for i,x in enumerate(df_idx_names_OG)]\n",
    "    if tag_for_idx_names is not None:\n",
    "        df_idx_names = [f'{x}_{tag_for_idx_names}' for x in df_idx_names]\n",
    "    df.index.names=df_idx_names\n",
    "    #-------------------------\n",
    "    reset_merge_on = []\n",
    "    for idfr in merge_on:\n",
    "        assert(Utilities.is_object_one_of_types(idfr, [str, list, tuple]))\n",
    "        if idfr in df.columns:\n",
    "            reset_merge_on.append(idfr)\n",
    "        else:\n",
    "            # Must be in indices!\n",
    "            if isinstance(idfr, str):\n",
    "                assert(idfr.startswith('index'))\n",
    "                if idfr=='index':\n",
    "                    idfr_idx_lvl=0\n",
    "                else:\n",
    "                    idfr_idx_lvl = re.findall('index_(\\d*)', idfr)\n",
    "                    assert(len(idfr_idx_lvl)==1)\n",
    "                    idfr_idx_lvl=idfr_idx_lvl[0]\n",
    "                    idfr_idx_lvl=int(idfr_idx_lvl)\n",
    "            else:\n",
    "                assert(len(idfr)==2)\n",
    "                assert(idfr[0]=='index')\n",
    "                idx_level_name = idfr[1]\n",
    "                # If tag_for_idx_names, df.index.names already changed, so idx_level_name must be adjusted\n",
    "                if tag_for_idx_names is not None:\n",
    "                    idx_level_name = f'{idx_level_name}_{tag_for_idx_names}'\n",
    "                assert(idx_level_name in df.index.names)\n",
    "                idfr_idx_lvl = df.index.names.index(idx_level_name)\n",
    "            #---------------\n",
    "            assert(idfr_idx_lvl < df.index.nlevels)\n",
    "            reset_merge_on_i = df.index.names[idfr_idx_lvl]\n",
    "            # NOTE: If df.columns.nlevels>1, then calling df.reset_index() below\n",
    "            #       will make the bottom level reset_merge_on_i and all the rest ''\n",
    "            #       e.g., if nlevels=2, after df.reset_index(), reset_merge_on_i--> (reset_merge_on_i, '')\n",
    "            if df.columns.nlevels>1:\n",
    "                reset_merge_on_i=tuple([reset_merge_on_i] + ['']*(df.columns.nlevels-1))\n",
    "            reset_merge_on.append(reset_merge_on_i)\n",
    "    #-------------------------\n",
    "    # Call reset_index on df, making all indices into columns, and double check that all reset_merge_on\n",
    "    #   are contained in the columns\n",
    "    df = df.reset_index()\n",
    "    assert(len(set(reset_merge_on).difference(set(df.columns)))==0)\n",
    "    #-------------------------\n",
    "    return dict(\n",
    "        df=df, \n",
    "        df_idx_names_OG=df_idx_names_OG, \n",
    "        df_idx_names=df_idx_names, \n",
    "        reset_merge_on=reset_merge_on\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_rcpo_and_df(\n",
    "    rcpo_df, \n",
    "    df_2, \n",
    "    rcpo_df_on,\n",
    "    df_2_on, \n",
    "    how='left'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Merge together rcpo_df and df_2 dfs.\n",
    "    Designed specifically for rcpo_df and time_infos_df.\n",
    "    \n",
    "    rcpo_df_on/df_2_on:\n",
    "        These are lists which direct the columns/indices to be used in the join.\n",
    "        Column identifiers:\n",
    "            Single strings for normal DF, lists/tuples for MultiIndex columns\n",
    "        Index identifiers:\n",
    "            f'index_{idx_level}' to specify index level by number\n",
    "            ('index', idx_level_name) to specify index level by name\n",
    "            \n",
    "        NOTE: Calling reset_index() on both DFs will be the easiest method for this type of general merging, in\n",
    "              which the DFs can be merged by columns, specific index levels or any mixture of the two.\n",
    "              This is done through the use of reset_index_and_identify_cols_to_merge\n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    # Only expecting at most 2 levels in columns (e.g., counts or counts_norm as level 0, and reason as level 1)\n",
    "    #     - probably not a necessary assertion, if function to be expanded later\n",
    "    #   Ultimately, the number of levels in df_2 will match that of rcpo_df, so making the same\n",
    "    #     assertion on df_2\n",
    "    assert((rcpo_df.columns.nlevels <= 2) and (df_2.columns.nlevels <= 2))\n",
    "    if rcpo_df.columns.nlevels==2:\n",
    "        # If rcpo_df has two column levels, df_2 must also for the proper merging to occur\n",
    "        #   --Merging with unequal levels will cause all levels to be collapsed down to single dimension\n",
    "        #-----\n",
    "        # Expecting at most 2 unique values for level 0 (definitely not a necessary assertion)\n",
    "        assert(rcpo_df.columns.get_level_values(0).nunique()<=2)\n",
    "        # In this case, likely df_2 has only single level columns.\n",
    "        #   For proper merge, the number of levels should match\n",
    "        if df_2.columns.nlevels==1:\n",
    "            level_0_vals = rcpo_df.columns.get_level_values(0).unique().tolist()\n",
    "            # Add new top level to df_2 with value equal to level_0_vals[0]\n",
    "            df_2=Utilities_df.prepend_level_to_MultiIndex(\n",
    "                df=df_2, level_val=level_0_vals[0], level_name=None, axis=1\n",
    "            )\n",
    "            if len(level_0_vals)>1:\n",
    "                # Grab df without new column level to be copied to other new column level values\n",
    "                # NOTE: If extra [] placed around level_0_vals[0] below, the new column level would be returned\n",
    "                #       (which is not desired here!)\n",
    "                df_0 = df_2[level_0_vals[0]]\n",
    "                df_0_cols = df_0.columns.tolist()\n",
    "                # Reproduce the entries of df_2 for all column level 0 values in rcpo_df\n",
    "                for i_lvl in range(1,len(level_0_vals)):\n",
    "                    new_cols = pd.MultiIndex.from_product([[level_0_vals[i_lvl]], df_0_cols])\n",
    "                    df_2[new_cols] = df_0.copy()\n",
    "        # Now, at this stage, rcpo_df and df_2 should have the same number of column levels\n",
    "        #   and should have overlapping level 0 values if nlevels>1\n",
    "        assert((rcpo_df.columns.nlevels <= 2) and (df_2.columns.nlevels <= 2)) #not needed\n",
    "        assert(rcpo_df.columns.nlevels == df_2.columns.nlevels)\n",
    "        if rcpo_df.columns.nlevels == 2:\n",
    "            # Make sure overlapping 0 values.  \n",
    "            # I suppose user could supply df_2 with only a single level 0 value while rcpo_df has\n",
    "            #   two values.  In this case, only the single value would be merged to rcpo_df\n",
    "            assert(len(set(df_2.columns.get_level_values(0).unique().tolist()).difference(\n",
    "                set(rcpo_df.columns.get_level_values(0).unique().tolist())\n",
    "            ))==0)\n",
    "    else:\n",
    "        assert(rcpo_df.columns.nlevels==df_2.columns.nlevels==1)\n",
    "    #--------------------------------------------------\n",
    "    reset_rcpo_df_dict = reset_index_and_identify_cols_to_merge(\n",
    "        df=rcpo_df, \n",
    "        merge_on=rcpo_df_on, \n",
    "        tag_for_idx_names='from_rcpo_df'\n",
    "    )\n",
    "\n",
    "    reset_df_2_dict = reset_index_and_identify_cols_to_merge(\n",
    "        df=df_2, \n",
    "        merge_on=df_2_on, \n",
    "        tag_for_idx_names='from_df_2'\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df = pd.merge(\n",
    "        reset_rcpo_df_dict['df'], \n",
    "        reset_df_2_dict['df'], \n",
    "        left_on=reset_rcpo_df_dict['reset_merge_on'], \n",
    "        right_on = reset_df_2_dict['reset_merge_on'], \n",
    "        how=how\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Want to set index first before changing names back to originals, as the\n",
    "    #   originals could have been None\n",
    "    merged_df = merged_df.set_index(reset_rcpo_df_dict['df_idx_names'])\n",
    "\n",
    "    # Two lines below (instead of calling simply df.index.names=df_idx_names_OG) \n",
    "    #   ensures the order is the same\n",
    "    rcpo_df_rename_dict = dict(zip(reset_rcpo_df_dict['df_idx_names'], reset_rcpo_df_dict['df_idx_names_OG']))\n",
    "    merged_df.index.names = [rcpo_df_rename_dict[x] for x in merged_df.index.names]\n",
    "    #-------------------------\n",
    "    # When merging two columns whose names are different, both columns are kept\n",
    "    #   This is redundant, as these will have identical values, as they were merged, so get rid of\n",
    "    #   Note: If the column names are the same, this is obviously not an issue (hence the need to find\n",
    "    #         cols_to_drop below, instead of simply dropping all of reset_df_2_dict['reset_merge_on']\n",
    "    cols_to_drop = [x for x in reset_df_2_dict['reset_merge_on'] if x in merged_df.columns]\n",
    "    merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Rename columns from df_2 to original values (if original values were not None!)\n",
    "    df_2_rename_dict = dict(zip(reset_df_2_dict['df_idx_names'], reset_df_2_dict['df_idx_names_OG']))\n",
    "    df_2_rename_dict = {k:v for k,v in df_2_rename_dict.items() if k in merged_df.columns and v is not None}\n",
    "    merged_df=merged_df.rename(columns=df_2_rename_dict)\n",
    "    #-------------------------\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96d73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa57c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO still needs work...\n",
    "# This replaces get_active_SNs_for_xfmrs_OLD (but, typically use get_active_SNs_for_xfmrs_in_rcpo_df)\n",
    "def get_active_SNs_for_xfmrs(\n",
    "    trsf_pole_nbs,     \n",
    "    df_mp_curr, \n",
    "    df_mp_hist,\n",
    "    time_infos_df,     \n",
    "    time_infos_to_PNs = ['index'], \n",
    "    PNs_to_time_infos = ['index'], \n",
    "    how='left',     \n",
    "    output_trsf_pole_nb_col=None, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Difficulty is that default.meter_premise_hist does not have trsf_pole_nb field.\n",
    "    Therefore, one must use default.meter_premise to find the premise numbers for xfrms in trsf_pole_nbs,\n",
    "      then use those PNs to select the correct entries from default.meter_premise_hist.\n",
    "      \n",
    "    time_infos_to_PNs:\n",
    "      Defines how time_infos_df and PNs_for_xfmrs will be merged.\n",
    "      NOTE: PNs_for_xfmrs will have indices equal to trsf_pole_nbs and values equal to lists of associated prem_nbs\n",
    "      See merge_rcpo_and_df and reset_index_and_identify_cols_to_merge for more information\n",
    "\n",
    "    If df_mp_curr OR df_mp_hist is not supplied, both will be built!\n",
    "    \n",
    "    addtnl_mp_df_curr_cols/addtnl_mp_df_hist_cols:\n",
    "      Only used when df_mp_curr/df_mp_hist not supplied and therefore need to be built\n",
    "      \n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    assert(t_min_col in time_infos_df.columns and \n",
    "           t_max_col in time_infos_df.columns)\n",
    "    time_infos_df = time_infos_df[[t_min_col, t_max_col]]\n",
    "    #--------------------------------------------------\n",
    "    #-------------------------\n",
    "    necessary_mp_cols = [df_mp_serial_number_col, df_mp_prem_nb_col, df_mp_install_time_col, df_mp_removal_time_col]\n",
    "    #-------------------------\n",
    "    if df_mp_curr is None or df_mp_hist is None:\n",
    "        mp_df_curr_hist = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "            trsf_pole_nbs, \n",
    "            join_curr_hist=False, \n",
    "            addtnl_mp_df_curr_cols=addtnl_mp_df_curr_cols, \n",
    "            addtnl_mp_df_hist_cols=addtnl_mp_df_hist_cols, \n",
    "            df_mp_serial_number_col=df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col=df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col=df_mp_install_time_col, \n",
    "            df_mp_removal_time_col=df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col=df_mp_trsf_pole_nb_col\n",
    "        )\n",
    "        df_mp_curr = mp_df_curr_hist['mp_df_curr']\n",
    "        df_mp_hist = mp_df_curr_hist['mp_df_hist']\n",
    "    #-------------------------\n",
    "    # At a bare minimum, df_mp_curr and df_mp_hist must both have the following columns:\n",
    "    #   necessary_mp_cols = ['mfr_devc_ser_nbr', 'prem_nb', 'inst_ts', 'rmvl_ts']\n",
    "    assert(all([x in df_mp_curr.columns for x in necessary_mp_cols+[df_mp_trsf_pole_nb_col]]))\n",
    "    assert(all([x in df_mp_hist.columns for x in necessary_mp_cols]))\n",
    "    #-------------------------\n",
    "    # PNs_for_xfmrs is a DF with trsf_pole_nbs indices and elements which are lists of PNs for each xfmr\n",
    "    PNs_for_xfmrs = MeterPremise.get_SNs_andor_PNs_for_xfmrs(\n",
    "        trsf_pole_nbs=trsf_pole_nbs, \n",
    "        include_SNs=False,\n",
    "        include_PNs=True,\n",
    "        trsf_pole_nb_col=df_mp_trsf_pole_nb_col, \n",
    "        serial_number_col=df_mp_serial_number_col, \n",
    "        prem_nb_col=df_mp_prem_nb_col, \n",
    "        return_SNs_col=None, #Not grabbing SNs\n",
    "        return_PNs_col=return_prem_nbs_col, \n",
    "        assert_all_trsf_pole_nbs_found=assert_all_trsf_pole_nbs_found, \n",
    "        mp_df=df_mp_curr, \n",
    "        return_mp_df_also=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Join together time_infos_df and PNs_for_xfmrs\n",
    "    #-----\n",
    "    time_infos_df = merge_rcpo_and_df(\n",
    "        rcpo_df=time_infos_df, \n",
    "        df_2=PNs_for_xfmrs, \n",
    "        rcpo_df_on=time_infos_to_PNs,\n",
    "        df_2_on=PNs_to_time_infos, \n",
    "        how=how\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    # Only reason for making dict is to ensure trsf_pole_nbs are not repeated \n",
    "    active_SNs_in_xfmrs_dfs_dict = {}\n",
    "    if output_trsf_pole_nb_col is None:\n",
    "        output_trsf_pole_nb_col='trsf_pole_nb'\n",
    "    for trsf_pole_nb in trsf_pole_nbs:\n",
    "        # active_SNs_df_i will have indices equal to premise numbers and value equal to lists\n",
    "        #   of active SNs for each PN\n",
    "        PNs_i=time_infos_df.loc[trsf_pole_nb, return_prem_nbs_col]\n",
    "        dt_0_i=time_infos_df.loc[trsf_pole_nb, t_min_col]\n",
    "        dt_1_i=time_infos_df.loc[trsf_pole_nb, t_max_col]\n",
    "        #-----\n",
    "        # See NOTEs above regarding t_min/t_max being empty\n",
    "        # In such a case, it is simply impossibe (with the summary files currently generated) to access\n",
    "        #   the date over which the data would have been run, if any events existed.\n",
    "        #   In future versions, this information will be included in the summary files!\n",
    "        # I don't want to completely exclude these (by e.g., setting dt_0_i=pd.Timestamp.min and \n",
    "        #   dt_1_i=pd.Timestamp.max), so I will simply include the meters which are active TODAY.\n",
    "        # This obviously is not correct, but this occurrence is rare (only happening when every single meter\n",
    "        #   on a transformer had no events during the time period) and this crude approximation will be fine.\n",
    "        if Utilities.is_object_one_of_types(dt_0_i, [list, np.ndarray]):\n",
    "            assert(len(dt_0_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            assert(Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]) and len(dt_1_i)==0)\n",
    "            dt_0_i=pd.Timestamp.today()\n",
    "        if Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]):\n",
    "            assert(len(dt_1_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            # But, dt_0_i changed already above, so must check time_infos_df.loc[trsf_pole_nb, t_min_col] instead!\n",
    "            assert(Utilities.is_object_one_of_types(time_infos_df.loc[trsf_pole_nb, t_min_col], [list, np.ndarray]) and \n",
    "                   len(time_infos_df.loc[trsf_pole_nb, t_min_col])==0)\n",
    "            dt_1_i=pd.Timestamp.today()\n",
    "        active_SNs_df_i = MeterPremise.get_active_SNs_for_PNs_at_datetime_interval(\n",
    "            PNs=PNs_i,\n",
    "            df_mp_curr=df_mp_curr, \n",
    "            df_mp_hist=df_mp_hist, \n",
    "            dt_0=dt_0_i,\n",
    "            dt_1=dt_1_i,\n",
    "            output_index=None,\n",
    "            output_groupby=[df_mp_prem_nb_col], \n",
    "            include_prems_wo_active_SNs_when_groupby=True, \n",
    "            assert_all_PNs_found=False\n",
    "        )\n",
    "        active_SNs_df_i=active_SNs_df_i.reset_index()\n",
    "        if active_SNs_df_i.shape[0]==0:\n",
    "            active_SNs_df_i[df_mp_prem_nb_col] = np.nan\n",
    "            active_SNs_df_i[df_mp_serial_number_col] = [[]] \n",
    "            active_SNs_df_i[output_trsf_pole_nb_col] = trsf_pole_nb\n",
    "            active_SNs_df_i = active_SNs_df_i.set_index(output_trsf_pole_nb_col)\n",
    "        else:\n",
    "            active_SNs_df_i[output_trsf_pole_nb_col] = trsf_pole_nb\n",
    "            active_SNs_df_i = active_SNs_df_i.explode(df_mp_serial_number_col)\n",
    "            active_SNs_df_i = Utilities_df.consolidate_df(\n",
    "                df=active_SNs_df_i, \n",
    "                groupby_cols=[output_trsf_pole_nb_col], \n",
    "                cols_shared_by_group=None, \n",
    "                cols_to_collect_in_lists=[df_mp_serial_number_col, df_mp_prem_nb_col], \n",
    "                include_groupby_cols_in_output_cols=False, \n",
    "                allow_duplicates_in_lists=False, \n",
    "                recover_uniqueness_violators=True, \n",
    "                rename_cols=None, \n",
    "                verbose=False\n",
    "            )\n",
    "        assert(trsf_pole_nb not in active_SNs_in_xfmrs_dfs_dict)\n",
    "        active_SNs_in_xfmrs_dfs_dict[trsf_pole_nb] = active_SNs_df_i\n",
    "    #-------------------------\n",
    "    active_SNs_df = pd.concat(list(active_SNs_in_xfmrs_dfs_dict.values()))\n",
    "    #-------------------------\n",
    "    # Change [nan] entries to []\n",
    "    found_nans_srs = active_SNs_df[df_mp_serial_number_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_serial_number_col] = [[]]\n",
    "    #-----\n",
    "    found_nans_srs = active_SNs_df[df_mp_prem_nb_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_prem_nb_col] = [[]]\n",
    "    #-------------------------\n",
    "    active_SNs_df = active_SNs_df.rename(columns={\n",
    "        df_mp_prem_nb_col:return_prem_nbs_col, \n",
    "        df_mp_serial_number_col:return_SNs_col\n",
    "    })\n",
    "    #-------------------------\n",
    "    return active_SNs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces get_active_SNs_for_xfmrs_OLD, but should probably build get_active_SNs_for_xfmrs\n",
    "#  which accepts a list of trsf_pole_nbs instead of rcpo_df, which this function can use\n",
    "def get_active_SNs_for_xfmrs_in_rcpo_df(\n",
    "    rcpo_df, \n",
    "    trsf_pole_nbs_loc, \n",
    "    df_mp_curr, \n",
    "    df_mp_hist,\n",
    "    time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')], \n",
    "    time_infos_to_rcpo_df_on = ['index'], \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')], \n",
    "    PNs_to_rcpo_df_on = ['index'], \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Difficulty is that default.meter_premise_hist does not have trsf_pole_nb field.\n",
    "    Therefore, one must use default.meter_premise to find the premise numbers for xfrms in trsf_pole_nbs,\n",
    "      then use those PNs to select the correct entries from default.meter_premise_hist.\n",
    "    The trsf_pole_nbs should be contained in rcpo_df, and will be found using the trsf_pole_nbs_loc\n",
    "      parameter described below.\n",
    "      \n",
    "    trsf_pole_nbs_loc:\n",
    "        Directs where the transformer pole numbers are located\n",
    "        This should identify an index (w/ level)\n",
    "        Set equal to 'index' for normal DFs, or when trsf_pole_nbs are in level 0 of index.\n",
    "        For a DF with MultiIndex index, there are two options:\n",
    "            i.  Set equal to f'index_{idx_level}' for a DF with MutliIndex index, where idx_level\n",
    "                is an int identifying the level in which the trsf_pole_nbs reside\n",
    "            ii. Set equal to the tuple ('index', trsf_pole_nbs_idx_name), where trsf_pole_nbs_idx_name is\n",
    "            the name of the index level in which the trsf_pole_nbs reside.\n",
    "\n",
    "    If df_mp_curr OR df_mp_hist is not supplied, both will be built!\n",
    "    \n",
    "    addtnl_mp_df_curr_cols/addtnl_mp_df_hist_cols:\n",
    "      Only used when df_mp_curr/df_mp_hist not supplied and therefore need to be built\n",
    "      \n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    assert(t_min_col in time_infos_df.columns and \n",
    "           t_max_col in time_infos_df.columns)\n",
    "    time_infos_df = time_infos_df[[t_min_col, t_max_col]]\n",
    "    #--------------------------------------------------\n",
    "    # trsf_pole_nbs_loc can be a string or tuple/list\n",
    "    # First, find trsf_pole_nbs and trsf_pole_nbs_idx_lvl\n",
    "    assert(Utilities.is_object_one_of_types(trsf_pole_nbs_loc, [str, list, tuple]))\n",
    "    if isinstance(trsf_pole_nbs_loc, str):\n",
    "        assert(trsf_pole_nbs_loc.startswith('index'))\n",
    "        if trsf_pole_nbs_loc=='index':\n",
    "            trsf_pole_nbs_idx_lvl = 0\n",
    "        else:\n",
    "            trsf_pole_nbs_idx_lvl = re.findall('index_(\\d*)', trsf_pole_nbs_loc)\n",
    "            assert(len(trsf_pole_nbs_idx_lvl)==1)\n",
    "            trsf_pole_nbs_idx_lvl=trsf_pole_nbs_idx_lvl[0]\n",
    "            trsf_pole_nbs_idx_lvl=int(trsf_pole_nbs_idx_lvl)\n",
    "    else:\n",
    "        assert(len(trsf_pole_nbs_loc)==2)\n",
    "        assert(trsf_pole_nbs_loc[0]=='index')\n",
    "        assert(trsf_pole_nbs_loc[1] in rcpo_df.index.names)\n",
    "        trsf_pole_nbs_idx_lvl = rcpo_df.index.names.index(trsf_pole_nbs_loc[1])\n",
    "        #---------------\n",
    "        assert(trsf_pole_nbs_idx_lvl < rcpo_df.index.nlevels)\n",
    "        trsf_pole_nbs = rcpo_df.index.get_level_values(trsf_pole_nbs_idx_lvl).tolist()\n",
    "    #--------------------------------------------------\n",
    "    #-------------------------\n",
    "    necessary_mp_cols = [df_mp_serial_number_col, df_mp_prem_nb_col, df_mp_install_time_col, df_mp_removal_time_col]\n",
    "    #-------------------------\n",
    "    if df_mp_curr is None or df_mp_hist is None:\n",
    "        mp_df_curr_hist = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "            trsf_pole_nbs, \n",
    "            join_curr_hist=False, \n",
    "            addtnl_mp_df_curr_cols=addtnl_mp_df_curr_cols, \n",
    "            addtnl_mp_df_hist_cols=addtnl_mp_df_hist_cols, \n",
    "            df_mp_serial_number_col=df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col=df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col=df_mp_install_time_col, \n",
    "            df_mp_removal_time_col=df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col=df_mp_trsf_pole_nb_col\n",
    "        )\n",
    "        df_mp_curr = mp_df_curr_hist['mp_df_curr']\n",
    "        df_mp_hist = mp_df_curr_hist['mp_df_hist']\n",
    "    #-------------------------\n",
    "    # At a bare minimum, df_mp_curr and df_mp_hist must both have the following columns:\n",
    "    #   necessary_mp_cols = ['mfr_devc_ser_nbr', 'prem_nb', 'inst_ts', 'rmvl_ts']\n",
    "    assert(all([x in df_mp_curr.columns for x in necessary_mp_cols+[df_mp_trsf_pole_nb_col]]))\n",
    "    assert(all([x in df_mp_hist.columns for x in necessary_mp_cols]))\n",
    "    #-------------------------\n",
    "    # PNs_for_xfmrs is a DF with trsf_pole_nbs indices and elements which are lists of PNs for each xfmr\n",
    "    PNs_for_xfmrs = MeterPremise.get_SNs_andor_PNs_for_xfmrs(\n",
    "        trsf_pole_nbs=trsf_pole_nbs, \n",
    "        include_SNs=False,\n",
    "        include_PNs=True,\n",
    "        trsf_pole_nb_col=df_mp_trsf_pole_nb_col, \n",
    "        serial_number_col=df_mp_serial_number_col, \n",
    "        prem_nb_col=df_mp_prem_nb_col, \n",
    "        return_SNs_col=None, #Not grabbing SNs\n",
    "        return_PNs_col=return_prem_nbs_col, \n",
    "        assert_all_trsf_pole_nbs_found=assert_all_trsf_pole_nbs_found, \n",
    "        mp_df=df_mp_curr, \n",
    "        return_mp_df_also=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Join together rcpo_df, time_infos_df and PNs_for_xfmrs\n",
    "    rcpo_df = merge_rcpo_and_df(\n",
    "        rcpo_df=rcpo_df, \n",
    "        df_2=time_infos_df, \n",
    "        rcpo_df_on=rcpo_df_to_time_infos_on,\n",
    "        df_2_on=time_infos_to_rcpo_df_on, \n",
    "        how=how\n",
    "    )\n",
    "    #-----\n",
    "    rcpo_df = merge_rcpo_and_df(\n",
    "        rcpo_df=rcpo_df, \n",
    "        df_2=PNs_for_xfmrs, \n",
    "        rcpo_df_on=rcpo_df_to_PNs_on,\n",
    "        df_2_on=PNs_to_rcpo_df_on, \n",
    "        how=how\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    # Only reason for making dict is to ensure trsf_pole_nbs are not repeated \n",
    "    active_SNs_in_xfmrs_dfs_dict = {}\n",
    "\n",
    "    rcpo_idx_names = list(rcpo_df.index.names)\n",
    "    assert(not any([x is None for x in rcpo_idx_names]))\n",
    "    for idx_i, row_i in rcpo_df.iterrows():\n",
    "        # active_SNs_df_i will have indices equal to premise numbers and value equal to lists\n",
    "        #   of active SNs for each PN\n",
    "        # Purpose of making idx_names_w_vals a list of tuples, instead of a dict, is to ensure the correct order is maintained\n",
    "        #   Dicts usually return the correct order, but this is not guaranteed\n",
    "        if len(rcpo_idx_names)==1:\n",
    "            assert(rcpo_df.index.nlevels==1)\n",
    "            idx_names_w_vals = [(rcpo_idx_names[0], idx_i)]\n",
    "        else:\n",
    "            idx_names_w_vals = [((rcpo_idx_names[i] if i!=trsf_pole_nbs_idx_lvl else df_mp_trsf_pole_nb_col), idx_i[i]) \n",
    "                                for i in range(len(idx_i))]\n",
    "        PNs_i=row_i[return_prem_nbs_col]\n",
    "        dt_0_i=row_i[t_min_col]\n",
    "        dt_1_i=row_i[t_max_col]\n",
    "        #-----\n",
    "        # See NOTEs above regarding t_min/t_max being empty\n",
    "        # In such a case, it is simply impossibe (with the summary files currently generated) to access\n",
    "        #   the date over which the data would have been run, if any events existed.\n",
    "        #   In future versions, this information will be included in the summary files!\n",
    "        # I don't want to completely exclude these (by e.g., setting dt_0_i=pd.Timestamp.min and \n",
    "        #   dt_1_i=pd.Timestamp.max), so I will simply include the meters which are active TODAY.\n",
    "        # This obviously is not correct, but this occurrence is rare (only happening when every single meter\n",
    "        #   on a transformer had no events during the time period) and this crude approximation will be fine.\n",
    "        if Utilities.is_object_one_of_types(dt_0_i, [list, np.ndarray]):\n",
    "            assert(len(dt_0_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            assert(Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]) and len(dt_1_i)==0)\n",
    "            dt_0_i=pd.Timestamp.today()\n",
    "        if Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]):\n",
    "            assert(len(dt_1_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            # But, dt_0_i changed already above, so must check row_i[t_min_col] instead!\n",
    "            assert(Utilities.is_object_one_of_types(row_i[t_min_col], [list, np.ndarray]) and len(row_i[t_min_col])==0)\n",
    "            dt_1_i=pd.Timestamp.today()\n",
    "        active_SNs_df_i = MeterPremise.get_active_SNs_for_PNs_at_datetime_interval(\n",
    "            PNs=PNs_i,\n",
    "            df_mp_curr=df_mp_curr, \n",
    "            df_mp_hist=df_mp_hist, \n",
    "            dt_0=dt_0_i,\n",
    "            dt_1=dt_1_i,\n",
    "            output_index=None,\n",
    "            output_groupby=[df_mp_prem_nb_col], \n",
    "            include_prems_wo_active_SNs_when_groupby=True, \n",
    "            assert_all_PNs_found=False\n",
    "        )\n",
    "        active_SNs_df_i=active_SNs_df_i.reset_index()\n",
    "        if active_SNs_df_i.shape[0]==0:\n",
    "            active_SNs_df_i[df_mp_prem_nb_col] = np.nan\n",
    "            active_SNs_df_i[df_mp_serial_number_col] = [[]] \n",
    "            for name,val in idx_names_w_vals:\n",
    "                active_SNs_df_i[name] = val\n",
    "            active_SNs_df_i = active_SNs_df_i.set_index([x[0] for x in idx_names_w_vals])\n",
    "        else:\n",
    "            for name,val in idx_names_w_vals:\n",
    "                active_SNs_df_i[name] = val\n",
    "            active_SNs_df_i = active_SNs_df_i.explode(df_mp_serial_number_col)\n",
    "            active_SNs_df_i = Utilities_df.consolidate_df(\n",
    "                df=active_SNs_df_i, \n",
    "                groupby_cols=[x[0] for x in idx_names_w_vals], \n",
    "                cols_shared_by_group=None, \n",
    "                cols_to_collect_in_lists=[df_mp_serial_number_col, df_mp_prem_nb_col], \n",
    "                include_groupby_cols_in_output_cols=False, \n",
    "                allow_duplicates_in_lists=False, \n",
    "                recover_uniqueness_violators=True, \n",
    "                rename_cols=None, \n",
    "                verbose=False\n",
    "            )\n",
    "        assert(idx_i not in active_SNs_in_xfmrs_dfs_dict)\n",
    "        active_SNs_in_xfmrs_dfs_dict[idx_i] = active_SNs_df_i\n",
    "    #-------------------------\n",
    "    active_SNs_df = pd.concat(list(active_SNs_in_xfmrs_dfs_dict.values()))\n",
    "    #-------------------------\n",
    "    # Change [nan] entries to []\n",
    "    found_nans_srs = active_SNs_df[df_mp_serial_number_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_serial_number_col] = [[]]\n",
    "    #-----\n",
    "    found_nans_srs = active_SNs_df[df_mp_prem_nb_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_prem_nb_col] = [[]]\n",
    "    #-------------------------\n",
    "    active_SNs_df = active_SNs_df.rename(columns={\n",
    "        df_mp_prem_nb_col:return_prem_nbs_col, \n",
    "        df_mp_serial_number_col:return_SNs_col\n",
    "    })\n",
    "    #-------------------------\n",
    "    return active_SNs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd52d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces get_active_SNs_for_xfmrs_OLD, but should probably build get_active_SNs_for_xfmrs\n",
    "#  which accepts a list of trsf_pole_nbs instead of rcpo_df, which this function can use\n",
    "def get_active_SNs_for_xfmrs_in_rcpo_df_v2(\n",
    "    rcpo_df, \n",
    "    trsf_pole_nbs_loc, \n",
    "    df_mp_curr, \n",
    "    df_mp_hist,\n",
    "    time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')], \n",
    "    time_infos_to_rcpo_df_on = ['index'], \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')], \n",
    "    PNs_to_rcpo_df_on = ['index'], \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    "):\n",
    "    r\"\"\"\n",
    "    Difficulty is that default.meter_premise_hist does not have trsf_pole_nb field.\n",
    "    Therefore, one must use default.meter_premise to find the premise numbers for xfrms in trsf_pole_nbs,\n",
    "      then use those PNs to select the correct entries from default.meter_premise_hist.\n",
    "    The trsf_pole_nbs should be contained in rcpo_df, and will be found using the trsf_pole_nbs_loc\n",
    "      parameter described below.\n",
    "      \n",
    "    trsf_pole_nbs_loc:\n",
    "        Directs where the transformer pole numbers are located\n",
    "        This should identify an index (w/ level)\n",
    "        Set equal to 'index' for normal DFs, or when trsf_pole_nbs are in level 0 of index.\n",
    "        For a DF with MultiIndex index, there are two options:\n",
    "            i.  Set equal to f'index_{idx_level}' for a DF with MutliIndex index, where idx_level\n",
    "                is an int identifying the level in which the trsf_pole_nbs reside\n",
    "            ii. Set equal to the tuple ('index', trsf_pole_nbs_idx_name), where trsf_pole_nbs_idx_name is\n",
    "            the name of the index level in which the trsf_pole_nbs reside.\n",
    "\n",
    "    If df_mp_curr OR df_mp_hist is not supplied, both will be built!\n",
    "    \n",
    "    addtnl_mp_df_curr_cols/addtnl_mp_df_hist_cols:\n",
    "      Only used when df_mp_curr/df_mp_hist not supplied and therefore need to be built\n",
    "      \n",
    "    \"\"\"\n",
    "    #--------------------------------------------------\n",
    "    assert(t_min_col in time_infos_df.columns and \n",
    "           t_max_col in time_infos_df.columns)\n",
    "    time_infos_df = time_infos_df[[t_min_col, t_max_col]]\n",
    "    #--------------------------------------------------\n",
    "    # trsf_pole_nbs_loc can be a string or tuple/list\n",
    "    # First, find trsf_pole_nbs and trsf_pole_nbs_idx_lvl\n",
    "    assert(Utilities.is_object_one_of_types(trsf_pole_nbs_loc, [str, list, tuple]))\n",
    "    if isinstance(trsf_pole_nbs_loc, str):\n",
    "        assert(trsf_pole_nbs_loc.startswith('index'))\n",
    "        if trsf_pole_nbs_loc=='index':\n",
    "            trsf_pole_nbs_idx_lvl = 0\n",
    "        else:\n",
    "            trsf_pole_nbs_idx_lvl = re.findall('index_(\\d*)', trsf_pole_nbs_loc)\n",
    "            assert(len(trsf_pole_nbs_idx_lvl)==1)\n",
    "            trsf_pole_nbs_idx_lvl=trsf_pole_nbs_idx_lvl[0]\n",
    "            trsf_pole_nbs_idx_lvl=int(trsf_pole_nbs_idx_lvl)\n",
    "    else:\n",
    "        assert(len(trsf_pole_nbs_loc)==2)\n",
    "        assert(trsf_pole_nbs_loc[0]=='index')\n",
    "        assert(trsf_pole_nbs_loc[1] in rcpo_df.index.names)\n",
    "        trsf_pole_nbs_idx_lvl = rcpo_df.index.names.index(trsf_pole_nbs_loc[1])\n",
    "        #---------------\n",
    "        assert(trsf_pole_nbs_idx_lvl < rcpo_df.index.nlevels)\n",
    "        trsf_pole_nbs = rcpo_df.index.get_level_values(trsf_pole_nbs_idx_lvl).tolist()\n",
    "    #--------------------------------------------------\n",
    "    #-------------------------\n",
    "    necessary_mp_cols = [df_mp_serial_number_col, df_mp_prem_nb_col, df_mp_install_time_col, df_mp_removal_time_col]\n",
    "    #-------------------------\n",
    "    if df_mp_curr is None or df_mp_hist is None:\n",
    "        mp_df_curr_hist = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "            trsf_pole_nbs, \n",
    "            join_curr_hist=False, \n",
    "            addtnl_mp_df_curr_cols=addtnl_mp_df_curr_cols, \n",
    "            addtnl_mp_df_hist_cols=addtnl_mp_df_hist_cols, \n",
    "            df_mp_serial_number_col=df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col=df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col=df_mp_install_time_col, \n",
    "            df_mp_removal_time_col=df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col=df_mp_trsf_pole_nb_col\n",
    "        )\n",
    "        df_mp_curr = mp_df_curr_hist['mp_df_curr']\n",
    "        df_mp_hist = mp_df_curr_hist['mp_df_hist']\n",
    "    #-------------------------\n",
    "    # At a bare minimum, df_mp_curr and df_mp_hist must both have the following columns:\n",
    "    #   necessary_mp_cols = ['mfr_devc_ser_nbr', 'prem_nb', 'inst_ts', 'rmvl_ts']\n",
    "    assert(all([x in df_mp_curr.columns for x in necessary_mp_cols+[df_mp_trsf_pole_nb_col]]))\n",
    "    assert(all([x in df_mp_hist.columns for x in necessary_mp_cols]))\n",
    "    #-------------------------\n",
    "    # PNs_for_xfmrs is a DF with trsf_pole_nbs indices and elements which are lists of PNs for each xfmr\n",
    "    PNs_for_xfmrs = MeterPremise.get_SNs_andor_PNs_for_xfmrs(\n",
    "        trsf_pole_nbs=trsf_pole_nbs, \n",
    "        include_SNs=False,\n",
    "        include_PNs=True,\n",
    "        trsf_pole_nb_col=df_mp_trsf_pole_nb_col, \n",
    "        serial_number_col=df_mp_serial_number_col, \n",
    "        prem_nb_col=df_mp_prem_nb_col, \n",
    "        return_SNs_col=None, #Not grabbing SNs\n",
    "        return_PNs_col=return_prem_nbs_col, \n",
    "        assert_all_trsf_pole_nbs_found=assert_all_trsf_pole_nbs_found, \n",
    "        mp_df=df_mp_curr, \n",
    "        return_mp_df_also=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Join together rcpo_df, time_infos_df and PNs_for_xfmrs\n",
    "    rcpo_df = merge_rcpo_and_df(\n",
    "        rcpo_df=rcpo_df, \n",
    "        df_2=time_infos_df, \n",
    "        rcpo_df_on=rcpo_df_to_time_infos_on,\n",
    "        df_2_on=time_infos_to_rcpo_df_on, \n",
    "        how=how\n",
    "    )\n",
    "    #-----\n",
    "    rcpo_df = merge_rcpo_and_df(\n",
    "        rcpo_df=rcpo_df, \n",
    "        df_2=PNs_for_xfmrs, \n",
    "        rcpo_df_on=rcpo_df_to_PNs_on,\n",
    "        df_2_on=PNs_to_rcpo_df_on, \n",
    "        how=how\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    # Only reason for making dict is to ensure trsf_pole_nbs are not repeated \n",
    "    active_SNs_in_xfmrs_dfs_dict = {}\n",
    "\n",
    "    rcpo_idx_names = list(rcpo_df.index.names)\n",
    "    assert(not any([x is None for x in rcpo_idx_names]))\n",
    "    for idx_i, row_i in rcpo_df.iterrows():\n",
    "        # active_SNs_df_i will have indices equal to premise numbers and value equal to lists\n",
    "        #   of active SNs for each PN\n",
    "        # Purpose of making idx_names_w_vals a list of tuples, instead of a dict, is to ensure the correct order is maintained\n",
    "        #   Dicts usually return the correct order, but this is not guaranteed\n",
    "        if len(rcpo_idx_names)==1:\n",
    "            assert(rcpo_df.index.nlevels==1)\n",
    "            idx_names_w_vals = [(rcpo_idx_names[0], idx_i)]\n",
    "        else:\n",
    "            idx_names_w_vals = [((rcpo_idx_names[i] if i!=trsf_pole_nbs_idx_lvl else df_mp_trsf_pole_nb_col), idx_i[i]) \n",
    "                                for i in range(len(idx_i))]\n",
    "        PNs_i=row_i[return_prem_nbs_col]\n",
    "        dt_0_i=row_i[t_min_col]\n",
    "        dt_1_i=row_i[t_max_col]\n",
    "        #-----\n",
    "        # See NOTEs above regarding t_min/t_max being empty\n",
    "        # In such a case, it is simply impossibe (with the summary files currently generated) to access\n",
    "        #   the date over which the data would have been run, if any events existed.\n",
    "        #   In future versions, this information will be included in the summary files!\n",
    "        # I don't want to completely exclude these (by e.g., setting dt_0_i=pd.Timestamp.min and \n",
    "        #   dt_1_i=pd.Timestamp.max), so I will simply include the meters which are active TODAY.\n",
    "        # This obviously is not correct, but this occurrence is rare (only happening when every single meter\n",
    "        #   on a transformer had no events during the time period) and this crude approximation will be fine.\n",
    "        if Utilities.is_object_one_of_types(dt_0_i, [list, np.ndarray]):\n",
    "            assert(len(dt_0_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            assert(Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]) and len(dt_1_i)==0)\n",
    "            dt_0_i=pd.Timestamp.today()\n",
    "        if Utilities.is_object_one_of_types(dt_1_i, [list, np.ndarray]):\n",
    "            assert(len(dt_1_i)==0)\n",
    "            # I believe if this happens for one it should happen for both...\n",
    "            # But, dt_0_i changed already above, so must check row_i[t_min_col] instead!\n",
    "            assert(Utilities.is_object_one_of_types(row_i[t_min_col], [list, np.ndarray]) and len(row_i[t_min_col])==0)\n",
    "            dt_1_i=pd.Timestamp.today()\n",
    "        active_SNs_df_i = MeterPremise.get_active_SNs_for_PNs_at_datetime_interval(\n",
    "            PNs=PNs_i,\n",
    "            df_mp_curr=df_mp_curr, \n",
    "            df_mp_hist=df_mp_hist, \n",
    "            dt_0=dt_0_i,\n",
    "            dt_1=dt_1_i,\n",
    "            output_index=None,\n",
    "            output_groupby=[df_mp_prem_nb_col], \n",
    "            include_prems_wo_active_SNs_when_groupby=True, \n",
    "            assert_all_PNs_found=False\n",
    "        )\n",
    "        active_SNs_df_i=active_SNs_df_i.reset_index()\n",
    "        if active_SNs_df_i.shape[0]==0:\n",
    "            active_SNs_df_i[df_mp_prem_nb_col] = np.nan\n",
    "            active_SNs_df_i[df_mp_serial_number_col] = [[]] \n",
    "        for name,val in idx_names_w_vals:\n",
    "            active_SNs_df_i[name] = val\n",
    "        active_SNs_df_i = active_SNs_df_i.explode(df_mp_serial_number_col)\n",
    "        assert(idx_i not in active_SNs_in_xfmrs_dfs_dict)\n",
    "        active_SNs_in_xfmrs_dfs_dict[idx_i] = active_SNs_df_i\n",
    "    #-------------------------\n",
    "    active_SNs_df = pd.concat(list(active_SNs_in_xfmrs_dfs_dict.values()))\n",
    "    #-------------------------\n",
    "    active_SNs_df = Utilities_df.consolidate_df(\n",
    "        df=active_SNs_df, \n",
    "        groupby_cols=[x[0] for x in idx_names_w_vals], \n",
    "        cols_shared_by_group=None, \n",
    "        cols_to_collect_in_lists=[df_mp_serial_number_col, df_mp_prem_nb_col], \n",
    "        include_groupby_cols_in_output_cols=False, \n",
    "        allow_duplicates_in_lists=False, \n",
    "        recover_uniqueness_violators=True, \n",
    "        rename_cols=None, \n",
    "        verbose=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Change [nan] entries to []\n",
    "    found_nans_srs = active_SNs_df[df_mp_serial_number_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_serial_number_col] = [[]]\n",
    "    #-----\n",
    "    found_nans_srs = active_SNs_df[df_mp_prem_nb_col].apply(lambda x: len([ix for ix in x if not pd.isna(ix)]))==0\n",
    "    if found_nans_srs.sum()>0:\n",
    "        active_SNs_df.loc[found_nans_srs, df_mp_prem_nb_col] = [[]]\n",
    "    #-------------------------\n",
    "    active_SNs_df = active_SNs_df.rename(columns={\n",
    "        df_mp_prem_nb_col:return_prem_nbs_col, \n",
    "        df_mp_serial_number_col:return_SNs_col\n",
    "    })\n",
    "    #-------------------------\n",
    "    return active_SNs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces add_xfmr_active_SNs_to_rcpo_df_OLD\n",
    "def add_xfmr_active_SNs_to_rcpo_df(\n",
    "    rcpo_df, \n",
    "    trsf_pole_nbs_loc, \n",
    "    set_xfmr_nSNs=True, \n",
    "    include_active_xfmr_PNs=False, \n",
    "    df_mp_curr=None,\n",
    "    df_mp_hist=None, \n",
    "    time_infos_df=None, \n",
    "    rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')], \n",
    "    time_infos_to_rcpo_df_on = ['index'], \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')], \n",
    "    PNs_to_rcpo_df_on = ['index'], \n",
    "    addtnl_get_active_SNs_for_xfmrs_kwargs=None, \n",
    "    xfmr_SNs_col='_xfmr_SNs', \n",
    "    xfmr_nSNs_col='_xfmr_nSNs', \n",
    "    xfmr_PNs_col='_xfmr_PNs', \n",
    "    xfmr_nPNs_col='_xfmr_nPNs', \n",
    "):\n",
    "    r\"\"\"\n",
    "    NOTE: If include_active_xfmr_PNs is True, this column (named xfmr_PNs_col='_xfmr_SNs') should be \n",
    "          equal to the PNs already in rcpo_df!\n",
    "    NOTE: xfmr_SNs_col, xfmr_nSNs_col, xfmr_PNs_col, and xfmr_nPNs_col should all be strings, not tuples.\n",
    "          If column is multiindex, the level_0 value will be handled below.\n",
    "          \n",
    "    NOTE: If any of xfmr_SNs_col, xfmr_nSNs_col, xfmr_PNs_col, and xfmr_nPNs_col are already contained in \n",
    "          rcpo_df, they will be replaced.  This is needed so that the merge operation does not come back with _x and _y\n",
    "          values.  So, one should make sure this function call is truly needed, as grabbing the serial numbers for the\n",
    "          outages typically takes a couple/few minutes.\n",
    "          \n",
    "    NOTE: To make things run faster, the user can supply df_mp_curr and df_mp_hist.  These will be included in \n",
    "          get_active_SNs_for_xfmrs_kwargs.\n",
    "          NOTE: If df_mp_curr/df_mp_hist is also supplied in addtnl_get_active_SNs_for_xfmrs_kwargs,\n",
    "                that/those in addtnl_get_active_SNs_for_xfmrs_kwargs will ultimately be used (not the\n",
    "                explicity df_mp_hist/curr in the function arguments!)\n",
    "          CAREFUL: If one does supple df_mp_curr/hist, one must be certain these DFs contain all necessary elements!\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    get_active_SNs_for_xfmrs_kwargs = dict(\n",
    "        rcpo_df=rcpo_df, \n",
    "        trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "        df_mp_curr=df_mp_curr, \n",
    "        df_mp_hist=df_mp_hist, \n",
    "        time_infos_df=time_infos_df, \n",
    "        rcpo_df_to_time_infos_on=rcpo_df_to_time_infos_on, \n",
    "        time_infos_to_rcpo_df_on=time_infos_to_rcpo_df_on, \n",
    "        how=how, \n",
    "        rcpo_df_to_PNs_on=rcpo_df_to_PNs_on, \n",
    "        PNs_to_rcpo_df_on=PNs_to_rcpo_df_on, \n",
    "        return_prem_nbs_col=xfmr_PNs_col, \n",
    "        return_SNs_col=xfmr_SNs_col\n",
    "    )\n",
    "    if addtnl_get_active_SNs_for_xfmrs_kwargs is not None:\n",
    "        get_active_SNs_for_xfmrs_kwargs = {**get_active_SNs_for_xfmrs_kwargs, \n",
    "                                           **addtnl_get_active_SNs_for_xfmrs_kwargs}\n",
    "    active_SNs_df = get_active_SNs_for_xfmrs_in_rcpo_df(**get_active_SNs_for_xfmrs_kwargs)\n",
    "    assert(isinstance(active_SNs_df, pd.DataFrame))\n",
    "    #-------------------------\n",
    "    # Assert below might be too strong here...\n",
    "    assert(sorted(rcpo_df.index.unique().tolist())==sorted(active_SNs_df.index.unique().tolist()))\n",
    "    assert(rcpo_df.columns.nlevels<=2)\n",
    "    if rcpo_df.columns.nlevels==1:\n",
    "        #----------\n",
    "        # See note above about columns being replaced/dropped\n",
    "        cols_to_drop = [x for x in rcpo_df.columns if x in active_SNs_df.columns]\n",
    "        if len(cols_to_drop)>0:\n",
    "            rcpo_df = rcpo_df.drop(columns=cols_to_drop)\n",
    "        #----------\n",
    "        rcpo_df = rcpo_df.merge(active_SNs_df, left_index=True, right_index=True)\n",
    "        #----------\n",
    "        if set_xfmr_nSNs:\n",
    "            rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, xfmr_SNs_col, xfmr_nSNs_col)\n",
    "            if include_active_xfmr_PNs:\n",
    "                rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, xfmr_PNs_col, xfmr_nPNs_col)\n",
    "    else:\n",
    "        # Currently, only expecting raw and/or norm.  No problem to allow more, but for now keep this to alert \n",
    "        # of anything unexpected\n",
    "        assert(rcpo_df.columns.get_level_values(0).nunique()<=2)\n",
    "        for i,level_0_val in enumerate(rcpo_df.columns.get_level_values(0).unique()):\n",
    "            if i==0:\n",
    "                active_SNs_df.columns = pd.MultiIndex.from_product([[level_0_val], active_SNs_df.columns])\n",
    "            else:\n",
    "                active_SNs_df.columns = active_SNs_df.columns.set_levels([level_0_val], level=0)\n",
    "            #----------\n",
    "            # See note above about columns being replaced/dropped\n",
    "            cols_to_drop = [x for x in rcpo_df.columns if x in active_SNs_df.columns]\n",
    "            if len(cols_to_drop)>0:\n",
    "                rcpo_df = rcpo_df.drop(columns=cols_to_drop)\n",
    "            #----------\n",
    "            rcpo_df = rcpo_df.merge(active_SNs_df, left_index=True, right_index=True)\n",
    "            #----------\n",
    "            if set_xfmr_nSNs:\n",
    "                rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, (level_0_val, xfmr_SNs_col), (level_0_val, xfmr_nSNs_col))\n",
    "                if include_active_xfmr_PNs:\n",
    "                    rcpo_df = MECPODf.set_nSNs_from_SNs_in_rcpo_df(rcpo_df, (level_0_val, xfmr_PNs_col), (level_0_val, xfmr_nPNs_col))\n",
    "    #-------------------------\n",
    "    rcpo_df = rcpo_df.sort_index(axis=1,level=0)\n",
    "    #-------------------------\n",
    "    return rcpo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces build_rcpo_df_norm_by_xfmr_active_nSNs_OLD\n",
    "def build_rcpo_df_norm_by_xfmr_active_nSNs(\n",
    "    rcpo_df_raw, \n",
    "    trsf_pole_nbs_loc, \n",
    "    xfmr_nSNs_col='_xfmr_nSNs', \n",
    "    xfmr_SNs_col='_xfmr_SNs', \n",
    "    other_SNs_col_tags_to_ignore=['_SNs', '_nSNs', '_prem_nbs', '_nprem_nbs', '_xfmr_PNs', '_xfmr_nPNs'], \n",
    "    drop_xfmr_nSNs_eq_0=True, \n",
    "    new_level_0_val='counts_norm_by_xfmr_nSNs', \n",
    "    remove_SNs_cols=False, \n",
    "    df_mp_curr=None,\n",
    "    df_mp_hist=None, \n",
    "    time_infos_df=None,\n",
    "    rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')], \n",
    "    time_infos_to_rcpo_df_on = ['index'], \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')], \n",
    "    PNs_to_rcpo_df_on = ['index'], \n",
    "    addtnl_get_active_SNs_for_xfmrs_kwargs=None\n",
    "):\n",
    "    r\"\"\"\n",
    "    Build rcpo_df normalized by the number of serial numbers in each outage\n",
    "\n",
    "    drop_xfmr_nSNs_eq_0:\n",
    "      It is possible for the number of serial numbers in an outage to be zero!\n",
    "      Premise numbers are always found, but the meter_premise database does not always \n",
    "        contain the premise numbers.\n",
    "      Dividing by zero will make all counts for such an entry equal to NaN or inf.\n",
    "      When drop_xfmr_nSNs_eq_0 is True, such entries will be removed.\n",
    "\n",
    "    NOTE: xfmr_SNs_col and xfmr_nSNs_col should both be strings, not tuples.\n",
    "          If column is MultiIndex, the level_0 value will be handled below.\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    n_counts_col = xfmr_nSNs_col\n",
    "    list_col = xfmr_SNs_col\n",
    "    #-------------------------\n",
    "    # NOTE: MECPODf.add_outage_SNs_to_rcpo_df expects xfmr_SNs_col and xfmr_nSNs_col to be strings, not tuples\n",
    "    #       as it handles the level 0 values if they exist.  So, if tuples, use only highest level values (i.e., level 1)\n",
    "    assert(Utilities.is_object_one_of_types(list_col, [str, tuple]))\n",
    "    assert(Utilities.is_object_one_of_types(n_counts_col, [str, tuple]))\n",
    "    #-----\n",
    "    add_list_col_to_rcpo_df_func = add_xfmr_active_SNs_to_rcpo_df\n",
    "    add_list_col_to_rcpo_df_kwargs = dict(\n",
    "        trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "        set_xfmr_nSNs=True, \n",
    "        include_active_xfmr_PNs=True, \n",
    "        df_mp_curr=df_mp_curr,\n",
    "        df_mp_hist=df_mp_hist, \n",
    "        time_infos_df=time_infos_df, \n",
    "        rcpo_df_to_time_infos_on=rcpo_df_to_time_infos_on, \n",
    "        time_infos_to_rcpo_df_on=time_infos_to_rcpo_df_on, \n",
    "        how=how, \n",
    "        rcpo_df_to_PNs_on=rcpo_df_to_PNs_on, \n",
    "        PNs_to_rcpo_df_on=PNs_to_rcpo_df_on, \n",
    "        addtnl_get_active_SNs_for_xfmrs_kwargs=addtnl_get_active_SNs_for_xfmrs_kwargs, \n",
    "        xfmr_SNs_col='_xfmr_SNs', \n",
    "        xfmr_nSNs_col='_xfmr_nSNs', \n",
    "        xfmr_PNs_col='_xfmr_PNs', \n",
    "        xfmr_nPNs_col='_xfmr_nPNs', \n",
    "    )\n",
    "    #-------------------------\n",
    "    other_col_tags_to_ignore = other_SNs_col_tags_to_ignore\n",
    "    drop_n_counts_eq_0 = drop_xfmr_nSNs_eq_0\n",
    "    new_level_0_val = new_level_0_val\n",
    "    remove_ignored_cols = remove_SNs_cols\n",
    "    #-------------------------\n",
    "    return MECPODf.build_rcpo_df_norm_by_list_counts(\n",
    "        rcpo_df_raw=rcpo_df_raw, \n",
    "        n_counts_col=n_counts_col, \n",
    "        list_col=list_col, \n",
    "        add_list_col_to_rcpo_df_func=add_list_col_to_rcpo_df_func, \n",
    "        add_list_col_to_rcpo_df_kwargs=add_list_col_to_rcpo_df_kwargs, \n",
    "        other_col_tags_to_ignore=other_col_tags_to_ignore, \n",
    "        drop_n_counts_eq_0=drop_n_counts_eq_0, \n",
    "        new_level_0_val=new_level_0_val, \n",
    "        remove_ignored_cols=remove_ignored_cols\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b8e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b84c10",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_testing_data=True\n",
    "fig_num=0\n",
    "\n",
    "dovs_and_end_events_data_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data'\n",
    "if run_testing_data:\n",
    "    dovs_and_end_events_data_dir = os.path.join(dovs_and_end_events_data_dir, r'TESTING_DATASETS')\n",
    "\n",
    "files_dir_outg             = os.path.join(dovs_and_end_events_data_dir, r'EndEvents')\n",
    "files_dir_outg_prim_strict = os.path.join(dovs_and_end_events_data_dir, r'EndEvents_prim_strict')\n",
    "files_dir_no_outg = os.path.join(dovs_and_end_events_data_dir, r'EndEvents_NoOutg')\n",
    "\n",
    "file_path_glob = r'end_events_[0-9]*.csv'\n",
    "file_path_regex = None\n",
    "\n",
    "\n",
    "assert_all_cols_equal=True\n",
    "include_normalize_by_nSNs=True\n",
    "inclue_zero_counts=True\n",
    "return_multiindex_outg_reason=False\n",
    "return_normalized_separately=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4202a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65e7ed8b",
   "metadata": {},
   "source": [
    "## No Outage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO OUTG\n",
    "outg_rec_nb_col='trsf_pole_nb'\n",
    "group_cols='trsf_pole_nb'\n",
    "addtnl_dropna_subset_cols=None\n",
    "\n",
    "prem_nb_col='aep_premise_nb'\n",
    "#-------------------------\n",
    "paths_no_outg = Utilities.find_all_paths(\n",
    "    base_dir=files_dir_no_outg, \n",
    "    glob_pattern=file_path_glob, \n",
    "    regex_pattern=file_path_regex\n",
    ")\n",
    "paths_no_outg = paths_no_outg[0:10]\n",
    "#-------------------------\n",
    "end_events_df_no_outg = GenAn.read_df_from_csv_batch(\n",
    "    paths=paths_no_outg, \n",
    "    cols_and_types_to_convert_dict=None, \n",
    "    to_numeric_errors='coerce', \n",
    "    make_all_columns_lowercase=True, \n",
    "    assert_all_cols_equal=True\n",
    ")\n",
    "#-------------------------\n",
    "if (f'{outg_rec_nb_col}_gpd_for_sql' in end_events_df_no_outg.columns and \n",
    "    outg_rec_nb_col not in end_events_df_no_outg.columns):\n",
    "    end_events_df_no_outg = end_events_df_no_outg.rename(columns={f'{outg_rec_nb_col}_gpd_for_sql':outg_rec_nb_col})\n",
    "assert(outg_rec_nb_col in end_events_df_no_outg.columns)\n",
    "#-------------------------\n",
    "dropna_subset_cols = [outg_rec_nb_col]\n",
    "if addtnl_dropna_subset_cols is not None:\n",
    "    dropna_subset_cols.extend(addtnl_dropna_subset_cols)\n",
    "end_events_df_no_outg = end_events_df_no_outg.dropna(subset=dropna_subset_cols)\n",
    "#-------------------------\n",
    "end_events_df_no_outg = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "    df=end_events_df_no_outg, \n",
    "    patterns_to_replace=patterns_to_replace\n",
    ")\n",
    "#-------------------------\n",
    "rcpo_df_no_outg = AMIEndEvents.get_reason_counts_per_group(\n",
    "    end_events_df_no_outg, \n",
    "    group_cols=group_cols,\n",
    "    group_freq=None, \n",
    "    serial_number_col='serialnumber', \n",
    "    reason_col='reason', \n",
    "    include_normalize_by_nSNs=False, \n",
    "    inclue_zero_counts=False,\n",
    "    possible_reasons=None, \n",
    "    include_nSNs=True, \n",
    "    include_SNs=True, \n",
    "    prem_nb_col='aep_premise_nb', \n",
    "    include_nprem_nbs=False,\n",
    "    include_prem_nbs=False, \n",
    "    return_form = dict(return_multiindex_outg_reason = False, \n",
    "                       return_normalized_separately  = False)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830612b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df27a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO This has two trsf_pole_nbs, should drop one\n",
    "end_events_df_no_outg['trsf_pole_nb'].equals(end_events_df_no_outg['trsf_pole_nb_gpd_for_sql'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build no_outg_time_infos_df, which has prem_nbs indices and t_min, t_max (and possible summary_path) columns\n",
    "# This is where the time information for each premise number comes from\n",
    "no_outg_time_infos_df = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "    summary_paths=[AMIEndEvents.find_summary_file_from_csv(x) for x in paths_no_outg], \n",
    "    output_prem_nbs_col='prem_nbs', \n",
    "    output_t_min_col='t_min', \n",
    "    output_t_max_col='t_max', \n",
    "    make_prem_nbs_idx=True, \n",
    "    include_summary_paths=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ad0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_df_curr_hist_no_outgs = MeterPremise.build_mp_df_curr_hist_for_xfmrs(trsf_pole_nbs=rcpo_df_1.index.tolist())\n",
    "mp_df_curr_hist_no_outgs = MeterPremise.build_mp_df_curr_hist_for_xfmrs(trsf_pole_nbs=rcpo_df_no_outg.index.get_level_values(0).tolist())\n",
    "print(mp_df_curr_hist_no_outgs['mp_df_curr'].shape)\n",
    "print(mp_df_curr_hist_no_outgs['mp_df_hist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d68678",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_for_xfmrs_no_outg = get_active_SNs_for_xfmrs_OLD(\n",
    "    trsf_pole_nbs=rcpo_df_no_outg.index.tolist(), \n",
    "    df_mp_curr=mp_df_curr_hist_no_outgs['mp_df_curr'], \n",
    "    df_mp_hist=mp_df_curr_hist_no_outgs['mp_df_hist'],\n",
    "    no_outg_time_infos_df=no_outg_time_infos_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_for_xfmrs_no_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea638a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcpo_df_no_outg = add_xfmr_active_SNs_to_rcpo_df_OLD(\n",
    "#     rcpo_df_no_outg.copy(), \n",
    "#     df_mp_curr=mp_df_curr_hist_no_outgs['mp_df_curr'], \n",
    "#     df_mp_hist=mp_df_curr_hist_no_outgs['mp_df_hist'],\n",
    "#     no_outg_time_infos_df=no_outg_time_infos_df   \n",
    "# )\n",
    "\n",
    "rcpo_df_no_outg = build_rcpo_df_norm_by_xfmr_active_nSNs_OLD(\n",
    "    rcpo_df_no_outg.copy(), \n",
    "    df_mp_curr=mp_df_curr_hist_no_outgs['mp_df_curr'], \n",
    "    df_mp_hist=mp_df_curr_hist_no_outgs['mp_df_hist'],\n",
    "    no_outg_time_infos_df=no_outg_time_infos_df   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf900e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf_pole_nbs=rcpo_df_no_outg.index.tolist()\n",
    "# df_mp_curr=mp_df_curr_hist_no_outgs['mp_df_curr']\n",
    "# df_mp_hist=mp_df_curr_hist_no_outgs['mp_df_hist'] \n",
    "# no_outg_time_infos_df=no_outg_time_infos_df\n",
    "# addtnl_mp_df_curr_cols=None\n",
    "# addtnl_mp_df_hist_cols=None \n",
    "# # files_dir_no_outg=r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\EndEvents_NoOutg'\n",
    "# file_path_glob_no_outg = r'end_events_[0-9]*.csv'\n",
    "# return_SNs_col='SNs'\n",
    "# return_prem_nbs_col='prem_nbs' \n",
    "# assert_all_trsf_pole_nbs_found=True \n",
    "# df_mp_serial_number_col='mfr_devc_ser_nbr' \n",
    "# df_mp_prem_nb_col='prem_nb'\n",
    "# df_mp_install_time_col='inst_ts' \n",
    "# df_mp_removal_time_col='rmvl_ts' \n",
    "# df_mp_trsf_pole_nb_col='trsf_pole_nb' \n",
    "# t_min_col='t_min'\n",
    "# t_max_col='t_max'\n",
    "# #-------------------------\n",
    "# necessary_mp_cols = [df_mp_serial_number_col, df_mp_prem_nb_col, df_mp_install_time_col, df_mp_removal_time_col]\n",
    "# #-------------------------\n",
    "# # At a bare minimum, df_mp_curr and df_mp_hist must both have the following columns:\n",
    "# #   necessary_mp_cols = ['mfr_devc_ser_nbr', 'prem_nb', 'inst_ts', 'rmvl_ts']\n",
    "# assert(all([x in df_mp_curr.columns for x in necessary_mp_cols+[df_mp_trsf_pole_nb_col]]))\n",
    "# assert(all([x in df_mp_hist.columns for x in necessary_mp_cols]))\n",
    "# #-------------------------\n",
    "# # PNs_for_xfmrs is a DF with trsf_pole_nbs indices and elements which are lists of PNs for each xfmr\n",
    "# PNs_for_xfmrs = MeterPremise.get_SNs_andor_PNs_for_xfmrs(\n",
    "#     trsf_pole_nbs=trsf_pole_nbs, \n",
    "#     include_SNs=False,\n",
    "#     include_PNs=True,\n",
    "#     trsf_pole_nb_col=df_mp_trsf_pole_nb_col, \n",
    "#     serial_number_col=df_mp_serial_number_col, \n",
    "#     prem_nb_col=df_mp_prem_nb_col, \n",
    "#     return_SNs_col=None, #Not grabbing SNs\n",
    "#     return_PNs_col=return_prem_nbs_col, \n",
    "#     assert_all_trsf_pole_nbs_found=assert_all_trsf_pole_nbs_found, \n",
    "#     mp_df=df_mp_curr, \n",
    "#     return_mp_df_also=False\n",
    "# )\n",
    "# #-------------------------\n",
    "# # Instead of a DF with trsf_pole_nb index and prem_nb column, we want opposite\n",
    "# xfmr_for_PNs_df = PNs_for_xfmrs.explode(return_prem_nbs_col)\n",
    "# xfmr_for_PNs_df[xfmr_for_PNs_df.index.name] = xfmr_for_PNs_df.index\n",
    "# xfmr_for_PNs_df = xfmr_for_PNs_df.set_index(return_prem_nbs_col)  \n",
    "# #-------------------------\n",
    "# #-------------------------\n",
    "# # Merge xfmr_for_PNs_df with no_outg_time_infos_df to append the time data to the former\n",
    "# # NOTE: It is possible for t_min/t_max to be NaT (NaN) for some entries after the merge, meaning that the \n",
    "# #       premise numbers were not found in no_outg_time_infos_df\n",
    "# #       This happens because these premise numbers must not have had any meter events, and thus were not included \n",
    "# #         in the SQL query (as it takes a long time to find empty results, so I weed these out before running the \n",
    "# #         query), and therefore the premise numbers were not found in the summary files/no_outg_time_infos_df.    \n",
    "# xfmr_for_PNs_df = pd.merge(xfmr_for_PNs_df, no_outg_time_infos_df, how='left', left_index=True, right_index=True)\n",
    "# #-------------------------\n",
    "# # Want to consolidate xfmr_for_PNs_df, grouping by trsf_pole_nb and collecting t_min,t_max, and a list\n",
    "# # of the premise numbers.  Therefore, first the index must be reset to make a PNs columns\n",
    "# xfmr_for_PNs_df=xfmr_for_PNs_df.reset_index()\n",
    "# #-----\n",
    "# # # Consolidate xfmr_for_PNs_df\n",
    "# # # NOTE: If t_min/t_max is NaT (NaN) for all premise numbers in a given trsf_pole_nb (see NOTE above before merge\n",
    "# # #       with no_outg_time_infos_df), then Utilities_df.consolidate_df will return an empty list (technically, an\n",
    "# # #       empty np.ndarray) for that trsf_pole_nb\n",
    "# # xfmr_for_PNs_df=Utilities_df.consolidate_df(\n",
    "# #     df=xfmr_for_PNs_df, \n",
    "# #     groupby_col=df_mp_trsf_pole_nb_col, \n",
    "# #     cols_shared_by_group=[t_min_col, t_max_col], \n",
    "# #     cols_to_collect_in_lists=[return_prem_nbs_col], \n",
    "# #     verbose=True\n",
    "# # )   \n",
    "# #-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = xfmr_for_PNs_df.copy()\n",
    "# groupby_col=df_mp_trsf_pole_nb_col\n",
    "# cols_shared_by_group=[t_min_col, t_max_col]\n",
    "# cols_to_collect_in_lists=[return_prem_nbs_col]\n",
    "# include_groupby_col_in_output_cols=False\n",
    "# allow_duplicates_in_lists=False\n",
    "# recover_uniqueness_violators=True\n",
    "# rename_cols=None\n",
    "# verbose=False\n",
    "# #-------------------------\n",
    "# if cols_shared_by_group is None or len(cols_shared_by_group)==0:\n",
    "#     cols_shared_by_group = groupby_col\n",
    "# assert(Utilities.is_object_one_of_types(cols_shared_by_group, [list, str, int]))\n",
    "# if not isinstance(cols_shared_by_group, list):\n",
    "#     cols_shared_by_group=[cols_shared_by_group]\n",
    "# #-----\n",
    "# assert(Utilities.is_object_one_of_types(cols_to_collect_in_lists, [list, str, int]))\n",
    "# if not isinstance(cols_to_collect_in_lists, list):\n",
    "#     cols_to_collect_in_lists=[cols_to_collect_in_lists]\n",
    "# #-------------------------\n",
    "# # Only include groups which have one unique entry for each of cols_shared_by_group\n",
    "# # The below series has a True/False value for each group stating whether (True)\n",
    "# #   or not (False) all cols in cols_shared_by_group have one unique value\n",
    "# group_has_unq_val_where_expected = (df.groupby(groupby_col)[cols_shared_by_group].nunique()<=1).all(axis=1)\n",
    "\n",
    "# # Those not satisfying the uniqueness criterion are collected below\n",
    "# groups_violating_uniqueness = group_has_unq_val_where_expected[~group_has_unq_val_where_expected.values].index.tolist()\n",
    "# #-------------------------\n",
    "# red_df = df.groupby(groupby_col).filter(lambda x: x.name not in groups_violating_uniqueness)\n",
    "# #-------------------------\n",
    "# # Consolidate xfmr_for_PNs_df\n",
    "# # NOTE: If t_min/t_max is NaT (NaN) for all premise numbers in a given trsf_pole_nb (see NOTE above before merge\n",
    "# #       with no_outg_time_infos_df), then Utilities_df.consolidate_df will return an empty list (technically, an\n",
    "# #       empty np.ndarray) for that trsf_pole_nb\n",
    "# xfmr_for_PNs_df=Utilities_df.consolidate_df_OLD(\n",
    "#     df=xfmr_for_PNs_df, \n",
    "#     groupby_col=df_mp_trsf_pole_nb_col, \n",
    "#     cols_shared_by_group=[t_min_col, t_max_col], \n",
    "#     cols_to_collect_in_lists=[return_prem_nbs_col], \n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNs_for_xfmrs_no_outg   = PNs_for_xfmrs.copy()\n",
    "# xfmr_for_PNs_df_no_outg = xfmr_for_PNs_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xfmr_for_PNs_df_no_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199f17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57b01086",
   "metadata": {},
   "source": [
    "## Outage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ab92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTG\n",
    "outg_rec_nb_col='outg_rec_nb'\n",
    "# group_cols='outg_rec_nb'\n",
    "group_cols=['outg_rec_nb', 'trsf_pole_nb']\n",
    "addtnl_dropna_subset_cols=None\n",
    "\n",
    "prem_nb_col='aep_premise_nb'\n",
    "#-------------------------\n",
    "paths_outg = Utilities.find_all_paths(\n",
    "    base_dir=files_dir_outg, \n",
    "    glob_pattern=file_path_glob, \n",
    "    regex_pattern=file_path_regex\n",
    ")\n",
    "paths_outg = paths_outg[:10]\n",
    "#-------------------------\n",
    "end_events_df_outg = GenAn.read_df_from_csv_batch(\n",
    "    paths=paths_outg, \n",
    "    cols_and_types_to_convert_dict=None, \n",
    "    to_numeric_errors='coerce', \n",
    "    make_all_columns_lowercase=True, \n",
    "    assert_all_cols_equal=True\n",
    ")\n",
    "#-------------------------\n",
    "if (f'{outg_rec_nb_col}_gpd_for_sql' in end_events_df_outg.columns and \n",
    "    outg_rec_nb_col not in end_events_df_outg.columns):\n",
    "    end_events_df_outg = end_events_df_outg.rename(columns={f'{outg_rec_nb_col}_gpd_for_sql':outg_rec_nb_col})\n",
    "assert(outg_rec_nb_col in end_events_df_outg.columns)\n",
    "#-------------------------\n",
    "dropna_subset_cols = [outg_rec_nb_col]\n",
    "if addtnl_dropna_subset_cols is not None:\n",
    "    dropna_subset_cols.extend(addtnl_dropna_subset_cols)\n",
    "end_events_df_outg = end_events_df_outg.dropna(subset=dropna_subset_cols)\n",
    "#-------------------------\n",
    "end_events_df_outg = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "    df=end_events_df_outg, \n",
    "    patterns_to_replace=patterns_to_replace\n",
    ")\n",
    "#-------------------------\n",
    "rcpo_df_outg = AMIEndEvents.get_reason_counts_per_group(\n",
    "    end_events_df_outg, \n",
    "    group_cols=group_cols,\n",
    "    group_freq=None, \n",
    "    serial_number_col='serialnumber', \n",
    "    reason_col='reason', \n",
    "    include_normalize_by_nSNs=False, \n",
    "    inclue_zero_counts=False,\n",
    "    possible_reasons=None, \n",
    "    include_nSNs=True, \n",
    "    include_SNs=True, \n",
    "    prem_nb_col='aep_premise_nb', \n",
    "    include_nprem_nbs=False,\n",
    "    include_prem_nbs=False, \n",
    "    return_form = dict(return_multiindex_outg_reason = False, \n",
    "                       return_normalized_separately  = False)    \n",
    ")\n",
    "rcpo_df_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55065550",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df = rcpo_df_outg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be570b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dovs_outgs = DOVSOutages(                 \n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True, \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=rcpo_df.index.get_level_values(0).tolist(), \n",
    "        from_table_alias='DOV', \n",
    "        datetime_col='DT_OFF_TS_FULL', \n",
    "        cols_of_interest=[\n",
    "            'OUTG_REC_NB', \n",
    "            dict(field_desc=f\"DOV.DT_ON_TS - DOV.STEP_DRTN_NB/(60*24)\", \n",
    "                 alias='DT_OFF_TS_FULL', table_alias_prefix=None)\n",
    "        ], \n",
    "        field_to_split='outg_rec_nbs'\n",
    "    ),\n",
    ")\n",
    "outg_dt_off_df = dovs_outgs.df\n",
    "outg_dt_off_df = Utilities_df.convert_col_type(df=outg_dt_off_df, column='OUTG_REC_NB', to_type=str)\n",
    "outg_dt_off_df=outg_dt_off_df.set_index('OUTG_REC_NB')\n",
    "outg_dt_off_series = outg_dt_off_df['DT_OFF_TS_FULL']\n",
    "\n",
    "#--------------------------------------------------\n",
    "time_infos_df = outg_dt_off_df.copy()\n",
    "time_infos_df['t_min'] = pd.to_datetime(time_infos_df['DT_OFF_TS_FULL'])-datetime.timedelta(days=1)\n",
    "time_infos_df['t_max'] = pd.to_datetime(time_infos_df['DT_OFF_TS_FULL'])+datetime.timedelta(days=1)\n",
    "time_infos_df = time_infos_df.drop(columns=['DT_OFF_TS_FULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEED TO BE AUTOMATED\n",
    "outg_rec_nb_idx_lvl=0\n",
    "trsf_pole_nbs_idx_lvl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268aa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if group_cols=='outg_rec_nb':\n",
    "    mp_df_curr_hist_outg = DOVSOutages.build_mp_df_curr_hist_for_outgs(outg_rec_nbs=rcpo_df.index.get_level_values(outg_rec_nb_idx_lvl).tolist())\n",
    "else:\n",
    "    mp_df_curr_hist_outg = MeterPremise.build_mp_df_curr_hist_for_xfmrs(trsf_pole_nbs=rcpo_df.index.get_level_values(trsf_pole_nbs_idx_lvl).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533980b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp_curr=mp_df_curr_hist_outg['mp_df_curr']\n",
    "df_mp_hist=mp_df_curr_hist_outg['mp_df_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f7d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ea9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf_pole_nbs_loc = 'index_1'\n",
    "trsf_pole_nbs_loc = ('index', 'trsf_pole_nb')\n",
    "# trsf_pole_nbs_loc = 'index'\n",
    "# trsf_pole_nbs_loc = ('counts', 'trsf_pole_nb')\n",
    "\n",
    "# rcpo_df_to_time_infos_on = ['index_0']\n",
    "rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')]\n",
    "time_infos_to_rcpo_df_on = ['index']\n",
    "how='left'\n",
    "\n",
    "\n",
    "rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')]\n",
    "PNs_to_rcpo_df_on = ['index']\n",
    "how='left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce431bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c06b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_SNs_col='SNs' \n",
    "return_prem_nbs_col='prem_nbs'\n",
    "assert_all_trsf_pole_nbs_found=True\n",
    "df_mp_serial_number_col='mfr_devc_ser_nbr'\n",
    "df_mp_prem_nb_col='prem_nb'\n",
    "df_mp_install_time_col='inst_ts'\n",
    "df_mp_removal_time_col='rmvl_ts'\n",
    "df_mp_trsf_pole_nb_col='trsf_pole_nb'\n",
    "t_min_col='t_min'\n",
    "t_max_col='t_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d187d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "active_SNs_df = get_active_SNs_for_xfmrs_in_rcpo_df(\n",
    "    rcpo_df=rcpo_df, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how=how, \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    ")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf79296",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "active_SNs_df_2 = get_active_SNs_for_xfmrs_in_rcpo_df_v2(\n",
    "    rcpo_df=rcpo_df, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how=how, \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    ")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_df.equals(active_SNs_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf735b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(sorted(rcpo_df.index.unique().tolist())==sorted(active_SNs_df.index.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441da9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562669f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd534a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee824e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_w_shit = rcpo_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6facb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_w_shit = add_xfmr_active_SNs_to_rcpo_df(\n",
    "    rcpo_df=rcpo_df_w_shit, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how=how, \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51328d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_w_shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733cd24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af290af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca997e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e89f44",
   "metadata": {},
   "source": [
    "## No Outage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251f2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTG\n",
    "outg_rec_nb_col='trsf_pole_nb'\n",
    "group_cols='trsf_pole_nb'\n",
    "# group_cols=['outg_rec_nb', 'trsf_pole_nb']\n",
    "addtnl_dropna_subset_cols=None\n",
    "\n",
    "prem_nb_col='aep_premise_nb'\n",
    "#-------------------------\n",
    "paths_no_outg = Utilities.find_all_paths(\n",
    "    base_dir=files_dir_no_outg, \n",
    "    glob_pattern=file_path_glob, \n",
    "    regex_pattern=file_path_regex\n",
    ")\n",
    "paths_no_outg = paths_no_outg[:10]\n",
    "#-------------------------\n",
    "end_events_df_no_outg = GenAn.read_df_from_csv_batch(\n",
    "    paths=paths_no_outg, \n",
    "    cols_and_types_to_convert_dict=None, \n",
    "    to_numeric_errors='coerce', \n",
    "    make_all_columns_lowercase=True, \n",
    "    assert_all_cols_equal=True\n",
    ")\n",
    "#-------------------------\n",
    "if (f'{outg_rec_nb_col}_gpd_for_sql' in end_events_df_no_outg.columns and \n",
    "    outg_rec_nb_col not in end_events_df_no_outg.columns):\n",
    "    end_events_df_no_outg = end_events_df_no_outg.rename(columns={f'{outg_rec_nb_col}_gpd_for_sql':outg_rec_nb_col})\n",
    "assert(outg_rec_nb_col in end_events_df_no_outg.columns)\n",
    "#-------------------------\n",
    "dropna_subset_cols = [outg_rec_nb_col]\n",
    "if addtnl_dropna_subset_cols is not None:\n",
    "    dropna_subset_cols.extend(addtnl_dropna_subset_cols)\n",
    "end_events_df_no_outg = end_events_df_no_outg.dropna(subset=dropna_subset_cols)\n",
    "#-------------------------\n",
    "end_events_df_no_outg = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "    df=end_events_df_no_outg, \n",
    "    patterns_to_replace=patterns_to_replace\n",
    ")\n",
    "#-------------------------\n",
    "rcpo_df_no_outg_2 = AMIEndEvents.get_reason_counts_per_group(\n",
    "    end_events_df_no_outg, \n",
    "    group_cols=group_cols,\n",
    "    group_freq=None, \n",
    "    serial_number_col='serialnumber', \n",
    "    reason_col='reason', \n",
    "    include_normalize_by_nSNs=False, \n",
    "    inclue_zero_counts=False,\n",
    "    possible_reasons=None, \n",
    "    include_nSNs=True, \n",
    "    include_SNs=True, \n",
    "    prem_nb_col='aep_premise_nb', \n",
    "    include_nprem_nbs=False,\n",
    "    include_prem_nbs=False, \n",
    "    return_form = dict(return_multiindex_outg_reason = False, \n",
    "                       return_normalized_separately  = False)    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a8255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7054b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg_2.equals(rcpo_df_no_outg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df = rcpo_df_no_outg_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6992cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outg_time_infos_df_NEW = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "    summary_paths=[AMIEndEvents.find_summary_file_from_csv(x) for x in paths_no_outg], \n",
    "    output_prem_nbs_col='prem_nbs', \n",
    "    output_t_min_col='t_min', \n",
    "    output_t_max_col='t_max', \n",
    "    make_addtnl_groupby_idx=True, \n",
    "    include_summary_paths=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outg_time_infos_df_NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe64119",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_infos_df = no_outg_time_infos_df_NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_pole_nbs_idx_lvl=0\n",
    "mp_df_curr_hist_no_outg_2 = MeterPremise.build_mp_df_curr_hist_for_xfmrs(trsf_pole_nbs=rcpo_df.index.get_level_values(trsf_pole_nbs_idx_lvl).tolist())\n",
    "print(mp_df_curr_hist_no_outg_2['mp_df_curr'].shape)\n",
    "print(mp_df_curr_hist_no_outg_2['mp_df_hist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea762642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp_curr=mp_df_curr_hist_no_outg_2['mp_df_curr']\n",
    "df_mp_hist=mp_df_curr_hist_no_outg_2['mp_df_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6125eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsf_pole_nbs_loc = ('index', 'trsf_pole_nb')\n",
    "\n",
    "\n",
    "# rcpo_df_to_time_infos_on = ['index_0']\n",
    "rcpo_df_to_time_infos_on = [('index', 'trsf_pole_nb')]\n",
    "time_infos_to_rcpo_df_on = ['index']\n",
    "how='left'\n",
    "\n",
    "\n",
    "rcpo_df_to_PNs_on = [('index', 'trsf_pole_nb')]\n",
    "PNs_to_rcpo_df_on = ['index']\n",
    "how='left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df.index.nlevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "active_SNs_1 = get_active_SNs_for_xfmrs_in_rcpo_df(\n",
    "    rcpo_df=rcpo_df, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    ")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78be2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15268414",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "active_SNs_2 = get_active_SNs_for_xfmrs_in_rcpo_df_v2(\n",
    "    rcpo_df=rcpo_df, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on, \n",
    "    addtnl_mp_df_curr_cols=None, \n",
    "    addtnl_mp_df_hist_cols=None, \n",
    "    return_SNs_col='SNs', \n",
    "    return_prem_nbs_col='prem_nbs', \n",
    "    assert_all_trsf_pole_nbs_found=True, \n",
    "    df_mp_serial_number_col='mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col='prem_nb', \n",
    "    df_mp_install_time_col='inst_ts', \n",
    "    df_mp_removal_time_col='rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col='trsf_pole_nb', \n",
    "    t_min_col='t_min', \n",
    "    t_max_col='t_max'\n",
    ")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95292fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca10751",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_SNs_2.equals(active_SNs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fcbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d79c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg2_w_shit = rcpo_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcpo_df_no_outg2_w_shit = add_xfmr_active_SNs_to_rcpo_df(\n",
    "#     rcpo_df=rcpo_df_no_outg2_w_shit, \n",
    "#     trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "#     df_mp_curr=df_mp_curr, \n",
    "#     df_mp_hist=df_mp_hist,\n",
    "#     time_infos_df=time_infos_df, \n",
    "#     rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "#     time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "#     how='left', \n",
    "#     rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "#     PNs_to_rcpo_df_on = PNs_to_rcpo_df_on\n",
    "# )\n",
    "\n",
    "\n",
    "rcpo_df_no_outg2_w_shit = build_rcpo_df_norm_by_xfmr_active_nSNs(\n",
    "    rcpo_df_raw=rcpo_df_no_outg2_w_shit, \n",
    "    trsf_pole_nbs_loc=trsf_pole_nbs_loc, \n",
    "    df_mp_curr=df_mp_curr, \n",
    "    df_mp_hist=df_mp_hist,\n",
    "    time_infos_df=time_infos_df, \n",
    "    rcpo_df_to_time_infos_on = rcpo_df_to_time_infos_on, \n",
    "    time_infos_to_rcpo_df_on = time_infos_to_rcpo_df_on, \n",
    "    how='left', \n",
    "    rcpo_df_to_PNs_on = rcpo_df_to_PNs_on, \n",
    "    PNs_to_rcpo_df_on = PNs_to_rcpo_df_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63328459",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg2_w_shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_no_outg2_w_shit.equals(rcpo_df_no_outg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5268d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ee2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c90700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE V1 Results\n",
    "print(active_SNs_2.equals(active_SNs_for_xfmrs_no_outg))\n",
    "# print(active_SNs_2['prem_nbs'].apply(lambda x: sorted(x)).equals(xfmr_for_PNs_df_no_outg['prem_nbs'].apply(lambda x: sorted(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792ee37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f748acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc015f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b387af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d81cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
