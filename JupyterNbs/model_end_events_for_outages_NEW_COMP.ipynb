{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50003e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb520489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s346557\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./model_end_events_for_outages_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5755605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "from functools import reduce\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "from EEMSP import EEMSP\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIEDE_DEV import AMIEDE_DEV\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from MECPOCollection import MECPOCollection\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from OutageModeler import OutageModeler\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from CustomJSON import CustomEncoder, CustomWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f7b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459065",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d471c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "data_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data'\n",
    "\n",
    "# save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\Models_00_05'\n",
    "# save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20230615\\Models'\n",
    "save_dir_model_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20231221\\Models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d97a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "save_model   = False\n",
    "\n",
    "# save_dir_model = None\n",
    "save_dir_model = 'All_EEMSP_agg_Top10_v3'\n",
    "if save_dir_model is None:\n",
    "    save_dir_model = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir_model = os.path.join(save_dir_model_base, save_dir_model)\n",
    "#-----\n",
    "if not os.path.exists(save_dir_model) and (save_results or save_model):\n",
    "    os.makedirs(save_dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128d2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_mecpo_colls = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2578e-9281-4a64-ae44-dd09025a2818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44fa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    verbose = True\n",
    "    #----- Outages -------------------------------------------------------------\n",
    "    # run_date_outg = '20230615'\n",
    "    # event_date_ranges_outg = [\n",
    "    #     ['2020-01-01', '2020-12-31'],\n",
    "    #     ['2021-01-01', '2021-12-31'], \n",
    "    #     ['2022-01-01', '2022-09-30'], \n",
    "    # ]\n",
    "    # run_date_outg = '20231201'\n",
    "    # event_date_ranges_outg = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_outg = '20231221'\n",
    "    event_date_ranges_outg = [\n",
    "        ['2023-04-01', '2023-11-30'], \n",
    "    ]\n",
    "    grp_by_cols_outg = ['outg_rec_nb', 'trsf_pole_nb']    \n",
    "    #----- No Outages ----------------------------------------------------------\n",
    "    # run_date_otbl = '20230512'\n",
    "    # event_date_ranges_otbl = [\n",
    "    #     ['2022-01-01', '2022-12-31'], \n",
    "    # ]\n",
    "    # run_date_otbl = '20231201'\n",
    "    # event_date_ranges_otbl = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_otbl = '20231221'\n",
    "    event_date_ranges_otbl = [\n",
    "        ['2023-04-01', '2023-11-30'], \n",
    "    ]\n",
    "    grp_by_cols_otbl = ['trsf_pole_nb', 'no_outg_rec_nb']    \n",
    "    #----- No Outages Pristine -------------------------------------------------\n",
    "    # run_date_prbl = '20230301'\n",
    "    # event_date_ranges_prbl = [\n",
    "    #     ['2022-01-01', '2022-12-31'], \n",
    "    # ]\n",
    "    # run_date_prbl = '20231201'\n",
    "    # event_date_ranges_prbl = [\n",
    "    #     ['2023-04-01', '2023-09-30'], \n",
    "    # ]\n",
    "    run_date_prbl = '20231221'\n",
    "    event_date_ranges_prbl = [\n",
    "        ['2023-04-01', '2023-11-30'], \n",
    "    ]\n",
    "    grp_by_cols_prbl = ['trsf_pole_nb', 'no_outg_rec_nb']    \n",
    "    #---------------------------------------------------------------------------\n",
    "    normalize_by_time_interval  = True\n",
    "    #-----\n",
    "    include_power_down_minus_up = False\n",
    "    pd_col = 'Primary Power Down'\n",
    "    pu_col = 'Primary Power Up'\n",
    "    pd_m_pu_col = 'Power Down Minus Up'\n",
    "    #-----\n",
    "    regex_to_remove_patterns    = ['.*cleared.*', '.*Test Mode.*']\n",
    "    regex_to_remove_ignore_case = True\n",
    "    #---------------------------------------------------------------------------\n",
    "    max_total_counts = None\n",
    "    # max_total_counts=150\n",
    "    # max_total_counts={\n",
    "    #     '01-05 Days':150, \n",
    "    #     '06-10 Days':150, \n",
    "    #     '11-15 Days':150, \n",
    "    #     '16-20 Days':150,\n",
    "    #     '21-25 Days':150, \n",
    "    #     '26-30 Days':150\n",
    "    # }\n",
    "    how_max_total_counts='any'\n",
    "    #---------------------------------------------------------------------------    \n",
    "    rcpo_dfs_name_outg = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "    rcpo_dfs_name_otbl = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "    rcpo_dfs_name_prbl = 'rcpo_df_norm_by_xfmr_nSNs'\n",
    "\n",
    "    mecpo_idx_for_ordering = 0\n",
    "    #-------------------------\n",
    "    icpo_dfs_name_outg          = 'i'+rcpo_dfs_name_outg[1:]\n",
    "    icpo_dfs_name_otbl       = 'i'+rcpo_dfs_name_otbl[1:]\n",
    "    icpo_dfs_name_prbl = 'i'+rcpo_dfs_name_prbl[1:]    \n",
    "    #---------------------------------------------------------------------------\n",
    "    freq='5D'\n",
    "    days_min_max_outg_td_windows=[\n",
    "        [1,6], [6,11], [11,16], [16,21], [21,26], [26,31]\n",
    "    ]\n",
    "    old_to_new_keys_dict = {\n",
    "        'outg_td_window_1_to_6_days'  :'01-06 Days',\n",
    "        'outg_td_window_6_to_11_days' :'06-11 Days',\n",
    "        'outg_td_window_11_to_16_days':'11-16 Days',\n",
    "        'outg_td_window_16_to_21_days':'16-21 Days',\n",
    "        'outg_td_window_21_to_26_days':'21-26 Days',\n",
    "        'outg_td_window_26_to_31_days':'26-31 Days'\n",
    "    }\n",
    "\n",
    "    #-------------------------\n",
    "    assert(len(old_to_new_keys_dict)==len(days_min_max_outg_td_windows))\n",
    "    #-------------------------\n",
    "    # Sanity check\n",
    "    for window_i in days_min_max_outg_td_windows:\n",
    "        assert(pd.Timedelta(f'{window_i[1]}D')-pd.Timedelta(f'{window_i[0]}D')==pd.Timedelta(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c7d30e-763c-4e46-92ea-c660a54c060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trsf_pole_nb', 'no_outg_rec_nb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_by_cols_otbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccbc45-5263-4e9e-a8c3-8d1228a50c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e3038-f511-4bfb-b619-f725f4b7850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28ffe3-fad0-4b55-b168-b4f5301d557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "643a7499-de74-40a8-92ab-d333c202dd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 6], [6, 11], [11, 16], [16, 21], [21, 26], [26, 31]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_min_max_outg_td_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3bb4cab-fe12-4915-aaeb-79a381107188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outg_td_window_1_to_6_days': '01-06 Days',\n",
       " 'outg_td_window_6_to_11_days': '06-11 Days',\n",
       " 'outg_td_window_11_to_16_days': '11-16 Days',\n",
       " 'outg_td_window_16_to_21_days': '16-21 Days',\n",
       " 'outg_td_window_21_to_26_days': '21-26 Days',\n",
       " 'outg_td_window_26_to_31_days': '26-31 Days'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_to_new_keys_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3764098-eb4c-4bd0-93d9-0a6ba1765b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ee14f8-0420-47a8-bcb3-58a31b3c4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs_outg = get_mecpx_base_dirs(\n",
    "    dataset          = 'outg', \n",
    "    acq_run_date     = run_date_outg, \n",
    "    data_date_ranges = event_date_ranges_outg, \n",
    "    data_dir_base    = data_dir_base, \n",
    "    assert_found     = True\n",
    ")\n",
    "\n",
    "base_dirs_otbl = get_mecpx_base_dirs(\n",
    "    dataset          = 'otbl', \n",
    "    acq_run_date     = run_date_otbl, \n",
    "    data_date_ranges = event_date_ranges_otbl, \n",
    "    data_dir_base    = data_dir_base, \n",
    "    assert_found     = True\n",
    ")\n",
    "\n",
    "base_dirs_prbl = get_mecpx_base_dirs(\n",
    "    dataset          = 'prbl', \n",
    "    acq_run_date     = run_date_prbl, \n",
    "    data_date_ranges = event_date_ranges_prbl, \n",
    "    data_dir_base    = data_dir_base, \n",
    "    assert_found     = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cdffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT REALLY NEEDED!\n",
    "# ede_data_dirs_ will be needed later for building time_infos_dfs, but these locations\n",
    "#   will be stored in the OutageModeler object\n",
    "if build_mecpo_colls:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    pkl_dirs_dict_outg = get_rcpo_pkl_dirs_for_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset          = 'outg', \n",
    "        acq_run_date     = run_date_outg, \n",
    "        data_date_ranges = event_date_ranges_outg, \n",
    "        grp_by_cols      = grp_by_cols_outg, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #-----\n",
    "    pkl_dirs_dict_otbl = get_rcpo_pkl_dirs_for_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset          = 'otbl', \n",
    "        acq_run_date     = run_date_otbl, \n",
    "        data_date_ranges = event_date_ranges_otbl, \n",
    "        grp_by_cols      = grp_by_cols_otbl, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #-----\n",
    "    pkl_dirs_dict_prbl = get_rcpo_pkl_dirs_for_build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset          = 'prbl', \n",
    "        acq_run_date     = run_date_prbl, \n",
    "        data_date_ranges = event_date_ranges_prbl, \n",
    "        grp_by_cols      = grp_by_cols_prbl, \n",
    "        data_dir_base    = data_dir_base\n",
    "    )\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    ede_data_dirs_outg = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_outg.values()]\n",
    "    ede_data_dirs_otbl = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_otbl.values()]\n",
    "    ede_data_dirs_prbl = [os.path.join(Path(x).parent, 'EndEvents') for x in pkl_dirs_dict_prbl.values()]\n",
    "    #-----\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_outg]))\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_otbl]))\n",
    "    assert(all([os.path.exists(x) for x in ede_data_dirs_prbl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5da1eb-e64c-4acf-97e5-43a38e63f10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeccc14-30f7-4a5f-89ae-b9376d7c0162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcb4df-64c1-4d32-b9a7-1374a558b1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd094780",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    mecpo_build_info_dict = dict()\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['run_date_outg']                   = run_date_outg\n",
    "    mecpo_build_info_dict['event_date_ranges_outg']          = event_date_ranges_outg\n",
    "    mecpo_build_info_dict['grp_by_cols_outg']                = grp_by_cols_outg\n",
    "    #-----\n",
    "    mecpo_build_info_dict['run_date_otbl']                   = run_date_otbl\n",
    "    mecpo_build_info_dict['event_date_ranges_otbl']          = event_date_ranges_otbl\n",
    "    mecpo_build_info_dict['grp_by_cols_otbl']                = grp_by_cols_otbl\n",
    "    #-----\n",
    "    mecpo_build_info_dict['run_date_prbl']                   = run_date_prbl\n",
    "    mecpo_build_info_dict['event_date_ranges_prbl']          = event_date_ranges_prbl\n",
    "    mecpo_build_info_dict['grp_by_cols_prbl']                = grp_by_cols_prbl\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['normalize_by_time_interval']      = normalize_by_time_interval\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['include_power_down_minus_up']     = include_power_down_minus_up\n",
    "    mecpo_build_info_dict['pd_col']                          = pd_col\n",
    "    mecpo_build_info_dict['pu_col']                          = pu_col\n",
    "    mecpo_build_info_dict['pd_m_pu_col']                     = pd_m_pu_col\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['regex_to_remove_patterns']        = regex_to_remove_patterns\n",
    "    mecpo_build_info_dict['regex_to_remove_ignore_case']     = regex_to_remove_ignore_case\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['max_total_counts']                = max_total_counts\n",
    "    mecpo_build_info_dict['how_max_total_counts']            = how_max_total_counts\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['mecpo_idx_for_ordering']          = mecpo_idx_for_ordering\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_outg']              = rcpo_dfs_name_outg\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_otbl']              = rcpo_dfs_name_otbl\n",
    "    mecpo_build_info_dict['rcpo_dfs_name_prbl']              = rcpo_dfs_name_prbl\n",
    "    #-----\n",
    "    mecpo_build_info_dict['icpo_dfs_name_outg']              = icpo_dfs_name_outg\n",
    "    mecpo_build_info_dict['icpo_dfs_name_otbl']              = icpo_dfs_name_otbl\n",
    "    mecpo_build_info_dict['icpo_dfs_name_prbl']              = icpo_dfs_name_prbl\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['freq']                            = freq\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['days_min_max_outg_td_windows']    = days_min_max_outg_td_windows\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['old_to_new_keys_dict']            = old_to_new_keys_dict\n",
    "    #-------------------------\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_outg']              = pkl_dirs_dict_outg\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_otbl']              = pkl_dirs_dict_otbl\n",
    "    mecpo_build_info_dict['pkl_dirs_dict_prbl']              = pkl_dirs_dict_prbl\n",
    "    #-----\n",
    "    mecpo_build_info_dict['ede_data_dirs_outg']              = ede_data_dirs_outg\n",
    "    mecpo_build_info_dict['ede_data_dirs_otbl']              = ede_data_dirs_otbl\n",
    "    mecpo_build_info_dict['ede_data_dirs_prbl']              = ede_data_dirs_prbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccb439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15f94421",
   "metadata": {},
   "source": [
    "# Build MECPOCollection objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f945458",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build MECPOCollection objects\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #----- Outages ------------------------------------\n",
    "    mecpo_coll_outg = build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'outg', \n",
    "        acq_run_date                 = run_date_outg, \n",
    "        data_date_ranges             = event_date_ranges_outg, \n",
    "        grp_by_cols                  = grp_by_cols_outg, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'Outages (All Xfmrs)', \n",
    "        barplot_kwargs_shared        = dict(facecolor='red'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )\n",
    "    \n",
    "    #----- No Outages ---------------------------------\n",
    "    mecpo_coll_otbl = build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'otbl', \n",
    "        acq_run_date                 = run_date_otbl, \n",
    "        data_date_ranges             = event_date_ranges_otbl, \n",
    "        grp_by_cols                  = grp_by_cols_otbl, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'No Outages', \n",
    "        barplot_kwargs_shared        = dict(facecolor='orange'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )    \n",
    "    \n",
    "    #----- No Outages Pristine ------------------------\n",
    "    mecpo_coll_prbl = build_and_combine_mecpo_colls_for_dates(\n",
    "        dataset                      = 'prbl', \n",
    "        acq_run_date                 = run_date_prbl, \n",
    "        data_date_ranges             = event_date_ranges_prbl, \n",
    "        grp_by_cols                  = grp_by_cols_prbl, \n",
    "        days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "        old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "        coll_label                   = 'No Outages', \n",
    "        barplot_kwargs_shared        = dict(facecolor='orange'), \n",
    "        normalize_by_time_interval   = normalize_by_time_interval, \n",
    "        data_dir_base                = data_dir_base\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da58184b-2d93-4e22-bd89-7a7cf83db505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_mecpx_colls_for_modeler(\n",
    "#     acq_run_date, \n",
    "#     data_date_ranges, \n",
    "#     data_dir_base, \n",
    "#     days_min_max_outg_td_windows, \n",
    "#     old_to_new_keys_dict, \n",
    "#     grp_by_cols_outg = ['outg_rec_nb', 'trsf_pole_nb'], \n",
    "#     grp_by_cols_bsln = ['trsf_pole_nb', 'no_outg_rec_nb'], \n",
    "#     include_prbl=True, \n",
    "#     normalize_by_time_interval=True, \n",
    "#     **kwargs\n",
    "# ):\n",
    "#     r\"\"\"\n",
    "#     Build the MECPOCollection objects for outage data (outg), outage transformers baseline data (otbl), and pristine baseline (prbl)\n",
    "#       to be used by the modeler.\n",
    "#     This function implicitly assumes outg, otbl, and prbl all share the same acq_run_date, data_date_ranges, and data_dir_base (and \n",
    "#       that otbl and prbl share grp_by_cols_bsln).\n",
    "#     If outg, otbl, and/or prbl do not share the same acq_run_date, data_date_ranges, and/or data_dir_base, then the dataset specific \n",
    "#       version of those parameters should be used (e.g., acq_run_date_outg, acq_run_date_otbl, acq_run_date_prbl)\n",
    "\n",
    "#     kwargs:\n",
    "#         As stated above, these are mainly used when outg, otbl, and/or prbl do not share the same input parameters.\n",
    "#         There are also kwargs hidden for setting coll_label, barplot_kwargs_shared\n",
    "#         Acceptable kwargs:\n",
    "#             Any of the following are acceptable with _outg, _otbl, or _prbl tags\n",
    "#             'acq_run_date',        (e.g., acq_run_date_outg, acq_run_date_otbl, acq_run_date_prbl)\n",
    "#             'data_date_ranges', \n",
    "#             'data_dir_base', \n",
    "#             'grp_by_cols', \n",
    "#             'coll_label', \n",
    "#             'barplot_kwargs_shared'\n",
    "#     \"\"\"\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     acceptable_kwargs = ['acq_run_date', 'data_date_ranges', 'data_dir_base', 'coll_label', 'barplot_kwargs_shared']\n",
    "#     acceptable_kwargs = list(itertools.chain.from_iterable([[f'{x}_outg', f'{x}_otbl', f'{x}_prbl'] for x in acceptable_kwargs]))\n",
    "#     acceptable_kwargs.extend(['grp_by_cols_otbl', 'grp_by_cols_prbl'])\n",
    "#     assert(set(kwargs.keys()).difference(set(acceptable_kwargs))==set())\n",
    "    \n",
    "#     #----- Outages (_outg) ------------------------------------------------------------------------------\n",
    "#     acq_run_date_outg          = kwargs.get('acq_run_date_outg',          acq_run_date)\n",
    "#     data_date_ranges_outg      = kwargs.get('data_date_ranges_outg',      data_date_ranges)\n",
    "#     data_dir_base_outg         = kwargs.get('data_dir_base_outg',         data_dir_base)\n",
    "#     # grp_by_cols_outg           = kwargs.get('grp_by_cols_outg',           grp_by_cols_outg)\n",
    "#     coll_label_outg            = kwargs.get('coll_label_outg',            'Outages')\n",
    "#     barplot_kwargs_shared_outg = kwargs.get('barplot_kwargs_shared_outg', dict(facecolor='red'))\n",
    "#     #-------------------------\n",
    "#     mecpx_coll_outg = build_and_combine_mecpo_colls_for_dates(\n",
    "#         dataset                      = 'outg', \n",
    "#         acq_run_date                 = acq_run_date_outg, \n",
    "#         data_date_ranges             = data_date_ranges_outg, \n",
    "#         grp_by_cols                  = grp_by_cols_outg, \n",
    "#         days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "#         old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "#         coll_label                   = coll_label_outg, \n",
    "#         barplot_kwargs_shared        = barplot_kwargs_shared_outg, \n",
    "#         normalize_by_time_interval   = normalize_by_time_interval, \n",
    "#         data_dir_base                = data_dir_base_outg\n",
    "#     )\n",
    "\n",
    "#     #----- Outage Transformers Baseline (_otbl) ---------------------------------------------------------\n",
    "#     acq_run_date_otbl          = kwargs.get('acq_run_date_otbl',          acq_run_date)\n",
    "#     data_date_ranges_otbl      = kwargs.get('data_date_ranges_otbl',      data_date_ranges)\n",
    "#     data_dir_base_otbl         = kwargs.get('data_dir_base_otbl',         data_dir_base)\n",
    "#     grp_by_cols_otbl           = kwargs.get('grp_by_cols_otbl',           grp_by_cols_bsln)\n",
    "#     coll_label_otbl            = kwargs.get('coll_label_otbl',            'Baseline (OTBL)')\n",
    "#     barplot_kwargs_shared_otbl = kwargs.get('barplot_kwargs_shared_otbl', dict(facecolor='orange'))\n",
    "#     #-------------------------\n",
    "#     mecpx_coll_otbl = build_and_combine_mecpo_colls_for_dates(\n",
    "#         dataset                      = 'otbl', \n",
    "#         acq_run_date                 = acq_run_date_otbl, \n",
    "#         data_date_ranges             = data_date_ranges_otbl, \n",
    "#         grp_by_cols                  = grp_by_cols_otbl, \n",
    "#         days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "#         old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "#         coll_label                   = coll_label_otbl, \n",
    "#         barplot_kwargs_shared        = barplot_kwargs_shared_otbl, \n",
    "#         normalize_by_time_interval   = normalize_by_time_interval, \n",
    "#         data_dir_base                = data_dir_base_otbl\n",
    "#     )\n",
    "\n",
    "#     #----- Pristine Baseline (_prbl) --------------------------------------------------------------------\n",
    "#     if include_prbl:\n",
    "#         acq_run_date_prbl          = kwargs.get('acq_run_date_prbl',          acq_run_date)\n",
    "#         data_date_ranges_prbl      = kwargs.get('data_date_ranges_prbl',      data_date_ranges)\n",
    "#         data_dir_base_prbl         = kwargs.get('data_dir_base_prbl',         data_dir_base)\n",
    "#         grp_by_cols_prbl           = kwargs.get('grp_by_cols_prbl',           grp_by_cols_bsln)\n",
    "#         coll_label_prbl            = kwargs.get('coll_label_prbl',            'Baseline (PRBL)')\n",
    "#         barplot_kwargs_shared_prbl = kwargs.get('barplot_kwargs_shared_prbl', dict(facecolor='orange'))\n",
    "#         #-------------------------\n",
    "#         mecpx_coll_prbl = build_and_combine_mecpo_colls_for_dates(\n",
    "#             dataset                      = 'prbl', \n",
    "#             acq_run_date                 = acq_run_date_prbl, \n",
    "#             data_date_ranges             = data_date_ranges_prbl, \n",
    "#             grp_by_cols                  = grp_by_cols_prbl, \n",
    "#             days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "#             old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "#             coll_label                   = coll_label_prbl, \n",
    "#             barplot_kwargs_shared        = barplot_kwargs_shared_prbl, \n",
    "#             normalize_by_time_interval   = normalize_by_time_interval, \n",
    "#             data_dir_base                = data_dir_base_prbl\n",
    "#         )\n",
    "#     else:\n",
    "#         mecpx_coll_prbl = None\n",
    "\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     return_dict = dict(\n",
    "#         outg = mecpx_coll_outg, \n",
    "#         otbl = mecpx_coll_otbl, \n",
    "#         prbl = mecpx_coll_prbl\n",
    "#     )\n",
    "#     return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b150b-90b3-4655-8afd-071657ab3552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea60bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_dict = OutageModeler.build_mecpx_colls_for_modeler(\n",
    "    acq_run_date                 = run_date_outg, \n",
    "    data_date_ranges             = event_date_ranges_outg, \n",
    "    data_dir_base                = data_dir_base, \n",
    "    days_min_max_outg_td_windows = days_min_max_outg_td_windows, \n",
    "    old_to_new_keys_dict         = old_to_new_keys_dict, \n",
    "    grp_by_cols_outg             = grp_by_cols_outg,   \n",
    "    grp_by_cols_bsln             = grp_by_cols_otbl, \n",
    "    include_prbl                 = True, \n",
    "    normalize_by_time_interval   = normalize_by_time_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c212fa07-1879-4095-9347-e77cf730333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_mecpx_colls(\n",
    "#     self, \n",
    "#     mecpx_coll_outg, \n",
    "#     mecpx_coll_otbl, \n",
    "#     mecpx_coll_prbl = None\n",
    "# ):\n",
    "#     r\"\"\"\n",
    "#     \"\"\"\n",
    "#     #-------------------------\n",
    "#     assert(isinstance(mecpx_coll_outg, MECPOCollection))\n",
    "#     assert(isinstance(mecpx_coll_otbl, MECPOCollection))\n",
    "#     if mecpx_coll_prbl is not None:\n",
    "#         assert(isinstance(mecpx_coll_prbl, MECPOCollection))\n",
    "#     #-------------------------\n",
    "#     self.mecpx_coll_outg = mecpx_coll_outg\n",
    "#     self.mecpx_coll_otbl = mecpx_coll_otbl\n",
    "#     self.mecpx_coll_prbl = mecpx_coll_prbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17852270-f637-4ae7-b53f-2730ab3cd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_similarity_operations(\n",
    "#     self, \n",
    "#     verbose=True\n",
    "# ):\n",
    "#     r\"\"\"\n",
    "#     Make the columns equal in the relevant DFs from the MECPOCollections\n",
    "#     \"\"\"\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     assert(self.mecpx_coll_outg is not None and self.mecpx_coll_otbl is not None)\n",
    "#     mecpo_colls_with_cpo_df_names = [\n",
    "#         [self.mecpx_coll_outg, self.cpx_dfs_name_outg], \n",
    "#         [self.mecpx_coll_otbl, self.cpx_dfs_name_otbl]\n",
    "#     ]\n",
    "#     #-----\n",
    "#     if self.mecpx_coll_prbl is not None:\n",
    "#         mecpo_colls_with_cpo_df_names.append([self.mecpx_coll_prbl, self.cpx_dfs_name_prbl])\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     if verbose:\n",
    "#         print('In OutageModeler.perform_similarity_operations\\nStarting shapes:')\n",
    "#         for i_coll, mecpo_coll_i_w_df_name in enumerate(mecpo_colls_with_cpo_df_names):\n",
    "#             print(f\"MECPO Collection {i_coll}\")\n",
    "#             for an_key in mecpo_coll_i_w_df_name[0].mecpo_an_keys:\n",
    "#                 print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_i_w_df_name[0].get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     # First, make columns equal between MECPOAn objects within each MECPOCollection\n",
    "#     for mecpo_coll_i_w_df_name in mecpo_colls_with_cpo_df_names:\n",
    "#         mecpo_coll_i_w_df_name[0].make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "\n",
    "#     #-------------------------\n",
    "#     # Now, make columns equal between the MECPOCollections\n",
    "#     MECPOCollection.make_cpo_columns_equal_between_mecpo_colls(\n",
    "#         mecpo_colls = [x[0] for x in mecpo_colls_with_cpo_df_names], \n",
    "#         drop_empty_cpo_dfs=True\n",
    "#     )\n",
    "\n",
    "#     #-------------------------\n",
    "#     # If not all same cpo_df names are used between collections, then one should call \n",
    "#     #   MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls.\n",
    "#     if len(set([x[1] for x in mecpo_colls_with_cpo_df_names]))>1:\n",
    "#         MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls(\n",
    "#             mecpo_colls_with_cpo_df_names = mecpo_colls_with_cpo_df_names, \n",
    "#             segregate_by_mecpo_an_keys=False\n",
    "#         )\n",
    "        \n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     if verbose:\n",
    "#         print('\\n\\nAfter making columns equal amongst collections:')\n",
    "#         for i_coll, mecpo_coll_i_w_df_name in enumerate(mecpo_colls_with_cpo_df_names):\n",
    "#             print(f\"MECPO Collection {i_coll}\")\n",
    "#             for an_key in mecpo_coll_i_w_df_name[0].mecpo_an_keys:\n",
    "#                 print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_i_w_df_name[0].get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c41e5f33-a2a4-4e15-a0e7-7e75ea380e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: This is resource wasting as it performs reductions on all DFs, not just those of the appropriate name\n",
    "# def perform_reduction_operations(\n",
    "#     self, \n",
    "#     verbose=True\n",
    "# ):\n",
    "#     r\"\"\"\n",
    "#     Remove and/or combine reasons\n",
    "#     Also, insert power_down_minus_up column if set.\n",
    "#     \"\"\"\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     assert(self.mecpx_coll_outg is not None and self.mecpx_coll_otbl is not None)\n",
    "#     mecpo_colls_with_cpo_df_names = [\n",
    "#         [self.mecpx_coll_outg, self.cpx_dfs_name_outg], \n",
    "#         [self.mecpx_coll_otbl, self.cpx_dfs_name_otbl]\n",
    "#     ]\n",
    "#     #-----\n",
    "#     if self.mecpx_coll_prbl is not None:\n",
    "#         mecpo_colls_with_cpo_df_names.append([self.mecpx_coll_prbl, self.cpx_dfs_name_prbl])\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     if verbose:\n",
    "#         print('In OutageModeler.perform_reduction_operations\\nStarting shapes:')\n",
    "#         for i_coll, mecpo_coll_i_w_df_name in enumerate(mecpo_colls_with_cpo_df_names):\n",
    "#             print(f\"MECPO Collection {i_coll}\")\n",
    "#             for an_key in mecpo_coll_i_w_df_name[0].mecpo_an_keys:\n",
    "#                 print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_i_w_df_name[0].get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     # Remove and/or combine reasons\n",
    "#     #----------------------------------------------------------------------------------------------------\n",
    "#     #-------------------------\n",
    "#     # Remove all reasons containing 'cleared'\n",
    "#     for mecpo_coll_i_w_df_name in mecpo_colls_with_cpo_df_names:\n",
    "#         mecpo_coll_i_w_df_name[0].remove_reasons_from_all_rcpo_dfs(\n",
    "#             regex_patterns_to_remove = self.mecpx_build_info_dict['regex_to_remove_patterns'], \n",
    "#             ignore_case              = self.mecpx_build_info_dict['regex_to_remove_ignore_case']\n",
    "#         )\n",
    "\n",
    "#     #-------------------------\n",
    "#     # Combine reasons using the standard combine (see dflt_patterns_and_replace in MECPODf.combine_cpo_df_reasons\n",
    "#     #   for the list of default patterns_and_replace)\n",
    "#     for mecpo_coll_i_w_df_name in mecpo_colls_with_cpo_df_names:\n",
    "#         mecpo_coll_i_w_df_name[0].combine_reasons_in_all_rcpo_dfs(**self.combine_reasons_kwargs)\n",
    "\n",
    "#     #-------------------------\n",
    "#     # Build power down minus power up counts\n",
    "#     if self.mecpx_build_info_dict['include_power_down_minus_up']:\n",
    "#         for mecpo_coll_i_w_df_name in mecpo_colls_with_cpo_df_names:\n",
    "#             mecpo_coll_i_w_df_name[0].delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "#                 reasons_1         = self.mecpx_build_info_dict['pd_col'],\n",
    "#                 reasons_2         = self.mecpx_build_info_dict['pu_col'],\n",
    "#                 delta_reason_name = self.mecpx_build_info_dict['pd_m_pu_col']\n",
    "#             )        \n",
    "#     #-------------------------\n",
    "#     # Don't want to include SNs or nSNs cols (and similar) in plotting, so remove\n",
    "#     for mecpo_coll_i_w_df_name in mecpo_colls_with_cpo_df_names:\n",
    "#         mecpo_coll_i_w_df_name[0].remove_SNs_cols_from_all_cpo_dfs()\n",
    "    \n",
    "#     #****************************************************************************************************\n",
    "#     if verbose:\n",
    "#         print('\\n\\nAfter removing and/or combining reasons:')\n",
    "#         for i_coll, mecpo_coll_i_w_df_name in enumerate(mecpo_colls_with_cpo_df_names):\n",
    "#             print(f\"MECPO Collection {i_coll}\")\n",
    "#             for an_key in mecpo_coll_i_w_df_name[0].mecpo_an_keys:\n",
    "#                 print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_i_w_df_name[0].get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb61d0a-c4ba-40c3-968c-901bf6041eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr = OutageModeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38615f9b-9621-43c1-bbe0-049e64bc047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_mdlr.set_mecpx_colls(\n",
    "    mecpx_coll_outg = copy.deepcopy(we_dict['outg']), \n",
    "    mecpx_coll_otbl = copy.deepcopy(we_dict['otbl']), \n",
    "    mecpx_coll_prbl = copy.deepcopy(we_dict['prbl']), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17acb5b5-828e-4c49-8d79-cfa760dddb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In OutageModeler.perform_similarity_operations\n",
      "Starting shapes:\n",
      "MECPO Collection 0\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 43)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 40)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 39)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 42)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 36)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 44)\n",
      "MECPO Collection 1\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 41)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 41)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 41)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 40)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 41)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 37)\n",
      "MECPO Collection 2\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 40)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 41)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 38)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 42)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 43)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 38)\n",
      "\n",
      "\n",
      "After making columns equal amongst collections:\n",
      "MECPO Collection 0\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 55)\n",
      "MECPO Collection 1\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 55)\n",
      "MECPO Collection 2\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 55)\n",
      "In OutageModeler.perform_reduction_operations\n",
      "Starting shapes:\n",
      "MECPO Collection 0\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 55)\n",
      "MECPO Collection 1\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 55)\n",
      "MECPO Collection 2\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 55)\n",
      "\n",
      "\n",
      "After removing and/or combining reasons:\n",
      "MECPO Collection 0\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 23)\n",
      "MECPO Collection 1\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 23)\n",
      "MECPO Collection 2\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 23)\n"
     ]
    }
   ],
   "source": [
    "outg_mdlr.perform_similarity_operations()\n",
    "outg_mdlr.perform_reduction_operations()\n",
    "outg_mdlr.compile_merged_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09cf1340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shapes:\n",
      "\tmecpo_coll_outg\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 43)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 40)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 39)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 42)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 36)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 44)\n",
      "\tmecpo_coll_otbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 41)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 41)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 41)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 40)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 41)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 37)\n",
      "\tmecpo_coll_prbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 40)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 41)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 38)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 42)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 43)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 38)\n",
      "\n",
      "\n",
      "After making columns equal amongst collections:\n",
      "\tmecpo_coll_outg\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 55)\n",
      "\tmecpo_coll_otbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 55)\n",
      "\tmecpo_coll_prbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 55)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 55)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 55)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 55)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 55)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 55)\n",
      "\n",
      "\n",
      "After removing and/or combining reasons:\n",
      "\tmecpo_coll_outg\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1722, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1779, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1452, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1527, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1672, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (1782, 23)\n",
      "\tmecpo_coll_otbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2440, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2287, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2726, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2156, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2471, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (2760, 23)\n",
      "\tmecpo_coll_prbl\n",
      "\t\t01-06 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (978, 23)\n",
      "\t\t06-11 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (955, 23)\n",
      "\t\t11-16 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (961, 23)\n",
      "\t\t16-21 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (948, 23)\n",
      "\t\t21-26 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (953, 23)\n",
      "\t\t26-31 Days, 'rcpo_df_norm_by_xfmr_nSNs' shape: (981, 23)\n"
     ]
    }
   ],
   "source": [
    "if build_mecpo_colls:\n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('Starting shapes:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_outg')\n",
    "        for an_key in mecpo_coll_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_outg.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_otbl')\n",
    "        for an_key in mecpo_coll_otbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_otbl}' shape: {mecpo_coll_otbl.get_cpo_df(an_key, rcpo_dfs_name_otbl).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_prbl')\n",
    "        for an_key in mecpo_coll_prbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_prbl}' shape: {mecpo_coll_prbl.get_cpo_df(an_key, rcpo_dfs_name_prbl).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Similarity operations\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # First, make columns equal between MECPOAn objects within each MECPOCollection\n",
    "    mecpo_coll_outg.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "    mecpo_coll_otbl.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "    mecpo_coll_prbl.make_cpo_columns_equal(drop_empty_cpo_dfs=True)\n",
    "\n",
    "    #-------------------------\n",
    "    # Now, make columns equal between the MECPOCollections\n",
    "    MECPOCollection.make_cpo_columns_equal_between_mecpo_colls(\n",
    "        mecpo_colls = [\n",
    "            mecpo_coll_outg, \n",
    "            mecpo_coll_otbl, \n",
    "            mecpo_coll_prbl\n",
    "        ], \n",
    "        drop_empty_cpo_dfs=True\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # If not all same cpo_df names are used between collections, then one should call \n",
    "    #   MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls.\n",
    "    if not(rcpo_dfs_name_outg==rcpo_dfs_name_otbl==rcpo_dfs_name_prbl):\n",
    "        MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls(\n",
    "            mecpo_colls_with_cpo_df_names = [\n",
    "                [mecpo_coll_outg, rcpo_dfs_name_outg], \n",
    "                [mecpo_coll_otbl, rcpo_dfs_name_otbl], \n",
    "                [mecpo_coll_prbl, rcpo_dfs_name_prbl]\n",
    "            ], \n",
    "            segregate_by_mecpo_an_keys=False\n",
    "        )\n",
    "    #-------------------------\n",
    "    if not(icpo_dfs_name_outg==icpo_dfs_name_otbl==icpo_dfs_name_prbl):\n",
    "        MECPOCollection.make_mixed_cpo_columns_equal_between_mecpo_colls(\n",
    "            mecpo_colls_with_cpo_df_names = [\n",
    "                [mecpo_coll_outg, icpo_dfs_name_outg], \n",
    "                [mecpo_coll_otbl, icpo_dfs_name_otbl], \n",
    "                [mecpo_coll_prbl, icpo_dfs_name_prbl]\n",
    "            ], \n",
    "            segregate_by_mecpo_an_keys=False\n",
    "        )\n",
    "        \n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('\\n\\nAfter making columns equal amongst collections:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_outg')\n",
    "        for an_key in mecpo_coll_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_outg.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_otbl')\n",
    "        for an_key in mecpo_coll_otbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_otbl}' shape: {mecpo_coll_otbl.get_cpo_df(an_key, rcpo_dfs_name_otbl).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_prbl')\n",
    "        for an_key in mecpo_coll_prbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_prbl}' shape: {mecpo_coll_prbl.get_cpo_df(an_key, rcpo_dfs_name_prbl).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Remove and/or combine reasons\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #-------------------------\n",
    "    # Remove all reasons containing 'cleared'\n",
    "    mecpo_coll_outg.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "    mecpo_coll_otbl.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "    mecpo_coll_prbl.remove_reasons_from_all_rcpo_dfs(\n",
    "        regex_patterns_to_remove = regex_to_remove_patterns, \n",
    "        ignore_case              = regex_to_remove_ignore_case\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # Combine reasons using the standard combine (see dflt_patterns_and_replace in MECPODf.combine_cpo_df_reasons\n",
    "    #   for the list of default patterns_and_replace)\n",
    "    red_to_org_cols_dicts_outg = mecpo_coll_outg.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    )\n",
    "    red_to_org_cols_dicts_otbl = mecpo_coll_otbl.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    ) \n",
    "    red_to_org_cols_dicts_prbl = mecpo_coll_prbl.combine_reasons_in_all_rcpo_dfs(\n",
    "        initial_strip               = True, \n",
    "        initial_punctuation_removal = True, \n",
    "        return_red_to_org_cols_dict = True\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Build power down minus power up counts\n",
    "    if include_power_down_minus_up:\n",
    "        mecpo_coll_outg.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        mecpo_coll_otbl.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        mecpo_coll_prbl.delta_cpo_df_reasons_in_all_rcpo_dfs(\n",
    "            reasons_1         = pd_col,\n",
    "            reasons_2         = pu_col,\n",
    "            delta_reason_name = pd_m_pu_col\n",
    "        )\n",
    "        \n",
    "    #-------------------------\n",
    "    # Don't want to include SNs or nSNs cols (and similar) in plotting, so remove\n",
    "    mecpo_coll_outg.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    mecpo_coll_otbl.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    mecpo_coll_prbl.remove_SNs_cols_from_all_cpo_dfs()\n",
    "    \n",
    "    #****************************************************************************************************\n",
    "    if verbose:\n",
    "        print('\\n\\nAfter removing and/or combining reasons:')\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_outg')\n",
    "        for an_key in mecpo_coll_outg.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_outg}' shape: {mecpo_coll_outg.get_cpo_df(an_key, rcpo_dfs_name_outg).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_otbl')\n",
    "        for an_key in mecpo_coll_otbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_otbl}' shape: {mecpo_coll_otbl.get_cpo_df(an_key, rcpo_dfs_name_otbl).shape}\")\n",
    "        #-----\n",
    "        print('\\tmecpo_coll_prbl')\n",
    "        for an_key in mecpo_coll_prbl.mecpo_an_keys:\n",
    "            print(f\"\\t\\t{an_key}, '{rcpo_dfs_name_prbl}' shape: {mecpo_coll_prbl.get_cpo_df(an_key, rcpo_dfs_name_prbl).shape}\")\n",
    "    #****************************************************************************************************\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Get merged DFs from collections\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    merged_df_outg = mecpo_coll_outg.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_outg, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "    merged_df_otbl = mecpo_coll_otbl.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_otbl, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "    merged_df_prbl = mecpo_coll_prbl.get_merged_cpo_dfs(\n",
    "        cpo_df_name                         = rcpo_dfs_name_prbl, \n",
    "        cpo_df_subset_by_mjr_mnr_cause_args = None, \n",
    "        max_total_counts                    = max_total_counts, \n",
    "        how_max_total_counts                = how_max_total_counts\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    # Make sure all SNs columns are removed\n",
    "    merged_df_outg = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_outg)\n",
    "    merged_df_otbl = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_otbl)\n",
    "    merged_df_prbl = MECPODf.remove_SNs_cols_from_rcpo_df(merged_df_prbl)\n",
    "    \n",
    "    #-------------------------\n",
    "    # Sort columns and make sure all columns equal for all\n",
    "    merged_df_outg = merged_df_outg[merged_df_outg.columns.sort_values()]\n",
    "    merged_df_otbl = merged_df_otbl[merged_df_otbl.columns.sort_values()]\n",
    "    merged_df_prbl = merged_df_prbl[merged_df_prbl.columns.sort_values()]\n",
    "    #-----\n",
    "    assert(all(merged_df_otbl.columns==merged_df_outg.columns))\n",
    "    assert(all(merged_df_otbl.columns==merged_df_prbl.columns))\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build counts series\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    counts_series_outg = mecpo_coll_outg.get_counts_series(rcpo_dfs_name_outg, False)\n",
    "    counts_series_otbl = mecpo_coll_otbl.get_counts_series(rcpo_dfs_name_otbl, False)\n",
    "    counts_series_prbl = mecpo_coll_prbl.get_counts_series(rcpo_dfs_name_prbl, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a2f8b7e-f838-4f85-8d93-9ed2006c1b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_outg.equals(outg_mdlr.merged_df_outg))\n",
    "print(merged_df_otbl.equals(outg_mdlr.merged_df_otbl))\n",
    "print(merged_df_prbl.equals(outg_mdlr.merged_df_prbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2300b50-d9ec-4570-b4de-f29e5ff45a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(counts_series_outg.equals(outg_mdlr.counts_series_outg))\n",
    "print(counts_series_otbl.equals(outg_mdlr.counts_series_otbl))\n",
    "print(counts_series_prbl.equals(outg_mdlr.counts_series_prbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de41810-ae47-48a1-bd5a-0b3c5575cf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade5c26-25ce-46ad-97ae-c4a52de9b3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffc4b8a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f36d3d",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# SAVE OR LOAD\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_mecpo_colls:\n",
    "    merged_df_outg.to_pickle(os.path.join(save_dir_model_base, 'merged_df_outg.pkl'))\n",
    "    merged_df_otbl.to_pickle(os.path.join(save_dir_model_base, 'merged_df_otbl.pkl'))\n",
    "    merged_df_prbl.to_pickle(os.path.join(save_dir_model_base, 'merged_df_prbl.pkl'))\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_outg.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_outg, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_otbl.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_otbl, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_coll_prbl.pkl'), 'wb') as handle:\n",
    "        pickle.dump(mecpo_coll_prbl, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_outg.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_outg, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_otbl.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_otbl, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_prbl.pkl'), 'wb') as handle:\n",
    "        pickle.dump(counts_series_prbl, handle, protocol=pickle.HIGHEST_PROTOCOL)     \n",
    "    #-------------------------\n",
    "    CustomWriter.output_dict_to_json(\n",
    "        os.path.join(save_dir_model_base, 'mecpo_build_info_dict.json'), \n",
    "        mecpo_build_info_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92933a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not build_mecpo_colls:\n",
    "    merged_df_outg=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_outg.pkl'))\n",
    "    merged_df_otbl=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_otbl.pkl'))\n",
    "    merged_df_prbl=pd.read_pickle(os.path.join(save_dir_model_base, 'merged_df_prbl.pkl'))\n",
    "    #-------------------------\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_outg.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_outg = pickle.load(handle)\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_otbl.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_otbl = pickle.load(handle)\n",
    "    # with open(os.path.join(save_dir_model_base, 'mecpo_coll_prbl.pkl'), 'rb') as handle:\n",
    "    #     mecpo_coll_prbl = pickle.load(handle)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_outg.pkl'), 'rb') as handle:\n",
    "        counts_series_outg = pickle.load(handle)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_otbl.pkl'), 'rb') as handle:\n",
    "        counts_series_otbl = pickle.load(handle)\n",
    "    with open(os.path.join(save_dir_model_base, 'counts_series_prbl.pkl'), 'rb') as handle:\n",
    "        counts_series_prbl = pickle.load(handle)\n",
    "    #-------------------------\n",
    "    with open(os.path.join(save_dir_model_base, 'mecpo_build_info_dict.json'), 'rb') as handle:\n",
    "        mecpo_build_info_dict = json.load(handle)\n",
    "\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    merged_df_prbl.index.names     = ['trsf_pole_nb', 'no_outg_rec_nb']\n",
    "    counts_series_prbl.index.names = ['trsf_pole_nb', 'no_outg_rec_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55784996-72f8-49c5-b0ce-20487a58ce19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1658dcfe",
   "metadata": {},
   "source": [
    "### Initiate summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd574252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building time infos and EEMSP takes a while, so I suggest building these\n",
    "#   once, saving them, and loading each time\n",
    "# ==> These should generally be set to False\n",
    "build_time_infos_dfs = False\n",
    "build_eemsp          = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "random_state = None\n",
    "#-------------------------\n",
    "n_top_reasons_to_inclue = 10\n",
    "# n_top_reasons_to_inclue = None\n",
    "combine_others          = True\n",
    "#-------------------------\n",
    "merge_eemsp = True\n",
    "mult_strategy='agg'\n",
    "#-------------------------\n",
    "include_month = True\n",
    "#-------------------------\n",
    "an_keys_to_drop = None\n",
    "# an_keys_to_drop = ['00-01 Days']\n",
    "# an_keys_to_drop = ['01-06 Days']\n",
    "#-------------------------\n",
    "# date_0_train   = pd.to_datetime('2023-04-01')\n",
    "# date_1_train   = pd.to_datetime('2023-09-30')\n",
    "# #-----\n",
    "# date_0_test    = pd.to_datetime('2023-04-01')\n",
    "# date_1_test    = pd.to_datetime('2023-09-30')\n",
    "# #-----\n",
    "# date_0_holdout = pd.to_datetime('2022-06-01')\n",
    "# date_1_holdout = pd.to_datetime('2023-09-30')\n",
    "\n",
    "date_0_train   = pd.to_datetime('2023-04-01')\n",
    "date_1_train   = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_test    = pd.to_datetime('2023-04-01')\n",
    "date_1_test    = pd.to_datetime('2023-11-30')\n",
    "#-----\n",
    "date_0_holdout = pd.to_datetime('2022-06-01')\n",
    "date_1_holdout = pd.to_datetime('2023-11-30')\n",
    "\n",
    "#-------------------------\n",
    "test_size                = 0.33\n",
    "get_train_test_by_date   = False\n",
    "split_train_test_by_outg = True \n",
    "#-------------------------\n",
    "create_validation_set = False\n",
    "val_size              = 0.10 #w.r.t to train size (i.e., w.r.t 1.0-test_size)\n",
    "#-------------------------\n",
    "run_scaler=True\n",
    "#-------------------------\n",
    "run_PCA = False\n",
    "pca_n_components=0.95\n",
    "#-------------------------\n",
    "remove_others_from_outages=False\n",
    "#-------------------------\n",
    "# min_pct_target_1 = 25\n",
    "min_pct_target_1 = None\n",
    "#-------------------------\n",
    "reduce_train_size = False\n",
    "red_test_size = 0.75 #Amount kept will be 1.0-red_test_size\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac83ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfmr_equip_typ_nms_of_interest = ['TRANSFORMER, OH', 'TRANSFORMER, UG']\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_outg_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'EQUIP_TYP_NM'), \n",
    "#             value=xfmr_equip_typ_nms_of_interest, \n",
    "#             comparison_operator='isin'\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_outg_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MNR_CAUSE_NM'), \n",
    "#             value='EQUIPMENT FAILURE', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "slicer = DFSlicer()\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'EQUIP_TYP_NM'), \n",
    "#             value='CONDUCTOR OVERHEAD', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'LOCATION_ID'), \n",
    "#             value=merged_df_outg_w_DOVS.index.get_level_values(1), \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'OUTG_REC_NB'), \n",
    "#             value=outgs_w_single_xfmr, \n",
    "#             comparison_operator='isin'\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "# merged_df_outg_w_DOVS[('outg_dummy_lvl_0', 'OUTG_REC_NB')] = merged_df_outg_w_DOVS.index.get_level_values(0)\n",
    "#-----\n",
    "# slicer = DFSlicer(\n",
    "#     single_slicers = [\n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MJR_CAUSE_NM'), \n",
    "#             value='DISTRIBUTION LINE', \n",
    "#             comparison_operator='=='\n",
    "#         ), \n",
    "#         dict(\n",
    "#             column=('outg_dummy_lvl_0', 'MNR_CAUSE_NM'), \n",
    "#             value='EQUIPMENT FAILURE', \n",
    "#             comparison_operator='=='\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5de95-a61b-4933-a301-d79a3d9fb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutageModeler.get_default_mecpx_build_info_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3db29-1e09-45fe-9cb5-990ddb3a36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutageModeler.get_default_summary_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e4460-e92a-49ef-9ad2-1ab612477328",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(set(OutageModeler.get_default_mecpx_build_info_dict().keys()).intersection(set(OutageModeler.get_default_summary_dict().keys()))==set())\n",
    "acceptable_kwargs = list(OutageModeler.get_default_mecpx_build_info_dict().keys()) + list(OutageModeler.get_default_summary_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808bc8f-abee-4557-931b-8fbf68cbb205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e79c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "an_keys = natsorted(merged_df_outg.columns.get_level_values(0).unique().tolist())\n",
    "assert(an_keys==natsorted(merged_df_otbl.columns.get_level_values(0).unique().tolist()))\n",
    "assert(an_keys==natsorted(merged_df_prbl.columns.get_level_values(0).unique().tolist()))\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "summary_dict = dict()\n",
    "#-------------------------\n",
    "summary_dict['an_keys']                    = an_keys\n",
    "#-------------------------\n",
    "summary_dict['random_state']               = random_state\n",
    "#-------------------------\n",
    "summary_dict['n_top_reasons_to_inclue']    = n_top_reasons_to_inclue\n",
    "summary_dict['combine_others']             = combine_others\n",
    "#-------------------------\n",
    "summary_dict['merge_eemsp']                = merge_eemsp\n",
    "summary_dict['eemsp_mult_strategy']        = mult_strategy\n",
    "#-------------------------\n",
    "summary_dict['include_month']              = include_month\n",
    "#-------------------------\n",
    "summary_dict['an_keys_to_drop']            = an_keys_to_drop\n",
    "#-------------------------\n",
    "# NOTE: Timestamp is not JSON serializable, hence the need for strftime below\n",
    "summary_dict['date_0_train']               = date_0_train.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_train']               = date_1_train.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-----\n",
    "summary_dict['date_0_test']                = date_0_test.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_test']                = date_1_test.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-----\n",
    "summary_dict['date_0_holdout']             = date_0_holdout.strftime('%Y-%m-%d %H:%M:%S')\n",
    "summary_dict['date_1_holdout']             = date_1_holdout.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#-------------------------\n",
    "summary_dict['test_size']                  = test_size\n",
    "summary_dict['get_train_test_by_date']     = get_train_test_by_date\n",
    "summary_dict['split_train_test_by_outg']   = split_train_test_by_outg\n",
    "#-------------------------\n",
    "summary_dict['create_validation_set']      = create_validation_set\n",
    "summary_dict['val_size']                   = val_size\n",
    "#-------------------------\n",
    "summary_dict['run_scaler']                 = run_scaler\n",
    "#-------------------------\n",
    "summary_dict['run_PCA']                    = run_PCA\n",
    "summary_dict['pca_n_components']           = pca_n_components\n",
    "#-------------------------\n",
    "summary_dict['slicer']                     = slicer.as_dict()\n",
    "#-------------------------\n",
    "summary_dict['remove_others_from_outages'] = remove_others_from_outages\n",
    "#-------------------------\n",
    "summary_dict['min_pct_target_1']           = min_pct_target_1\n",
    "#-------------------------\n",
    "summary_dict['reduce_train_size']          = reduce_train_size\n",
    "summary_dict['red_test_size']              = red_test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81e311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368cb77d",
   "metadata": {},
   "source": [
    "### !!!!!!! No outage data have indices backwards from outages!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b21959",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_otbl = merged_df_otbl.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "counts_series_otbl = counts_series_otbl.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb']).squeeze()\n",
    "#-----\n",
    "merged_df_prbl = merged_df_prbl.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "counts_series_prbl = counts_series_prbl.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d90550",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg.columns.get_level_values(1).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf77a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c08e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(save_dir_model_base).name=='Models' or Path(save_dir_model_base).name=='Models_00_05':\n",
    "    is_norm=True\n",
    "elif Path(save_dir_model_base).name=='Models_raw' or Path(save_dir_model_base).name=='Models_00_05_raw':\n",
    "    is_norm=False\n",
    "else:\n",
    "    assert(0)\n",
    "\n",
    "if n_top_reasons_to_inclue is not None:\n",
    "    # NOTE: Cannot do get_top_reasons_subset_from_merged_cpo_df for each, as they will then in general have unequal columns!\n",
    "    merged_df_outg, [merged_df_otbl, merged_df_prbl] = MECPOCollection.get_top_reasons_subset_from_merged_cpo_df_and_project_from_others(\n",
    "        merged_cpo_df             = merged_df_outg,\n",
    "        other_dfs_w_counts_series = [ \n",
    "            [merged_df_otbl, counts_series_otbl], \n",
    "            [merged_df_prbl, counts_series_prbl]\n",
    "        ], \n",
    "        how                       = 'per_mecpo_an', \n",
    "        n_reasons_to_include      = n_top_reasons_to_inclue,\n",
    "        combine_others            = combine_others,\n",
    "        output_combine_others_col = 'Other Reasons',\n",
    "        SNs_tags                  = None, \n",
    "        is_norm                   = is_norm, \n",
    "        counts_series             = counts_series_outg\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe263b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_outg.shape)\n",
    "print(merged_df_otbl.shape)\n",
    "print(merged_df_prbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_outg.shape)\n",
    "print(merged_df_otbl.shape)\n",
    "print(merged_df_prbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62249ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_outg)\n",
    "merged_df_otbl=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_otbl)\n",
    "merged_df_prbl=MECPOCollection.get_total_event_counts_for_merged_cpo_df(merged_df_prbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_outg.shape)\n",
    "print(merged_df_otbl.shape)\n",
    "print(merged_df_prbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(set(merged_df_outg.index).difference(set(counts_series_outg.index)))==0)\n",
    "assert(len(set(merged_df_otbl.index).difference(set(counts_series_otbl.index)))==0)\n",
    "assert(len(set(merged_df_prbl.index).difference(set(counts_series_prbl.index)))==0)\n",
    "\n",
    "merged_df_outg = pd.merge(\n",
    "    merged_df_outg, \n",
    "    counts_series_outg.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')\n",
    "\n",
    "merged_df_otbl = pd.merge(\n",
    "    merged_df_otbl, \n",
    "    counts_series_otbl.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')\n",
    "\n",
    "merged_df_prbl = pd.merge(\n",
    "    merged_df_prbl, \n",
    "    counts_series_prbl.to_frame(name=('nSNs', 'nSNs')), \n",
    "    left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b826bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_outg.shape)\n",
    "print(merged_df_otbl.shape)\n",
    "print(merged_df_prbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_outg.shape)\n",
    "print(merged_df_outg.index.get_level_values(0).nunique())\n",
    "print(merged_df_outg.index.get_level_values(1).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg.index.get_level_values(1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf90da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_outg['01-05 Days']\n",
    "# merged_df_outg['00-01 Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bfd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8022c703",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606ec35",
   "metadata": {},
   "source": [
    "# Build/grab time_info DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979b070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_time_infos_dfs:\n",
    "    time_infos_df_outg = build_outg_time_infos_df(\n",
    "        rcpx_df=merged_df_outg.copy(), \n",
    "        outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "        dummy_col_levels_prefix='dummy_lvl_',     \n",
    "    )\n",
    "    time_infos_df_outg.to_pickle(os.path.join(save_dir_model_base, 'time_infos_df_outg.pkl'))    \n",
    "    #-------------------------\n",
    "    ede_data_dirs_otbl       = mecpo_build_info_dict['ede_data_dirs_otbl'] \n",
    "    ede_data_dirs_prbl = mecpo_build_info_dict['ede_data_dirs_prbl'] \n",
    "    #-----\n",
    "    no_outg_time_infos_df = build_baseline_time_infos_df(\n",
    "        ede_data_dirs_bsln = ede_data_dirs_otbl,\n",
    "        save_path          = os.path.join(save_dir_model_base, 'no_outg_time_infos_df.pkl')\n",
    "    )\n",
    "    #-----\n",
    "    no_outg_time_infos_prstn_df = build_baseline_time_infos_df(\n",
    "        ede_data_dirs_bsln = ede_data_dirs_prbl,\n",
    "        save_path          = os.path.join(save_dir_model_base, 'no_outg_time_infos_prstn_df.pkl')\n",
    "    )\n",
    "else:\n",
    "    time_infos_df_outg          = pd.read_pickle(os.path.join(save_dir_model_base, 'time_infos_df_outg.pkl'))\n",
    "    no_outg_time_infos_df       = pd.read_pickle(os.path.join(save_dir_model_base, 'no_outg_time_infos_df.pkl'))\n",
    "    no_outg_time_infos_prstn_df = pd.read_pickle(os.path.join(save_dir_model_base, 'no_outg_time_infos_prstn_df.pkl'))\n",
    "#-------------------------\n",
    "if 'is_first_after_outg' in no_outg_time_infos_df.index.names:\n",
    "    no_outg_time_infos_df = no_outg_time_infos_df.droplevel(level='is_first_after_outg', axis=0)\n",
    "#-----\n",
    "if 'is_first_after_outg' in no_outg_time_infos_prstn_df.index.names:\n",
    "    no_outg_time_infos_prstn_df = no_outg_time_infos_prstn_df.droplevel(level='is_first_after_outg', axis=0)\n",
    "    \n",
    "#-------------------------\n",
    "# NOTE: After new DFs are built and saved (using build_baseline_time_infos_df), the if statements\n",
    "#         below will no longer be necessary\n",
    "# Typically, want index as ['no_outg_rec_nb', 'trsf_pole_nb']\n",
    "if no_outg_time_infos_df.index.names!=['no_outg_rec_nb', 'trsf_pole_nb']:\n",
    "    no_outg_time_infos_df = no_outg_time_infos_df.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "#-----\n",
    "if no_outg_time_infos_prstn_df.index.names!=['no_outg_rec_nb', 'trsf_pole_nb']:\n",
    "    no_outg_time_infos_prstn_df = no_outg_time_infos_prstn_df.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "    \n",
    "#-------------------------\n",
    "# Make sure time info found for all\n",
    "# For the baseline data, typically the time dfs will have more entries than the data\n",
    "#   This can result from, e.g., transformers not registering any events, in which case\n",
    "#     they obviously will not be found in the data, but will be found in the time dfs because\n",
    "#     those are built through the collection of run SQL queries\n",
    "assert(len(set(merged_df_outg.index).difference(set(time_infos_df_outg.index)))==0)\n",
    "assert(len(set(merged_df_otbl.index).difference(set(no_outg_time_infos_df.index)))==0)\n",
    "assert(len(set(merged_df_prbl.index).difference(set(no_outg_time_infos_prstn_df.index)))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67754ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b7fac1",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c5e72",
   "metadata": {},
   "source": [
    "# EEMSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72eee6-87e0-448d-bb1f-b3ffe5249d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Build time_infos_df\n",
    "    #--------------------------------------------------\n",
    "    time_infos_df_otbl = build_baseline_time_infos_df_for_eemsp(\n",
    "        bsln_time_infos_df = no_outg_time_infos_df\n",
    "    )\n",
    "    #-----\n",
    "    time_infos_df_prbl = build_baseline_time_infos_df_for_eemsp(\n",
    "        bsln_time_infos_df  no_outg_time_infos_prstn_df\n",
    "    )\n",
    "    #-------------------------\n",
    "    time_infos_df = build_time_infos_df_for_eemsp(\n",
    "        time_infos_df_outg=time_infos_df_outg, \n",
    "        time_infos_df_otbl=time_infos_df_otbl, \n",
    "        time_infos_df_prbl=time_infos_df_prbl\n",
    "    )\n",
    "    #-------------------------\n",
    "    assert(time_infos_df.shape[0]==time_infos_df.reset_index().drop_duplicates().shape[0])\n",
    "    #-----\n",
    "    del time_infos_df_outg\n",
    "    del time_infos_df_otbl\n",
    "    del time_infos_df_prbl\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # Grab or build df_eemsp_reduce2\n",
    "    #--------------------------------------------------\n",
    "    trsf_pole_nbs = list(set(\n",
    "        merged_df_outg.index.get_level_values(1).unique().tolist()+\n",
    "        merged_df_otbl.index.get_level_values(1).unique().tolist()+\n",
    "        merged_df_prbl.index.get_level_values(1).unique().tolist()\n",
    "    ))\n",
    "    #-------------------------\n",
    "    if build_eemsp:\n",
    "        df_eemsp_OG, df_eemsp_reduce1, df_eemsp_reduce2 = OutageModeler.build_eemsp_df_for_xfmrs_w_time_info(\n",
    "            trsf_pole_nbs               = trsf_pole_nbs, \n",
    "            time_infos_df               = time_infos_df, \n",
    "            mult_strategy               = mult_strategy, \n",
    "            batch_size                  = 1000, \n",
    "            verbose                     = True, \n",
    "            n_update                    = 10, \n",
    "            addtnl_kwargs               = None, \n",
    "            time_infos_df_info_dict     = None, \n",
    "            eemsp_df_info_dict          = None, \n",
    "            min_pct_found_in_time_infos = 0.75, \n",
    "            save_dfs                    = True, \n",
    "            save_dir                    = save_dir_model_base, \n",
    "            return_3_dfs                = True\n",
    "        )\n",
    "    else:\n",
    "        df_eemsp_OG      = pd.read_pickle(os.path.join(save_dir_model_base, 'df_eemsp_OG.pkl'))\n",
    "        df_eemsp_reduce1 = pd.read_pickle(os.path.join(save_dir_model_base, 'df_eemsp_reduce1.pkl'))\n",
    "        df_eemsp_reduce2 = pd.read_pickle(os.path.join(save_dir_model_base, f'df_eemsp_reduce2_{mult_strategy}.pkl'))\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    print(f\"df_eemsp_reduce2['LOCATION_NB'].nunique() = {df_eemsp_reduce2['location_nb'].nunique()}\")\n",
    "    print(f\"len(trsf_pole_nbs)                        = {len(trsf_pole_nbs)}\")\n",
    "    print(f\"Diff                                      = {len(trsf_pole_nbs)-df_eemsp_reduce2['location_nb'].nunique()}\")\n",
    "    print()\n",
    "    #-------------------------\n",
    "    print(\"\\nShapes BEFORE merging\")\n",
    "    print(f\"merged_df_outg.shape          = {merged_df_outg.shape}\")\n",
    "    print(f\"merged_df_otbl.shape       = {merged_df_otbl.shape}\")\n",
    "    print(f\"merged_df_prbl.shape = {merged_df_prbl.shape}\")\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    merged_df_outg = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_outg, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['outg_rec_nb_to_merge', 'location_nb'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df_otbl = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_otbl, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['outg_rec_nb_to_merge', 'location_nb'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    merged_df_prbl = merge_rcpx_with_eemsp(\n",
    "        df_rcpx=merged_df_prbl, \n",
    "        df_eemsp=df_eemsp_reduce2, \n",
    "        merge_on_rcpx=['index_0', 'index_1'], \n",
    "        merge_on_eems=['outg_rec_nb_to_merge', 'location_nb'], \n",
    "        set_index=True\n",
    "    )\n",
    "    #-------------------------\n",
    "    print(\"\\nShapes AFTER merging\")\n",
    "    print(f\"merged_df_outg.shape = {merged_df_outg.shape}\")\n",
    "    print(f\"merged_df_otbl.shape = {merged_df_otbl.shape}\")\n",
    "    print(f\"merged_df_prbl.shape = {merged_df_prbl.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962f5b2-d696-4d17-958d-4c0e39b6be88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    fig,ax = Plot_General.default_subplots()\n",
    "    Plot_Hist.plot_hist(\n",
    "        ax=ax, \n",
    "        df=df_eemsp_reduce1.groupby('location_nb').size().to_frame(), \n",
    "        x_col=0, \n",
    "        min_max_and_bin_size=(0,10,1), \n",
    "        plot_sns=True, \n",
    "        hist_plot_kwargs=dict(discrete=True)\n",
    "    )\n",
    "    ax.set_title('# Xfmrs at Pole Location (Only those with >1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    fig,ax = Plot_General.default_subplots()\n",
    "    Plot_Hist.plot_hist(\n",
    "        ax=ax, \n",
    "        df=df_eemsp_reduce1.groupby(['location_nb', 'outg_rec_nb_to_merge']).size().to_frame(), \n",
    "        x_col=0, \n",
    "        min_max_and_bin_size=(0,10,1), \n",
    "        plot_sns=True, \n",
    "        hist_plot_kwargs=dict(discrete=True)\n",
    "    )\n",
    "    ax.set_title('# Xfmrs at Pole Location (Only those with >1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d71a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    del df_eemsp_OG\n",
    "    del df_eemsp_reduce1\n",
    "    del df_eemsp_reduce2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f66bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b3980-1656-46f3-aa60-cdd21fff66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_otbl.index.names       = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "merged_df_prbl.index.names = ['outg_rec_nb', 'trsf_pole_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415b68f-5f70-4b01-84a4-3a6ad98b3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_month or merge_eemsp:\n",
    "    # If month or EEMSP is included, we will need the time_info_df data\n",
    "    #-------------------------\n",
    "    merged_df_outg = OutageModeler.add_time_infos_features(\n",
    "        cpx_df              = merged_df_outg, \n",
    "        time_infos_df       = time_infos_df, \n",
    "        include_eemsp       = merge_eemsp, \n",
    "        include_month       = include_month, \n",
    "        t_min_col           = 't_min', \n",
    "        trsf_install_dt_col = ('EEMSP_0', 'install_dt'), \n",
    "        return_trsf_age_col = None, \n",
    "        return_month_col    = None, \n",
    "        keep_time_infos     = False\n",
    "    )\n",
    "    #-----\n",
    "    merged_df_otbl = OutageModeler.add_time_infos_features(\n",
    "        cpx_df              = merged_df_otbl, \n",
    "        time_infos_df       = time_infos_df, \n",
    "        include_eemsp       = merge_eemsp, \n",
    "        include_month       = include_month, \n",
    "        t_min_col           = 't_min', \n",
    "        trsf_install_dt_col = ('EEMSP_0', 'install_dt'), \n",
    "        return_trsf_age_col = None, \n",
    "        return_month_col    = None, \n",
    "        keep_time_infos     = False\n",
    "    )\n",
    "    #-----\n",
    "    merged_df_prbl = OutageModeler.add_time_infos_features(\n",
    "        cpx_df              = merged_df_prbl, \n",
    "        time_infos_df       = time_infos_df, \n",
    "        include_eemsp       = merge_eemsp, \n",
    "        include_month       = include_month, \n",
    "        t_min_col           = 't_min', \n",
    "        trsf_install_dt_col = ('EEMSP_0', 'install_dt'), \n",
    "        return_trsf_age_col = None, \n",
    "        return_month_col    = None, \n",
    "        keep_time_infos     = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING SCHEDULED OUTAGES\n",
    "\n",
    "print(f'merged_df_outg.shape = {merged_df_outg.shape}')\n",
    "\n",
    "merged_df_outg =  MECPODf.get_cpo_df_subset_excluding_mjr_mnr_causes( \n",
    "    cpo_df=merged_df_outg, \n",
    "    mjr_mnr_causes_to_exclude=None, \n",
    "    mjr_causes_to_exclude=None,\n",
    "    mnr_causes_to_exclude=['SCO', 'SO'], \n",
    "    outg_rec_nb_col='index'\n",
    ")\n",
    "\n",
    "print(f'merged_df_outg.shape = {merged_df_outg.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d2867-3f4b-421b-b956-3bb49bc06411",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('is_outg', 'is_outg') in merged_df_outg.columns:\n",
    "    merged_df_outg = Utilities_df.move_cols_to_back(merged_df_outg, [('is_outg', 'is_outg')])\n",
    "if ('is_outg', 'is_outg') in merged_df_otbl.columns:\n",
    "    merged_df_otbl = Utilities_df.move_cols_to_back(merged_df_otbl, [('is_outg', 'is_outg')])\n",
    "if ('is_outg', 'is_outg') in merged_df_prbl.columns:\n",
    "    merged_df_prbl = Utilities_df.move_cols_to_back(merged_df_prbl, [('is_outg', 'is_outg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a675507-0d96-4886-b366-e1d41eb17faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b9252-7494-4a8b-a00f-3ee85ca754b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ef468-b933-46a5-8b33-7f6c7bb4af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9c011c",
   "metadata": {},
   "source": [
    "# !~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~!~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NETWORK and PRIMARY trsf_pole_nbs\n",
    "merged_df_outg = merged_df_outg.loc[~merged_df_outg.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]\n",
    "merged_df_otbl = merged_df_otbl.loc[~merged_df_otbl.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]\n",
    "merged_df_prbl = merged_df_prbl.loc[~merged_df_prbl.index.get_level_values(1).isin(['NETWORK', 'PRIMARY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd880459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DOVS info to be used for setting target values\n",
    "merged_df_outg_w_DOVS = DOVSOutages.append_outg_info_to_df(\n",
    "    df=merged_df_outg.copy(), \n",
    "    outg_rec_nb_idfr=('index', 'outg_rec_nb'), \n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_std_outage, \n",
    ")\n",
    "merged_df_outg_w_DOVS=merged_df_outg_w_DOVS[['outg_dummy_lvl_0']]\n",
    "merged_df_outg_w_DOVS[('is_outg', 'is_outg')]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108122e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'from_outg' information so I can track how many are in target=1 and target=0 \n",
    "merged_df_outg[('from_outg', 'from_outg')]          = 1\n",
    "merged_df_otbl[('from_outg', 'from_outg')]       = 0\n",
    "merged_df_prbl[('from_outg', 'from_outg')] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44544757",
   "metadata": {},
   "source": [
    "# Drop any time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if an_keys_to_drop is not None:\n",
    "    merged_df_outg = merged_df_outg.drop(columns=an_keys_to_drop, level=0)\n",
    "    merged_df_otbl = merged_df_otbl.drop(columns=an_keys_to_drop, level=0)\n",
    "    merged_df_prbl = merged_df_prbl.drop(columns=an_keys_to_drop, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108941b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cf157c6-2374-4da6-b3ad-d6b944ad7423",
   "metadata": {},
   "source": [
    "# BEG DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b48b1-8e8d-49bc-874b-afe5bcdd0bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7d083-4cef-4984-b122-074c70144db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_dict_outg = OutageModeler.train_test_split_outg(\n",
    "    df                       = merged_df_outg, \n",
    "    split_train_test_by_outg = split_train_test_by_outg, \n",
    "    test_size                = test_size, \n",
    "    random_state             = random_state, \n",
    "    get_train_test_by_date   = get_train_test_by_date,\n",
    "    date_range_train         = [date_0_train, date_1_train], \n",
    "    date_range_test          = [date_0_test,  date_1_test], \n",
    "    outg_rec_nb_idfr         = ('index', 'outg_rec_nb'), \n",
    "    date_range_holdout       = None, \n",
    "    verbose                  = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b915e-0fe5-4703-9bcc-263c978e693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_dict_otbl = OutageModeler.train_test_split_bsln(\n",
    "    df                       = merged_df_otbl, \n",
    "    split_train_test_by_outg = split_train_test_by_outg, \n",
    "    test_size                = test_size, \n",
    "    random_state             = random_state, \n",
    "    get_train_test_by_date   = get_train_test_by_date,\n",
    "    bsln_time_infos_df       = time_infos_df, \n",
    "    date_range_train         = [date_0_train, date_1_train], \n",
    "    date_range_test          = [date_0_test,  date_1_test], \n",
    "    # no_outg_rec_nb_idfr      = ('index', 'no_outg_rec_nb'), \n",
    "    no_outg_rec_nb_idfr      = ('index', 'outg_rec_nb'), \n",
    "    bsln_time_infos_time_col = 't_min', \n",
    "    date_range_holdout       = None, \n",
    "    verbose                  = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695da90b-d1d8-4839-81c4-a1f6bbed44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_dict_prbl = OutageModeler.train_test_split_bsln(\n",
    "    df                       = merged_df_prbl, \n",
    "    split_train_test_by_outg = split_train_test_by_outg, \n",
    "    test_size                = test_size, \n",
    "    random_state             = random_state, \n",
    "    get_train_test_by_date   = get_train_test_by_date,\n",
    "    bsln_time_infos_df       = time_infos_df, \n",
    "    date_range_train         = [date_0_train, date_1_train], \n",
    "    date_range_test          = [date_0_test,  date_1_test], \n",
    "    # no_outg_rec_nb_idfr      = ('index', 'no_outg_rec_nb'), \n",
    "    no_outg_rec_nb_idfr      = ('index', 'outg_rec_nb'), \n",
    "    bsln_time_infos_time_col = 't_min', \n",
    "    date_range_holdout       = None, \n",
    "    verbose                  = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dec59c-418b-44f3-accd-c1181b4e6827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3499d48f-648d-4491-ad81-f4877a278870",
   "metadata": {},
   "source": [
    "# END DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516f17d-4484-4b5e-8475-55440e06f70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c1392-62cf-4c8a-af4c-461f67ad3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtnl_bsln_frac = 1.0\n",
    "\n",
    "addtnl_bsln_train   = pd.concat([split_data_dict_otbl['train'],   split_data_dict_prbl['train']])\n",
    "addtnl_bsln_test    = pd.concat([split_data_dict_otbl['test'],    split_data_dict_prbl['test']])\n",
    "addtnl_bsln_holdout = pd.concat([split_data_dict_otbl['holdout'], split_data_dict_prbl['holdout']])\n",
    "\n",
    "assert(0 <= addtnl_bsln_frac <= 1.0)\n",
    "if addtnl_bsln_frac < 1.0:\n",
    "    addtnl_bsln_train = addtnl_bsln_train.sample(frac = addtnl_bsln_frac)\n",
    "    addtnl_bsln_test = addtnl_bsln_test.sample(frac = addtnl_bsln_frac)\n",
    "    addtnl_bsln_holdout = addtnl_bsln_holdout.sample(frac = addtnl_bsln_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_train   = pd.concat([split_data_dict_outg['train'],   addtnl_bsln_train])\n",
    "full_data_df_test    = pd.concat([split_data_dict_outg['test'],    addtnl_bsln_test])\n",
    "full_data_df_holdout = pd.concat([split_data_dict_outg['holdout'], addtnl_bsln_holdout])\n",
    "\n",
    "#Shuffle the data\n",
    "full_data_df_train   = full_data_df_train.sample(frac=1)\n",
    "full_data_df_test    = full_data_df_test.sample(frac=1)\n",
    "full_data_df_holdout = full_data_df_holdout.sample(frac=1)\n",
    "\n",
    "full_data_df = pd.concat([full_data_df_train, full_data_df_test, full_data_df_holdout])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf029347",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ca611",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73dd8a-f6a8-45f7-89a0-68134caa49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_eemsp:\n",
    "    [\n",
    "        full_data_df, \n",
    "        full_data_df_train, \n",
    "        full_data_df_test, \n",
    "        full_data_df_holdout\n",
    "    ], eemsp_enc = OutageModeler.encode_eemsp(\n",
    "        df             = [\n",
    "            full_data_df, \n",
    "            full_data_df_train, \n",
    "            full_data_df_test, \n",
    "            full_data_df_holdout\n",
    "        ], \n",
    "        eemsp_enc      = None, \n",
    "        eemsp_lvl_0_nm = 'EEMSP_0', \n",
    "        cols_to_encode = None, \n",
    "        numeric_cols   = ['kva_size', 'install_dt'], \n",
    "        run_transform  = True, \n",
    "        no_xfrm_df0    = True, \n",
    "    )\n",
    "    #-------------------------\n",
    "    if save_model:\n",
    "        joblib.dump(eemsp_enc, os.path.join(save_dir_model, 'eemsp_encoder.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea910c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83e219c",
   "metadata": {},
   "source": [
    "# Set target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_outg_w_DOVS_i = slicer.set_simple_column_value(df=merged_df_outg_w_DOVS.copy(), column=('is_outg', 'is_outg'), value=1)\n",
    "full_outg_idxs_i = merged_df_outg_w_DOVS_i[merged_df_outg_w_DOVS_i[('is_outg', 'is_outg')]==1].index\n",
    "\n",
    "#NOTE: To achieve exclusion equal to that in set_target_val_1_by_idx, one could use:\n",
    "#        full_outg_idxs_exclude_i = merged_df_outg_w_DOVS_i[merged_df_outg_w_DOVS_i[('is_outg', 'is_outg')]==0].index\n",
    "#      then use .drop(index=list(set(full_data_df_i.index).intersection(set(full_outg_idxs_exclude_i))))\n",
    "#      However, as noted in the function, the methods in set_target_val_1_by_idx are probably safer/more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc23d1-b89a-4dcd-8d74-82cd2dd845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "[\n",
    "    full_data_df_i, \n",
    "    full_data_df_train_i, \n",
    "    full_data_df_test_i, \n",
    "    full_data_df_holdout_i\n",
    "] = OutageModeler.set_target_val_1_by_idx(\n",
    "    df                         = [\n",
    "        full_data_df.copy(), \n",
    "        full_data_df_train.copy(), \n",
    "        full_data_df_test.copy(), \n",
    "        full_data_df_holdout.copy()\n",
    "    ],\n",
    "    val_1_idxs                 = full_outg_idxs_i,\n",
    "    remove_others_from_outages = remove_others_from_outages, \n",
    "    target_col                 = ('is_outg', 'is_outg'), \n",
    "    from_outg_col              = ('from_outg', 'from_outg')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da28ae-f5d5-46ca-95be-cae7a7ad5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutageModeler.print_data_composition(\n",
    "    df            = [full_data_df_train_i, full_data_df_test_i, full_data_df_holdout_i], \n",
    "    headline_str  = ['TRAIN',              'TEST',              'HOLDOUT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5dbf95-aac8-4040-8dd8-7fecc4e053b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_data_df_train_i[('is_outg', 'is_outg')].sum()==0:\n",
    "    print(f\"Not enough target value==1 in train\\n#target==1 train:   {full_data_df_train_i[('is_outg', 'is_outg')].sum()}\")\n",
    "#-----\n",
    "if full_data_df_test_i[('is_outg', 'is_outg')].sum()==0:\n",
    "    print(f\"Not enough target value==1 in test\\n#target==1 test:    {full_data_df_test_i[('is_outg', 'is_outg')].sum()}\")\n",
    "#-----\n",
    "if full_data_df_holdout_i.shape[0]>0 and full_data_df_holdout_i[('is_outg', 'is_outg')].sum()==0:\n",
    "    print(f\"Not enough target value==1 in holdout\\n#target==1 holdout: {full_data_df_holdout_i[('is_outg', 'is_outg')].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e1964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_pct_target_1 is not None:\n",
    "    full_data_df_train_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_train_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----\n",
    "    full_data_df_test_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_test_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----\n",
    "    full_data_df_holdout_i = ensure_target_val_1_min_pct(\n",
    "        df=full_data_df_holdout_i,\n",
    "        min_pct=min_pct_target_1,\n",
    "        target_col=('is_outg', 'is_outg'), \n",
    "        random_state=random_state, \n",
    "        return_discarded=False\n",
    "    )\n",
    "    #-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b431c6-a294-4d4d-974e-98c32ef0bb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9126cdb-2b9b-4d62-98ee-8170fc611e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutageModeler.print_data_composition(\n",
    "    df            = [full_data_df_train_i, full_data_df_test_i, full_data_df_holdout_i], \n",
    "    headline_str  = ['TRAIN',              'TEST',              'HOLDOUT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef13c6-dacd-47d0-aea7-8a803a278843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84da32-1631-4251-a5cf-aad3dd61c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('from_outg', 'from_outg') in full_data_df_i.columns.tolist():\n",
    "    full_data_df_i = full_data_df_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_train_i.columns.tolist():\n",
    "    full_data_df_train_i = full_data_df_train_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_test_i.columns.tolist():\n",
    "    full_data_df_test_i = full_data_df_test_i.drop(columns=[('from_outg', 'from_outg')])\n",
    "if ('from_outg', 'from_outg') in full_data_df_holdout_i.columns.tolist():\n",
    "    full_data_df_holdout_i = full_data_df_holdout_i.drop(columns=[('from_outg', 'from_outg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d98635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd269a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reduce_train_size:\n",
    "    if split_train_test_by_outg:\n",
    "        full_data_df_train_i, _ = train_test_split_df_by_outage(\n",
    "            df=full_data_df_train_i, \n",
    "            outg_rec_nb_idfr='index_0', \n",
    "            test_size=red_test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        full_data_df_train_i, _ = train_test_split(\n",
    "            full_data_df_train_i, \n",
    "            test_size=red_test_size, \n",
    "            random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fba3de",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "X_train_OG = full_data_df_train_i.iloc[:, :-1].copy()\n",
    "y_train    = full_data_df_train_i.iloc[:, -1].copy()\n",
    "\n",
    "X_test_OG = full_data_df_test_i.iloc[:, :-1].copy()\n",
    "y_test    = full_data_df_test_i.iloc[:, -1].copy()\n",
    "\n",
    "if full_data_df_holdout_i.shape[0]>0:\n",
    "    X_holdout = full_data_df_holdout_i.iloc[:, :-1]\n",
    "    y_holdout = full_data_df_holdout_i.iloc[:, -1]\n",
    "else:\n",
    "    X_holdout = pd.DataFrame()\n",
    "    y_holdout = pd.DataFrame()\n",
    "#-------------------------\n",
    "if save_model:\n",
    "    X_train_OG.head().to_pickle(os.path.join(save_dir_model, 'data_structure_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed07983-1fe6-4a5f-b882-a61e73c149f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1385e19-c5ba-4a37-817a-3e14479783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = OutageModeler.plot_target_counts_full_train_test(\n",
    "    df_full     = full_data_df_i, \n",
    "    df_train    = y_train, \n",
    "    df_test     = y_test, \n",
    "    df_holdout  = y_holdout, \n",
    "    is_outg_col = ('is_outg', 'is_outg')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45927394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67150a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b6b7c-5db7-4570-84b4-9a0ab6e415bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "if create_validation_set:\n",
    "    if split_train_test_by_outg:\n",
    "        X_train_OG, X_val_OG, y_train, y_val = train_test_split_df_group(\n",
    "            X=X_train_OG, \n",
    "            y=y_train, \n",
    "            groups=X_train_OG.index.get_level_values(0), \n",
    "            test_size=val_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        X_train_OG, X_val_OG, y_train, y_val = train_test_split(X_train_OG, y_train, test_size=val_size, random_state=random_state)\n",
    "#-------------------------\n",
    "if run_scaler:\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_OG)\n",
    "    #-----\n",
    "    if create_validation_set:\n",
    "        X_val   = scaler.transform(X_val_OG)\n",
    "    X_test  = scaler.transform(X_test_OG)\n",
    "    if full_data_df_holdout_i.shape[0]>0:\n",
    "        X_holdout   = scaler.transform(X_holdout)\n",
    "    #-----\n",
    "    if save_model:\n",
    "        joblib.dump(scaler, os.path.join(save_dir_model, 'scaler.joblib'))\n",
    "else:\n",
    "    X_train = X_train_OG\n",
    "    if create_validation_set:\n",
    "        X_val   = X_val_OG\n",
    "    X_test  = X_test_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4dfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_PCA:\n",
    "    # First, generate a PCA plot, showing the explained variance on the y-axis and number of components on x\n",
    "    # This is simply to check that the number of components kept looks correct\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    plt.plot(cumsum)\n",
    "    \n",
    "    # Now, run the PCA with pca_n_components and perform transforms\n",
    "    pca=PCA(n_components=pca_n_components)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    print(f'PCA n-components       = {pca.n_components_}')\n",
    "    print(f'PCA explained variance = {pca.explained_variance_ratio_.sum()}')\n",
    "    #-----\n",
    "    if create_validation_set:\n",
    "        X_val      = pca.transform(X_val)\n",
    "    X_test     = pca.transform(X_test)\n",
    "    if full_data_df_holdout_i.shape[0]>0:\n",
    "        X_holdout  = pca.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92971c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "806e071f",
   "metadata": {},
   "source": [
    "# Dumb Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2dc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_clf = DumbClassifier()\n",
    "cross_val_score(dumb_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = dumb_clf.predict(X_test)\n",
    "# print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "# print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "# print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9092fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0202b280",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40851f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_clf = RandomForestClassifier(n_estimators = 100)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, criterion='entropy', n_jobs=-1)\n",
    "\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=-1)\n",
    "forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=None)\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=25, n_jobs=None, class_weight='balanced')\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 1000, max_depth=None, n_jobs=None) #probably dont want max_depth=None\n",
    "# forest_clf = RandomForestClassifier(n_estimators = 5000, max_depth=50, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8d5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b404c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine mecpo_build_info_dict and summary_dict\n",
    "assert(set(mecpo_build_info_dict.keys()).intersection(set(summary_dict.keys()))==set())\n",
    "summary_dict = summary_dict | mecpo_build_info_dict\n",
    "#-------------------------\n",
    "if save_results:\n",
    "    CustomWriter.output_dict_to_json(\n",
    "        os.path.join(save_dir_model, 'summary_dict.json'), \n",
    "        summary_dict\n",
    "    )\n",
    "#-----\n",
    "if save_model:\n",
    "    joblib.dump(forest_clf, os.path.join(save_dir_model, 'forest_clf.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = forest_clf.predict(X_train)\n",
    "print('*****'*5)\n",
    "print('TRAINING DATASET')\n",
    "print('*****'*5)\n",
    "print(f\"#(target==1): {y_train.sum()}\")\n",
    "print(f\"#(target==0): {y_train.shape[0]-y_train.sum()}\")\n",
    "print(f\"%(target==1): {100*(y_train.sum()/(y_train.shape[0]))}\")\n",
    "print('-----'*5)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_train, y_pred_train))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_train, y_pred_train))\n",
    "print()\n",
    "\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "print('*****'*5)\n",
    "print('TESTING DATASET')\n",
    "print('*****'*5)\n",
    "print(f\"#(target==1): {y_test.sum()}\")\n",
    "print(f\"#(target==0): {y_test.shape[0]-y_test.sum()}\")\n",
    "print(f\"%(target==1): {100*(y_test.sum()/(y_test.shape[0]))}\")\n",
    "print('-----'*5)\n",
    "print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "print(\"PRECISION OF THE MODEL: \", precision_score(y_test, y_pred))\n",
    "print(\"RECALL    OF THE MODEL: \", recall_score(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "if full_data_df_holdout_i.shape[0]>0:\n",
    "    y_pred_holdout = forest_clf.predict(X_holdout)\n",
    "    print('*****'*5)\n",
    "    print('HOLDOOUT DATASET')\n",
    "    print('*****'*5)\n",
    "    print(f\"#(target==1): {y_holdout.sum()}\")\n",
    "    print(f\"#(target==0): {y_holdout.shape[0]-y_holdout.sum()}\")\n",
    "    print(f\"%(target==1): {100*(y_holdout.sum()/(y_holdout.shape[0]))}\")\n",
    "    print('-----'*5)\n",
    "    print(\"ACCURACY  OF THE MODEL: \", accuracy_score(y_holdout, y_pred_holdout))\n",
    "    print(\"PRECISION OF THE MODEL: \", precision_score(y_holdout, y_pred_holdout))\n",
    "    print(\"RECALL    OF THE MODEL: \", recall_score(y_holdout, y_pred_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10ecc9-545f-4356-8d41-6d451d79ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Utilities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_n_xfmrs = get_n_trsf_poles_per_outg(\n",
    "    df=merged_df_outg, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "outgs_w_single_xfmr = outg_n_xfmrs[outg_n_xfmrs==1].index.tolist()\n",
    "#-------------------------\n",
    "n_dir_indir_tp_fn_train = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_train_i, \n",
    "    y_pred=y_pred_train, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")\n",
    "#-----\n",
    "n_dir_indir_tp_fn_test = get_n_direct_xfmrs_in_tp_fn(\n",
    "    data_df=full_data_df_test_i, \n",
    "    y_pred=y_pred, \n",
    "    y_col=('is_outg', 'is_outg'), \n",
    "    outgs_w_single_xfmr=outgs_w_single_xfmr, \n",
    "    xfmr_equip_typ_nms_of_interest=None, \n",
    "    outg_rec_nb_idfr='index_0', \n",
    "    trsf_pole_nb_idfr='index_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a4f33-ea03-4cd2-90c1-d8a43bae7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Utilities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = pd.DataFrame(columns=['idk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d660f3-9f79-4c37-bb23-f16f2cc74903",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc132a-d208-4356-9474-d38d4d80b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18b797-073a-4bdc-b413-e23a7b5e6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = Utilities_df.convert_col_type(\n",
    "    df=idk, \n",
    "    column='idk', \n",
    "    to_type=int, \n",
    "    to_numeric_errors='coerce', \n",
    "    inplace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa90aa4-0367-40ad-8a21-895ff275edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24fe9b-f42c-44b4-bdc1-6e0ebeabd51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fafbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs    = save_results\n",
    "fig_save_dir = save_dir_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = Plot_General.default_subplots(\n",
    "#     n_x=1, \n",
    "#     n_y=3, \n",
    "#     fig_num=fig_num, \n",
    "#     unit_figsize_width=6., \n",
    "#     unit_figsize_height=4., \n",
    "# )\n",
    "# Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_train, \n",
    "#     y_pred=y_pred_train, \n",
    "#     title='Train', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[0]\n",
    "# )\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_test, \n",
    "#     y_pred=y_pred, \n",
    "#     title='Test', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[1]\n",
    "# )\n",
    "# #-----\n",
    "# cmd = draw_outg_confusion_matrix(\n",
    "#     y=y_holdout, \n",
    "#     y_pred=y_pred_holdout, \n",
    "#     title='Holdout', \n",
    "#     normalize=None, \n",
    "#     scientific=True, \n",
    "#     ax=axs[2]\n",
    "# )\n",
    "# #-----\n",
    "# if save_figs:\n",
    "#     if not os.path.exists(fig_save_dir):\n",
    "#         os.makedirs(fig_save_dir)\n",
    "#     Plot_General.save_fig(\n",
    "#         fig=fig, \n",
    "#         save_dir=fig_save_dir, \n",
    "#         save_name='ConfusionMatrices.png', \n",
    "#         bbox_inches='tight'\n",
    "#     )\n",
    "# #-----\n",
    "# fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c605150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = Plot_General.default_subplots(\n",
    "    n_x=1, \n",
    "    n_y=2, \n",
    "    fig_num=fig_num, \n",
    "    unit_figsize_width=6., \n",
    "    unit_figsize_height=4., \n",
    ")\n",
    "Plot_General.adjust_subplots_args(fig, dict(hspace=0.4))\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_train, \n",
    "    y_pred=y_pred_train, \n",
    "    title='Train', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[0], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_train\n",
    ")\n",
    "#-----\n",
    "cmd = draw_outg_confusion_matrix(\n",
    "    y=y_test, \n",
    "    y_pred=y_pred, \n",
    "    title='Test', \n",
    "    normalize=None, \n",
    "    scientific=False, \n",
    "    ax=axs[1], \n",
    "    n_dir_indir_tp_fn=n_dir_indir_tp_fn_test\n",
    ")\n",
    "#-----\n",
    "if save_figs:\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.makedirs(fig_save_dir)\n",
    "    Plot_General.save_fig(\n",
    "        fig=fig, \n",
    "        save_dir=fig_save_dir, \n",
    "        save_name='ConfusionMatrices.png', \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "#-----\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b296345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559c24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f15d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa713d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdffea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba7bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
