{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./check_DOVS_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "from packaging import version\n",
    "\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "import Utilities_dt\n",
    "from Utilities_df import DFConstructType\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025651d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898398c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb65d6fd",
   "metadata": {},
   "source": [
    "# Analyze collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074daca",
   "metadata": {},
   "source": [
    "## AMI NonVee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "paths = Utilities.find_all_paths(\n",
    "    base_dir=r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\AMINonVee', \n",
    "    glob_pattern=r'ami_nonvee_[0-9]*.csv', \n",
    "    regex_pattern=None\n",
    ")\n",
    "paths=natsorted(paths)\n",
    "#-------------------------\n",
    "outg_rec_nbs_in_files = dict()\n",
    "for path in paths:\n",
    "    assert(path not in outg_rec_nbs_in_files.keys())\n",
    "    df = GenAn.read_df_from_csv(path)\n",
    "    outg_rec_nbs_in_files[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "outg_rec_nb_to_files_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files)\n",
    "all_outg_rec_nbs = list(outg_rec_nb_to_files_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92299455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57008118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "paths_ede = Utilities.find_all_paths(\n",
    "    base_dir=r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\EndEvents', \n",
    "    glob_pattern=r'end_events_[0-9]*.csv', \n",
    "    regex_pattern=None\n",
    ")\n",
    "paths_ede=natsorted(paths_ede)\n",
    "#-------------------------\n",
    "outg_rec_nbs_in_files_ede = dict()\n",
    "for path in paths_ede:\n",
    "    assert(path not in outg_rec_nbs_in_files_ede.keys())\n",
    "    df = GenAn.read_df_from_csv(path)\n",
    "    outg_rec_nbs_in_files_ede[path] = df['OUTG_REC_NB_GPD_FOR_SQL'].unique().tolist()\n",
    "outg_rec_nb_to_files_ede_dict = invert_file_to_outg_rec_nbs_dict(outg_rec_nbs_in_files_ede)\n",
    "all_outg_rec_nbs_ede = list(outg_rec_nb_to_files_ede_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outg_rec_nbs_in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012d638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc69cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "instvabc_slcr = DFSlicer(\n",
    "    single_slicers = [\n",
    "        dict(\n",
    "            column='aep_derived_uom', \n",
    "            value='VOLT', \n",
    "            comparison_operator='=='\n",
    "        ), \n",
    "        dict(\n",
    "            column='aep_srvc_qlty_idntfr', \n",
    "            value=['INSTVA1', 'INSTVB1', 'INSTVC1'], \n",
    "            comparison_operator='isin'\n",
    "        )\n",
    "    ], \n",
    "    name='VOLT, INSTV(ABC)1', \n",
    "    join_single_slicers='and'\n",
    ")\n",
    "#-------------------------\n",
    "volt_avg_slcr = DFSlicer(\n",
    "    single_slicers = [\n",
    "        dict(\n",
    "            column='aep_derived_uom', \n",
    "            value='VOLT', \n",
    "            comparison_operator='=='\n",
    "        ), \n",
    "        dict(\n",
    "            column='aep_srvc_qlty_idntfr', \n",
    "            value='AVG', \n",
    "            comparison_operator='=='\n",
    "        )\n",
    "    ], \n",
    "    name='VOLT, AVG', \n",
    "    join_single_slicers='and'\n",
    ")\n",
    "#-------------------------\n",
    "slicers=[instvabc_slcr, volt_avg_slcr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad29c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Build mico_df_for_plt to be used in plotting times from mico_df\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "conn_outages = Utilities.get_utldb01p_oracle_connection()\n",
    "outgs_file_from_mico = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\2023-04-08 to 04-15 Reviews (1).xlsx'\n",
    "expand_time = pd.Timedelta('1 day')\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "mico_df_raw = pd.read_excel(outgs_file_from_mico, sheet_name='Scorecard')\n",
    "mico_df = mico_df_raw.copy()\n",
    "#-----\n",
    "# For now, keep only the following columns:\n",
    "mico_cols_to_keep = [\n",
    "    'Outage #', \n",
    "    'Outage Start DT', \n",
    "    'Adj Outage Start DT', \n",
    "    'Outage End DT',\n",
    "    'Adj Outage End DT', \n",
    "    'Circuit Name',\n",
    "    'Step CMI'\n",
    "]\n",
    "mico_df = mico_df[mico_cols_to_keep]\n",
    "\n",
    "#-------------------------\n",
    "# Currently, outage numbers have -1, -2, etc. appended.\n",
    "# I believe an outage number will have such multiple rows when the outage affects more than one circuit.\n",
    "# In the DOVS database, these will be split iunto separate outg_rec_nbs\n",
    "#-----\n",
    "# I will instead merge the data via the outage number and circuit name, so remove the -1, -2, etc. from \n",
    "#   the 'Outage #', store the result in 'OUTAGE_NB' (to be consistent with DOVS), and drop 'Outage #'\n",
    "mico_df['OUTAGE_NB'] = mico_df['Outage #'].apply(lambda x: re.sub('(\\d*)-\\d*', r'\\1', x))\n",
    "mico_df=mico_df.drop(columns=['Outage #'])\n",
    "\n",
    "#-------------------------\n",
    "# Each outage can also have multiple rows corresponding to the power recover steps\n",
    "# Aggregate the steps into a single row for each outage\n",
    "mico_df = mico_df.groupby(\n",
    "    ['OUTAGE_NB', 'Circuit Name'], \n",
    "    dropna=False, \n",
    "    as_index=False, \n",
    "    group_keys=False\n",
    ").agg({\n",
    "    'Outage Start DT':     'min', \n",
    "    'Adj Outage Start DT': 'min', \n",
    "    'Outage End DT':       'max', \n",
    "    'Adj Outage End DT':   'max', \n",
    "    'Step CMI':            'sum'\n",
    "})\n",
    "\n",
    "# At this point, each outage (unique combinatino of 'OUTAGE_NB' and 'Circuit Name') should\n",
    "#   correspond to a single row\n",
    "assert(mico_df.shape[0] == mico_df.groupby(['OUTAGE_NB', 'Circuit Name']).ngroups)\n",
    "\n",
    "#-------------------------\n",
    "mico_df['Min Start Date'] = mico_df[['Outage Start DT', 'Adj Outage Start DT']].min(axis=1).dt.date - expand_time\n",
    "mico_df['Max End Date']   = mico_df[['Outage End DT',   'Adj Outage End DT'  ]].max(axis=1).dt.date + expand_time\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# NOTE: A single OUTAGE_NB can correspond to more than one OUTG_REC_NBs!\n",
    "#       It appears this is the case when the outage affects multiple GIS_CRCT_NBs, in which case,\n",
    "#         each GIS_CRCT_NB gets its own OUTG_REC_NB\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# First, grab DF containing all OUTAGE_NBs\n",
    "# Note, the OUTAGE_NB is not unique, so there will generally be multiple entries\n",
    "#   Here, I'm talking about the same OUTAGE_NB being used for different outages throughout the years, \n",
    "#     not a single OUTAGE_NB corresponding to multiple OUTG_REC_NBs, as described above.\n",
    "#   Determine which is correct entry using the times from mico_df\n",
    "sql_using_outage_nbs = DOVSOutages_SQL.build_sql_std_outage(\n",
    "    mjr_mnr_cause=None, \n",
    "    include_premise=True, \n",
    "    outage_nbs=mico_df['OUTAGE_NB'].unique().tolist(), \n",
    "    date_range=[mico_df['Min Start Date'].min(), mico_df['Max End Date'].max()], \n",
    "    MJR_CAUSE_CD=None, \n",
    "    DEVICE_CD=None, \n",
    "    INTRPTN_TYP_CD=None, \n",
    "    CURR_REC_STAT_CD=None, \n",
    "    select_cols_DOVS_PREMISE_DIM=['CIRCT_NM']\n",
    ").get_sql_statement()\n",
    "#-----\n",
    "df_using_outage_nbs = pd.read_sql_query(\n",
    "    sql_using_outage_nbs, \n",
    "    conn_outages, \n",
    "    dtype={\n",
    "        'CI_NB':np.int32, \n",
    "        'CMI_NB':np.float64, \n",
    "        'OUTG_REC_NB':np.int32\n",
    "    }\n",
    ")\n",
    "#-------------------------\n",
    "# Determine appropriate OUTG_REC_NBs by using 'Min Start Date', 'Max End Date'\n",
    "df_using_outage_nbs = pd.merge(\n",
    "    df_using_outage_nbs, \n",
    "    mico_df[['OUTAGE_NB', 'Circuit Name', 'Min Start Date', 'Max End Date']], \n",
    "    left_on=['OUTAGE_NB', 'CIRCT_NM'], \n",
    "    right_on=['OUTAGE_NB', 'Circuit Name'], \n",
    "    how='inner'\n",
    ")\n",
    "df_using_outage_nbs= df_using_outage_nbs[\n",
    "    (df_using_outage_nbs['DT_OFF_TS_FULL'].dt.date >= df_using_outage_nbs['Min Start Date']) & \n",
    "    (df_using_outage_nbs['DT_ON_TS'].dt.date       <= df_using_outage_nbs['Max End Date'])\n",
    "]\n",
    "df_using_outage_nbs = df_using_outage_nbs.drop(columns=['Min Start Date', 'Max End Date', 'Circuit Name'])\n",
    "\n",
    "print(time.time()-start)\n",
    "\n",
    "# NOTE: Keep CIRCT_NM (although it comes from DOVS_PREMISE_DIM), as this will be used to merge as there exist \n",
    "#         duplicate OUTAGE_NB entries in Mico's df which have different OUTG_REC_NBs if the outage affects multiple circuits\n",
    "df_outage_noPNs = df_using_outage_nbs.drop(columns=['OFF_TM', 'REST_TM', 'PREMISE_NB']).drop_duplicates()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "mico_df_for_plt = pd.merge(\n",
    "    mico_df, \n",
    "    df_outage_noPNs[['OUTAGE_NB', 'CIRCT_NM', 'OUTG_REC_NB']], \n",
    "    left_on=['OUTAGE_NB', 'Circuit Name'], \n",
    "    right_on=['OUTAGE_NB', 'CIRCT_NM'], \n",
    "    how='inner'\n",
    ")\n",
    "#-----\n",
    "mico_df_for_plt['Final Outage Start'] = mico_df_for_plt['Adj Outage Start DT'].fillna(mico_df_for_plt['Outage Start DT'])\n",
    "mico_df_for_plt['Final Outage End']   = mico_df_for_plt['Adj Outage End DT'].fillna(mico_df_for_plt['Outage End DT'])\n",
    "mico_df_for_plt = mico_df_for_plt.drop(columns=[\n",
    "    'Adj Outage Start DT', 'Outage Start DT', \n",
    "    'Adj Outage End DT',   'Outage End DT', \n",
    "    'Circuit Name', \n",
    "    'Step CMI', 'Min Start Date', 'Max End Date'\n",
    "])\n",
    "mico_df_for_plt['OUTG_REC_NB'] = mico_df_for_plt['OUTG_REC_NB'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_by_PN = True\n",
    "# combine_by_PN_likeness_thresh = pd.Timedelta('1 minutes')\n",
    "combine_by_PN_likeness_thresh = pd.Timedelta('15 minutes')\n",
    "\n",
    "expand_outg_search_time_tight = pd.Timedelta('1 hours')\n",
    "expand_outg_search_time_loose = pd.Timedelta('12 hours')\n",
    "use_est_outg_times=False\n",
    "use_full_ede_outgs=False\n",
    "run_outg_inclusion_assessment=False\n",
    "#-----\n",
    "expand_outg_est_search_time = expand_outg_search_time_loose\n",
    "if use_est_outg_times:\n",
    "    expand_outg_search_time = expand_outg_search_time_tight\n",
    "else:\n",
    "    expand_outg_search_time = expand_outg_search_time_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4724e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results'\n",
    "pdf = PdfPages(os.path.join(save_dir, r'ResultsNEW_PN2_NEWEDEMETHOD.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outg_rec_nbs_uiq = [\n",
    "#     '13294548',\n",
    "#     '13294660',\n",
    "#     '13294879',\n",
    "#     '13295201',\n",
    "#     '13295264',\n",
    "#     '13297352',\n",
    "#     '13297819',\n",
    "#     '13298920',\n",
    "#     '13298928',\n",
    "#     '13298955',\n",
    "#     '13299354',\n",
    "#     '13300546',\n",
    "#     '13300325',\n",
    "#     '13300583',\n",
    "#     '13302073',\n",
    "#     '13302188',\n",
    "#     '13302515',\n",
    "#     '13303019',\n",
    "#     '13304108'\n",
    "# ]\n",
    "# save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results'\n",
    "# pdf = PdfPages(os.path.join(save_dir, r'Results_UIQ.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Below are actually all entries with some sort of comment\n",
    "# outg_rec_nbs_uiq = [\n",
    "#     '13294548',\n",
    "#     '13294660',\n",
    "#     '13294714',\n",
    "#     '13294761',\n",
    "#     '13294879',\n",
    "#     '13294840',\n",
    "#     '13295201',\n",
    "#     '13295078',\n",
    "#     '13295264',\n",
    "#     '13295522',\n",
    "#     '13295395',\n",
    "#     '13295459',\n",
    "#     '13295530',\n",
    "#     '13297352',\n",
    "#     '13297586',\n",
    "#     '13297819',\n",
    "#     '13298920',\n",
    "#     '13298928',\n",
    "#     '13298955',\n",
    "#     '13299354',\n",
    "#     '13300028',\n",
    "#     '13300335',\n",
    "#     '13300546',\n",
    "#     '13300325',\n",
    "#     '13300583',\n",
    "#     '13302048',\n",
    "#     '13302078',\n",
    "#     '13302073',\n",
    "#     '13302082',\n",
    "#     '13302198',\n",
    "#     '13302188',\n",
    "#     '13302515',\n",
    "#     '13303019',\n",
    "#     '13303187',\n",
    "#     '13303801',\n",
    "#     '13304108',\n",
    "#     '13304254'\n",
    "# ]\n",
    "# save_dir = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results'\n",
    "# pdf = PdfPages(os.path.join(save_dir, r'Results_wComment.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ffbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19aaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_num=0\n",
    "all_detailed_summary_dfs=[]\n",
    "ci_cmi_summary_df = pd.DataFrame(columns=[\n",
    "    'outg_rec_nb', \n",
    "    'ci_dovs',  'ci_ami', \n",
    "    'cmi_dovs', 'cmi_ami'\n",
    "])\n",
    "\n",
    "#-------------------------\n",
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args=None, \n",
    "    init_df_in_constructor=True,\n",
    "    build_sql_function=DOVSOutages_SQL.build_sql_outage, \n",
    "    build_sql_function_kwargs=dict(\n",
    "        outg_rec_nbs=all_outg_rec_nbs, \n",
    "        field_to_split='outg_rec_nbs', \n",
    "        include_premise=True\n",
    "    ), \n",
    "    build_consolidated=True\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "\n",
    "#-------------------------\n",
    "# Now, iterate through all outages\n",
    "for i_outg, outg_rec_nb in enumerate(all_outg_rec_nbs):\n",
    "    print(f'\\n\\ti_outg: {i_outg+1}/{len(all_outg_rec_nbs)}')\n",
    "    print(f'\\toutg_rec_nb = {outg_rec_nb}')\n",
    "    #-----\n",
    "    ami_df = GenAn.read_df_from_csv_batch(outg_rec_nb_to_files_dict[outg_rec_nb])\n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = ami_df[ami_df['OUTG_REC_NB_GPD_FOR_SQL']==outg_rec_nb].copy()\n",
    "    \n",
    "    # Although I cannot yet call choose_best_slicer_and_perform_slicing and reduce_INSTV_ABC_1_vals_in_df, \n",
    "    #   as the standard cleaning and conversions must be done first, I am able to cut down the size of\n",
    "    #   ami_df_i by joining the slicers with 'or' statements.\n",
    "    # Thus, ami_df_i will be reduced to only the subset of data which will be considered in \n",
    "    #   choose_best_slicer_and_perform_slicing\n",
    "    # As mentioned, this will cut down the size of ami_df_i and will also save time and resources by not having\n",
    "    #   to run entire DF through cleaning and conversions procedures.\n",
    "    ami_df_i = DFSlicer.combine_slicers_and_perform_slicing(\n",
    "        df=ami_df_i, \n",
    "        slicers=slicers, \n",
    "        join_slicers='or'\n",
    "    )\n",
    "    if ami_df.shape[0]==0:\n",
    "        continue\n",
    "        \n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = AMINonVee.perform_std_initiation_and_cleaning(ami_df_i)\n",
    "    #-----\n",
    "    # Should the following be added to AMINonVee.perform_std_initiation_and_cleaning?\n",
    "    ami_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df_i, \n",
    "        time_col='starttimeperiod', \n",
    "        placement_col='starttimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    ami_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "        df=ami_df_i, \n",
    "        time_col='endtimeperiod', \n",
    "        placement_col='endtimeperiod_local', \n",
    "        run_quick=True, \n",
    "        n_strip=6, \n",
    "        inplace=False\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    ami_df_i = choose_best_slicer_and_perform_slicing(\n",
    "        df=ami_df_i, \n",
    "        slicers=slicers, \n",
    "        groupby_SN=True, \n",
    "        t_search_min_max=None, \n",
    "        time_col='starttimeperiod_local', \n",
    "        value_col=None, \n",
    "        SN_col='serialnumber', \n",
    "        return_sorted=True\n",
    "    )\n",
    "\n",
    "    ami_df_i = reduce_INSTV_ABC_1_vals_in_df(\n",
    "        df=ami_df_i, \n",
    "        value_col='value', \n",
    "        aep_derived_uom_col='aep_derived_uom', \n",
    "        aep_srvc_qlty_idntfr_col='aep_srvc_qlty_idntfr', \n",
    "        output_aep_srvc_qlty_idntfr = 'INSTV(ABC)1'\n",
    "    )\n",
    "\n",
    "    if ami_df_i.shape[0]==0:\n",
    "        continue\n",
    "        \n",
    "    #-------------------------\n",
    "    # Each serial number should have a single value per time stamp\n",
    "    assert(ami_df_i.groupby(['serialnumber', 'starttimeperiod_local']).ngroups == ami_df_i.shape[0])\n",
    "\n",
    "    #-------------------------\n",
    "    if run_outg_inclusion_assessment:\n",
    "        to_include_i = assess_outage_inclusion_requirements(\n",
    "            ami_df_i=ami_df_i, \n",
    "            outg_rec_nb=outg_rec_nb, \n",
    "            dovs_df=dovs_df, \n",
    "            max_pct_PNs_missing_allowed=0\n",
    "\n",
    "        )\n",
    "        if not to_include_i:\n",
    "            print(f'outg_rec_nb={outg_rec_nb} did not pass inclusion requirements, skipping!!!!!')\n",
    "            continue\n",
    "    #-------------------------    \n",
    "    n_SNs  = ami_df_i['serialnumber'].nunique()\n",
    "    n_PNs  = ami_df_i['aep_premise_nb'].nunique()\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # NOTE: Can save time by grabbing ede_df_i then performing tz conversion and adding DOVS\n",
    "    if outg_rec_nb not in outg_rec_nb_to_files_ede_dict.keys():\n",
    "        ede_df_i=None\n",
    "    else:\n",
    "        ede_df = GenAn.read_df_from_csv_batch(outg_rec_nb_to_files_ede_dict[outg_rec_nb])\n",
    "        ede_df_i = ede_df[ede_df['OUTG_REC_NB_GPD_FOR_SQL']==outg_rec_nb].copy()\n",
    "\n",
    "        #-----\n",
    "        ede_df_i = Utilities_dt.strip_tz_info_and_convert_to_dt(\n",
    "            df=ede_df_i, \n",
    "            time_col='valuesinterval', \n",
    "            placement_col='valuesinterval_local', \n",
    "            run_quick=True, \n",
    "            n_strip=6, \n",
    "            inplace=False\n",
    "        )\n",
    "        ede_df_i = AMIEndEvents.reduce_end_event_reasons_in_df(df=ede_df_i)\n",
    "        #-----\n",
    "        ede_cols_to_keep = [\n",
    "            'valuesinterval_local', \n",
    "            'reason', \n",
    "            'serialnumber', \n",
    "            'aep_premise_nb', \n",
    "            'enddeviceeventtypeid', \n",
    "            'event_type', \n",
    "            'OUTG_REC_NB_GPD_FOR_SQL', \n",
    "            'trsf_pole_nb_GPD_FOR_SQL',\n",
    "        ]\n",
    "        ede_df_i = ede_df_i[ede_cols_to_keep]\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    dovs_df_i = DOVSOutages.retrieve_outage_from_dovs_df(\n",
    "        dovs_df=dovs_df, \n",
    "        outg_rec_nb=outg_rec_nb, \n",
    "        outg_rec_nb_idfr='index', \n",
    "        assert_outg_rec_nb_found=True\n",
    "    )\n",
    "    assert(dovs_df_i.shape[0]==1)\n",
    "    # Get the outage time from DOVS\n",
    "    dovs_outg_t_beg_end = dovs_df_i.iloc[0][['DT_OFF_TS_FULL', 'DT_ON_TS']].tolist()\n",
    "    assert(len(dovs_outg_t_beg_end)==2)\n",
    "    dovs_outg_t_beg, dovs_outg_t_end = dovs_outg_t_beg_end\n",
    "    #-------------------------\n",
    "    # Get the CI and CMI from DOVS\n",
    "    ci_cmi_dovs = dovs_df_i.iloc[0][['CI_NB', 'CMI_NB']].tolist()\n",
    "    assert(len(ci_cmi_dovs)==2)\n",
    "    ci_dovs, cmi_dovs = ci_cmi_dovs\n",
    "    #-------------------------\n",
    "    # Get the number of premises from DOVS\n",
    "    n_PNs_dovs = len(set(dovs_df_i.iloc[0]['premise_nbs']))\n",
    "    #-------------------------\n",
    "    # Get the outage number from DOVS\n",
    "    outage_nb = dovs_df_i.iloc[0]['OUTAGE_NB']\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    res_dict = calculate_ci_cmi_w_ami_w_ede_help(\n",
    "        df=ami_df_i, \n",
    "        ede_df=ede_df_i, \n",
    "        dovs_outg_t_beg_end=dovs_outg_t_beg_end, \n",
    "        expand_outg_search_time=expand_outg_search_time, \n",
    "        conservative_estimate=True, \n",
    "        est_ede_kwargs=dict(use_full_ede_outgs=use_full_ede_outgs), \n",
    "        audit_selection_method='ede only', \n",
    "        return_CI_SNs=False, \n",
    "        use_est_outg_times=use_est_outg_times, \n",
    "        pct_SNs_required_for_outage_est=0, \n",
    "        expand_outg_est_search_time=expand_outg_est_search_time, \n",
    "        use_only_overall_endpoints_of_est_outg_times=False, \n",
    "        time_col='starttimeperiod_local', \n",
    "        value_col='value', \n",
    "        SN_col='serialnumber', \n",
    "        return_all_best_ests=True, \n",
    "        return_all_best_ests_type='pd.DataFrame'\n",
    "    )\n",
    "    #-----\n",
    "    ci_ami       = res_dict['CI']\n",
    "    cmi_ami      = res_dict['CMI']\n",
    "    best_ests_df = res_dict['all_best_ests']\n",
    "    #--------------------------------------------------\n",
    "    if calculate_by_PN and best_ests_df.shape[0]>0:\n",
    "        best_ests_df = combine_PNs_in_best_ests_df(\n",
    "            best_ests_df, \n",
    "            likeness_thresh = combine_by_PN_likeness_thresh, \n",
    "            SN_col = 'SN', \n",
    "            PN_col = 'PN', \n",
    "            i_outg_col = 'i_outg'     \n",
    "        )\n",
    "        ci_ami  = best_ests_df['PN'].nunique()\n",
    "        cmi_ami = (best_ests_df['winner_max']-best_ests_df['winner_min']).sum().total_seconds()/60\n",
    "    #--------------------------------------------------\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        means_df, best_ests_df_w_db_lbl = get_mean_times_w_dbscan(\n",
    "            best_ests_df, \n",
    "            eps_min=5, \n",
    "            min_samples=2, \n",
    "            ests_to_include_in_clustering=['winner_min', 'winner_max'],\n",
    "            ests_to_include_in_output=[\n",
    "                'winner_min', 'winner_max', \n",
    "                'conservative_min', 'conservative_max', \n",
    "                'zero_times_min', 'zero_times_max'\n",
    "            ], \n",
    "            return_labelled_best_ests_df=True\n",
    "        )\n",
    "        #-----\n",
    "        detailed_summary_df_i = build_detailed_summary_df(\n",
    "            means_df=means_df, \n",
    "            best_ests_df_w_db_lbl=best_ests_df_w_db_lbl,\n",
    "            CI_tot=ci_ami, \n",
    "            CMI_tot=cmi_ami, \n",
    "            n_PNs_ami=n_PNs,\n",
    "            outg_rec_nb=outg_rec_nb, \n",
    "            dovs_df_i=dovs_df_i, \n",
    "            db_label_col='db_label', \n",
    "            winner_min_col='winner_min', \n",
    "            winner_max_col='winner_max', \n",
    "            PN_col='PN' if calculate_by_PN else 'SN', \n",
    "            i_outg_col='i_outg'\n",
    "        )\n",
    "        all_detailed_summary_dfs.append(detailed_summary_df_i)\n",
    "    else:\n",
    "        means_df, best_ests_df_w_db_lbl = None, None\n",
    "    #-------------------------\n",
    "    ci_cmi_summary_df = pd.concat([\n",
    "        ci_cmi_summary_df, \n",
    "        pd.DataFrame(\n",
    "            dict(\n",
    "                outg_rec_nb=outg_rec_nb, \n",
    "                ci_dovs=ci_dovs,   ci_ami=ci_ami, \n",
    "                cmi_dovs=cmi_dovs, cmi_ami=cmi_ami\n",
    "            ), \n",
    "            index=[ci_cmi_summary_df.shape[0]]\n",
    "        )\n",
    "    ])\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    # ######################### PLOTTING #########################\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    if means_df is not None:\n",
    "        cnsrvtv_out_t_beg = np.min([means_df.min().min(), dovs_outg_t_beg])\n",
    "        cnsrvtv_out_t_end = np.max([means_df.max().max(), dovs_outg_t_end])\n",
    "    else:\n",
    "        cnsrvtv_out_t_beg = dovs_outg_t_beg\n",
    "        cnsrvtv_out_t_end = dovs_outg_t_end\n",
    "    #--------------------------------------------------\n",
    "    # Instead of using get_full_part_not_outage_subset_dfs, simply grab the PNs which suffered\n",
    "    #   outages from best_ests_df\n",
    "    if best_ests_df.shape[0]>0:\n",
    "        outg_SNs = best_ests_df['PN'].unique().tolist()\n",
    "    else:\n",
    "        outg_SNs = []\n",
    "    #-----\n",
    "    ami_df_i_out      = ami_df_i[ami_df_i['aep_premise_nb'].isin(outg_SNs)]\n",
    "    ami_df_i_not_out  = ami_df_i[~ami_df_i['aep_premise_nb'].isin(outg_SNs)]  \n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    fig, axs = Plot_General.default_subplots(\n",
    "        n_x=1,\n",
    "        n_y=3,\n",
    "        fig_num=fig_num,\n",
    "        sharex=False,\n",
    "        sharey=False,\n",
    "        unit_figsize_width=14,\n",
    "        unit_figsize_height=6, \n",
    "        return_flattened_axes=True,\n",
    "        row_major=True\n",
    "    )\n",
    "    Plot_General.adjust_subplots_args(fig, dict(hspace=0.30))\n",
    "\n",
    "    palette = Plot_General.get_standard_colors_dict(\n",
    "        keys=ami_df_i['serialnumber'].unique().tolist(), \n",
    "        palette='colorblind'\n",
    "    )\n",
    "\n",
    "    #-------------------------\n",
    "    i_subplot=0\n",
    "    fig, axs[i_subplot] = AMINonVee.plot_usage_around_outage(\n",
    "        fig=fig, \n",
    "        ax=axs[i_subplot], \n",
    "        data=ami_df_i, \n",
    "        x='starttimeperiod_local', \n",
    "        y='value', \n",
    "        hue='serialnumber', \n",
    "        out_t_beg=dovs_outg_t_beg, \n",
    "        out_t_end=dovs_outg_t_end, \n",
    "        expand_time=pd.Timedelta('1 hour'), \n",
    "        plot_time_beg_end=[cnsrvtv_out_t_beg, cnsrvtv_out_t_end], \n",
    "        data_label='', \n",
    "        title_args=dict(label=f\"All (#SNs = {ami_df_i['serialnumber'].nunique()})\", fontdict=dict(fontsize=24)), \n",
    "        ax_args=None, \n",
    "        xlabel_args=None, \n",
    "        ylabel_args=None, \n",
    "        df_mean=None, \n",
    "        df_mean_col=None, \n",
    "        mean_args=None, \n",
    "        draw_outage_limits=True, \n",
    "        draw_outage_limits_kwargs=dict(alpha=1.0, linewidth=5.0, ymax=0.1), \n",
    "        include_outage_limits_text=dict(\n",
    "            out_t_beg_text='DOVS Beg.', \n",
    "            out_t_beg_ypos=(0.12, 'ax_coord'), \n",
    "            out_t_beg_va='bottom', \n",
    "            out_t_beg_ha='center', \n",
    "            out_t_beg_color='red', \n",
    "            #-----\n",
    "            out_t_end_text='DOVS End', \n",
    "            out_t_end_ypos=(0.12, 'ax_coord'), \n",
    "            out_t_end_va='bottom', \n",
    "            out_t_end_ha='center', \n",
    "            out_t_end_color='green', \n",
    "        ), \n",
    "        draw_without_hue_also=False, \n",
    "        seg_line_freq=None, \n",
    "        palette=palette\n",
    "    )\n",
    "    axs[i_subplot].legend().set_visible(False)\n",
    "    Plot_General.set_general_plotting_args(\n",
    "        ax=axs[i_subplot], \n",
    "        tick_args =[\n",
    "            dict(axis='x', labelrotation=0, labelsize=14.0, direction='out'), \n",
    "            dict(axis='y', labelrotation=0, labelsize=14.0, direction='out')\n",
    "        ], \n",
    "        xlabel_args=dict(xlabel=axs[i_subplot].get_xlabel(), fontsize=16), \n",
    "        ylabel_args=dict(ylabel=axs[i_subplot].get_ylabel(), fontsize=16)\n",
    "    )\n",
    "\n",
    "\n",
    "    #-------------------------\n",
    "    i_subplot=1\n",
    "    if ami_df_i_out.shape[0]>0:\n",
    "        fig, axs[i_subplot] = AMINonVee.plot_usage_around_outage(\n",
    "            fig=fig, \n",
    "            ax=axs[i_subplot], \n",
    "            data=ami_df_i_out, \n",
    "            x='starttimeperiod_local', \n",
    "            y='value', \n",
    "            hue='serialnumber', \n",
    "            out_t_beg=dovs_outg_t_beg, \n",
    "            out_t_end=dovs_outg_t_end, \n",
    "            expand_time=pd.Timedelta('1 hour'), \n",
    "            plot_time_beg_end=[cnsrvtv_out_t_beg, cnsrvtv_out_t_end], \n",
    "            data_label='', \n",
    "            title_args=dict(label=f\"Out (#SNs = {ami_df_i_out['serialnumber'].nunique()})\", fontdict=dict(fontsize=24)), \n",
    "            ax_args=None, \n",
    "            xlabel_args=None, \n",
    "            ylabel_args=None, \n",
    "            df_mean=None, \n",
    "            df_mean_col=None, \n",
    "            mean_args=None, \n",
    "            draw_outage_limits=True, \n",
    "            draw_outage_limits_kwargs=dict(alpha=1.0, linewidth=5.0, ymax=0.1), \n",
    "            include_outage_limits_text=dict(\n",
    "                out_t_beg_text='DOVS Beg.', \n",
    "                out_t_beg_ypos=(0.12, 'ax_coord'), \n",
    "                out_t_beg_va='bottom', \n",
    "                out_t_beg_ha='center', \n",
    "                out_t_beg_color='red', \n",
    "                #-----\n",
    "                out_t_end_text='DOVS End', \n",
    "                out_t_end_ypos=(0.12, 'ax_coord'), \n",
    "                out_t_end_va='bottom', \n",
    "                out_t_end_ha='center', \n",
    "                out_t_end_color='green', \n",
    "            ), \n",
    "            draw_without_hue_also=False, \n",
    "            seg_line_freq=None, \n",
    "            palette=palette\n",
    "        )\n",
    "        axs[i_subplot].legend().set_visible(False)\n",
    "        add_all_best_ests_to_axis(\n",
    "            axs[i_subplot], \n",
    "            means_df, \n",
    "            line_kwargs_by_est_key=dict(\n",
    "                conservative=dict(alpha=0.25, linewidth=5.0, ymax=0.6), \n",
    "                zero_times=dict(alpha=0.25, linewidth=5.0, ymax=0.4) \n",
    "            ), \n",
    "            keys_to_include=['winner', 'conservative', 'zero_times']\n",
    "        )\n",
    "\n",
    "        #-------------------------\n",
    "        if mico_df_for_plt is None:\n",
    "            include_mico_in_leg = False\n",
    "        else:\n",
    "            mico_df_for_plt_i = mico_df_for_plt[\n",
    "                (mico_df_for_plt['OUTAGE_NB']==dovs_df.loc[outg_rec_nb]['OUTAGE_NB']) & \n",
    "                (mico_df_for_plt['OUTG_REC_NB']==outg_rec_nb)\n",
    "            ]\n",
    "            if mico_df_for_plt_i.shape[0]>0:\n",
    "                assert(mico_df_for_plt_i.shape[0]==1)\n",
    "                include_mico_in_leg = True\n",
    "                mico_beg, mico_end = mico_df_for_plt_i.iloc[0][['Final Outage Start', 'Final Outage End']]\n",
    "                add_best_est_to_axis(\n",
    "                    ax=axs[i_subplot], \n",
    "                    est_val_beg=mico_beg,\n",
    "                    est_val_end=mico_end,\n",
    "                    line_kwargs=dict(color_beg='maroon', color_end='darkgreen', linestyle='dotted'), \n",
    "                    expand_ax_to_accommodate=False\n",
    "                )\n",
    "            else:\n",
    "                include_mico_in_leg = False\n",
    "        #-------------------------\n",
    "\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            ax=axs[i_subplot], \n",
    "            tick_args =[\n",
    "                dict(axis='x', labelrotation=0, labelsize=14.0, direction='out'), \n",
    "                dict(axis='y', labelrotation=0, labelsize=14.0, direction='out')\n",
    "            ], \n",
    "            xlabel_args=dict(xlabel=axs[i_subplot].get_xlabel(), fontsize=16), \n",
    "            ylabel_args=dict(ylabel=axs[i_subplot].get_ylabel(), fontsize=16)\n",
    "        )\n",
    "    else:\n",
    "        axs[i_subplot].set_title(\n",
    "            label=f'Out', \n",
    "            fontdict=dict(fontsize=24)\n",
    "        )\n",
    "\n",
    "    #-------------------------\n",
    "    i_subplot=2\n",
    "    if ami_df_i_not_out.shape[0]>0:\n",
    "        fig, axs[i_subplot] = AMINonVee.plot_usage_around_outage(\n",
    "            fig=fig, \n",
    "            ax=axs[i_subplot], \n",
    "            data=ami_df_i_not_out, \n",
    "            x='starttimeperiod_local', \n",
    "            y='value', \n",
    "            hue='serialnumber', \n",
    "            out_t_beg=dovs_outg_t_beg, \n",
    "            out_t_end=dovs_outg_t_end, \n",
    "            expand_time=pd.Timedelta('1 hour'), \n",
    "            plot_time_beg_end=[cnsrvtv_out_t_beg, cnsrvtv_out_t_end], \n",
    "            data_label='', \n",
    "            title_args=dict(label=f\"Not Out (#SNs = {ami_df_i_not_out['serialnumber'].nunique()})\", fontdict=dict(fontsize=24)), \n",
    "            ax_args=None, \n",
    "            xlabel_args=None, \n",
    "            ylabel_args=None, \n",
    "            df_mean=None, \n",
    "            df_mean_col=None, \n",
    "            mean_args=None, \n",
    "            draw_outage_limits=True, \n",
    "            draw_outage_limits_kwargs=dict(alpha=1.0, linewidth=5.0, ymax=0.1), \n",
    "            include_outage_limits_text=dict(\n",
    "                out_t_beg_text='DOVS Beg.', \n",
    "                out_t_beg_ypos=(0.12, 'ax_coord'), \n",
    "                out_t_beg_va='bottom', \n",
    "                out_t_beg_ha='center', \n",
    "                out_t_beg_color='red', \n",
    "                #-----\n",
    "                out_t_end_text='DOVS End', \n",
    "                out_t_end_ypos=(0.12, 'ax_coord'), \n",
    "                out_t_end_va='bottom', \n",
    "                out_t_end_ha='center', \n",
    "                out_t_end_color='green', \n",
    "            ), \n",
    "            draw_without_hue_also=False, \n",
    "            seg_line_freq=None, \n",
    "            palette=palette\n",
    "        )\n",
    "        axs[i_subplot].legend().set_visible(False)\n",
    "        Plot_General.set_general_plotting_args(\n",
    "            ax=axs[i_subplot], \n",
    "            tick_args =[\n",
    "                dict(axis='x', labelrotation=0, labelsize=14.0, direction='out'), \n",
    "                dict(axis='y', labelrotation=0, labelsize=14.0, direction='out')\n",
    "            ], \n",
    "            xlabel_args=dict(xlabel=axs[i_subplot].get_xlabel(), fontsize=16), \n",
    "            ylabel_args=dict(ylabel=axs[i_subplot].get_ylabel(), fontsize=16)\n",
    "        )\n",
    "    else:\n",
    "        axs[i_subplot].set_title(label='Not Out', fontdict=dict(fontsize=24))\n",
    "\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # Add legend to first plot\n",
    "    patch_dovs_beg = Line2D(\n",
    "        [0], [0], color='red', \n",
    "        alpha=1.0, linewidth=5.0, linestyle='-', \n",
    "        label='DOVS Beg.'\n",
    "    )\n",
    "    patch_dovs_end = Line2D(\n",
    "        [0], [0], color='green', \n",
    "        alpha=1.0, linewidth=5.0, linestyle='-', \n",
    "        label='DOVS End'\n",
    "    )\n",
    "    #-----\n",
    "    patch_ui_beg =  Line2D(\n",
    "        [0], [0], color='red', \n",
    "        alpha=1.0, linewidth=5.0, linestyle=':', \n",
    "        label='Beg. Uncertainty Interval'\n",
    "    )\n",
    "    patch_ui_end =  Line2D(\n",
    "        [0], [0], color='green', \n",
    "        alpha=1.0, linewidth=5.0, linestyle=':', \n",
    "        label='End Uncertainty Interval'\n",
    "    )\n",
    "    #-----\n",
    "    patch_best_beg =  Line2D(\n",
    "        [0], [0], color='red', \n",
    "        alpha=1.0, linewidth=1.0, linestyle='--', \n",
    "        label='Best Est. Beg.'\n",
    "    )\n",
    "    patch_best_end =  Line2D(\n",
    "        [0], [0], color='green', \n",
    "        alpha=1.0, linewidth=1.0, linestyle='--', \n",
    "        label='Best Est. End'\n",
    "    )\n",
    "    #-------------------------\n",
    "    handles=[patch_dovs_beg, patch_dovs_end, patch_ui_beg, patch_ui_end, patch_best_beg, patch_best_end]\n",
    "    if include_mico_in_leg:\n",
    "        patch_mico_beg =  Line2D(\n",
    "            [0], [0], color='maroon', \n",
    "            alpha=1.0, linewidth=1.0, linestyle='dotted', \n",
    "            label='Mico Xlsx Beg.'\n",
    "        )\n",
    "        patch_mico_end =  Line2D(\n",
    "            [0], [0], color='darkgreen', \n",
    "            alpha=1.0, linewidth=1.0, linestyle='dotted', \n",
    "            label='Mico Xlsx End'\n",
    "        )\n",
    "        handles.extend([patch_mico_beg, patch_mico_end])\n",
    "    #-------------------------\n",
    "    leg_1 = axs[0].legend(\n",
    "        title=None, \n",
    "        handles=handles, \n",
    "        bbox_to_anchor=(1, 1.025), \n",
    "        loc='upper left', \n",
    "        fontsize=15\n",
    "    )        \n",
    "\n",
    "    #--------------------------------------------------\n",
    "    ci_info_fontsize = 20\n",
    "    left_text_x=0.95\n",
    "    right_text_x = 1.05\n",
    "    if include_mico_in_leg:\n",
    "        shift_text_down = 0.05\n",
    "    else:\n",
    "        shift_text_down = 0\n",
    "\n",
    "    fig.text(left_text_x, 0.745-shift_text_down, f'OUTG_REC_NB: {outg_rec_nb}', fontsize=ci_info_fontsize+4)\n",
    "    fig.text(left_text_x, 0.715-shift_text_down, f\"OUTAGE_NB:     {dovs_df.loc[outg_rec_nb]['OUTAGE_NB']}\", fontsize=ci_info_fontsize+4)\n",
    "\n",
    "    fig.text(left_text_x, 0.675-shift_text_down, f\"#PNs from DOVS = {n_PNs_dovs}\", fontsize=ci_info_fontsize)\n",
    "\n",
    "    fig.text(left_text_x, 0.640-shift_text_down, \"----- Found in AMI -----\", fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.615-shift_text_down, f\"#PNs = {n_PNs}\", fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.590-shift_text_down, f\"#SNs = {n_SNs}\", fontsize=ci_info_fontsize)\n",
    "\n",
    "    fig.text(left_text_x, 0.485-shift_text_down, '-----'*5+'\\nDOVS\\n'+'-----'*5, fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.460-shift_text_down, f'CI    = {ci_dovs}', fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.435-shift_text_down, f'CMI = {np.round(cmi_dovs, decimals=2)}', fontsize=ci_info_fontsize)\n",
    "\n",
    "    fig.text(left_text_x, 0.360-shift_text_down, '-----'*5+'\\nUsing AMI\\n'+'-----'*5, fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.335-shift_text_down, f'CI    = {ci_ami}', fontsize=ci_info_fontsize)\n",
    "    fig.text(left_text_x, 0.310-shift_text_down, f'CMI = {np.round(cmi_ami, decimals=2)}', fontsize=ci_info_fontsize)\n",
    "    #-----\n",
    "    fig.text(\n",
    "        left_text_x, 0.285-shift_text_down, \n",
    "        f'$\\Delta$CI    = {ci_dovs-ci_ami} ({np.round(100*(ci_dovs-ci_ami)/ci_dovs, decimals=2)}%)', \n",
    "        fontsize=ci_info_fontsize\n",
    "    )\n",
    "    fig.text(\n",
    "        left_text_x, 0.260-shift_text_down, \n",
    "        f'$\\Delta$CMI = {np.round(cmi_dovs-cmi_ami, decimals=2)} ({np.round(100*(cmi_dovs-cmi_ami)/cmi_dovs, decimals=2)}%)', \n",
    "        fontsize=ci_info_fontsize\n",
    "    )\n",
    "\n",
    "    fig_num += 1\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "detailed_summary_df = pd.concat(all_detailed_summary_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()\n",
    "detailed_summary_df.to_pickle(os.path.join(save_dir, r'SummaryNEW_PN2_NEWEDEMETHOD.pkl'))\n",
    "#-----\n",
    "# detailed_summary_df.to_csv(os.path.join(save_dir, r'SummaryNEW.csv'), index=True)\n",
    "# #-----\n",
    "# detailed_summary_df_for_csv = drop_multiindex_duplicate_idxs_for_csv_output(detailed_summary_df.copy())\n",
    "# detailed_summary_df_for_csv.to_csv(os.path.join(save_dir, r'Summary_dropMultiNEW.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba36e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cmi_summary_df['ci_dovs']   = ci_cmi_summary_df['ci_dovs'].astype(float)\n",
    "ci_cmi_summary_df['ci_ami'] = ci_cmi_summary_df['ci_ami'].astype(float)\n",
    "#-----\n",
    "ci_cmi_summary_df['delta_ci_dovs_ami']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami']\n",
    "ci_cmi_summary_df['delta_cmi_dovs_ami'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami']\n",
    "#-----\n",
    "# For plotting purposes, make a outg_rec_in column which is simply 0 to delta_df.shape[0]-1\n",
    "ci_cmi_summary_df['outg_rec_int'] = range(ci_cmi_summary_df.shape[0])\n",
    "#-----\n",
    "ci_cmi_summary_df.to_pickle(os.path.join(save_dir, r'ci_cmi_summary.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc182092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef8023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56c673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1afda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdffd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\Summary.pkl')\n",
    "summary_df = Utilities_df.convert_col_types(summary_df, {'outg_i_beg':datetime.datetime, 'outg_i_end':datetime.datetime})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6751011",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_outages = Utilities.get_utldb01p_oracle_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e20882",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgs_file_from_mico = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\2023-04-08 to 04-15 Reviews (1).xlsx'\n",
    "expand_time = pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65724ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "mico_df_raw = pd.read_excel(outgs_file_from_mico, sheet_name='Scorecard')\n",
    "mico_df = mico_df_raw.copy()\n",
    "#-----\n",
    "# For now, keep only the following columns:\n",
    "mico_cols_to_keep = [\n",
    "    'Outage #', \n",
    "    'Outage Start DT', \n",
    "    'Adj Outage Start DT', \n",
    "    'Outage End DT',\n",
    "    'Adj Outage End DT', \n",
    "    'Circuit Name',\n",
    "    'Step CMI', \n",
    "    \n",
    "    'Count of AMI Flag',\n",
    "    'Count of AMI Y/N',\n",
    "    'Min of Outage % AMI', \n",
    "    \n",
    "    'Analyst Comments'\n",
    "]\n",
    "mico_df = mico_df[mico_cols_to_keep]\n",
    "\n",
    "# NOTE: Although 'Min of Outage % AMI' column appears on range 0-100% in Excel, when read in as csv,\n",
    "#       it is converted to range 0-1\n",
    "mico_df['Min of Outage % AMI'] = 100.*mico_df['Min of Outage % AMI']\n",
    "\n",
    "#-------------------------\n",
    "# Currently, outage numbers have -1, -2, etc. appended.\n",
    "# I believe an outage number will have such multiple rows when the outage affects more than one circuit.\n",
    "# In the DOVS database, these will be split iunto separate outg_rec_nbs\n",
    "#-----\n",
    "# I will instead merge the data via the outage number and circuit name, so remove the -1, -2, etc. from \n",
    "#   the 'Outage #', store the result in 'OUTAGE_NB' (to be consistent with DOVS), and drop 'Outage #'\n",
    "mico_df['OUTAGE_NB'] = mico_df['Outage #'].apply(lambda x: re.sub('(\\d*)-\\d*', r'\\1', x))\n",
    "mico_df=mico_df.drop(columns=['Outage #'])\n",
    "\n",
    "#-------------------------\n",
    "# Each outage can also have multiple rows corresponding to the power recover steps\n",
    "# Aggregate the steps into a single row for each outage\n",
    "mico_df = mico_df.groupby(\n",
    "    ['OUTAGE_NB', 'Circuit Name'], \n",
    "    dropna=False, \n",
    "    as_index=False, \n",
    "    group_keys=False\n",
    ").agg({\n",
    "    'Outage Start DT':     'min', \n",
    "    'Adj Outage Start DT': 'min', \n",
    "    'Outage End DT':       'max', \n",
    "    'Adj Outage End DT':   'max', \n",
    "    'Step CMI':            'sum', \n",
    "    \n",
    "    'Count of AMI Flag':   'first',\n",
    "    'Count of AMI Y/N':    'first',\n",
    "    'Min of Outage % AMI': 'first', \n",
    "    \n",
    "    'Analyst Comments': 'first'\n",
    "})\n",
    "\n",
    "# At this point, each outage (unique combinatino of 'OUTAGE_NB' and 'Circuit Name') should\n",
    "#   correspond to a single row\n",
    "assert(mico_df.shape[0] == mico_df.groupby(['OUTAGE_NB', 'Circuit Name']).ngroups)\n",
    "\n",
    "#-------------------------\n",
    "mico_df['Min Start Date'] = mico_df[['Outage Start DT', 'Adj Outage Start DT']].min(axis=1).dt.date - expand_time\n",
    "mico_df['Max End Date']   = mico_df[['Outage End DT',   'Adj Outage End DT'  ]].max(axis=1).dt.date + expand_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8fa367",
   "metadata": {},
   "outputs": [],
   "source": [
    "mico_df['OUTAGE_NB'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mico_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff908bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# NOTE: A single OUTAGE_NB can correspond to more than one OUTG_REC_NBs!\n",
    "#       It appears this is the case when the outage affects multiple GIS_CRCT_NBs, in which case,\n",
    "#         each GIS_CRCT_NB gets its own OUTG_REC_NB\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# First, grab DF containing all OUTAGE_NBs\n",
    "# Note, the OUTAGE_NB is not unique, so there will generally be multiple entries\n",
    "#   Here, I'm talking about the same OUTAGE_NB being used for different outages throughout the years, \n",
    "#     not a single OUTAGE_NB corresponding to multiple OUTG_REC_NBs, as described above.\n",
    "#   Determine which is correct entry using the times from mico_df\n",
    "sql_using_outage_nbs = DOVSOutages_SQL.build_sql_std_outage(\n",
    "    mjr_mnr_cause=None, \n",
    "    include_premise=True, \n",
    "    outage_nbs=mico_df['OUTAGE_NB'].unique().tolist(), \n",
    "    date_range=[mico_df['Min Start Date'].min(), mico_df['Max End Date'].max()], \n",
    "    MJR_CAUSE_CD=None, \n",
    "    DEVICE_CD=None, \n",
    "    INTRPTN_TYP_CD=None, \n",
    "    CURR_REC_STAT_CD=None, \n",
    "    select_cols_DOVS_PREMISE_DIM=['CIRCT_NM']\n",
    ").get_sql_statement()\n",
    "#-----\n",
    "df_using_outage_nbs = pd.read_sql_query(\n",
    "    sql_using_outage_nbs, \n",
    "    conn_outages, \n",
    "    dtype={\n",
    "        'CI_NB':np.int32, \n",
    "        'CMI_NB':np.float64, \n",
    "        'OUTG_REC_NB':np.int32\n",
    "    }\n",
    ")\n",
    "#-------------------------\n",
    "# Determine appropriate OUTG_REC_NBs by using 'Min Start Date', 'Max End Date'\n",
    "df_using_outage_nbs = pd.merge(\n",
    "    df_using_outage_nbs, \n",
    "    mico_df[['OUTAGE_NB', 'Circuit Name', 'Min Start Date', 'Max End Date']], \n",
    "    left_on=['OUTAGE_NB', 'CIRCT_NM'], \n",
    "    right_on=['OUTAGE_NB', 'Circuit Name'], \n",
    "    how='inner'\n",
    ")\n",
    "df_using_outage_nbs= df_using_outage_nbs[\n",
    "    (df_using_outage_nbs['DT_OFF_TS_FULL'].dt.date >= df_using_outage_nbs['Min Start Date']) & \n",
    "    (df_using_outage_nbs['DT_ON_TS'].dt.date       <= df_using_outage_nbs['Max End Date'])\n",
    "]\n",
    "df_using_outage_nbs = df_using_outage_nbs.drop(columns=['Min Start Date', 'Max End Date', 'Circuit Name'])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54d2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outage = df_using_outage_nbs\n",
    "outg_rec_nbs_all = df_outage['OUTG_REC_NB'].unique().tolist()\n",
    "#-----\n",
    "print(f\"df_outage.shape = {df_outage.shape}\")\n",
    "print(f\"# OUTG_REC_NBs  = {df_outage['OUTG_REC_NB'].nunique()}\")\n",
    "\n",
    "# NOTE: Keep CIRCT_NM (although it comes from DOVS_PREMISE_DIM), as this will be used to merge as there exist \n",
    "#         duplicate OUTAGE_NB entries in Mico's df which have different OUTG_REC_NBs if the outage affects multiple circuits\n",
    "df_outage_noPNs = df_outage.drop(columns=['OFF_TM', 'REST_TM', 'PREMISE_NB']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de002355",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21449293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outage_noPNs.groupby(['OUTG_REC_NB', 'OUTAGE_NB']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.groupby(['OUTG_REC_NB', 'OUTAGE_NB']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg = summary_df[summary_df['Outage Subset']=='Full Outage'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outage_noPNs['OUTG_REC_NB'] = df_outage_noPNs['OUTG_REC_NB'].astype(str)\n",
    "set(summary_df_to_mrg.groupby(['OUTAGE_NB', 'OUTG_REC_NB']).groups.keys()).difference(\n",
    "    set(df_outage_noPNs.groupby(['OUTAGE_NB', 'OUTG_REC_NB']).groups.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg=summary_df_to_mrg.merge(\n",
    "    df_outage_noPNs[['OUTAGE_NB', 'OUTG_REC_NB', 'CIRCT_NM', 'DT_OFF_TS_FULL', 'DT_ON_TS']], \n",
    "    left_on=['OUTAGE_NB', 'OUTG_REC_NB'], \n",
    "    right_on=['OUTAGE_NB', 'OUTG_REC_NB'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9429fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg=summary_df_to_mrg.merge(\n",
    "    mico_df, \n",
    "    left_on=['OUTAGE_NB', 'CIRCT_NM'], \n",
    "    right_on=['OUTAGE_NB', 'Circuit Name'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg['abs(Delta Start) (min.)'] = summary_df_to_mrg['Adj Outage Start DT'].fillna(summary_df_to_mrg['Outage Start DT']) - summary_df_to_mrg['outg_i_beg']\n",
    "summary_df_to_mrg['abs(Delta Start) (min.)'] = summary_df_to_mrg['abs(Delta Start) (min.)'].apply(lambda x: np.abs(np.round(x.total_seconds()/60, decimals=2)))\n",
    "#-----\n",
    "summary_df_to_mrg['abs(Delta End) (min.)'] = summary_df_to_mrg['Adj Outage End DT'].fillna(summary_df_to_mrg['Outage End DT']) - summary_df_to_mrg['outg_i_end']\n",
    "summary_df_to_mrg['abs(Delta End) (min.)'] = summary_df_to_mrg['abs(Delta End) (min.)'].apply(lambda x: np.abs(np.round(x.total_seconds()/60, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efdd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg_cols_order = [\n",
    "    'OUTAGE_NB',\n",
    "    'OUTG_REC_NB',\n",
    "    'Circuit Name', \n",
    "    \n",
    "    'DT_OFF_TS_FULL', \n",
    "    'Outage Start DT',\n",
    "    'Adj Outage Start DT',\n",
    "    'outg_i_beg',\n",
    "    'abs(Delta Start) (min.)', \n",
    "    \n",
    "    'DT_ON_TS', \n",
    "    'Outage End DT',\n",
    "    'Adj Outage End DT', \n",
    "    'outg_i_end',\n",
    "    'abs(Delta End) (min.)', \n",
    "    \n",
    "    'Count of AMI Flag',\n",
    "    'n_PNs_ami',\n",
    "    \n",
    "    'Count of AMI Y/N',\n",
    "    'n_PNs_dovs',\n",
    "    \n",
    "    'Min of Outage % AMI',\n",
    "    'pct_PNs_found',\n",
    "    \n",
    "    'Step CMI',\n",
    "    'CMI_i',\n",
    "    'CI_i',\n",
    "    \n",
    "    'Analyst Comments'\n",
    "]\n",
    "summary_df_to_mrg = summary_df_to_mrg[summary_df_to_mrg_cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fd719",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg=summary_df_to_mrg.rename(columns={\n",
    "    'DT_OFF_TS_FULL': 'Outage Start DT (DOVS)', \n",
    "    'outg_i_beg':     'Outage Start DT (JB)', \n",
    "    \n",
    "    'DT_ON_TS':   'Outage End DT (DOVS)', \n",
    "    'outg_i_end': 'Outage End DT (JB)', \n",
    "    \n",
    "    'n_PNs_ami':     'Count AMI PNs used (JB)', \n",
    "    'n_PNs_dovs':    'Count PNs DOVS', \n",
    "    'pct_PNs_found': '% DOVS PNs Used', \n",
    "    \n",
    "    'Step CMI': 'SUM(Step CMI)', \n",
    "    \n",
    "    'CMI_i': 'CMI (JB)', \n",
    "    'CI_i':  'CI (JB)'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df_to_mrg.to_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\Summary_mergeMicoXlsx_v0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg_w_empty_cols = summary_df_to_mrg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ccbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty columns will be placed before these\n",
    "cols_beg_gps = [\n",
    "    'Outage Start DT (DOVS)', \n",
    "    'Outage End DT (DOVS)', \n",
    "    'Count of AMI Flag', \n",
    "    'SUM(Step CMI)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8496a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(cols_beg_gps): \n",
    "    summary_df_to_mrg_w_empty_cols.insert(\n",
    "        loc=Utilities_df.find_idxs_in_highest_order_of_columns(summary_df_to_mrg_w_empty_cols, col)[0], \n",
    "        #column=f'SPACER {(i+1)}', \n",
    "        column=' '*20+' '*i, \n",
    "        value=['']*len(summary_df_to_mrg_w_empty_cols)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdd0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg_w_empty_cols.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_to_mrg_w_empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89606e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df_to_mrg_w_empty_cols.to_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\Summary_mergeMicoXlsx.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df_to_mrg_w_empty_cols[\n",
    "#     summary_df_to_mrg_w_empty_cols['Analyst Comments']=='UIQ'\n",
    "# ].to_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\Summary_mergeMicoXlsx_UIQ.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63470280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df_to_mrg_w_empty_cols[\n",
    "#     summary_df_to_mrg_w_empty_cols['Analyst Comments']=='UIQ'\n",
    "# ]['OUTG_REC_NB'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b728bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df_to_mrg_w_empty_cols[\n",
    "#     summary_df_to_mrg_w_empty_cols['Analyst Comments'].notna()\n",
    "# ].to_csv(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\Summary_mergeMicoXlsx_wComment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab457b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# summary_df_to_mrg_w_empty_cols[\n",
    "#     summary_df_to_mrg_w_empty_cols['Analyst Comments'].notna()\n",
    "# ]['OUTG_REC_NB'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b441f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7036b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f34940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\SummaryNEW_PN2.pkl')\n",
    "df2 = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\forMico2\\Results\\SummaryNEW_PN2_NEWEDEMETHOD.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.equals(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df1.index).difference(set(df2.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd052c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = Utilities_df.get_dfs_diff(df1.reset_index(), df2.reset_index())\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a03c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_outg_rec_nbs = df2.loc[list(set(df2.index).difference(set(df1.index)))].reset_index()['OUTG_REC_NB'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.index.get_level_values(1).isin(diff_outg_rec_nbs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5aaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.index.get_level_values(1).isin(diff_outg_rec_nbs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b97f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_comp = df1.loc[list(set(df1.index).intersection(set(df2.index)))].copy().reset_index()\n",
    "df_2_comp = df2.loc[list(set(df1.index).intersection(set(df2.index)))].copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f671670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = Utilities_df.get_dfs_diff_approx_ok(df_1_comp, df_2_comp, precision=0.00001, return_df_only=True)\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40693140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1_comp.loc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cmi_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a09e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\Results\\Results_ede_only_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3f289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
