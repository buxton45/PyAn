{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5161966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIEDE_DEV import AMIEDE_DEV\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad43c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reason_counts_per_group_QUICK(\n",
    "        end_events_df, \n",
    "        group_cols=['serialnumber', 'aep_premise_nb'], \n",
    "        group_freq=None, \n",
    "        gpby_dropna=True, \n",
    "        reason_col='reason'\n",
    "):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    #-------------------------\n",
    "    # String and tuple (for MultiIndex columns) used for single group_col, whereas\n",
    "    #   list used for multiple\n",
    "    assert(Utilities.is_object_one_of_types(group_cols, [str, list, tuple]))\n",
    "    if not isinstance(group_cols, list):\n",
    "        group_cols = [group_cols]\n",
    "    #-------------------------\n",
    "    tmp_idx_col=None #Only set if group_freq is str, in which case grouping index\n",
    "    if group_freq is not None:\n",
    "        assert(Utilities.is_object_one_of_types(group_freq, [str, pd.core.resample.TimeGrouper]))\n",
    "        if isinstance(group_freq, str):\n",
    "            # Grouping by time on index!  \n",
    "            # If one wants to group by time on column, need to supply full pd.Grouper object with \n",
    "            #   key argument equal to column\n",
    "            # HOWEVER, functionality is easier here when grouping by column instead of index, so reset_index\n",
    "            #   making it a column\n",
    "            tmp_idx_col = Utilities.generate_random_string()\n",
    "            assert(end_events_df.index.nlevels==1)\n",
    "            end_events_df = end_events_df.reset_index(drop=False, names=tmp_idx_col)\n",
    "            group_freq = pd.Grouper(freq=group_freq, key=tmp_idx_col)\n",
    "        #-----\n",
    "        grp_by_full = group_cols+[group_freq]\n",
    "    else:\n",
    "        grp_by_full = group_cols\n",
    "    #-------------------------\n",
    "    # First, get the number of counts in each group for each reason\n",
    "    # Must add reason to grp_by_full, if not already (set operation to ensure not added twice)\n",
    "    grp_by_full = list(set(grp_by_full+[reason_col]))\n",
    "    \n",
    "    # The result of this operation will be a DF with columns equal to grp_by_full+'size'\n",
    "    return_df = end_events_df.groupby(grp_by_full, dropna=gpby_dropna, as_index=False).size()\n",
    "    \n",
    "    #-------------------------\n",
    "    # Second, pivot about the reason column (with indices equal to all others in grp_by_full)\n",
    "    # So, reason_col must be removed form grp_by_full\n",
    "    # Also, if group_freq included, the item in grp_by_full needs to be changed from the pd.Grouper object\n",
    "    #   to the column used for grouping (i.e., to group_freq.key)\n",
    "    # NOTE: This will make the columns MultiIndex, with level_0 values equal to 'size' and level_1\n",
    "    #       values equal to the reasons.\n",
    "    # Any groups missing counts for various reasons will be filled with nan, hence the need for fillna(0)\n",
    "    grp_by_full.remove(reason_col)\n",
    "    if group_freq is not None:\n",
    "        grp_by_full.remove(group_freq)\n",
    "        grp_by_full.append(group_freq.key)\n",
    "    return_df = return_df.pivot(index=grp_by_full, columns=reason_col).fillna(0)\n",
    "    #-----\n",
    "    # Drop level 0 from columns (all values = 'size', as stated above)\n",
    "    # This will leave the reason columns.  However, this will give return_df.columns.name = reason_col, which\n",
    "    #   will be confusing after we reset the index to include the grp_by_full values.\n",
    "    # So, also rename the columns to None\n",
    "    return_df = return_df.droplevel(0, axis=1)\n",
    "    return_df.columns.name = None\n",
    "    return_df = return_df.reset_index()\n",
    "    \n",
    "    #-------------------------\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40bcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1f6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_base_raw = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\regex_check\\EndEvents'\n",
    "save_dir_base_cur = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\regex_check\\Case_Sensitive\\EndEvents_curated'\n",
    "save_dir_base_rcpo = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\regex_check\\Case_Sensitive\\RCPO_Quick'\n",
    "\n",
    "# save_dir_base_raw = r'U:\\CloudData\\dovs_and_end_events_data\\regex_check\\EndEvents'\n",
    "# save_dir_base_cur = r'U:\\CloudData\\dovs_and_end_events_data\\regex_check\\Case_Sensitive\\EndEvents_curated'\n",
    "# save_dir_base_rcpo = r'U:\\CloudData\\dovs_and_end_events_data\\regex_check\\Case_Sensitive\\RCPO_Quick'\n",
    "\n",
    "date_ranges = [\n",
    "    ['2023-04-01', '2023-04-07'], \n",
    "    ['2023-04-08', '2023-04-14'], \n",
    "    ['2023-04-15', '2023-04-21'], \n",
    "    ['2023-04-22', '2023-04-28'], \n",
    "    ['2023-04-29', '2023-05-05'], \n",
    "    ['2023-05-06', '2023-05-12'], \n",
    "    ['2023-05-13', '2023-05-19'], \n",
    "    ['2023-05-20', '2023-05-26'], \n",
    "    ['2023-05-27', '2023-05-31'], \n",
    "]\n",
    "opcos = [\n",
    "#     'ap', \n",
    "#     'oh', \n",
    "#     'im', \n",
    "#     'pso', \n",
    "#     'swp', \n",
    "    'tx'\n",
    "]\n",
    "\n",
    "freq='D'\n",
    "group_cols=['serialnumber', 'aep_premise_nb']\n",
    "group_freq=pd.Grouper(freq=freq, key='aep_event_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for opco in opcos:\n",
    "    for date_range in date_ranges:\n",
    "        end_events_sql_function_kwargs=dict(\n",
    "            date_range=date_range, \n",
    "            opco=opco\n",
    "        )\n",
    "        save_name = f\"end_events_{opco}_{date_range[0].replace('-','')}_{date_range[1].replace('-','')}.pkl\"\n",
    "        #-----\n",
    "        end_events = AMIEndEvents(\n",
    "            df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "            contstruct_df_args = None, \n",
    "            build_sql_function=AMIEndEvents_SQL.build_sql_end_events, \n",
    "            build_sql_function_kwargs=end_events_sql_function_kwargs, \n",
    "            init_df_in_constructor=True, \n",
    "            save_args=False\n",
    "        )\n",
    "        end_events.df.to_pickle(os.path.join(save_dir_base_raw, save_name))\n",
    "        #-------------------------\n",
    "        ede_df = end_events.df\n",
    "        #-----\n",
    "        ede_df = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "            df=ede_df, \n",
    "            reason_col='reason', \n",
    "            edetypeid_col='enddeviceeventtypeid',  \n",
    "            placement_col='curated_reason', \n",
    "            flags=0\n",
    "        )\n",
    "        #-----\n",
    "        ede_df.to_pickle(os.path.join(save_dir_base_cur, save_name))\n",
    "        #-------------------------\n",
    "        ede_df['aep_event_dt'] = pd.to_datetime(ede_df['aep_event_dt'])\n",
    "        #-----\n",
    "        rcpo_df = get_reason_counts_per_group_QUICK(\n",
    "            end_events_df=ede_df, \n",
    "            group_cols=group_cols, \n",
    "            group_freq=group_freq, \n",
    "            gpby_dropna=True, \n",
    "            reason_col='curated_reason'\n",
    "        )\n",
    "        #-----\n",
    "        rcpo_df.to_pickle(os.path.join(save_dir_base_rcpo, save_name))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ca601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for opco in opcos:\n",
    "#     for date_range in date_ranges:\n",
    "#         end_events_sql_function_kwargs=dict(\n",
    "#             date_range=date_range, \n",
    "#             opco=opco\n",
    "#         )\n",
    "#         save_name = f\"end_events_{opco}_{date_range[0].replace('-','')}_{date_range[1].replace('-','')}.pkl\"\n",
    "#         #-----\n",
    "#         end_events = AMIEndEvents(\n",
    "#             df_construct_type=DFConstructType.kRunSqlQuery, \n",
    "#             contstruct_df_args = None, \n",
    "#             build_sql_function=AMIEndEvents_SQL.build_sql_end_events, \n",
    "#             build_sql_function_kwargs=end_events_sql_function_kwargs, \n",
    "#             init_df_in_constructor=True, \n",
    "#             save_args=False\n",
    "#         )\n",
    "#         end_events.df.to_pickle(os.path.join(save_dir_base_raw, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98957b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for opco in opcos:\n",
    "#     for date_range in date_ranges:\n",
    "#         save_name = f\"end_events_{opco}_{date_range[0].replace('-','')}_{date_range[1].replace('-','')}.pkl\"\n",
    "#         ede_df = pd.read_pickle(os.path.join(save_dir_base_raw, save_name))\n",
    "#         #-----\n",
    "#         ede_df = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "#             df=ede_df, \n",
    "#             reason_col='reason', \n",
    "#             edetypeid_col='enddeviceeventtypeid',  \n",
    "#             placement_col='curated_reason', \n",
    "#             flags=0\n",
    "#         )\n",
    "#         #-----\n",
    "#         ede_df.to_pickle(os.path.join(save_dir_base_cur, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq='D'\n",
    "# group_cols=['serialnumber', 'aep_premise_nb']\n",
    "# group_freq=pd.Grouper(freq=freq, key='aep_event_dt')\n",
    "\n",
    "# for opco in opcos:\n",
    "#     for date_range in date_ranges:\n",
    "#         save_name = f\"end_events_{opco}_{date_range[0].replace('-','')}_{date_range[1].replace('-','')}.pkl\"\n",
    "#         ede_df = pd.read_pickle(os.path.join(save_dir_base_cur, save_name))\n",
    "#         ede_df['aep_event_dt'] = pd.to_datetime(ede_df['aep_event_dt'])\n",
    "#         #-----\n",
    "#         rcpo_df = get_reason_counts_per_group_QUICK(\n",
    "#             end_events_df=ede_df, \n",
    "#             group_cols=group_cols, \n",
    "#             group_freq=group_freq, \n",
    "#             gpby_dropna=True, \n",
    "#             reason_col='curated_reason'\n",
    "#         )\n",
    "#         #-----\n",
    "#         rcpo_df.to_pickle(os.path.join(save_dir_base_rcpo, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a35486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq='D'\n",
    "# group_cols=['serialnumber', 'aep_premise_nb']\n",
    "# group_freq=pd.Grouper(freq=freq, key='aep_event_dt')\n",
    "\n",
    "# for opco in opcos:\n",
    "#     for date_range in date_ranges:\n",
    "#         save_name = f\"end_events_{opco}_{date_range[0].replace('-','')}_{date_range[1].replace('-','')}.pkl\"\n",
    "#         ede_df = pd.read_pickle(os.path.join(save_dir_base_raw, save_name))\n",
    "#         #-----\n",
    "#         ede_df = AMIEndEvents.reduce_end_event_reasons_in_df(\n",
    "#             df=ede_df, \n",
    "#             reason_col='reason', \n",
    "#             edetypeid_col='enddeviceeventtypeid',  \n",
    "#             placement_col='curated_reason', \n",
    "#             flags=0\n",
    "#         )\n",
    "#         #-----\n",
    "#         ede_df.to_pickle(os.path.join(save_dir_base_cur, save_name))\n",
    "#         #-------------------------\n",
    "#         ede_df['aep_event_dt'] = pd.to_datetime(ede_df['aep_event_dt'])\n",
    "#         #-----\n",
    "#         rcpo_df = get_reason_counts_per_group_QUICK(\n",
    "#             end_events_df=ede_df, \n",
    "#             group_cols=group_cols, \n",
    "#             group_freq=group_freq, \n",
    "#             gpby_dropna=True, \n",
    "#             reason_col='curated_reason'\n",
    "#         )\n",
    "#         #-----\n",
    "#         rcpo_df.to_pickle(os.path.join(save_dir_base_rcpo, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db297028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb2607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
