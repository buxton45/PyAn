{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fab2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./check_DOVS_METHODS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d9dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import adjustText\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from DOVSAudit import DOVSAudit\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import PDFMerger\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSingleSlicer as DFSingleSlicer\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65d6fd",
   "metadata": {},
   "source": [
    "# Analyze collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074daca",
   "metadata": {},
   "source": [
    "## AMI NonVee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fd082-590a-4209-a646-11907ee2d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_0 = '2025-01-12'\n",
    "date_1 = '2025-01-18'\n",
    "opco   = 'pso'\n",
    "#-------------------------\n",
    "# Whether or not to skip pre-existing results\n",
    "skip_prex_results = True\n",
    "perform_plotting  = True\n",
    "build_summary_dfs = True\n",
    "#-------------------------\n",
    "save_dir_base = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check'\n",
    "save_subdir = f\"{date_0.replace('-','')}_{date_1.replace('-','')}\"\n",
    "#-----\n",
    "base_dir     = os.path.join(save_dir_base, save_subdir, opco)\n",
    "base_dir_ami = os.path.join(base_dir, r'AMINonVee')\n",
    "base_dir_ede = os.path.join(base_dir, r'EndEvents')\n",
    "#-----\n",
    "save_dir           = os.path.join(base_dir, r'Results')\n",
    "dovs_audits_subdir = os.path.join(save_dir, 'dovs_audits')\n",
    "#-----\n",
    "assert(os.path.exists(base_dir_ami))\n",
    "assert(os.path.exists(base_dir_ede))\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(dovs_audits_subdir):\n",
    "    os.makedirs(dovs_audits_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626d505-fe2a-4d8b-8a02-6c11331e5977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290eb80-f220-4cad-89ea-49f495df4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "calculate_by_PN = True\n",
    "#-------------------------\n",
    "# combine_by_PN_likeness_thresh = pd.Timedelta('1 minutes')\n",
    "combine_by_PN_likeness_thresh = pd.Timedelta('15 minutes')\n",
    "#-------------------------\n",
    "expand_outg_search_time_tight = pd.Timedelta('1 hours')\n",
    "expand_outg_search_time_loose = pd.Timedelta('12 hours')\n",
    "#-------------------------\n",
    "use_est_outg_times=False\n",
    "# use_est_outg_times=True\n",
    "#-------------------------\n",
    "use_full_ede_outgs=False\n",
    "#-------------------------\n",
    "run_outg_inclusion_assessment=True\n",
    "#-------------------------\n",
    "max_pct_PNs_missing_allowed=0\n",
    "# max_pct_PNs_missing_allowed=20\n",
    "\n",
    "#--------------------------------------------------\n",
    "include_suboutg_endpt_plots=True\n",
    "#-------------------------\n",
    "n_PNs_w_power_threshold = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "outg_rec_nb_to_files_dict = DOVSAudit.get_outg_rec_nb_to_files_dict_ami(\n",
    "    base_dir_dict   = base_dir,\n",
    "    base_dir_data   = base_dir_ami, \n",
    "    rebuild         = False, \n",
    "    save_dict       = True\n",
    ")\n",
    "all_outg_rec_nbs = list(outg_rec_nb_to_files_dict.keys())\n",
    "#-------------------------\n",
    "outg_rec_nb_to_files_ede_dict = DOVSAudit.get_outg_rec_nb_to_files_dict_ede(\n",
    "    base_dir_dict   = base_dir,\n",
    "    base_dir_data   = base_dir_ede, \n",
    "    rebuild         = False, \n",
    "    save_dict       = True\n",
    ")\n",
    "all_outg_rec_nbs_ede = list(outg_rec_nb_to_files_ede_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c5923-04fb-45f8-b906-11627e026858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_plotting:\n",
    "    # In some cases, keeping all of the PdfPages objects open becomes taxing in terms of memory\n",
    "    # Therefore, I will save all of the PDFs as separate documents, closing each at the end of each iteration\n",
    "    #   and collecting all in their respective single files at the end.\n",
    "    # The following paths are for the final, single files\n",
    "    #--------------------------------------------------\n",
    "    res_tmp_subdir = 'TMP_Results'\n",
    "    res_pdf_path   = os.path.join(save_dir, r'Results.pdf')\n",
    "    #-------------------------\n",
    "    res_dovs_beg_tmp_subdir = 'TMP_Results_dovs_beg'\n",
    "    res_dovs_beg_pdf_path   = Utilities.append_to_path(\n",
    "        res_pdf_path, \n",
    "        '_dovs_beg', \n",
    "        ext_to_find='.pdf', \n",
    "        append_to_end_if_ext_no_found=False\n",
    "    )\n",
    "    #-------------------------\n",
    "    res_w_endpts_tmp_subdir = 'TMP_Results_w_suboutg_endpt'\n",
    "    res_w_endpts_pdf_path   = Utilities.append_to_path(\n",
    "        res_pdf_path, \n",
    "        '_w_suboutg_endpt_plots', \n",
    "        ext_to_find='.pdf', \n",
    "        append_to_end_if_ext_no_found=False\n",
    "    )\n",
    "    #--------------------------------------------------\n",
    "    tmp_subdirs = [\n",
    "        res_tmp_subdir, \n",
    "        res_dovs_beg_tmp_subdir, \n",
    "        res_w_endpts_tmp_subdir\n",
    "    ]\n",
    "    #-----\n",
    "    tmp_subdir_paths = Utilities.make_tmp_save_dir(\n",
    "        base_dir_path = save_dir,\n",
    "        tmp_dir_name  = tmp_subdirs, \n",
    "        return_path   = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb328e-8a42-47c4-bc2c-cdf36c29a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any pre-existing results\n",
    "prex_audit_paths = Utilities.find_all_paths(\n",
    "    base_dir      = os.path.join(save_dir, dovs_audits_subdir), \n",
    "    glob_pattern  = r'*.pkl', \n",
    "    regex_pattern = None\n",
    ")\n",
    "prex_audit_paths = natsorted(prex_audit_paths)\n",
    "prex_audits      = [Path(x).stem for x in prex_audit_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9caeaec-6094-4590-9fbb-97c2b59dbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_prex_results:\n",
    "    outg_rec_nbs = list(set(all_outg_rec_nbs).difference(set(prex_audits)))\n",
    "else:\n",
    "    outg_rec_nbs = all_outg_rec_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e357f6-9aa9-425e-9c7b-be9c729990db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(all_outg_rec_nbs): {len(all_outg_rec_nbs)}')\n",
    "print(f'len(prex_audits):      {len(prex_audits)}')\n",
    "print(f'len(outg_rec_nbs):     {len(outg_rec_nbs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539a5a3-242e-4c23-aa37-9b794d8213b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d73bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "outgs_pass = []\n",
    "outgs_fail = []\n",
    "#-------------------------\n",
    "fig_num                           = 0\n",
    "all_detailed_summary_dfs          = []\n",
    "all_detailed_summary_dfs_dovs_beg = []\n",
    "ci_cmi_summary_dfs                = []\n",
    "warnings_text                     = ''\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Build dovs_df\n",
    "dovs = DOVSOutages(\n",
    "    df_construct_type         = DFConstructType.kRunSqlQuery, \n",
    "    contstruct_df_args        = None, \n",
    "    init_df_in_constructor    = True,\n",
    "    build_sql_function        = DOVSOutages_SQL.build_sql_std_outage, \n",
    "    build_sql_function_kwargs = dict(\n",
    "        outg_rec_nbs    = outg_rec_nbs, \n",
    "        field_to_split  = 'outg_rec_nbs', \n",
    "        include_premise = True, \n",
    "        opco            = opco\n",
    "    ), \n",
    "    build_consolidated        = True\n",
    ")\n",
    "dovs_df = dovs.df.copy()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Now, iterate through all outages\n",
    "for i_outg, outg_rec_nb in enumerate(outg_rec_nbs):\n",
    "    print(f'\\n\\ti_outg: {i_outg}/{len(outg_rec_nbs)-1}')\n",
    "    print(f'\\toutg_rec_nb = {outg_rec_nb}')\n",
    "    #--------------------------------------------------\n",
    "    try:\n",
    "        audit_i = DOVSAudit(\n",
    "            outg_rec_nb                   = outg_rec_nb, \n",
    "            calculate_by_PN               = calculate_by_PN, \n",
    "            combine_by_PN_likeness_thresh = combine_by_PN_likeness_thresh, \n",
    "            expand_outg_search_time_tight = expand_outg_search_time_tight, \n",
    "            expand_outg_search_time_loose = expand_outg_search_time_loose, \n",
    "            use_est_outg_times            = use_est_outg_times, \n",
    "            use_full_ede_outgs            = use_full_ede_outgs, \n",
    "            run_outg_inclusion_assessment = run_outg_inclusion_assessment, \n",
    "            max_pct_PNs_missing_allowed   = max_pct_PNs_missing_allowed, \n",
    "            opco                          = opco\n",
    "        )\n",
    "        \n",
    "        audit_i.load_ami_from_csvs(\n",
    "            paths                          = outg_rec_nb_to_files_dict[outg_rec_nb], \n",
    "            slicers                        = None, \n",
    "            ami_df_info_dict               = None, \n",
    "            run_std_init                   = True, \n",
    "            cols_and_types_to_convert_dict = None, \n",
    "            to_numeric_errors              = 'coerce', \n",
    "            drop_na_rows_when_exception    = True, \n",
    "            drop_unnamed0_col              = True, \n",
    "            pd_read_csv_kwargs             = None, \n",
    "            make_all_columns_lowercase     = False, \n",
    "            assert_all_cols_equal          = True, \n",
    "            min_fsize_MB                   = None\n",
    "        )\n",
    "        #--------------------------------------------------\n",
    "        if audit_i.ami_df_i.shape[0]==0:\n",
    "            outgs_fail.append((audit_i.outg_rec_nb, \"ami_df_i.shape[0]==0\"))\n",
    "            continue\n",
    "    \n",
    "        #-------------------------\n",
    "        # Need to load dovs before running self assessment below\n",
    "        audit_i.load_dovs(\n",
    "            dovs_df           = dovs_df, \n",
    "            dovs_df_info_dict = None\n",
    "        )\n",
    "        \n",
    "        if run_outg_inclusion_assessment:\n",
    "            to_include_i = audit_i.self_assess_outage_inclusion_requirements(max_pct_PNs_missing_allowed, None)\n",
    "            if not to_include_i:\n",
    "                print(f'outg_rec_nb={audit_i.outg_rec_nb} did not pass inclusion requirements, skipping!!!!!')\n",
    "                outgs_fail.append((audit_i.outg_rec_nb, \"Inclusion Requirements\"))\n",
    "                continue\n",
    "        #-------------------------    \n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        if audit_i.outg_rec_nb in outg_rec_nb_to_files_ede_dict.keys():\n",
    "            audit_i.load_ede_from_csvs(\n",
    "                paths                          = outg_rec_nb_to_files_ede_dict[audit_i.outg_rec_nb], \n",
    "                ede_df_info_dict               = None, \n",
    "                run_std_init                   = True, \n",
    "                cols_and_types_to_convert_dict = None, \n",
    "                to_numeric_errors              = 'coerce', \n",
    "                drop_na_rows_when_exception    = True, \n",
    "                drop_unnamed0_col              = True, \n",
    "                pd_read_csv_kwargs             = None, \n",
    "                make_all_columns_lowercase     = False, \n",
    "                assert_all_cols_equal          = True, \n",
    "                min_fsize_MB                   = None\n",
    "            )\n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        audit_i.build_best_ests_df()\n",
    "        #--------------------------------------------------\n",
    "        # cnsrvtv_out_t_beg/_end are used for placing bounds on the plots generated\n",
    "        # NOTE: If one did not want to show any data which was thrown out due to overlapping, one would want to\n",
    "        #         update cnsrvtv_out_t_beg/_end after the identify_dovs_overlaps_from_best_ests procedure below \n",
    "        #         (and subsequent trimming of audit_i.best_ests_df)\n",
    "        cnsrvtv_out_t_beg_end = audit_i.get_cnsrvtv_out_t_beg_end()\n",
    "\n",
    "        #--------------------------------------------------\n",
    "        audit_i.identify_overlaps_and_resolve(\n",
    "            overlaps_dovs_sql_fcn           = DOVSOutages_SQL.build_sql_outage, \n",
    "            dovs_df                         = None, \n",
    "            t_min_col                       = 'winner_min', \n",
    "            t_max_col                       = 'winner_max', \n",
    "            keep_col                        = 'keep', \n",
    "            overlap_DOVS_col                = 'overlap_DOVS', \n",
    "            outg_rec_nb_col_dovs            = 'OUTG_REC_NB', \n",
    "            dt_off_ts_full_col_dovs         = 'DT_OFF_TS_FULL', \n",
    "            dt_on_ts_col_dovs               = 'DT_ON_TS', \n",
    "            overlaps_addtnl_dovs_sql_kwargs = dict(\n",
    "                CI_NB_min  = 0, \n",
    "                CMI_NB_min = 0\n",
    "            ), \n",
    "            overlap_disagree_cols           = ['ovrlp_disagree_typeA', 'ovrlp_disagree_typeB'], \n",
    "            unq_idfr_cols                   = ['PN', 'i_outg'], \n",
    "            open_beg_col                    = 'open_beg', \n",
    "            open_end_col                    = 'open_end'\n",
    "        )\n",
    "        #--------------------------------------------------\n",
    "        audit_i.finalize_analysis()\n",
    "        #--------------------------------------------------\n",
    "        audit_i.save(os.path.join(dovs_audits_subdir, f'{audit_i.outg_rec_nb}.pkl'))\n",
    "        #--------------------------------------------------\n",
    "        if not audit_i.can_analyze:\n",
    "            outgs_fail.append((audit_i.outg_rec_nb, \"not can_analyze (likely overlapping DOVS)\"))\n",
    "            continue\n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        if build_summary_dfs:\n",
    "            detailed_summary_df_i = audit_i.get_detailed_summary_df(\n",
    "                dovs_beg        = False, \n",
    "                delta_t_off_cut = pd.Timedelta('5min'), \n",
    "                delta_t_on_cut  = pd.Timedelta('5min'), \n",
    "                delta_ci_cut    = 3, \n",
    "                delta_cmi_cut   = None, \n",
    "                n_PNs_w_power_threshold = n_PNs_w_power_threshold, \n",
    "            )\n",
    "            if detailed_summary_df_i.shape[0]>0:\n",
    "                all_detailed_summary_dfs.append(detailed_summary_df_i)\n",
    "            #-----\n",
    "            detailed_summary_df_dovs_beg_i = audit_i.get_detailed_summary_df(\n",
    "                dovs_beg        = True, \n",
    "                delta_t_off_cut = pd.Timedelta('5min'), \n",
    "                delta_t_on_cut  = pd.Timedelta('5min'), \n",
    "                delta_ci_cut    = 3, \n",
    "                delta_cmi_cut   = None, \n",
    "                n_PNs_w_power_threshold = n_PNs_w_power_threshold, \n",
    "            )\n",
    "            if detailed_summary_df_dovs_beg_i.shape[0]>0:\n",
    "                all_detailed_summary_dfs_dovs_beg.append(detailed_summary_df_dovs_beg_i)\n",
    "            #-----\n",
    "            warnings_text += audit_i.generate_warnings_text()\n",
    "            #-------------------------\n",
    "            ci_cmi_summary_dfs.append(\n",
    "                pd.DataFrame(\n",
    "                    dict(\n",
    "                        outg_rec_nb      = audit_i.outg_rec_nb, \n",
    "                        ci_dovs          = audit_i.ci_dovs,   \n",
    "                        ci_ami           = audit_i.ci, \n",
    "                        ci_ami_dovs_beg  = audit_i.ci_dovs_beg, \n",
    "                        cmi_dovs         = audit_i.cmi_dovs, \n",
    "                        cmi_ami          = audit_i.cmi, \n",
    "                        cmi_ami_dovs_beg = audit_i.cmi_dovs_beg\n",
    "                    ), \n",
    "                    index=[len(ci_cmi_summary_dfs)]\n",
    "                )\n",
    "            )\n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        # ######################### PLOTTING #########################\n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        if perform_plotting:\n",
    "            fig, axs = audit_i.plot_results(\n",
    "                include_dovs_beg_text      = True, \n",
    "                name                       = 'AMI', \n",
    "                expand_time                = pd.Timedelta('1 hour'), \n",
    "                n_PNs_w_power_threshold    = n_PNs_w_power_threshold, \n",
    "                fig_num                    = fig_num\n",
    "            )    \n",
    "            Plot_General.save_fig(\n",
    "                fig         = fig, \n",
    "                save_dir    = os.path.join(save_dir, res_tmp_subdir), \n",
    "                save_name   = f\"{audit_i.outg_rec_nb}.pdf\", \n",
    "                bbox_inches = 'tight'\n",
    "            )\n",
    "            if include_suboutg_endpt_plots:\n",
    "                Plot_General.save_fig(\n",
    "                    fig         = fig, \n",
    "                    save_dir    = os.path.join(save_dir, res_w_endpts_tmp_subdir), \n",
    "                    save_name   = f\"{audit_i.outg_rec_nb}_0.pdf\", \n",
    "                    bbox_inches = 'tight'\n",
    "                )\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            fig_num += 1\n",
    "            \n",
    "            #----------------------------------------------------------------------------------------------------\n",
    "            if audit_i.best_ests_means_df_dovs_beg is not None and audit_i.best_ests_means_df_dovs_beg.shape[0]>0:\n",
    "                fig, axs = audit_i.plot_results_dovs_beg(\n",
    "                    include_full_alg_text      = True, \n",
    "                    name                       = 'AMI w/ DOVS t_beg', \n",
    "                    expand_time                = pd.Timedelta('1 hour'), \n",
    "                    n_PNs_w_power_threshold    = n_PNs_w_power_threshold, \n",
    "                    fig_num                    = fig_num\n",
    "                )    \n",
    "                Plot_General.save_fig(\n",
    "                    fig         = fig, \n",
    "                    save_dir    = os.path.join(save_dir, res_dovs_beg_tmp_subdir), \n",
    "                    save_name   = f\"{audit_i.outg_rec_nb}.pdf\", \n",
    "                    bbox_inches = 'tight'\n",
    "                )\n",
    "                fig.clear()\n",
    "                plt.close(fig)\n",
    "                fig_num += 1\n",
    "            \n",
    "            #----------------------------------------------------------------------------------------------------\n",
    "            if include_suboutg_endpt_plots:\n",
    "                fig_axs = audit_i.plot_zoomed_endpts(\n",
    "                    fig_num     = fig_num\n",
    "                )\n",
    "                if fig_axs is not None:\n",
    "                    fig = fig_axs[0]\n",
    "                    axs = fig_axs[1]\n",
    "                    #-------------------------\n",
    "                    Plot_General.save_fig(\n",
    "                        fig         = fig, \n",
    "                        save_dir    = os.path.join(save_dir, res_w_endpts_tmp_subdir), \n",
    "                        save_name   = f\"{audit_i.outg_rec_nb}_1.pdf\", \n",
    "                        bbox_inches = 'tight'\n",
    "                    ) \n",
    "                    fig.clear()\n",
    "                    plt.close(fig)\n",
    "                    fig_num += 1\n",
    "    \n",
    "        #----------------------------------------------------------------------------------------------------\n",
    "        outgs_pass.append(audit_i.outg_rec_nb)\n",
    "\n",
    "    except:\n",
    "        outgs_fail.append((audit_i.outg_rec_nb, \"Unknown\"))\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "if build_summary_dfs:\n",
    "    detailed_summary_df          = Utilities_df.concat_dfs(\n",
    "        dfs                  = all_detailed_summary_dfs, \n",
    "        axis                 = 0, \n",
    "        make_col_types_equal = False\n",
    "    )\n",
    "    detailed_summary_df_dovs_beg = Utilities_df.concat_dfs(\n",
    "        dfs                  = all_detailed_summary_dfs_dovs_beg, \n",
    "        axis                 = 0, \n",
    "        make_col_types_equal = False\n",
    "    )\n",
    "    #-------------------------\n",
    "    detailed_summary_df = DOVSAudit.sort_detailed_summary_df(\n",
    "        detailed_summary_df = detailed_summary_df, \n",
    "        how                 = 'abs_delta_ci_cmi', \n",
    "    )\n",
    "    #-----\n",
    "    detailed_summary_df_dovs_beg = DOVSAudit.sort_detailed_summary_df(\n",
    "        detailed_summary_df = detailed_summary_df_dovs_beg, \n",
    "        how                 = 'abs_delta_ci_cmi', \n",
    "    )\n",
    "    #-------------------------\n",
    "    ci_cmi_summary_df            = Utilities_df.concat_dfs(\n",
    "        dfs                  = ci_cmi_summary_dfs, \n",
    "        axis                 = 0, \n",
    "        make_col_types_equal = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd42a0c-6d91-47b2-8af1-28dcaa4f8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"#OUTG_REC_NBs = {len(outg_rec_nbs)}\")\n",
    "print(f\"\\tpass: {len(outgs_pass)}\")\n",
    "print(f\"\\tfail: {len(outgs_fail)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5ca9a-4331-4dd3-a79d-253c2049f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_plotting:\n",
    "    PDFMerger.merge_all_pdfs_in_dir(\n",
    "        dir_to_merge = os.path.join(save_dir, res_tmp_subdir), \n",
    "        output_path  = res_pdf_path, \n",
    "    )\n",
    "    #-----\n",
    "    PDFMerger.merge_all_pdfs_in_dir(\n",
    "        dir_to_merge = os.path.join(save_dir, res_dovs_beg_tmp_subdir), \n",
    "        output_path  = res_dovs_beg_pdf_path, \n",
    "    )\n",
    "    #-----\n",
    "    PDFMerger.merge_all_pdfs_in_dir(\n",
    "        dir_to_merge = os.path.join(save_dir, res_w_endpts_tmp_subdir), \n",
    "        output_path  = res_w_endpts_pdf_path, \n",
    "    )\n",
    "    #-------------------------\n",
    "    # Utilities.del_tmp_save_dir(\n",
    "    #     base_dir_path = save_dir,\n",
    "    #     tmp_dir_name  = tmp_subdirs\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63d8c2-d992-4b0f-a0b5-efdcad59c389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_summary_dfs:\n",
    "    ci_cmi_summary_df['ci_dovs']         = ci_cmi_summary_df['ci_dovs'].astype(float)\n",
    "    ci_cmi_summary_df['ci_ami']          = ci_cmi_summary_df['ci_ami'].astype(float)\n",
    "    ci_cmi_summary_df['ci_ami_dovs_beg'] = ci_cmi_summary_df['ci_ami_dovs_beg'].astype(float)\n",
    "    #-----\n",
    "    ci_cmi_summary_df['delta_ci_dovs_ami']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami']\n",
    "    ci_cmi_summary_df['delta_cmi_dovs_ami'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami']\n",
    "    #-----\n",
    "    ci_cmi_summary_df['delta_ci_dovs_ami_dovs_beg']  = ci_cmi_summary_df['ci_dovs']-ci_cmi_summary_df['ci_ami_dovs_beg']\n",
    "    ci_cmi_summary_df['delta_cmi_dovs_ami_dovs_beg'] = ci_cmi_summary_df['cmi_dovs']-ci_cmi_summary_df['cmi_ami_dovs_beg']\n",
    "    #-----\n",
    "    # For plotting purposes, make a outg_rec_in column which is simply 0 to delta_df.shape[0]-1\n",
    "    ci_cmi_summary_df['outg_rec_int'] = range(ci_cmi_summary_df.shape[0])\n",
    "    #-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_summary_dfs:\n",
    "    detailed_summary_df.to_pickle(os.path.join(save_dir, r'detailed_summary.pkl'))\n",
    "    detailed_summary_df_dovs_beg.to_pickle(os.path.join(save_dir, r'detailed_summary_dovs_beg.pkl'))\n",
    "    ci_cmi_summary_df.to_pickle(os.path.join(save_dir, r'ci_cmi_summary.pkl'))\n",
    "    #-----\n",
    "    detailed_summary_df.to_csv(os.path.join(save_dir, r'detailed_summary.csv'))\n",
    "    detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, r'detailed_summary_dovs_beg.csv'))\n",
    "    ci_cmi_summary_df.to_csv(os.path.join(save_dir, r'ci_cmi_summary.csv'))\n",
    "    #-----\n",
    "    # For Mico and Amanda\n",
    "    detailed_summary_df_dovs_beg.to_csv(os.path.join(save_dir, f'detailed_summary_dovs_beg_{save_subdir}.csv'))\n",
    "    #-----\n",
    "    with open(os.path.join(save_dir, r'warnings.txt'), 'w') as f:\n",
    "        f.write(warnings_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c23948-22ac-45ff-b352-0e6e26cf0661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57ce29",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5bb3b-9797-48bc-8023-97220b7d0102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351e8ce7-b2c0-4bdb-a3e6-6f1912bb99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap  = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\ap\\Results\\detailed_summary_dovs_beg.pkl')\n",
    "df_im  = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\im\\Results\\detailed_summary_dovs_beg.pkl')\n",
    "df_oh  = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\oh\\Results\\detailed_summary_dovs_beg.pkl')\n",
    "df_pso = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\pso\\Results\\detailed_summary_dovs_beg.pkl')\n",
    "df_swp = pd.read_pickle(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\swp\\Results\\detailed_summary_dovs_beg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70500154-e91a-4855-b67b-ae36e9e49e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d5a6b-d34a-4c24-bd64-63c091a81df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed75c24e-7a5c-40fd-9a0c-1f300c9244a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\AllOPCOs\\Results\\detailed_summary_dovs_beg_20250112_20250118.xlsx') as writer:  \n",
    "    df_ap.reset_index().to_excel(writer, sheet_name='ap')\n",
    "    df_im.reset_index().to_excel(writer, sheet_name='im')\n",
    "    df_oh.reset_index().to_excel(writer, sheet_name='oh')\n",
    "    df_pso.reset_index().to_excel(writer, sheet_name='pso')\n",
    "    df_swp.reset_index().to_excel(writer, sheet_name='swp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27add276-a1b1-46b8-b6c9-9b82face2839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f9486e-79c1-457c-b492-ff6a79ea635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFMerger.merge_list(\n",
    "    files_to_merge = [\n",
    "        r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\ap\\Results\\Results_dovs_beg.pdf', \n",
    "        r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\im\\Results\\Results_dovs_beg.pdf', \n",
    "        r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\oh\\Results\\Results_dovs_beg.pdf', \n",
    "        r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\pso\\Results\\Results_dovs_beg.pdf', \n",
    "        r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\swp\\Results\\Results_dovs_beg.pdf', \n",
    "    ], \n",
    "    output_path    = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_check\\20250112_20250118\\AllOPCOs\\Results\\Results_dovs_beg_20250112_20250118.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21880e-4e8b-44b2-8d16-19b4250246ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
