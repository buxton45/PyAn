{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5755605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(Utilities)\n",
    "#reload(clm)1\n",
    "# NOTE: To reload a class imported as, e.g., \n",
    "# from module import class\n",
    "# One must call:\n",
    "#   1. import module\n",
    "#   2. reload module\n",
    "#   3. from module import class\n",
    "\n",
    "import sys, os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_dtype, is_timedelta64_dtype\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from packaging import version\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pyodbc\n",
    "#---------------------------------------------------------------------\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import dates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm #e.g. for cmap=cm.jet\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, os.path.realpath('..'))\n",
    "import Utilities_config\n",
    "#-----\n",
    "import CommonLearningMethods as clm\n",
    "#-----\n",
    "from MeterPremise import MeterPremise\n",
    "#-----\n",
    "from AMI_SQL import AMI_SQL\n",
    "from AMINonVee_SQL import AMINonVee_SQL\n",
    "from AMIEndEvents_SQL import AMIEndEvents_SQL\n",
    "from AMIUsgInst_SQL import AMIUsgInst_SQL\n",
    "from DOVSOutages_SQL import DOVSOutages_SQL\n",
    "#-----\n",
    "from GenAn import GenAn\n",
    "from AMINonVee import AMINonVee\n",
    "from AMIEndEvents import AMIEndEvents\n",
    "from MECPODf import MECPODf\n",
    "from MECPOAn import MECPOAn\n",
    "from AMIUsgInst import AMIUsgInst\n",
    "from DOVSOutages import DOVSOutages\n",
    "from OutageDAQ import OutageDataInfo as ODI\n",
    "from OutageMdlrPrep import OutageMdlrPrep\n",
    "#---------------------------------------------------------------------\n",
    "sys.path.insert(0, Utilities_config.get_sql_aids_dir())\n",
    "import Utilities_sql\n",
    "import TableInfos\n",
    "from TableInfos import TableInfo\n",
    "from SQLElement import SQLElement\n",
    "from SQLElementsCollection import SQLElementsCollection\n",
    "from SQLSelect import SQLSelectElement, SQLSelect\n",
    "from SQLFrom import SQLFrom\n",
    "from SQLWhere import SQLWhereElement, SQLWhere\n",
    "from SQLJoin import SQLJoin, SQLJoinCollection\n",
    "from SQLGroupBy import SQLGroupByElement, SQLGroupBy\n",
    "from SQLHaving import SQLHaving\n",
    "from SQLOrderBy import SQLOrderByElement, SQLOrderBy\n",
    "from SQLQuery import SQLQuery\n",
    "from SQLQueryGeneric import SQLQueryGeneric\n",
    "#---------------------------------------------------------------------\n",
    "#sys.path.insert(0, os.path.join(os.path.realpath('..'), 'Utilities'))\n",
    "sys.path.insert(0, Utilities_config.get_utilities_dir())\n",
    "import Utilities\n",
    "import Utilities_df\n",
    "from Utilities_df import DFConstructType\n",
    "import Utilities_dt\n",
    "import Plot_General\n",
    "import Plot_Box_sns\n",
    "import Plot_Hist\n",
    "import Plot_Bar\n",
    "import GrubbsTest\n",
    "import DataFrameSubsetSlicer\n",
    "from DataFrameSubsetSlicer import DataFrameSubsetSlicer as DFSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb5f3f-f5da-4adf-946f-7067d4d1283d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7d5e9-2b25-4108-8546-36884270c1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions moved from _METHOD notebook to OutageMdlrPrep class\n",
    "# get_active_SNs_for_xfmrs_OLD\n",
    "# add_xfmr_active_SNs_to_rcpo_df_OLD\n",
    "# build_rcpo_df_norm_by_xfmr_active_nSNs_OLD\n",
    "# reset_index_and_identify_cols_to_merge\n",
    "# merge_rcpo_and_df\n",
    "# get_active_SNs_for_xfmrs\n",
    "# get_active_SNs_for_xfmrs_in_rcpo_df\n",
    "# get_active_SNs_for_xfmrs_in_rcpo_df_v2\n",
    "# add_xfmr_active_SNs_to_rcpo_df\n",
    "# build_rcpo_df_norm_by_xfmr_active_nSNs\n",
    "# get_outg_time_infos_df\n",
    "# build_reason_counts_per_outage_from_csvs_v0\n",
    "# check_end_events_merge_with_mp\n",
    "# perform_build_RCPX_from_csvs_prereqs_v0\n",
    "# find_all_cols_with_gpd_for_sql_appendix\n",
    "# identify_ede_cols_of_interest_to_update_andor_drop\n",
    "# perform_build_RCPX_from_csvs_prereqs\n",
    "# drop_gpd_for_sql_appendix_from_all_cols\n",
    "# drop_gpd_for_sql_appendix_from_all_index_names\n",
    "# build_reason_counts_per_outage_from_csvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b710f04-2d33-4c73-a90e-b3f3705d0c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "run_date = '20240906' # Date of data acquisition\n",
    "#-------------------------\n",
    "date_0   = '2023-04-01' # Lower limit for end events\n",
    "date_1   = '2024-08-31' # Upper limit for end events\n",
    "#-------------------------\n",
    "# dataset  = 'outg'\n",
    "dataset  = 'otbl'\n",
    "# dataset  = 'prbl'\n",
    "#-------------------------\n",
    "save_dfs_to_pkl   = True\n",
    "read_dfs_from_pkl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cf0df-7fd8-4af3-bafe-c4478090cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--------------------------------------------------\n",
    "# outg_mdlr_prep = OutageMdlrPrep(\n",
    "#     dataset         = dataset, \n",
    "#     run_date        = run_date, \n",
    "#     date_0          = date_0, \n",
    "#     date_1          = date_1, \n",
    "#     data_evs_sum_vw = False, \n",
    "#     data_base_dir   = None, \n",
    "#     verbose         = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5965d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f428f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7caabf-b43a-43c5-bbe8-42344fbf69f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cee1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "ODI.assert_dataset(dataset)\n",
    "#-------------------------\n",
    "date_pd_subdir = f\"{date_0.replace('-','')}_{date_1.replace('-','')}\"\n",
    "data_base_dir  = os.path.join(\n",
    "    Utilities.get_local_data_dir(), \n",
    "    r'dovs_and_end_events_data', \n",
    "    run_date, \n",
    "    date_pd_subdir, \n",
    "    ODI.get_subdir(dataset)\n",
    ")\n",
    "#-------------------------\n",
    "assert(os.path.isdir(data_base_dir))\n",
    "#-------------------------\n",
    "files_dir    = os.path.join(data_base_dir, 'EndEvents')\n",
    "naming_tag   = ODI.get_naming_tag(dataset)\n",
    "is_no_outage = ODI.get_is_no_outage(dataset)\n",
    "#-------------------------\n",
    "assert(os.path.isdir(files_dir))\n",
    "#-------------------------\n",
    "print(f'data_base_dir = {data_base_dir}')\n",
    "print(f'files_dir     = {files_dir}')\n",
    "print(f'naming_tag    = {naming_tag}')\n",
    "print(f'is_no_outage  = {is_no_outage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b383c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "file_path_glob                = r'end_events_[0-9]*.csv'\n",
    "file_path_regex               = None\n",
    "\n",
    "assert_all_cols_equal         = False #Seems new EndEvents have curr_acct_cls_cd as well...\n",
    "include_normalize_by_nSNs     = True\n",
    "inclue_zero_counts            = True\n",
    "return_multiindex_outg_reason = False\n",
    "return_normalized_separately  = False\n",
    "\n",
    "# 0-31, 1-6, 6-11, 11-16, 16-21, 21-26, 26-31\n",
    "days_min_outg_td_window=6\n",
    "days_max_outg_td_window=11\n",
    "\n",
    "xfmr_equip_typ_nms_of_interest = ['TRANSFORMER, OH', 'TRANSFORMER, UG']\n",
    "\n",
    "# In the past, the mp_df data (which was saved during DAQ) were needed for the trsf_pole_nb information\n",
    "# However, these data are now typically saved with the end_events data themselves (in the csvs), so \n",
    "#   mp_df is rarely needed anymore\n",
    "mp_df_needed_to_build_rcpx_from_csvs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99706616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "if is_no_outage:\n",
    "    batch_size      = 100\n",
    "    grp_by_col      = ['trsf_pole_nb', 'no_outg_rec_nb']\n",
    "    outg_rec_nb_col = 'no_outg_rec_nb'\n",
    "else:\n",
    "    batch_size      = 1000\n",
    "    grp_by_col      = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "    outg_rec_nb_col = 'outg_rec_nb'\n",
    "#-------------------------\n",
    "if include_normalize_by_nSNs and not return_normalized_separately:\n",
    "    normalize_by_nSNs_included=True\n",
    "else:\n",
    "    normalize_by_nSNs_included=False\n",
    "\n",
    "#--------------------------------------------------\n",
    "assert(save_dfs_to_pkl+read_dfs_from_pkl <=1) # Should never both read and write!\n",
    "#--------------------------------------------------\n",
    "# Currently, expecting grp_by_col to be 'outg_rec_nb', 'trsf_pole_nb', or ['outg_rec_nb', 'trsf_pole_nb']\n",
    "#   Actually, 'outg_rec_nb' will probably not be run again, instead will likely always be ['outg_rec_nb', 'trsf_pole_nb']\n",
    "assert(\n",
    "    grp_by_col=='outg_rec_nb' or \n",
    "    grp_by_col==['outg_rec_nb', 'trsf_pole_nb'] or \n",
    "    grp_by_col=='trsf_pole_nb' or \n",
    "    grp_by_col==['trsf_pole_nb', 'no_outg_rec_nb']\n",
    ")\n",
    "\n",
    "# Not possible for have outg_rec_nb for no outage case!\n",
    "if is_no_outage:\n",
    "    assert(grp_by_col!='outg_rec_nb' and grp_by_col!=('outg_rec_nb', 'trsf_pole_nb'))\n",
    "#--------------------------------------------------\n",
    "save_subdir_pkls = 'rcpo_dfs'\n",
    "if   grp_by_col == ['outg_rec_nb', 'trsf_pole_nb']:\n",
    "    save_subdir_pkls += '_GRP_BY_OUTG_AND_XFMR'\n",
    "elif grp_by_col == 'trsf_pole_nb':\n",
    "    save_subdir_pkls += '_GRP_BY_XFMR'\n",
    "elif grp_by_col == 'outg_rec_nb':\n",
    "    save_subdir_pkls += '_GRP_BY_OUTG'\n",
    "elif grp_by_col == ['trsf_pole_nb', 'no_outg_rec_nb']:\n",
    "    save_subdir_pkls += '_GRP_BY_NO_OUTG_AND_XFMR'\n",
    "else:\n",
    "    assert(0)\n",
    "#-----\n",
    "save_dir_base_pkls = os.path.join(data_base_dir, save_subdir_pkls)\n",
    "save_dir_pkls      = os.path.join(save_dir_base_pkls, f'outg_td_window_{days_min_outg_td_window}_to_{days_max_outg_td_window}_days')\n",
    "#-----\n",
    "if save_dfs_to_pkl and not os.path.exists(save_dir_pkls):\n",
    "    os.makedirs(save_dir_pkls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedc53f-97d2-45cd-9bfc-25ef74655295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEED TO BE AUTOMATED\n",
    "if is_no_outage:\n",
    "    outg_rec_nb_idx_lvl      =-1\n",
    "    trsf_pole_nbs_idx_lvl    = 0\n",
    "    \n",
    "    trsf_pole_nbs_loc        = ('index', 'trsf_pole_nb')\n",
    "    rcpo_df_to_time_infos_on = [('index', 'trsf_pole_nb'), ('index', 'no_outg_rec_nb')]\n",
    "    time_infos_to_rcpo_df_on = [('index', 'trsf_pole_nb'), ('index', 'no_outg_rec_nb')]\n",
    "    \n",
    "    rcpo_df_to_PNs_on        = ['index']\n",
    "    PNs_to_rcpo_df_on        = ['index']\n",
    "    how                      = 'left'\n",
    "else:\n",
    "    outg_rec_nb_idx_lvl      = 0\n",
    "    trsf_pole_nbs_idx_lvl    = 1\n",
    "    \n",
    "    trsf_pole_nbs_loc        = ('index', 'trsf_pole_nb')\n",
    "    rcpo_df_to_time_infos_on = [('index', 'outg_rec_nb')]\n",
    "    time_infos_to_rcpo_df_on = ['index']\n",
    "    \n",
    "    rcpo_df_to_PNs_on        = [('index', 'trsf_pole_nb')]\n",
    "    PNs_to_rcpo_df_on        = ['index']\n",
    "    how                      = 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e102d3-6b86-40a0-8404-8b21250925fd",
   "metadata": {},
   "source": [
    "# Grab mp_df if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cd3b2-3759-48e6-a1c4-d46cf89de8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp_df_needed_to_build_rcpx_from_csvs:\n",
    "    mp_df_path      = os.path.join(data_base_dir, r'df_mp_outg_full.pkl')\n",
    "    mp_df           = pd.read_pickle(mp_df_path)\n",
    "    merge_on_mp     = ['mfr_devc_ser_nbr', 'prem_nb', 'OUTG_REC_NB']\n",
    "    mp_df_cols      = dict(\n",
    "        serial_number_col = 'mfr_devc_ser_nbr', \n",
    "        prem_nb_col       = 'prem_nb', \n",
    "        trsf_pole_nb_col  = 'trsf_pole_nb', \n",
    "        outg_rec_nb_col   = 'OUTG_REC_NB'\n",
    "    )    \n",
    "    # Below ensures there is only one entry per 'meter' (meter here is defined by a unique grouping of merge_on_mp)\n",
    "    if any(mp_df.groupby(merge_on_mp).size()>1):\n",
    "        print('Resolving uniqueness violators')\n",
    "        mp_df = Utilities_df.resolve_uniqueness_violators(\n",
    "            df                      = mp_df, \n",
    "            groupby_cols            = merge_on_mp, \n",
    "            gpby_dropna             = False,\n",
    "            run_nan_groups_separate = True\n",
    "        )\n",
    "    assert(not any(mp_df.groupby(merge_on_mp).size()>1))\n",
    "else:\n",
    "    mp_df           = None\n",
    "    mp_df_cols      = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e269d-2c3c-4f56-bff4-eff02e265739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943bbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not read_dfs_from_pkl:\n",
    "    start = time.time()\n",
    "    rcpo_df_OG, ede_typeid_to_reason_df_OG = OutageMdlrPrep.build_reason_counts_per_outage_from_csvs(    \n",
    "        files_dir                      = files_dir, \n",
    "        mp_df                          = mp_df, \n",
    "        file_path_glob                 = file_path_glob, \n",
    "        file_path_regex                = file_path_regex, \n",
    "        min_outg_td_window             = datetime.timedelta(days=days_min_outg_td_window),\n",
    "        max_outg_td_window             = datetime.timedelta(days=days_max_outg_td_window),\n",
    "        build_ede_typeid_to_reason_df  = True, \n",
    "        batch_size                     = batch_size, \n",
    "        cols_and_types_to_convert_dict = None, \n",
    "        to_numeric_errors              = 'coerce', \n",
    "        assert_all_cols_equal          = assert_all_cols_equal, \n",
    "        include_normalize_by_nSNs      = include_normalize_by_nSNs, \n",
    "        inclue_zero_counts             = inclue_zero_counts, \n",
    "        return_multiindex_outg_reason  = return_multiindex_outg_reason, \n",
    "        return_normalized_separately   = return_normalized_separately, \n",
    "        verbose                        = True, \n",
    "        n_update                       = 1, \n",
    "        # grp_by_cols                    = ['trsf_pole_nb_GPD_FOR_SQL', 'no_outg_rec_nb_GPD_FOR_SQL'], \n",
    "        grp_by_cols                    = grp_by_col, \n",
    "        outg_rec_nb_col                = outg_rec_nb_col,\n",
    "        trsf_pole_nb_col               = 'trsf_pole_nb', \n",
    "        addtnl_dropna_subset_cols      = None, \n",
    "        is_no_outage                   = is_no_outage, \n",
    "        prem_nb_col                    = 'aep_premise_nb', \n",
    "        serial_number_col              = 'serialnumber', \n",
    "        include_prem_nbs               = True, \n",
    "        set_faulty_mp_vals_to_nan      = False,\n",
    "        correct_faulty_mp_vals         = False, \n",
    "        trust_sql_grouping             = True, \n",
    "        drop_gpd_for_sql_appendix      = True, \n",
    "        mp_df_cols                     = mp_df_cols, \n",
    "        make_all_columns_lowercase     = True\n",
    "    )\n",
    "    print(time.time()-start)\n",
    "    #-------------------------\n",
    "    if save_dfs_to_pkl:\n",
    "        rcpo_df_OG.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_OG.pkl'))\n",
    "        ede_typeid_to_reason_df_OG.to_pickle(os.path.join(save_dir_pkls, f'ede_typeid_to_reason{naming_tag}_df_OG.pkl'))        \n",
    "else:\n",
    "    rcpo_df_OG = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_OG.pkl'))\n",
    "    ede_typeid_to_reason_df_OG = pd.read_pickle(os.path.join(save_dir_pkls, f'ede_typeid_to_reason{naming_tag}_df_OG.pkl'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO DELETE ME!!!!!!!!!\n",
    "# rcpo_df_OG = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_OG.pkl'))\n",
    "# ede_typeid_to_reason_df_OG = pd.read_pickle(os.path.join(save_dir_pkls, f'ede_typeid_to_reason{naming_tag}_df_OG.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16453752",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_to_ede_typeid_df = AMIEndEvents.invert_ede_typeid_to_reason_df(ede_typeid_to_reason_df_OG)\n",
    "rcpo_df = rcpo_df_OG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb912f-f184-4ce1-887e-18e9fa7a6f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174bb4f-4968-44ff-8ca3-7b829e95aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols_prefix = 'dummy_lvl_'\n",
    "#--------------------------------------------------\n",
    "# Append time information to rcpo_df using either:\n",
    "#   -  Build no_outg_time_infos_df for baseline data\n",
    "#   -  Utilize DOVSOutages.append_outg_info_to_df for signal data\n",
    "#--------------------------------------------------\n",
    "if is_no_outage:\n",
    "    # Build no_outg_time_infos_df, which has prem_nbs indices and t_min, t_max (and possible summary_path) columns\n",
    "    # This is where the time information for each premise number comes from\n",
    "    paths = Utilities.find_all_paths(base_dir=files_dir, glob_pattern=file_path_glob)\n",
    "    #-----\n",
    "    no_outg_time_infos_df = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "        summary_paths           = [AMIEndEvents.find_summary_file_from_csv(x) for x in paths], \n",
    "        output_prem_nbs_col     = 'prem_nbs', \n",
    "        output_t_min_col        = 't_min', \n",
    "        output_t_max_col        = 't_max', \n",
    "        make_addtnl_groupby_idx = True, \n",
    "        include_summary_paths   = True\n",
    "    )\n",
    "    #-------------------------\n",
    "    rcpo_df = Utilities_df.merge_dfs(\n",
    "        df_1        = rcpo_df, \n",
    "        df_2        = no_outg_time_infos_df, \n",
    "        merge_on_1  = [\n",
    "            ('index', 'trsf_pole_nb'), \n",
    "            ('index', 'no_outg_rec_nb')\n",
    "        ], \n",
    "        merge_on_2  = [\n",
    "            ('index', 'trsf_pole_nb'), \n",
    "            ('index', 'no_outg_rec_nb')\n",
    "        ], \n",
    "        how         = 'left', \n",
    "        final_index = 1, \n",
    "        dummy_col_levels_prefix = time_cols_prefix\n",
    "    )\n",
    "else:\n",
    "    rcpo_df = DOVSOutages.append_outg_info_to_df(\n",
    "        df                        = rcpo_df, \n",
    "        outg_rec_nb_idfr          = 'index', \n",
    "        contstruct_df_args        = None, \n",
    "        build_sql_function        = None, \n",
    "        build_sql_function_kwargs = None, \n",
    "        dummy_col_levels_prefix   = time_cols_prefix\n",
    "    )\n",
    "#-------------------------    \n",
    "assert(rcpo_df.columns.nlevels==2)\n",
    "time_cols_lvl_0_val = f'{time_cols_prefix}0'\n",
    "assert(time_cols_lvl_0_val in rcpo_df.columns.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49277687-df26-4bab-bb85-6b817772e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "borrow_mp_df_curr_hist_if_exists = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae38a4e-d429-408c-920d-70c63a62d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp_serial_number_col = 'mfr_devc_ser_nbr'\n",
    "df_mp_prem_nb_col       = 'prem_nb'\n",
    "df_mp_install_time_col  = 'inst_ts' \n",
    "df_mp_removal_time_col  = 'rmvl_ts' \n",
    "df_mp_trsf_pole_nb_col  = 'trsf_pole_nb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf52c3-1353-4b2e-a10a-21cc5a0a07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df_curr_hist = None\n",
    "if borrow_mp_df_curr_hist_if_exists:\n",
    "    mp_df_curr_hist = OutageMdlrPrep.try_to_steal_mp_df_curr_hist_from_previous(\n",
    "        save_dir_base_pkls      = save_dir_base_pkls, \n",
    "        days_min_outg_td_window = days_min_outg_td_window, \n",
    "        days_max_outg_td_window = days_max_outg_td_window, \n",
    "        subdir_regex            = r'^outg_td_window_(\\d*)_to_(\\d*)_days$', \n",
    "        naming_tag              = naming_tag, \n",
    "        verbose                 = True, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016054b-fd67-43e5-8247-133194ef162f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9caa1-fd48-4ae3-8bdc-e46a50943602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If borrow_mp_df_curr_hist_if_exists==False OR if True but no appropriate mp_df_curr_hist was found\n",
    "#   then mp_df_curr_hist must be built!\n",
    "# In either case, mp_df_curr_hist will be None\n",
    "if mp_df_curr_hist is None:\n",
    "    #--------------------------------------------------\n",
    "    # NOTE: Need mp_df_curr and mp_df_hist separate for functionality, so one cannot simply use mp_df loaded earlier.\n",
    "    # NOTE: drop_approx_duplicates=False below. These will be dropped later\n",
    "    #-----\n",
    "    if grp_by_col=='outg_rec_nb':\n",
    "        mp_df_curr_hist = DOVSOutages.build_mp_df_curr_hist_for_outgs(\n",
    "            outg_rec_nbs            = rcpo_df.index.get_level_values(outg_rec_nb_idx_lvl).tolist(), \n",
    "            join_curr_hist          = False, \n",
    "            addtnl_mp_df_curr_cols  = None, \n",
    "            addtnl_mp_df_hist_cols  = None, \n",
    "            df_mp_serial_number_col = df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col       = df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col  = df_mp_install_time_col, \n",
    "            df_mp_removal_time_col  = df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col  = df_mp_trsf_pole_nb_col\n",
    "        )\n",
    "    else:\n",
    "        mp_df_curr_hist = MeterPremise.build_mp_df_curr_hist_for_xfmrs(\n",
    "            trsf_pole_nbs               = rcpo_df.index.get_level_values(trsf_pole_nbs_idx_lvl).tolist(), \n",
    "            join_curr_hist              = False, \n",
    "            addtnl_mp_df_curr_cols      = None, \n",
    "            addtnl_mp_df_hist_cols      = None, \n",
    "            assume_one_xfmr_per_PN      = True, \n",
    "            drop_approx_duplicates      = False, \n",
    "            drop_approx_duplicates_args = None, \n",
    "            df_mp_serial_number_col     = df_mp_serial_number_col, \n",
    "            df_mp_prem_nb_col           = df_mp_prem_nb_col, \n",
    "            df_mp_install_time_col      = df_mp_install_time_col, \n",
    "            df_mp_removal_time_col      = df_mp_removal_time_col, \n",
    "            df_mp_trsf_pole_nb_col      = df_mp_trsf_pole_nb_col\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38e43a-70cb-4e47-90b0-1d0b988d73ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03226b80-eabd-477c-894d-35f0c8181572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Make sure all dates are datetime objects, not e.g., strings\n",
    "mp_df_curr_hist = Utilities_df.ensure_dt_cols(\n",
    "    df      = mp_df_curr_hist, \n",
    "    dt_cols = [df_mp_install_time_col, df_mp_removal_time_col]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec26e6-72b9-4eb6-b9c5-7cd0ebc20b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# I don't think I want to do the removal on current, only hist!\n",
    "# This is because current is used for get_SNs_andor_PNs_for_xfmrs\n",
    "# e.g., I was missing some PNs because maybe a new meter was installed after rcpo_df['DT_OFF_TS_FULL'].max()\n",
    "#   So, in all likelihood that was an appropriate meter entry in historical, but this was excluded because\n",
    "#   there wasn't an entry in current that passed the cuts below\n",
    "#-----\n",
    "if is_no_outage:\n",
    "    t_min_col = 't_min'\n",
    "    t_max_col = 't_max'\n",
    "else:\n",
    "    t_min_col = 'DT_OFF_TS_FULL'\n",
    "    t_max_col = 'DT_OFF_TS_FULL'\n",
    "    # t_max_col = 'DT_ON_TS'\n",
    "#-----    \n",
    "rcpo_df_t_min = rcpo_df[(time_cols_lvl_0_val, t_min_col)].min()\n",
    "rcpo_df_t_max = rcpo_df[(time_cols_lvl_0_val, t_max_col)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766b710-4ca8-490d-b53b-ff1a80ea82e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc5e8c-89c5-4416-9b5d-b95cd29ca12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a655854-4499-4d75-80c2-17e629201d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df_curr_hist = OutageMdlrPrep.rough_time_slice_and_drop_dups_mp_df_curr_hist(\n",
    "    mp_df_curr_hist         = mp_df_curr_hist, \n",
    "    t_min                   = rcpo_df_t_min, \n",
    "    t_max                   = rcpo_df_t_max, \n",
    "    df_mp_serial_number_col = 'mfr_devc_ser_nbr', \n",
    "    df_mp_prem_nb_col       = 'prem_nb', \n",
    "    df_mp_install_time_col  = 'inst_ts', \n",
    "    df_mp_removal_time_col  = 'rmvl_ts', \n",
    "    df_mp_trsf_pole_nb_col  = 'trsf_pole_nb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cffdd9-bd29-4826-8120-33d7c1d38649",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_dfs_to_pkl:\n",
    "    mp_df_curr_hist['mp_df_hist'].to_pickle(os.path.join(save_dir_pkls, f'mp{naming_tag}_df_hist.pkl'))\n",
    "    mp_df_curr_hist['mp_df_curr'].to_pickle(os.path.join(save_dir_pkls, f'mp{naming_tag}_df_curr.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a98c5e-6a54-4325-9752-80a0256aba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529cfbd-4a4a-4395-855b-8c1c89ea3472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74db7f-fa0b-4541-a26f-c429061ded7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a04b3c-d680-494c-be9c-245d92849e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Need time_infos_df (only if grp_by_col!='outg_rec_nb')\n",
    "if grp_by_col!='outg_rec_nb':\n",
    "    if not read_dfs_from_pkl:\n",
    "        if is_no_outage:\n",
    "            paths = Utilities.find_all_paths(\n",
    "                base_dir     = files_dir, \n",
    "                glob_pattern = file_path_glob\n",
    "            )\n",
    "            #-----\n",
    "            time_infos_df = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "                summary_paths           = [AMIEndEvents.find_summary_file_from_csv(x) for x in paths], \n",
    "                output_prem_nbs_col     = 'prem_nbs', \n",
    "                output_t_min_col        = 't_min', \n",
    "                output_t_max_col        = 't_max', \n",
    "                make_addtnl_groupby_idx = True, \n",
    "                include_summary_paths   = False\n",
    "            )\n",
    "        else:\n",
    "            time_infos_df = OutageMdlrPrep.get_outg_time_infos_df(\n",
    "                rcpo_df                       = rcpo_df, \n",
    "                outg_rec_nb_idx_lvl           = outg_rec_nb_idx_lvl, \n",
    "                times_relative_to_off_ts_only = True, \n",
    "                td_for_left                   = None, \n",
    "                td_for_right                  = None\n",
    "            )\n",
    "        #-------------------------\n",
    "        if save_dfs_to_pkl:\n",
    "            time_infos_df.to_pickle(os.path.join(save_dir_pkls, f'time_infos{naming_tag}_df.pkl'))\n",
    "    else:\n",
    "        time_infos_df = pd.read_pickle(os.path.join(save_dir_pkls, f'time_infos{naming_tag}_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53e060-d9a2-4f65-b5e9-83c9d43486b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00872a37-ef62-42e1-81c2-63c01145fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not read_dfs_from_pkl:\n",
    "    start=time.time()\n",
    "    #--------------------------------------------------\n",
    "    rcpo_df_raw = MECPODf.project_level_0_columns_from_rcpo_wide(\n",
    "        rcpo_df_wide = rcpo_df, \n",
    "        level_0_val  = 'counts', \n",
    "        droplevel    = True\n",
    "    )\n",
    "    #-----\n",
    "    if grp_by_col=='outg_rec_nb':\n",
    "        rcpo_df_raw = MECPODf.add_outage_active_SNs_to_rcpo_df(\n",
    "            rcpo_df                    = rcpo_df_raw, \n",
    "            set_outage_nSNs            = True, \n",
    "            include_outage_premise_nbs = True, \n",
    "            df_mp_curr                 = mp_df_curr_hist['mp_df_curr'], \n",
    "            df_mp_hist                 = mp_df_curr_hist['mp_df_hist']\n",
    "        )\n",
    "        #-----\n",
    "        rcpo_df_raw = MECPODf.add_active_prim_SNs_to_rcpo_df(\n",
    "            rcpo_df                             = rcpo_df_raw, \n",
    "            direct_SNs_in_outgs_df              = None, \n",
    "            outg_rec_nb_col                     = 'index', \n",
    "            prim_SNs_col                        = 'direct_serial_numbers', \n",
    "            set_prim_nSNs                       = True, \n",
    "            sort_SNs                            = True, \n",
    "            build_direct_SNs_in_outgs_df_kwargs = {}, \n",
    "            mp_df_curr                          = mp_df_curr_hist['mp_df_curr'], \n",
    "            mp_df_hist                          = mp_df_curr_hist['mp_df_hist']\n",
    "        )\n",
    "    else:\n",
    "        rcpo_df_raw = OutageMdlrPrep.add_xfmr_active_SNs_to_rcpo_df(\n",
    "            rcpo_df                                = rcpo_df_raw, \n",
    "            trsf_pole_nbs_loc                      = trsf_pole_nbs_loc, \n",
    "            set_xfmr_nSNs                          = True, \n",
    "            include_active_xfmr_PNs                = True, \n",
    "            df_mp_curr                             = mp_df_curr_hist['mp_df_curr'],\n",
    "            df_mp_hist                             = mp_df_curr_hist['mp_df_hist'], \n",
    "            time_infos_df                          = time_infos_df, \n",
    "            rcpo_df_to_time_infos_on               = rcpo_df_to_time_infos_on, \n",
    "            time_infos_to_rcpo_df_on               = time_infos_to_rcpo_df_on, \n",
    "            how                                    = how, \n",
    "            rcpo_df_to_PNs_on                      = rcpo_df_to_PNs_on, \n",
    "            PNs_to_rcpo_df_on                      = PNs_to_rcpo_df_on, \n",
    "            addtnl_get_active_SNs_for_xfmrs_kwargs = dict(\n",
    "                assert_all_trsf_pole_nbs_found=False\n",
    "            ), \n",
    "            xfmr_SNs_col                           = '_xfmr_SNs', \n",
    "            xfmr_nSNs_col                          = '_xfmr_nSNs', \n",
    "            xfmr_PNs_col                           = '_xfmr_PNs', \n",
    "            xfmr_nPNs_col                          = '_xfmr_nPNs',  \n",
    "        )\n",
    "    #-------------------------\n",
    "    icpo_df_raw = MECPODf.convert_rcpo_to_icpo_df(\n",
    "        rcpo_df                 = rcpo_df_raw, \n",
    "        reason_to_ede_typeid_df = reason_to_ede_typeid_df, \n",
    "        is_norm                 = False\n",
    "    )\n",
    "    #-------------------------\n",
    "    if save_dfs_to_pkl:\n",
    "        #-------------------------\n",
    "        rcpo_df_raw.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_raw.pkl'))\n",
    "        icpo_df_raw.to_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_raw.pkl'))\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    rcpo_df_norm = MECPODf.project_level_0_columns_from_rcpo_wide(\n",
    "        rcpo_df_wide = rcpo_df, \n",
    "        level_0_val  = 'counts_norm', \n",
    "        droplevel    = True\n",
    "    )\n",
    "    #-------------------------\n",
    "    icpo_df_norm = MECPODf.convert_rcpo_to_icpo_df(\n",
    "        rcpo_df                 = rcpo_df_norm, \n",
    "        reason_to_ede_typeid_df = reason_to_ede_typeid_df, \n",
    "        is_norm                 = True, \n",
    "        counts_col              = '_nSNs'\n",
    "    )\n",
    "    #-------------------------\n",
    "    if save_dfs_to_pkl:\n",
    "        #-------------------------\n",
    "        rcpo_df_norm.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm.pkl'))\n",
    "        icpo_df_norm.to_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm.pkl'))\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    if grp_by_col=='outg_rec_nb':\n",
    "        #--------------------------------------------------\n",
    "        rcpo_df_norm_by_outg_nSNs = MECPODf.build_rcpo_df_norm_by_outg_active_nSNs(\n",
    "            rcpo_df_raw, \n",
    "            df_mp_curr = mp_df_curr_hist['mp_df_curr'], \n",
    "            df_mp_hist = mp_df_curr_hist['mp_df_hist']\n",
    "        )\n",
    "        #-------------------------\n",
    "        icpo_df_norm_by_outg_nSNs = MECPODf.convert_rcpo_to_icpo_df(\n",
    "            rcpo_df                 = rcpo_df_norm_by_outg_nSNs, \n",
    "            reason_to_ede_typeid_df = reason_to_ede_typeid_df, \n",
    "            is_norm                 = True, \n",
    "            counts_col              = '_outg_nSNs'\n",
    "        )\n",
    "        #-------------------------\n",
    "        if save_dfs_to_pkl:\n",
    "            #-------------------------\n",
    "            rcpo_df_norm_by_outg_nSNs.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_outg_nSNs.pkl'))\n",
    "            icpo_df_norm_by_outg_nSNs.to_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_outg_nSNs.pkl'))\n",
    "        \n",
    "\n",
    "        #--------------------------------------------------\n",
    "        rcpo_df_norm_by_prim_nSNs = MECPODf.build_rcpo_df_norm_by_prim_active_nSNs(\n",
    "            rcpo_df_raw                         = rcpo_df_raw, \n",
    "            direct_SNs_in_outgs_df              = None, \n",
    "            outg_rec_nb_col                     = 'index', \n",
    "            prim_nSNs_col                       = '_prim_nSNs', \n",
    "            prim_SNs_col                        = '_prim_SNs', \n",
    "            other_SNs_col_tags_to_ignore        = ['_SNs', '_nSNs', '_prem_nbs', '_nprem_nbs'], \n",
    "            drop_prim_nSNs_eq_0                 = True, \n",
    "            new_level_0_val                     = 'counts_norm_by_prim_nSNs', \n",
    "            remove_SNs_cols                     = False, \n",
    "            build_direct_SNs_in_outgs_df_kwargs = dict(\n",
    "                equip_typ_nms_of_interest = xfmr_equip_typ_nms_of_interest\n",
    "            ), \n",
    "            df_mp_curr                          = mp_df_curr_hist['mp_df_curr'], \n",
    "            df_mp_hist                          = mp_df_curr_hist['mp_df_hist']\n",
    "        )\n",
    "        #-------------------------\n",
    "        icpo_df_norm_by_prim_nSNs = MECPODf.convert_rcpo_to_icpo_df(\n",
    "            rcpo_df                 = rcpo_df_norm_by_prim_nSNs, \n",
    "            reason_to_ede_typeid_df = reason_to_ede_typeid_df, \n",
    "            is_norm                 = True, \n",
    "            counts_col              = '_prim_nSNs'\n",
    "        )\n",
    "        #-------------------------\n",
    "        if save_dfs_to_pkl:\n",
    "            #-------------------------\n",
    "            rcpo_df_norm_by_prim_nSNs.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_prim_nSNs.pkl'))\n",
    "            icpo_df_norm_by_prim_nSNs.to_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_prim_nSNs.pkl'))\n",
    "    else:\n",
    "        #--------------------------------------------------\n",
    "        rcpo_df_norm_by_xfmr_nSNs = OutageMdlrPrep.build_rcpo_df_norm_by_xfmr_active_nSNs(\n",
    "            rcpo_df_raw                            = rcpo_df_raw, \n",
    "            trsf_pole_nbs_loc                      = trsf_pole_nbs_loc, \n",
    "            xfmr_nSNs_col                          = '_xfmr_nSNs', \n",
    "            xfmr_SNs_col                           = '_xfmr_SNs', \n",
    "            other_SNs_col_tags_to_ignore           = ['_SNs', '_nSNs', '_prem_nbs', '_nprem_nbs', '_xfmr_PNs', '_xfmr_nPNs'], \n",
    "            drop_xfmr_nSNs_eq_0                    = True, \n",
    "            new_level_0_val                        = 'counts_norm_by_xfmr_nSNs', \n",
    "            remove_SNs_cols                        = False, \n",
    "            df_mp_curr                             = mp_df_curr_hist['mp_df_curr'],\n",
    "            df_mp_hist                             = mp_df_curr_hist['mp_df_hist'], \n",
    "            time_infos_df                          = time_infos_df,\n",
    "            rcpo_df_to_time_infos_on               = rcpo_df_to_time_infos_on, \n",
    "            time_infos_to_rcpo_df_on               = time_infos_to_rcpo_df_on, \n",
    "            how                                    = how, \n",
    "            rcpo_df_to_PNs_on                      = rcpo_df_to_PNs_on, \n",
    "            PNs_to_rcpo_df_on                      = PNs_to_rcpo_df_on, \n",
    "            addtnl_get_active_SNs_for_xfmrs_kwargs = dict(\n",
    "                assert_all_trsf_pole_nbs_found=False\n",
    "            ), \n",
    "        )\n",
    "        #-------------------------\n",
    "        icpo_df_norm_by_xfmr_nSNs = MECPODf.convert_rcpo_to_icpo_df(\n",
    "            rcpo_df                 = rcpo_df_norm_by_xfmr_nSNs, \n",
    "            reason_to_ede_typeid_df = reason_to_ede_typeid_df, \n",
    "            is_norm                 = True, \n",
    "            counts_col              = '_xfmr_nSNs'\n",
    "        )\n",
    "        #-------------------------\n",
    "        if save_dfs_to_pkl:\n",
    "            #-------------------------\n",
    "            rcpo_df_norm_by_xfmr_nSNs.to_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_xfmr_nSNs.pkl'))\n",
    "            icpo_df_norm_by_xfmr_nSNs.to_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_xfmr_nSNs.pkl'))\n",
    "    \n",
    "    #-------------------------\n",
    "    print(time.time()-start)\n",
    "    #-------------------------\n",
    "else:\n",
    "    rcpo_df_raw               = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_raw.pkl'))\n",
    "    icpo_df_raw               = pd.read_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_raw.pkl'))\n",
    "    #-----\n",
    "    rcpo_df_norm              = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm.pkl'))\n",
    "    icpo_df_norm              = pd.read_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm.pkl'))\n",
    "\n",
    "    if grp_by_col=='outg_rec_nb':\n",
    "        rcpo_df_norm_by_outg_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_outg_nSNs.pkl'))\n",
    "        icpo_df_norm_by_outg_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_outg_nSNs.pkl'))\n",
    "        #-----\n",
    "        rcpo_df_norm_by_prim_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_prim_nSNs.pkl'))\n",
    "        icpo_df_norm_by_prim_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_prim_nSNs.pkl'))\n",
    "    else:\n",
    "        rcpo_df_norm_by_xfmr_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'rcpo{naming_tag}_df_norm_by_xfmr_nSNs.pkl'))\n",
    "        icpo_df_norm_by_xfmr_nSNs = pd.read_pickle(os.path.join(save_dir_pkls, f'icpo{naming_tag}_df_norm_by_xfmr_nSNs.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024287-280d-4f38-9255-652ab9d50a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e31a6-0be3-48f8-9959-49c493260c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b0288-4c1e-4739-875f-083561f9a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['no_outg_rec_nb_GPD_FOR_SQL', 'trsf_pole_nb_GPD_FOR_SQL']\n",
    "outg_rec_nb_col = 'no_outg_rec_nb'\n",
    "# files_dir                   = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20240620\\20230401_20240331\\Outages\\EvsSums'\n",
    "files_dir                   = r'C:\\Users\\s346557\\Documents\\LocalData\\dovs_and_end_events_data\\20240621\\20230401_20240331\\OutgXfmrBaseline\\EvsSums'\n",
    "file_path_glob              = r'events_summary_[0-9]*.csv'\n",
    "file_path_regex             = None\n",
    "\n",
    "# batch_size                     = 50\n",
    "batch_size                     = 10\n",
    "verbose = True\n",
    "n_update                       = 1\n",
    "cols_and_types_to_convert_dict = None\n",
    "to_numeric_errors              = 'coerce'\n",
    "make_all_columns_lowercase     = True\n",
    "assert_all_cols_equal          = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6379d6-3f63-485b-b405-20c8df7bf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df_0 = OutageMdlrPrep.build_evsSum_df_from_csvs(\n",
    "    files_dir                      = files_dir, \n",
    "    file_path_glob                 = file_path_glob, \n",
    "    file_path_regex                = file_path_regex, \n",
    "    batch_size                     = batch_size, \n",
    "    cols_and_types_to_convert_dict = cols_and_types_to_convert_dict, \n",
    "    to_numeric_errors              = to_numeric_errors, \n",
    "    make_all_columns_lowercase     = make_all_columns_lowercase, \n",
    "    assert_all_cols_equal          = assert_all_cols_equal,  \n",
    "    n_update                       = n_update, \n",
    "    verbose                        = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb258ad-046b-4402-a33a-78d973c23daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35182c67-24b9-4d6d-b917-fd8dbb357630",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df                   = evsSum_df_0.copy()\n",
    "prediction_date             = pd.to_datetime('2023-05-03 00:00:00')\n",
    "td_min                      = pd.Timedelta('1D')\n",
    "td_max                      = pd.Timedelta('31D')\n",
    "data_structure_df           = None\n",
    "cr_trans_dict               = None\n",
    "freq                        = '5D'\n",
    "# freq                        = None\n",
    "# group_cols                  = ['OUTG_REC_NB_GPD_FOR_SQL', 'trsf_pole_nb_GPD_FOR_SQL']\n",
    "date_col                    = 'aep_event_dt'\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "## Set to False, False last night, and was much closer to expected (and was non-zero for test case)\n",
    "# normalize_by_SNs            = True\n",
    "# normalize_by_time           = True\n",
    "\n",
    "normalize_by_SNs            = False\n",
    "normalize_by_time           = False\n",
    "\n",
    "include_power_down_minus_up = False\n",
    "regex_patterns_to_remove    = ['.*cleared.*', '.*Test Mode.*']\n",
    "combine_cpo_df_reasons      = True\n",
    "xf_meter_cnt_col            = 'xf_meter_cnt'\n",
    "events_tot_col              = 'events_tot'\n",
    "# outg_rec_nb_col             = 'outg_rec_nb\n",
    "trsf_pole_nb_col            = 'trsf_pole_nb'\n",
    "prem_nb_col                 = 'aep_premise_nb'\n",
    "serial_number_col           = 'serialnumber'\n",
    "other_reasons_col           = 'Other Reasons'\n",
    "total_counts_col            = 'total_counts'\n",
    "nSNs_col                    = 'nSNs'\n",
    "trust_sql_grouping          = True\n",
    "drop_gpd_for_sql_appendix   = True\n",
    "make_all_columns_lowercase  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de5c7e-222e-4b2c-8e7a-232676bb8ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548416d-7cf3-4aec-88c9-2ccd58836ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7c223-1f38-4b32-9967-0460317d2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df = evsSum_df_0.copy()\n",
    "group_cols = ['no_outg_rec_nb', 'trsf_pole_nb']\n",
    "evsSum_df = evsSum_df.rename(columns={'no_outg_rec_nb_gpd_for_sql':'no_outg_rec_nb', 'trsf_pole_nb_gpd':'trsf_pole_nb'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89a85c-8571-4b07-8a90-dd62a05a96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Utilities.find_all_paths(\n",
    "    base_dir     = files_dir, \n",
    "    glob_pattern = file_path_glob\n",
    ")\n",
    "#-----\n",
    "time_infos_df = MECPOAn.get_bsln_time_interval_infos_df_from_summary_files(\n",
    "    summary_paths           = [AMIEndEvents.find_summary_file_from_csv(x) for x in paths], \n",
    "    output_prem_nbs_col     = 'prem_nbs', \n",
    "    output_t_min_col        = 't_min', \n",
    "    output_t_max_col        = 't_max', \n",
    "    make_addtnl_groupby_idx = True, \n",
    "    include_summary_paths   = False, \n",
    "    date_only               = True, \n",
    "    date_col                = 'aep_event_dt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abf6d5-87e9-4ca8-b526-269d64aad668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b7eda-aa83-4e23-9015-9e2418b6fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(set(group_cols).difference(set(time_infos_df.reset_index().columns.tolist()))==set())\n",
    "assert(set(group_cols).difference(set(evsSum_df.columns.tolist()))==set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071897b-b777-4f12-b2f0-e7757b096788",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07330407-0ca9-45bb-a8a2-83d8607f1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_infos_df.loc[('1686036438804', 'Wroux10000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b509cff-5792-477c-b66f-7e9f9fca187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min_col = 't_min'\n",
    "t_max_col = 't_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b08a3-16e0-41bf-a3c9-ff8b8755f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_infos_df = time_infos_df.reset_index(drop=False)[group_cols+[t_min_col, t_max_col]].drop_duplicates()\n",
    "assert((time_infos_df.groupby(group_cols).size()<=1).all())\n",
    "#-------------------------\n",
    "evsSum_df_wtinfo = pd.merge(\n",
    "    evsSum_df, \n",
    "    time_infos_df, \n",
    "    how      = 'left', \n",
    "    left_on  = group_cols, \n",
    "    right_on = group_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6373e-1452-4940-ae10-73bc25816585",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df_wtinfo = evsSum_df_wtinfo[\n",
    "    (evsSum_df_wtinfo[date_col] >= evsSum_df_wtinfo[t_min_col]) & \n",
    "    (evsSum_df_wtinfo[date_col] <  evsSum_df_wtinfo[t_max_col])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd774ac0-7235-4a74-89a3-221f5a826086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab89eb7-8c03-43a7-8d3b-6830c8d10045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, this should come from data, NOT be calculated.\n",
    "evsSum_df_wtinfo['date_relative'] = evsSum_df_wtinfo[t_max_col]-evsSum_df_wtinfo[date_col]\n",
    "\n",
    "# Shift everything relative to a dummy date\n",
    "evsSum_df_wtinfo['dummy_date'] = pd.to_datetime('2 Nov. 1987') - evsSum_df_wtinfo['date_relative']\n",
    "\n",
    "date_col = 'dummy_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c837c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3c001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df = evsSum_df_wtinfo.copy()\n",
    "\n",
    "# evsSum_df = evsSum_df[(evsSum_df['no_outg_rec_nb']=='Wroux10000') & (evsSum_df['trsf_pole_nb']=='1686036438804')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c542ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_rcpx_from_evsSum_df\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Make sure td_min, td_max, and freq are all pd.Timedelta objects\n",
    "td_min = pd.Timedelta(td_min)\n",
    "td_max = pd.Timedelta(td_max)\n",
    "#-------------------------\n",
    "OutageMdlrPrep.assert_timedelta_is_days(td_min)\n",
    "OutageMdlrPrep.assert_timedelta_is_days(td_max)\n",
    "#-----\n",
    "days_min = td_min.days\n",
    "days_max = td_max.days\n",
    "if freq is not None:\n",
    "    freq   = pd.Timedelta(freq)\n",
    "    OutageMdlrPrep.assert_timedelta_is_days(freq)\n",
    "    days_freq = freq.days\n",
    "#--------------------------------------------------\n",
    "#-------------------------\n",
    "prereq_dict = OutageMdlrPrep.perform_build_RCPX_from_end_events_df_prereqs(\n",
    "    end_events_df                 = evsSum_df, \n",
    "    mp_df                         = None, \n",
    "    ede_mp_mismatch_threshold_pct = 1.0, \n",
    "    grp_by_cols                   = group_cols, \n",
    "    outg_rec_nb_col               = outg_rec_nb_col,\n",
    "    trsf_pole_nb_col              = trsf_pole_nb_col, \n",
    "    prem_nb_col                   = prem_nb_col, \n",
    "    serial_number_col             = serial_number_col,\n",
    "    mp_df_cols                    = None,  # Only needed if mp_df is not None\n",
    "    is_no_outage                  = False, # Only needed if mp_df is not None\n",
    "    trust_sql_grouping            = trust_sql_grouping, \n",
    "    drop_gpd_for_sql_appendix     = drop_gpd_for_sql_appendix, \n",
    "    make_all_columns_lowercase    = make_all_columns_lowercase\n",
    ")\n",
    "group_cols        = prereq_dict['grp_by_cols']\n",
    "outg_rec_nb_col   = prereq_dict['outg_rec_nb_col']\n",
    "trsf_pole_nb_col  = prereq_dict['trsf_pole_nb_col']\n",
    "prem_nb_col       = prereq_dict['prem_nb_col']\n",
    "serial_number_col = prereq_dict['serial_number_col']\n",
    "cols_to_drop      = prereq_dict['cols_to_drop']\n",
    "rename_cols_dict  = prereq_dict['rename_cols_dict']\n",
    "mp_df             = prereq_dict['mp_df']\n",
    "merge_on_ede      = prereq_dict['merge_on_ede']\n",
    "merge_on_mp       = prereq_dict['merge_on_mp']\n",
    "#--------------------------------------------------\n",
    "#-------------------------\n",
    "if make_all_columns_lowercase:\n",
    "    date_col          = date_col.lower()\n",
    "    xf_meter_cnt_col  = xf_meter_cnt_col.lower()\n",
    "    events_tot_col    = events_tot_col.lower()\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Look for any columns ending in _GPD_FOR_SQL and if not included in grpyby cols, then print warning!\n",
    "found_gpd_for_sql_cols = OutageMdlrPrep.find_gpd_for_sql_cols(\n",
    "    df        = evsSum_df, \n",
    "    col_level = -1\n",
    ")\n",
    "if len(found_gpd_for_sql_cols)>0:\n",
    "    # make loweercase, if needed\n",
    "    if make_all_columns_lowercase:\n",
    "        found_gpd_for_sql_cols = [x.lower() for x in found_gpd_for_sql_cols]\n",
    "    # change names, if needed\n",
    "    found_gpd_for_sql_cols = [rename_cols_dict.get(x, x) for x in found_gpd_for_sql_cols]\n",
    "    #-----\n",
    "    not_included = list(set(found_gpd_for_sql_cols).difference(set(group_cols)))\n",
    "    if len(not_included)>0:\n",
    "        print('\\n!!!!! WARNING !!!!!\\nOutageMdlrPrep.build_rcpx_from_evsSum_df\\nFOUND POSSIBLE GROUPBY COLUMNS NOT INCLUDED IN group_cols argument')\n",
    "        print(f\"\\tnot_included           = {not_included}\\n\\tfound_gpd_for_sql_cols = {found_gpd_for_sql_cols}\\n\\tgroup_cols             = {group_cols}\")   \n",
    "        print('!!!!!!!!!!!!!!!!!!!\\n')\n",
    "\n",
    "#-------------------------\n",
    "evsSum_df = OutageMdlrPrep.perform_std_col_renames_and_drops(\n",
    "    end_events_df              = evsSum_df.copy(), \n",
    "    cols_to_drop               = cols_to_drop, \n",
    "    rename_cols_dict           = rename_cols_dict, \n",
    "    make_all_columns_lowercase = make_all_columns_lowercase\n",
    ")\n",
    "#-----\n",
    "nec_cols = group_cols + [date_col, xf_meter_cnt_col, events_tot_col, trsf_pole_nb_col]\n",
    "assert(set(nec_cols).difference(set(evsSum_df.columns.tolist()))==set()) \n",
    "\n",
    "#--------------------------------------------------\n",
    "# 1. Build rcpo_0\n",
    "#     Construct rcpx_0 by aggregating evsSum_df by group_cols and by freq on date_col\n",
    "#--------------------------------------------------\n",
    "evsSum_df = OutageMdlrPrep.perform_std_col_type_conversions(evsSum_df = evsSum_df)\n",
    "#-------------------------\n",
    "if not isinstance(group_cols, list):\n",
    "    group_cols = [group_cols]\n",
    "assert(len(set(group_cols).difference(set(evsSum_df.columns.tolist())))==0)\n",
    "#-------------------------\n",
    "cr_cols = Utilities.find_in_list_with_regex(\n",
    "    lst           = evsSum_df.columns.tolist(), \n",
    "    regex_pattern = r'cr\\d*', \n",
    "    ignore_case   = False\n",
    ")\n",
    "#-----\n",
    "# cols_to_drop below are different from cols_to_drop = prereq_dict['cols_to_drop'] above.\n",
    "#   That defined above is used to remove cases when col_x and f\"{col_x}_GPD_FOR_SQL\" both exist in the data.\n",
    "#     For such cases, the trust_sql_grouping parameter settles which is kept.\n",
    "#   For that defined below, cols_to_drop is used to remove all the columns no longer needed for the analysis\n",
    "#       Typically, e.g., group_cols = ['outg_rec_nb', 'trsf_pole_nb']\n",
    "#       ==> cols_to_drop = ['is_first_after_outg', 'aep_opco', 'serialnumber', 'aep_premise_nb']\n",
    "cols_to_drop = set(evsSum_df.columns.tolist()).difference(\n",
    "    set(cr_cols+group_cols+[date_col, xf_meter_cnt_col, events_tot_col])\n",
    ")\n",
    "cols_to_drop = list(cols_to_drop)\n",
    "#-------------------------\n",
    "# Make sure date_col is datetime object\n",
    "evsSum_df[date_col] = pd.to_datetime(evsSum_df[date_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f775a8f-a663-4061-b16e-b397c77bb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evsSum_df[(evsSum_df['no_outg_rec_nb']=='Wroux10000') & (evsSum_df['trsf_pole_nb']=='1686036438804')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46ad23-1fe8-4c5d-a9e0-216b755d8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evsSum_df.sort_values(by='dummy_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# All of the cr# columns will be aggregated with np.sum, as will events_tot_col\n",
    "# xf_meter_cnt_col will be aggregated using np.max\n",
    "agg_dict = {col:'sum' for col in cr_cols+[events_tot_col, xf_meter_cnt_col]}\n",
    "agg_dict[xf_meter_cnt_col] = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35696f4c-a11a-4241-b027-b6dbbcf8b4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abdfc5-c1fa-4e25-aff0-2f9dc98b3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MECPOCollection import MECPOCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84e321-3856-400b-8521-b276fa23fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "evsSum_df['time_pd_grp']       = np.digitize(evsSum_df['date_relative'].dt.days, np.arange(days_min, days_max+1, days_freq))\n",
    "evsSum_df['time_pd_grp_width'] = days_freq \n",
    "\n",
    "grps_w_widths = list(evsSum_df.groupby(['time_pd_grp', 'time_pd_grp_width']).groups.keys())\n",
    "# Make sure grps_w_widths is properly sorted\n",
    "grps_w_widths = natsorted(grps_w_widths, key=lambda x:x[0])\n",
    "# Also note, for np.digitize, the indices apparently begin at 1, not 0\n",
    "assert(grps_w_widths[0][0]==1)\n",
    "grps_w_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82701f7f-6ed4-45af-bad5-e1254e6afe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_0 = evsSum_df.drop(columns=cols_to_drop).groupby(group_cols+['time_pd_grp']).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de35dac-a0cf-47f8-82ee-c408503ae568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Using grps_w_widths is a bit overkill currently, since freq is constant.\n",
    "# However, if freq is allowed to be irregular in the future, the overkill included\n",
    "#   will be necessary\n",
    "#-------------------------\n",
    "time_pds_rename = {}\n",
    "#-------------------------\n",
    "# Use padded zeros\n",
    "#   i.e., instead of '1-6 Days', use '01-06 Days'\n",
    "#   Will need to know longest string length for this\n",
    "#-----\n",
    "# Largest number, therefore largest str, will be days_min + all widths\n",
    "str_len = len(str(days_min + np.sum([x[1] for x in grps_w_widths])))\n",
    "#-----\n",
    "# Looks like a ton of curly braces below, but need double {{ and double }} to escape\n",
    "# ==> if str_len=2, then str_fmt = '{:02d}'\n",
    "str_fmt = f'{{:0{str_len}d}}'\n",
    "#-------------------------\n",
    "t_rght_i = days_min\n",
    "# Remember, since np.digitize was used, the indices apparently begin at 1, not 0\n",
    "for grp_i, width_i in grps_w_widths:\n",
    "    t_left_i = t_rght_i\n",
    "    t_rght_i = t_left_i + width_i\n",
    "    #-----\n",
    "    rename_i = \"{}-{} Days\".format(\n",
    "        str_fmt.format(t_left_i), \n",
    "        str_fmt.format(t_rght_i)\n",
    "    )\n",
    "    #-----\n",
    "    assert(grp_i not in time_pds_rename.keys())\n",
    "    time_pds_rename[grp_i] = rename_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28222dc-ecbd-4b4f-ae6d-ba3e9c65d6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66b01b-bc6c-464a-a6bd-a5892e8b8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# 2. Grab meter_cnt_per_gp_srs and all_groups\n",
    "#--------------------------------------------------\n",
    "# Project out the meter count per group, as it will be used later\n",
    "#   This information will be stored in the pd.Series object meter_cnt_per_gp_srs, where the index will\n",
    "#   contain the group_cols\n",
    "#-----\n",
    "# OLD METHOD\n",
    "# meter_cnt_per_gp_srs = rcpx_0.reset_index()[group_cols+['time_pd_grp', xf_meter_cnt_col]].drop_duplicates().set_index(group_cols+['time_pd_grp']).squeeze()\n",
    "#-------------------------\n",
    "meter_cnt_per_gp_srs = rcpx_0.reset_index()[group_cols+['time_pd_grp', xf_meter_cnt_col]].drop_duplicates().set_index(group_cols+['time_pd_grp'])\n",
    "# Generally, calling .squeeze() in this case works fine, UNLESS meter_cnt_per_gp_srs (which is a pd.DataFrame object as this point)\n",
    "#   has a single row, in which case a scalar is returned instead of a pd.Series object.\n",
    "# From the pd.DataFrame.squeeze documentation:\n",
    "#   Series or DataFrames with a single element are squeezed to a scalar.\n",
    "# To overcome the issue here, I specifically call .squeeze(axis=1)\n",
    "# For the more general case, where meter_cnt_per_gp_srs has multiple rows, calling .squeeze(axis=1) should deliver the same results \n",
    "#   as calling .squeeze()\n",
    "# NOTE ALSO: .squeeze(axis=1) could have been tacked on to the above command.  I have broken it out into two steps for illustrative purposes, \n",
    "#              so the explanation above makes sense!\n",
    "meter_cnt_per_gp_srs = meter_cnt_per_gp_srs.squeeze(axis=1)\n",
    "#-------------------------\n",
    "assert(meter_cnt_per_gp_srs.shape[0]==meter_cnt_per_gp_srs.index.nunique())\n",
    "meter_cnt_per_gp_srs.name = nSNs_col\n",
    "\n",
    "# Will also need the unique groups in rcpx_0\n",
    "#   This will be used later (see no_events_pd_i below)\n",
    "#   These can be grabbed from the index of rcpx_0 (excluding the 'time_pd_grp' level)\n",
    "all_groups = rcpx_0.droplevel('time_pd_grp', axis=0).index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfaa03-3d6a-4242-975e-0facb1911e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e913c4-9017-4573-8fa1-19d098f4e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# 3. Transform rcpx_0 to the form expected by the model\n",
    "#     i.e., similar to data_structure_df (if supplied).\n",
    "#     This is essentially just changing rcpo_0 from long form to wide form\n",
    "#--------------------------------------------------\n",
    "#-------------------------\n",
    "# 3a. Build time_pds_rename\n",
    "#      Need to convert the time periods, which are currently housed in the 'time_pd_grp' index of \n",
    "#        rcpx_0 from their specific dates to the names expected by the model.\n",
    "#      In rcpx_0, after grouping by the freq intervals, the values of 'time_pd_grp' are equal to the beginning\n",
    "#        dates of the given interval.\n",
    "#      These will be converted to the titles contained in final_time_pds below\n",
    "#      NOTE: This is probably not 100% necessary, but is useful nonetheless\n",
    "#-------------------------\n",
    "#--------------------------------------------------\n",
    "#    Need for data_structure_df?\n",
    "#     In general, not all curated reasons will be included in the model.\n",
    "#     Typically, 10 commong curated reasons will be included, and all others will be grouped together in \"Other Reasons\".\n",
    "#     Furthermore, some reasons may be combined together, others may be completely removed.\n",
    "#     For these reasons, it is beneficial to have some sample data (taken from when the model was created) to utilize \n",
    "#       in structuring the new data in the same fashion.\n",
    "#     Additionally, the data will be used to ensure the ordering of columns is correct before the data are fed into \n",
    "#       the model.\n",
    "#--------------------------------------------------\n",
    "# if data_structure_df is not None:\n",
    "#     assert(isinstance(data_structure_df, pd.DataFrame) and data_structure_df.shape[0]>0)\n",
    "#     # final_time_pds should all be found in data_structure_df to help\n",
    "#     #   ensure the alignment between the current data and data used when modelling\n",
    "#     assert(set(final_time_pds).difference(data_structure_df.columns.get_level_values(0).unique())==set())\n",
    "\n",
    "#-------------------------\n",
    "# 3b. Transform rcpx_0 to the form expected by the model\n",
    "#      As stated above, this is essentially just changing rcpo_0 from long form to wide form\n",
    "#      This will probably be formalized further in the future (i.e., function(s) developed to handle)\n",
    "rename_cols = {\n",
    "    events_tot_col   : total_counts_col, \n",
    "    xf_meter_cnt_col : nSNs_col\n",
    "}\n",
    "rcpx_0=rcpx_0.rename(columns=rename_cols)\n",
    "#-------------------------\n",
    "total_counts_col = total_counts_col\n",
    "nSNs_col         = nSNs_col\n",
    "non_reason_cols  = [nSNs_col, total_counts_col]\n",
    "#------------------------- \n",
    "pd_dfs = []\n",
    "for grp_i, width_i in grps_w_widths:\n",
    "    time_pd_i = grp_i\n",
    "    # Grab the proper time period name from final_time_pd_i\n",
    "    time_pd_i_rename = time_pds_rename[time_pd_i]\n",
    "    #-------------------------\n",
    "    rcpx_0_pd_i = OutageMdlrPrep.project_time_pd_from_rcpx_0_and_prepare(\n",
    "        rcpx_0                      = rcpx_0, \n",
    "        time_pd_i                   = time_pd_i, \n",
    "        meter_cnt_per_gp_srs        = meter_cnt_per_gp_srs, \n",
    "        all_groups                  = all_groups, \n",
    "        non_reason_cols             = non_reason_cols, \n",
    "        data_structure_df           = data_structure_df, \n",
    "        other_reasons_col           = other_reasons_col, \n",
    "        cr_trans_dict               = cr_trans_dict, \n",
    "        group_cols                  = group_cols, \n",
    "        time_pd_grp_idx             = 'time_pd_grp', \n",
    "        time_pd_i_rename            = time_pd_i_rename, \n",
    "        regex_patterns_to_remove    = regex_patterns_to_remove, \n",
    "        combine_cpo_df_reasons      = combine_cpo_df_reasons, \n",
    "        include_power_down_minus_up = include_power_down_minus_up, \n",
    "        total_counts_col            = total_counts_col, \n",
    "        nSNs_col                    = nSNs_col\n",
    "    )\n",
    "    #-------------------------\n",
    "    # Overkill here (since all time windows are of length freq), but something similar will \n",
    "    #   be needed if I want to move to non-uniform period lengths\n",
    "    # One could, e.g., simply divide by length of freq in days\n",
    "    if normalize_by_time:\n",
    "        #-------------------------\n",
    "        nSNs_b4 = rcpx_0_pd_i[(time_pd_i_rename, nSNs_col)].copy()\n",
    "        #-----\n",
    "        rcpx_0_pd_i = MECPODf.normalize_rcpo_df_by_time_interval(\n",
    "            rcpo_df                 = rcpx_0_pd_i, \n",
    "            days_min_outg_td_window = 0, \n",
    "            days_max_outg_td_window = width_i, \n",
    "            cols_to_adjust          = None, \n",
    "            SNs_tags                = None, \n",
    "            inplace                 = True\n",
    "        )\n",
    "        #-----\n",
    "        assert(rcpx_0_pd_i[(time_pd_i_rename, nSNs_col)].equals(nSNs_b4))\n",
    "    #-------------------------\n",
    "    if normalize_by_SNs:\n",
    "        cols_to_norm = [x for x in rcpx_0_pd_i.columns if x[1]!=nSNs_col]\n",
    "        rcpx_0_pd_i[cols_to_norm] = rcpx_0_pd_i[cols_to_norm].divide(rcpx_0_pd_i[(time_pd_i_rename, nSNs_col)], axis=0)\n",
    "    #-------------------------\n",
    "    pd_dfs.append(rcpx_0_pd_i)\n",
    "\n",
    "# Make sure all dfs in pd_dfs look correct\n",
    "shape_0 = pd_dfs[0].shape\n",
    "index_0 = pd_dfs[0].index\n",
    "for i in range(len(pd_dfs)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    assert(pd_dfs[i].shape==shape_0)\n",
    "    assert(len(set(index_0).symmetric_difference(set(pd_dfs[i].index)))==0)\n",
    "    #-----\n",
    "    # Aligning the indices is not strictly necessary, as pd.concat should handle that\n",
    "    # But, it's best to be safe\n",
    "    pd_dfs[i] = pd_dfs[i].loc[index_0]\n",
    "\n",
    "# Build rcpx_final by combining all dfs in pd_dfs\n",
    "# rcpx_final = pd.concat(pd_dfs, axis=1)\n",
    "rcpx_final = MECPOCollection.merge_cpo_dfs(\n",
    "    dfs_coll                      = pd_dfs, \n",
    "    max_total_counts              = None, \n",
    "    how_max_total_counts          = 'any', \n",
    "    SNs_tags                      = MECPODf.std_SNs_cols() + MECPODf.std_nSNs_cols(), \n",
    "    cols_to_init_with_empty_lists = MECPODf.std_SNs_cols(), \n",
    "    make_cols_equal               = False # b/c if data_structure_df provided, pd_dfs built accordingly\n",
    ")\n",
    "\n",
    "#-------------------------\n",
    "# For the number of SNs per group, use the average number of \n",
    "#   SNs for each group across all time periods\n",
    "nSNs_cols = [x for x in rcpx_final.columns if x[1]==nSNs_col]\n",
    "#-----\n",
    "# # There should be one nSNs col for each time period\n",
    "# assert(len(nSNs_cols)==len(final_time_pds))\n",
    "#-----\n",
    "rcpx_final[(nSNs_col, nSNs_col)] = rcpx_final[nSNs_cols].mean(axis=1)\n",
    "#-----\n",
    "# Sanity check on the merge\n",
    "assert(rcpx_final[nSNs_col].notna().all().all())\n",
    "#-----\n",
    "# Drop the time-period-specific nSNs columns\n",
    "rcpx_final = rcpx_final.drop(columns=nSNs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f4bd4-4d0d-40a1-a74d-19e46008ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910167cf-a96f-45cf-bc20-cee1d2f00b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final.loc[('Wroux10000', '1686036438804')]['01-06 Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6517b-70d4-4d0d-b126-51d8e620789d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becd8b1-7954-43e4-be2d-df67bd1ad68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062f099-70c4-48be-b6ff-2dc3ba125aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc42ff-d1d1-4218-b420-bbad8724cbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55199f89-aaea-46f2-a5f2-366979d4cc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df6685-0a9b-4006-9574-d35b1e73f351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ed38f-827e-466f-9932-3b4046976c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a313a99-012d-4237-a471-c685cbf16c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953eb74-7951-451b-bba1-7462f784c373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f1186-defa-4b99-b4de-c987d4557ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpo_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8f25d-f921-424e-acea-fdb145e13d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = rcpo_df_raw.copy()\n",
    "# df_1 = rcpo_df_norm_by_xfmr_nSNs.copy()\n",
    "df_2 = rcpx_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe92e6b-0632-409f-9082-e8bfee17fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.reset_index().set_index(['no_outg_rec_nb', 'trsf_pole_nb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393708a-942e-476b-85d1-9c43e6350c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9b360-ca76-43b7-8931-af66faeb0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e63807-72bc-493d-9043-13b9faf94c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df_1.index.get_level_values(0)).symmetric_difference(set(df_2.index.get_level_values(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da0016-04ea-47ce-b91b-47c8f0547a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2b = df_2['01-06 Days'].copy()\n",
    "df_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d93eaf-8b80-405c-842c-f11383510685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2b[df_2b['total_counts']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b860d6-2143-4e72-9a71-b780e4b55ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f188b21-243d-4604-864b-4fcf4991743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1  = df_1.reset_index().sort_values(by=['no_outg_rec_nb', 'trsf_pole_nb'], ignore_index=True, key=natsort_keygen()).set_index(['no_outg_rec_nb', 'trsf_pole_nb'])\n",
    "df_2b = df_2b.reset_index().sort_values(by=['no_outg_rec_nb', 'trsf_pole_nb'], ignore_index=True, key=natsort_keygen()).set_index(['no_outg_rec_nb', 'trsf_pole_nb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1b082-3a62-47f4-9ee1-56199861e4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d06b2-6b89-4e3d-9dd8-b01566df3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dac418-ea1b-4426-9bfa-d7b97b662ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bd228-c68a-4154-85d7-160da0d678e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.iloc[:, :-8].sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4862a0-fcf1-45c4-b184-0e0d648e65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2b.iloc[:,:-1].sum(axis=1)[:10]\n",
    "df_2b['total_counts'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff13b2-8d89-4d33-9be4-b884337ee268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60caee-ab53-45d6-aaeb-c94b7b8ad243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315b7e0-acd6-4dad-978d-f9bedf9f91ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ba687-296e-4fb4-a8c5-6d00a61e3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcpx_final.loc[[('Wroux10000','1686036438804')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fe57f-7adf-4108-b76f-da1df949d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovrlps = list(set(df_2b.index).intersection(df_1.index))\n",
    "df_1_ovrlp  = df_1.loc[ovrlps]\n",
    "df_2b_ovrlp = df_2b.loc[ovrlps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62753fe-7b7c-4126-b8f4-37be4c393c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_ovrlp.iloc[:, :-8].sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec41d3-0a17-4597-bd96-e3310cd161f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2b_ovrlp.iloc[:,:-1].sum(axis=1)[:10]\n",
    "df_2b_ovrlp['total_counts'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0264619-cbbc-4691-98d2-24f76180f7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686973d-01dc-453b-b3f1-a6257c8204de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d246e-c836-434f-a17b-2b4388ee6847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4727c-eaeb-477d-a58b-7a9ef8c249a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d7b23-424d-4b89-820b-88c005095d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
